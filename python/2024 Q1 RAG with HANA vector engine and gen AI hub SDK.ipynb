{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install hana_ml\n",
    "# !pip install generative-ai-hub-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will run a basic Q&A using Retrieval Augmented Generation.<br>\n",
    "The context is retrieved via a vector search in HANA Cloud.<br>\n",
    "First, we import some data from a csv file (which contains vector embeddings generated by text-embedding-ada-002).<br>\n",
    "Then we define a run_vector_search function which is is used in the ask_llm function to provide context which is infused into the prompt.<br>\n",
    "\n",
    "You need to set up SAP AI Core and generate \"deployments\" for the services you want to use. See https://github.wdf.sap.corp/AI/generative-ai-hub-sdk/tree/main/docs/proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some vector data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some vector data from csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/GRAPH_DOCU_QRC3.csv', low_memory=False)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to HANA\n",
    "from hana_ml.dataframe import ConnectionContext\n",
    "# cc = ConnectionContext(userkey='GR3', encrypt=True)\n",
    "cc= ConnectionContext(\n",
    "    address='[somehost].hanacloud.ondemand.com', \n",
    "    port='443', \n",
    "    user='[your user]', \n",
    "    password='[your password]', \n",
    "    encrypt=True\n",
    "    )\n",
    "print(cc.hana_version())\n",
    "print(cc.get_current_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop table if already exists\n",
    "# cursor = cc.connection.cursor()\n",
    "# sql_command = '''DROP TABLE GRAPH_DOCU_QRC3;'''\n",
    "# cursor.execute(sql_command)\n",
    "# cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table\n",
    "cursor = cc.connection.cursor()\n",
    "sql_command = '''CREATE TABLE GRAPH_DOCU_QRC3(ID BIGINT, L1 NVARCHAR(3), L2 NVARCHAR(3), L3 NVARCHAR(3), FILENAME NVARCHAR(100), HEADER1 NVARCHAR(5000), HEADER2 NVARCHAR(5000), TEXT NCLOB, VECTOR_STR NCLOB);'''\n",
    "cursor.execute(sql_command)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data\n",
    "from hana_ml.dataframe import create_dataframe_from_pandas\n",
    "v_hdf = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df,\n",
    "    table_name=\"GRAPH_DOCU_QRC3\", \n",
    "    allow_bigint=True,\n",
    "    append=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add REAL_VECTOR column\n",
    "cursor = cc.connection.cursor()\n",
    "sql_command = '''ALTER TABLE GRAPH_DOCU_QRC3 ADD (VECTOR REAL_VECTOR(1536));'''\n",
    "cursor.execute(sql_command)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectors from strings\n",
    "cursor = cc.connection.cursor()\n",
    "sql_command = '''UPDATE GRAPH_DOCU_QRC3 SET VECTOR = TO_REAL_VECTOR(VECTOR_STR);'''\n",
    "cursor.execute(sql_command)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG using gen ai hub sdk and HANA Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings\n",
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "\n",
    "def get_embedding(input, model_name=\"text-embedding-ada-002\") -> str:\n",
    "    response = embeddings.create(\n",
    "        input=input,\n",
    "        model_name=model_name, \n",
    "        )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping HANA vector search in a function\n",
    "def run_vector_search(query: str, metric=\"COSINE_SIMILARITY\", k=4):\n",
    "    if metric == 'L2DISTANCE':\n",
    "        sort = 'ASC'\n",
    "    else:\n",
    "        sort = 'DESC'\n",
    "    query_vector = get_embedding(query)\n",
    "    sql = '''SELECT TOP {k} \"ID\", \"HEADER1\", \"HEADER2\", \"TEXT\"\n",
    "        FROM \"GRAPH_DOCU_QRC3\"\n",
    "        ORDER BY \"{metric}\"(\"VECTOR\", TO_REAL_VECTOR('{qv}')) {sort}'''.format(k=k, metric=metric, qv=query_vector, sort=sort)\n",
    "    hdf = cc.sql(sql)\n",
    "    df_context = hdf.head(k).collect()\n",
    "    # context = ' '.join(df_context['TEXT'].astype('string'))\n",
    "    return df_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the vector search\n",
    "query = \"How can I run a shortest path algorithm?\"\n",
    "df_context = run_vector_search(query=query, metric=\"COSINE_SIMILARITY\",k=4)\n",
    "df_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.native.openai import chat\n",
    "\n",
    "# basic LLM prompt for RAG\n",
    "sys_content = '''Your task is to answer the question using the provided context wrapped in triple quotes. \n",
    "If the provided context does not contain the information needed to answer this question then come up with your own answer. '''\n",
    "\n",
    "def ask_llm(query: str, retrieval_augmented_generation: bool, metric='COSINE_SIMILARITY', k = 4) -> str:\n",
    "    context = ''\n",
    "    if retrieval_augmented_generation == True:\n",
    "        df_context = run_vector_search(query, metric, k)\n",
    "        context = ' '.join(df_context['TEXT'].astype('string'))\n",
    "    user_content = '\"\"\"' + context + '\"\"\"'+ ' Question: ' + query\n",
    "    messages=[{\"role\": \"system\", \"content\": sys_content}, {\"role\": \"user\", \"content\": user_content}]\n",
    "    \n",
    "    # kwargs = dict(model_name='gpt-4', messages=messages)\n",
    "    kwargs = dict(model_name='gpt-35-turbo', messages=messages)\n",
    "    \n",
    "    response = chat.completions.create(**kwargs)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Can you define a HANA graph workspace on a JSON document store collection?\"\n",
    "#query = \"How can I define a HANA graph workspace on a JSON document store collection?\"\n",
    "#query = \"How do you run a shortest path algorithm in SAP HANA Graph engine?\"\n",
    "# query = \"How can I run community detection Louvain in SAP HANA Graph?\"\n",
    "# query = \"How can I run a BFS traversal in HANA Cloud\"\n",
    "query = \"I want to calculate a shortest path. How do I do that?\"\n",
    "\n",
    "response = ask_llm(query=query, retrieval_augmented_generation=True, k=4)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
