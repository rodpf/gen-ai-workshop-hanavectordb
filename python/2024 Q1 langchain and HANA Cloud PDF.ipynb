{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using langchain's vectore store plugin for HANA Vector Engine\n",
    "to store embeddings generated by AI Core.\n",
    "\n",
    "Prerequisites:\n",
    "- langchain >= 0.1.4\n",
    "- generative-ai-hub-sdk 1.2.0\n",
    "- openAI ada deployment on AI Core\n",
    "\n",
    "See:<br>\n",
    "https://pypi.org/project/generative-ai-hub-sdk/<br>\n",
    "https://github.wdf.sap.corp/AI/generative-ai-hub-sdk/blob/main/docs/gen_ai_hub/examples/gen_ai_hub.ipynb<br>\n",
    "https://python.langchain.com/docs/integrations/vectorstores/sap_hanavector<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain version: 0.1.6\n",
      "langchain_community version: 0.0.19\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "import langchain_community\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, PyPDFDirectoryLoader, SitemapLoader\n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "\n",
    "from gen_ai_hub.proxy.langchain.openai import OpenAIEmbeddings\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print('langchain version:', langchain.__version__)\n",
    "print('langchain_community version:', langchain_community.__version__)\n",
    "# How to get the gen Ai Hub SDK version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document chunks: 2818\n"
     ]
    }
   ],
   "source": [
    "# using langchain to read and split the doc\n",
    "\n",
    "filePath = \"./data/PDFs\"\n",
    "# text_documents = TextLoader(\"data/state_of_the_union.txt\").load()\n",
    "loader = PyPDFDirectoryLoader(filePath)   \n",
    "documents = loader.load()\n",
    "#Load document \n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap = 10,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "text_chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Number of document chunks: {len(text_chunks)}\")\n",
    "\n",
    "# using ai core to embed\n",
    "embeddings = OpenAIEmbeddings(proxy_model_name='text-embedding-ada-002')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00.000.00.1710236938 (fa/CE2024.2)\n",
      "YAMAHA_USER\n"
     ]
    }
   ],
   "source": [
    "# Creating a connection using hana-ml\n",
    "from hana_ml import ConnectionContext\n",
    "# cc = ConnectionContext(userkey='VDB_BETA', encrypt=True)\n",
    "cc= ConnectionContext(\n",
    "    address='[somehost].hanacloud.ondemand.com', \n",
    "    port='443', \n",
    "    user='[your user]', \n",
    "    password='[your password]',\n",
    "    encrypt=True\n",
    "    )\n",
    "connection = cc.connection\n",
    "\n",
    "print(cc.hana_version())\n",
    "print(cc.get_current_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a table if not exists\n",
    "table = \"PDF_SAMPLE_\"\n",
    "db = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=table\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete already existing documents from the table\n",
    "# db.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks\n",
    "db.add_documents(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2818"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the table\n",
    "hdf = cc.sql(''' SELECT \"VEC_TEXT\", \"VEC_META\", TO_NVARCHAR(\"VEC_VECTOR\") AS \"VEC_VECTOR\" FROM \"{table}\" '''.format(table=table))\n",
    "df = hdf.head(5).collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"How to use Actions in SAP Build Process Automation?\"\n",
    "#query = \"What is the process of configuring API triggers?\"\n",
    "#query = \"When to use an automation and when to use a process in SBPA?\"\n",
    "#query = \"What is the usage of visibility scenarios?\"\n",
    "#query = \"Is it possible to use SAP Build Workzone with processes?How?\"\n",
    "#query = \"How to use SAPUI5 forms?\"\n",
    "#query = \"What are the different roles available to access SAP Build process automation?\"\n",
    "#query = \"What are the versions of Desktop Agent?\"\n",
    "#query = \"What kind of interactions does the screen record capture?\"\n",
    "#query = \"What is the Expression Editor?\"\n",
    "#query = \"How to use SAP HANA Vector DB?\"\n",
    "\n",
    "docs = db.similarity_search(query, k=20)\n",
    "\n",
    "context = \"\"\n",
    "for doc in docs:\n",
    "    #print(\"-\" * 80)\n",
    "    ##print(doc.page_content)\n",
    "    context = context + doc.page_content + \" \"\n",
    "#print (context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptTemplate_fstring = \"\"\"\n",
    "You are an Analyzing Given context.\n",
    "You are provided multiple context items that are related to the prompt you have to answer.\n",
    "Use the following pieces of context to answer the question at the end. If the query is not part of the given context, reply 'not under my scope'\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "promptTemplate = PromptTemplate.from_template(promptTemplate_fstring)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not under my scope\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.langchain import ChatOpenAI\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-35-turbo', temperature=0)\n",
    "prompt = promptTemplate.format(query=query, context=context)\n",
    "response = llm.predict(prompt)\n",
    "\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
