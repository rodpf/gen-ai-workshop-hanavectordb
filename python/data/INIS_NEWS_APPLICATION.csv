Key;Date;No;TopicNo;TopicID;TopicName;Domain;arXivID;Base;Link;SenderHTML;SenderName;Title;Abstract
2023.11.01.13.20.01;01.11.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.18752;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.18752.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sui_G/0/1/0/all/0/1"">Guanghu Sui</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Zhishuai Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Ziyue Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1"">Sun Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ruan_J/0/1/0/all/0/1"">Jingqing Ruan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1"">Hangyu Mao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1"">Rui Zhao</a>";Guanghu Sui,Zhishuai Li,Ziyue Li,Sun Yang,Jingqing Ruan,Hangyu Mao,Rui Zhao;Reboost Large Language Model-based Text-to-SQL, Text-to-Python, and Text-to-Function -- with Real Applications in Traffic Domain.;The previous state-of-the-art (SOTA) method achieved a remarkable execution accuracy on the Spider dataset, which is one of the largest and most diverse datasets in the Text-to-SQL domain. However, during our reproduction of the business dataset, we observed a significant drop in performance. We examined the differences in dataset complexity, as well as the clarity of questions' intentions, and assessed how those differences could impact the performance of prompting methods. Subsequently, We develop a more adaptable and more general prompting method, involving mainly query rewriting and SQL boosting, which respectively transform vague information into exact and precise information and enhance the SQL itself by incorporating execution feedback and the query results from the database content. In order to prevent information gaps, we include the comments, value types, and value samples for columns as part of the database description in the prompt. Our experiments with Large Language Models (LLMs) illustrate the significant performance improvement on the business dataset and prove the substantial potential of our method. In terms of execution accuracy on the business dataset, the SOTA method scored 21.05, while our approach scored 65.79. As a result, our approach achieved a notable performance improvement even when using a less capable pre-trained language model. Last but not least, we also explore the Text-to-Python and Text-to-Function options, and we deeply analyze the pros and cons among them, offering valuable insights to the community.
2023.11.01.13.20.02;01.11.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.20034;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.20034.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Graule_M/0/1/0/all/0/1"">Moritz A. Graule</a>, <a href=""http://arxiv.org/find/cs/1/au:+Isler_V/0/1/0/all/0/1"">Volkan Isler</a>";Moritz A. Graule,Volkan Isler;GG-LLM: Geometrically Grounding Large Language Models for Zero-shot Human Activity Forecasting in Human-Aware Task Planning.;A robot in a human-centric environment needs to account for the human's intent and future motion in its task and motion planning to ensure safe and effective operation. This requires symbolic reasoning about probable future actions and the ability to tie these actions to specific locations in the physical environment. While one can train behavioral models capable of predicting human motion from past activities, this approach requires large amounts of data to achieve acceptable long-horizon predictions. More importantly, the resulting models are constrained to specific data formats and modalities. Moreover, connecting predictions from such models to the environment at hand to ensure the applicability of these predictions is an unsolved problem. We present a system that utilizes a Large Language Model (LLM) to infer a human's next actions from a range of modalities without fine-tuning. A novel aspect of our system that is critical to robotics applications is that it links the predicted actions to specific locations in a semantic map of the environment. Our method leverages the fact that LLMs, trained on a vast corpus of text describing typical human behaviors, encode substantial world knowledge, including probable sequences of human actions and activities. We demonstrate how these localized activity predictions can be incorporated in a human-aware task planner for an assistive robot to reduce the occurrences of undesirable human-robot interactions by 29.2% on average.
2023.11.01.13.20.03;01.11.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.20329;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.20329.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1"">Qisheng Hu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1"">Kaixin Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1"">Xu Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1"">Yuxi Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1"">Tiedong Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"">Hui Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1"">Qizhe Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1"">Junxian He</a>";Qisheng Hu,Kaixin Li,Xu Zhao,Yuxi Xie,Tiedong Liu,Hui Chen,Qizhe Xie,Junxian He;InstructCoder: Empowering Language Models for Code Editing.;Code editing encompasses a variety of pragmatic tasks that developers deal with daily. Despite its relevance and practical usefulness, automatic code editing remains an underexplored area in the evolution of deep learning models, partly due to data scarcity. In this work, we explore the use of large language models (LLMs) to edit code based on user instructions, covering a broad range of implicit tasks such as comment insertion, code optimization, and code refactoring. To facilitate this, we introduce InstructCoder, the first dataset designed to adapt LLMs for general-purpose code editing, containing highdiversity code-editing tasks. It consists of over 114,000 instruction-input-output triplets and covers multiple distinct code editing scenarios. The dataset is systematically expanded through an iterative process that commences with code editing data sourced from GitHub commits as seed tasks. Seed and generated tasks are used subsequently to prompt ChatGPT for more task data. Our experiments demonstrate that open-source LLMs fine-tuned on InstructCoder can edit code correctly based on users' instructions most of the time, exhibiting unprecedented code-editing performance levels. Such results suggest that proficient instruction-finetuning can lead to significant amelioration in code editing abilities. The dataset and the source code are available at https://github.com/qishenghu/CodeInstruct.
2023.11.01.13.20.04;01.11.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.19998;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.19998.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Buehler_M/0/1/0/all/0/1"">Markus J. Buehler</a>";Markus J. Buehler;Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design.;Transformer neural networks show promising capabilities, in particular for uses in materials analysis, design and manufacturing, including their capacity to work effectively with both human language, symbols, code, and numerical data. Here we explore the use of large language models (LLMs) as a tool that can support engineering analysis of materials, applied to retrieving key information about subject areas, developing research hypotheses, discovery of mechanistic relationships across disparate areas of knowledge, and writing and executing simulation codes for active knowledge generation based on physical ground truths. When used as sets of AI agents with specific features, capabilities, and instructions, LLMs can provide powerful problem solution strategies for applications in analysis and design problems. Our experiments focus on using a fine-tuned model, MechGPT, developed based on training data in the mechanics of materials domain. We first affirm how finetuning endows LLMs with reasonable understanding of domain knowledge. However, when queried outside the context of learned matter, LLMs can have difficulty to recall correct information. We show how this can be addressed using retrieval-augmented Ontological Knowledge Graph strategies that discern how the model understands what concepts are important and how they are related. Illustrated for a use case of relating distinct areas of knowledge - here, music and proteins - such strategies can also provide an interpretable graph structure with rich information at the node, edge and subgraph level. We discuss nonlinear sampling strategies and agent-based modeling applied to complex question answering, code generation and execution in the context of automated force field development from actively learned Density Functional Theory (DFT) modeling, and data analysis.
2023.11.01.13.20.05;01.11.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/the-takeover-the-ai-copilot-terminates-the-c-suite-24a0a80b8971?source=rss----98111c9905da---4;;;The Takeover: The AI Copilot Terminates The C-Suite;The critical point I am making in this article is that AI, in one form or another, is disrupting the regular workflow of the C-Suite and other sub-levels of any company. Without wanting to mince my words, I am representing that AI is on its way to making the C-Suite as we know it today almost unrecognizable. To be sure, what I am saying about the C-Suite applies to wide-ranging fields, including, but not limited to, communication, administration, medicine and health, academia, customer service, stock exchange, real estate, marketing, resource management, teaching and training, and whatnot. ...
2023.11.01.13.20.06;01.11.2023;06;05;Industry;Industry 4.0, Production, Circular Economy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202311.0041/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Intelligent Feedrate Optimization using an Uncertainty-aware Digital Twin within a Model Predictive Control Framework;The future of intelligent manufacturing machines involves autonomous selection of process parameters to maximize productivity while maintaining quality within specified constraints. To effectively optimize process parameters, these machines need to adapt to existing uncertainties in the physical system. This paper proposes a novel framework and methodology for feedrate optimization that is based on a physics-informed data-driven digital twin with quantified uncertainty. The servo dynamics are modeled using a digital twin, which incorporates the known uncertainty in the physics-based models and predicts the distribution of contour error using a data-driven model that learns the unknown uncertainty on-the-fly by sensor measurements. Using the quantified uncertainty, the proposed feedrate optimization maximizes productivity while maintaining quality under desired servo error constraints and stringency (i.e., the tolerance for constraint violation under uncertainty) using a model predictive control framework. Experimental results obtained using a 3-axis desktop CNC machine tool and a desktop 3D printer demonstrate significant cycle time reductions of up to 38% and 17 respectively, while staying close to the error tolerances compared to the existing methods.
2023.11.01.13.20.07;01.11.2023;07;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;arxiv;2310.20274;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.20274.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Arora_J/0/1/0/all/0/1"">Jatin Arora</a>, <a href=""http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1"">Sumit Agrawal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1"">Pawan Goyal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pathak_S/0/1/0/all/0/1"">Sayan Pathak</a>";Jatin Arora,Sumit Agrawal,Pawan Goyal,Sayan Pathak;Extracting Entities of Interest from Comparative Product Reviews.;This paper presents a deep learning based approach to extract product comparison information out of user reviews on various e-commerce websites. Any comparative product review has three major entities of information: the names of the products being compared, the user opinion (predicate) and the feature or aspect under comparison. All these informing entities are dependent on each other and bound by the rules of the language, in the review. We observe that their inter-dependencies can be captured well using LSTMs. We evaluate our system on existing manually labeled datasets and observe out-performance over the existing Semantic Role Labeling (SRL) framework popular for this task.
2023.11.01.13.20.08;01.11.2023;08;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;arxiv;2310.20343;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.20343.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yi_Z/0/1/0/all/0/1"">Zixuan Yi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Long_Z/0/1/0/all/0/1"">Zijun Long</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1"">Iadh Ounis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1"">Craig Macdonald</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mccreadie_R/0/1/0/all/0/1"">Richard Mccreadie</a>";Zixuan Yi,Zijun Long,Iadh Ounis,Craig Macdonald,Richard Mccreadie;Large Multi-modal Encoders for Recommendation.;In recent years, the rapid growth of online multimedia services, such as e-commerce platforms, has necessitated the development of personalised recommendation approaches that can encode diverse content about each item. Indeed, modern multi-modal recommender systems exploit diverse features obtained from raw images and item descriptions to enhance the recommendation performance. However, the existing multi-modal recommenders primarily depend on the features extracted individually from different media through pre-trained modality-specific encoders, and exhibit only shallow alignments between different modalities - limiting these systems' ability to capture the underlying relationships between the modalities. In this paper, we investigate the usage of large multi-modal encoders within the specific context of recommender systems, as these have previously demonstrated state-of-the-art effectiveness when ranking items across various domains. Specifically, we tailor two state-of-the-art multi-modal encoders (CLIP and VLMo) for recommendation tasks using a range of strategies, including the exploration of pre-trained and fine-tuned encoders, as well as the assessment of the end-to-end training of these encoders. We demonstrate that pre-trained large multi-modal encoders can generate more aligned and effective user/item representations compared to existing modality-specific encoders across three multi-modal recommendation datasets. Furthermore, we show that fine-tuning these large multi-modal encoders with recommendation datasets leads to an enhanced recommendation performance. In terms of different training paradigms, our experiments highlight the essential role of the end-to-end training of large multi-modal encoders in multi-modal recommendation systems.
2023.11.01.13.20.09;01.11.2023;09;12;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202311.0080/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Low-Carbon Economic Dispatch of Virtual Power Plant considering Hydrogen Energy Storage and Tiered Carbon Trading in Multiple Scenarios;"Under the ""dual carbon"" target in China, virtual power plants (VPPs) play an important role in improving grid security and promoting clean and low-carbon energy transformation. VPPs can integrate and control distributed resources to participate in the energy market and make full use of distributed resources. However, the intermittency and volatility of renewable energy and the ""heat-driven"" working mode of CHP units create contradictions that seriously affect the peak-shaving ability of VPPs and lead to high carbon emissions. To solve these problems, this paper aggregates CHP units, wind power, photovoltaics, carbon capture, hydrogen energy storage, and electric boilers into a new type of virtual power plant. The ""hydrogen energy storage-electric boiler"" joint decoupling CHP working mode is used to strengthen the coupling relationship between electric-thermal-hydrogen load. At the same time, a tiered carbon trading mechanism is considered, with the net profit of the VPP as the optimization objective, balancing economic and environmental considerations. A low-carbon economic dispatch model for VPPs is established, and a genetic algorithm is used for optimization. Three different scheduling strategies are set, and simulations are conducted in three different seasonal scenarios. The results show that the net profit in the cooling season increased by 50.4%, and carbon emissions decreased by 42.3%. In the transitional season, the net profit increased by 39.2%, and carbon emissions decreased by 44.9%. In the heating season, the net profit increased by 19.4%, and carbon emissions decreased by 43.4%. Overall, the proposed dispatch strategy can improve the new energy consumption capacity and total revenue of VPPs while achieving the goal of reducing carbon emissions."
2023.11.01.13.20.10;01.11.2023;10;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.20367;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.20367.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Michalakopoulos_V/0/1/0/all/0/1"">Vasilis Michalakopoulos</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sarmas_E/0/1/0/all/0/1"">Elissaios Sarmas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Papias_I/0/1/0/all/0/1"">Ioannis Papias</a>, <a href=""http://arxiv.org/find/cs/1/au:+Skaloumpakas_P/0/1/0/all/0/1"">Panagiotis Skaloumpakas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Marinakis_V/0/1/0/all/0/1"">Vangelis Marinakis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Doukas_H/0/1/0/all/0/1"">Haris Doukas</a>";Vasilis Michalakopoulos,Elissaios Sarmas,Ioannis Papias,Panagiotis Skaloumpakas,Vangelis Marinakis,Haris Doukas;A Machine Learning-Based Framework for Clustering Residential Electricity Load Profiles to Enhance Demand Response Programs.;Load shapes derived from smart meter data are frequently employed to analyze daily energy consumption patterns, particularly in the context of applications like Demand Response (DR). Nevertheless, one of the most important challenges to this endeavor lies in identifying the most suitable consumer clusters with similar consumption behaviors. In this paper, we present a novel machine learning based framework in order to achieve optimal load profiling through a real case study, utilizing data from almost 5000 households in London. Four widely used clustering algorithms are applied specifically K-means, K-medoids, Hierarchical Agglomerative Clustering and Density-based Spatial Clustering. An empirical analysis as well as multiple evaluation metrics are leveraged to assess those algorithms. Following that, we redefine the problem as a probabilistic classification one, with the classifier emulating the behavior of a clustering algorithm,leveraging Explainable AI (xAI) to enhance the interpretability of our solution. According to the clustering algorithm analysis the optimal number of clusters for this case is seven. Despite that, our methodology shows that two of the clusters, almost 10\% of the dataset, exhibit significant internal dissimilarity and thus it splits them even further to create nine clusters in total. The scalability and versatility of our solution makes it an ideal choice for power utility companies aiming to segment their users for creating more targeted Demand Response programs.
2023.11.01.13.20.11;01.11.2023;11;13;Mobility;Mobility, Automotive, Self Driving et al.;arxiv;2310.20148;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.20148.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"">Xiao Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1"">Kaiwen Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tseng_H/0/1/0/all/0/1"">H. Eric Tseng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Girard_A/0/1/0/all/0/1"">Anouck Girard</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kolmanovsky_I/0/1/0/all/0/1"">Ilya Kolmanovsky</a>";Xiao Li,Kaiwen Liu,H. Eric Tseng,Anouck Girard,Ilya Kolmanovsky;Decision-Making for Autonomous Vehicles with Interaction-Aware Behavioral Prediction and Social-Attention Neural Network.;Autonomous vehicles need to accomplish their tasks while interacting with human drivers in traffic. It is thus crucial to equip autonomous vehicles with artificial reasoning to better comprehend the intentions of the surrounding traffic, thereby facilitating the accomplishments of the tasks. In this work, we propose a behavioral model that encodes drivers' interacting intentions into latent social-psychological parameters. Leveraging a Bayesian filter, we develop a receding-horizon optimization-based controller for autonomous vehicle decision-making which accounts for the uncertainties in the interacting drivers' intentions. For online deployment, we design a neural network architecture based on the attention mechanism which imitates the behavioral model with online estimated parameter priors. We also propose a decision tree search algorithm to solve the decision-making problem online. The proposed behavioral model is then evaluated in terms of its capabilities for real-world trajectory prediction. We further conduct extensive evaluations of the proposed decision-making module, in forced highway merging scenarios, using both simulated environments and real-world traffic datasets. The results demonstrate that our algorithms can complete the forced merging tasks in various traffic conditions while ensuring driving safety.
2023.11.01.13.20.12;01.11.2023;12;14;Public Services;Public Services, Traffic et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202311.0002/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Evaluation of Future Integrated Urban Water Management Using a Risk and Decision Analysis Framework: A Case Study in Denver-Colorado Metro Area (DCMA);This study examines the DCMA concerning the future risk of the water security status. We considered three risk factors: population growth, economic growth, and natural water supply demand differences. In the risk analysis part, we consulted with experts from several sectors including academia, Non-Governmental Organization (NGOs), and industry, to predict that the probability of future water stresses in high, medium, and low scenarios are 0.73, 0.24, and 0.03, respectively. In the decision analysis part, we adopted two Multiple Criteria Decision Analysis (MCDA) approaches that include Multiple Attribute Value Theory (MAVT) and Analytic Hierarchy Process (AHP) methods to evaluate the best alternative decision to alleviate future water stresses in the DCMA. The sensitivity analysis demonstrates the best option closely connects to the weighting scheme of the criteria considered in the framework. This study provides a valuable risk and decision analysis framework to analyze the water security status associated with the future water supply and demand gap decrease caused by three risk factors: population growth, climate change, and natural water supply.
2023.11.01.13.20.13;01.11.2023;13;14;Public Services;Public Services, Traffic et al.;arxiv;2310.20223;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.20223.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1"">Maoxiang Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1"">Weilong Ding</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1"">Tianpu Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zijian Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xing_M/0/1/0/all/0/1"">Mengda Xing</a>";Maoxiang Sun,Weilong Ding,Tianpu Zhang,Zijian Liu,Mengda Xing;STDA-Meta: A Meta-Learning Framework for Few-Shot Traffic Prediction.;As the development of cities, traffic congestion becomes an increasingly pressing issue, and traffic prediction is a classic method to relieve that issue. Traffic prediction is one specific application of spatio-temporal prediction learning, like taxi scheduling, weather prediction, and ship trajectory prediction. Against these problems, classical spatio-temporal prediction learning methods including deep learning, require large amounts of training data. In reality, some newly developed cities with insufficient sensors would not hold that assumption, and the data scarcity makes predictive performance worse. In such situation, the learning method on insufficient data is known as few-shot learning (FSL), and the FSL of traffic prediction remains challenges. On the one hand, graph structures' irregularity and dynamic nature of graphs cannot hold the performance of spatio-temporal learning method. On the other hand, conventional domain adaptation methods cannot work well on insufficient training data, when transferring knowledge from different domains to the intended target domain.To address these challenges, we propose a novel spatio-temporal domain adaptation (STDA) method that learns transferable spatio-temporal meta-knowledge from data-sufficient cities in an adversarial manner. This learned meta-knowledge can improve the prediction performance of data-scarce cities. Specifically, we train the STDA model using a Model-Agnostic Meta-Learning (MAML) based episode learning process, which is a model-agnostic meta-learning framework that enables the model to solve new learning tasks using only a small number of training samples. We conduct numerous experiments on four traffic prediction datasets, and our results show that the prediction performance of our model has improved by 7\% compared to baseline models on the two metrics of MAE and RMSE.
2023.10.31.15.57.01;31.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2305.14257;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.14257.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1"">Abishek Sridhar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lo_R/0/1/0/all/0/1"">Robert Lo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1"">Frank F. Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1"">Hao Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1"">Shuyan Zhou</a>";Abishek Sridhar,Robert Lo,Frank F. Xu,Hao Zhu,Shuyan Zhou;Hierarchical Prompting Assists Large Language Model on Web Navigation.;Large language models (LLMs) struggle on processing complicated observations in interactive decision making tasks. To alleviate this issue, we propose a simple hierarchical prompting approach. Diverging from previous prompting approaches that always put the full observation (e.g. a web page) to the prompt, we propose to first construct an action-aware observation which is more condensed and relevant with a dedicated SUMMARIZER prompt. The ACTOR prompt then predicts the next action based on the summarized observation. While our method has broad applicability, we particularly demonstrate its efficacy in the complex domain of web navigation where a full observation often contains redundant and irrelevant information. Our approach outperforms the previous state-of-the-art prompting mechanics by 6.2% on task success rate, demonstrating its potential on interactive decision making tasks with long observation traces.
2023.10.31.15.57.02;31.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2305.15393;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.15393.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1"">Weixi Feng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1"">Wanrong Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1"">Tsu-jui Fu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1"">Varun Jampani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Akula_A/0/1/0/all/0/1"">Arjun Akula</a>, <a href=""http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1"">Xuehai He</a>, <a href=""http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1"">Sugato Basu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"">Xin Eric Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1"">William Yang Wang</a>";Weixi Feng,Wanrong Zhu,Tsu-jui Fu,Varun Jampani,Arjun Akula,Xuehai He,Sugato Basu,Xin Eric Wang,William Yang Wang;LayoutGPT: Compositional Visual Planning and Generation with Large Language Models.;Attaining a high degree of user controllability in visual generation often requires intricate, fine-grained inputs like layouts. However, such inputs impose a substantial burden on users when compared to simple text inputs. To address the issue, we study how Large Language Models (LLMs) can serve as visual planners by generating layouts from text conditions, and thus collaborate with visual generative models. We propose LayoutGPT, a method to compose in-context visual demonstrations in style sheet language to enhance the visual planning skills of LLMs. LayoutGPT can generate plausible layouts in multiple domains, ranging from 2D images to 3D indoor scenes. LayoutGPT also shows superior performance in converting challenging language concepts like numerical and spatial relations to layout arrangements for faithful text-to-image generation. When combined with a downstream image generation model, LayoutGPT outperforms text-to-image models/systems by 20-40% and achieves comparable performance as human users in designing visual layouts for numerical and spatial correctness. Lastly, LayoutGPT achieves comparable performance to supervised methods in 3D indoor scene synthesis, demonstrating its effectiveness and potential in multiple visual domains.
2023.10.31.15.57.03;31.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/a-complete-guide-for-creating-an-ai-assistant-for-summarizing-youtube-videos-part-2-a008ee18f341?source=rss----98111c9905da---4;;;A Complete Guide for Creating an AI Assistant for Summarizing YouTube Videos — Part 2;Summarize a video transcript using LangChain and the Falcon model efficiently using Quantization ...
2023.10.31.15.57.04;31.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/gameplay-reimagined-the-ai-revolution-fff8ec62991c?source=rss----98111c9905da---4;;;Gameplay Reimagined: The AI Revolution;A Deep Dive into the Fusion of Generative AI and Game Development ...
2023.10.31.15.57.05;31.10.2023;05;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.18658;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2310.18658.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Huang_W/0/1/0/all/0/1"">Weihuan Huang</a>";Weihuan Huang;Estimating Systemic Risk within Financial Networks: A Two-Step Nonparametric Method.;CoVaR (conditional value-at-risk) is a crucial measure for assessing financial systemic risk, which is defined as a conditional quantile of a random variable, conditioned on other random variables reaching specific quantiles. It enables the measurement of risk associated with a particular node in financial networks, taking into account the simultaneous influence of risks from multiple correlated nodes. However, estimating CoVaR presents challenges due to the unobservability of the multivariate-quantiles condition. To address the challenges, we propose a two-step nonparametric estimation approach based on Monte-Carlo simulation data. In the first step, we estimate the unobservable multivariate-quantiles using order statistics. In the second step, we employ a kernel method to estimate the conditional quantile conditional on the order statistics. We establish the consistency and asymptotic normality of the two-step estimator, along with a bandwidth selection method. The results demonstrate that, under a mild restriction on the bandwidth, the estimation error arising from the first step can be ignored. Consequently, the asymptotic results depend solely on the estimation error of the second step, as if the multivariate-quantiles in the condition were observable. Numerical experiments demonstrate the favorable performance of the two-step estimator.
2023.10.31.15.57.06;31.10.2023;06;03;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:net:wpaper:2301&r=pay;;Sihan FangHyeokkoo Eric KwonTian LuYingjie Zhang;Mobile Effects on Two-Sided Financial Decisions: Evidence from Field Experiments on Peer-to-Peer Lending Platforms;We have witnessed the convenience of mobile channels and how they boost user engagement in multiple industries. Such positive effects might or might not stay with usersâ€™ financial behavior since it requires a significant cognitive effort and risk preferences could also alter the effect direction. Moreover, regarding their effects on two-sided platforms, prior studies have focused on the decision-making of one single side. This might bias our understanding of mobile channels, especially in the finance sector, where lendersâ€™ behavior would be influenced by borrowersâ€™ application quality and quantity. To bridge these gaps, we investigate how mobile channels shape the behaviors of both borrowers and lenders in peer-to-peer (P2P) lending platforms, as well as the corresponding impacts on credit risk management and economic return. Drawing upon the cognitive load theory, we postulate that borrowers and lenders under heavy and mild cognitive load would exhibit distinct behaviors when submitting loan applications or approving loan requests, respectively. Empirically, we collaborate with a leading P2P lending platform to launch two-sided field experiments, in which we randomly assign mobile treatments to borrowers and lenders. The results illustrate that mobile borrowers are more likely to terminate loan submissions, especially during peak commuting hours. By contrast, mobile lenders have a higher tendency to approve loan applications within a shorter period. Surprisingly, we observe no change in the quality of submitted or approved loans. Considering the improved debt collection capability of the platform, we reveal that mobile adoption brings profit enhancement. We offer multiple theoretical and managerial implications.
2023.10.31.15.57.07;31.10.2023;07;03;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:nbr:nberwo:31692&r=pay;;Bo BianMichaela PagelHuan Tang;Consumer Surveillance and Financial Fraud;Companies near constantly surveil their customers to collect, analyze, and profit from their private information. A prevailing concern is that the market for private data and security breaches expose consumers to financial fraud. In this study, we exploit Apple's App Tracking Transparency (ATT) policy, which greatly limited the tracking and sharing of personal information on the iOS platform, providing a major shock to the data industry. Using a difference-in-differences design and granular variations in iOS user shares across the US, we find that if 10% more people disallow tracking, the number of financial fraud complaints in the average zip code decreases by approximately 3.21%. We then show that the effects are concentrated in complaints related to lax data security and privacy, identified using keyword searches and machine learning on complaint narratives, and in complaints about firms that engage in intensive consumer surveillance and lack data safeguards. Our evidence quantifies one of the main consumer costs of lax data security standards.
2023.10.31.15.57.08;31.10.2023;08;03;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-cbe.rss.xml;http://d.repec.org/n?u=RePEc:cdl:ucsdec:qt5q14p1np&r=cbe;;Niederle, MurielVespa, Emanuel;Cognitive Limitations: Failures of Contingent Thinking;In recent years, experiments have documented a new mechanism that leads to failures of profit maximization: the failure of contingent thinking (FCT). This article summarizes key experimental findings, clarifies what constitutes an FCT, and outlines how FCTs can be tested in other environments. Subsequently, we relate FCTs to recent theoretical work on cognitive limitations in behavioral economics. Finally, we connect FCTs to suboptimal behavior documented in applied environments.
2023.10.31.15.57.09;31.10.2023;09;03;Finance;Finance, DeFi, Insurance, Banking et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1957/v1;;Preprints.org - The Multidisciplinary Preprint Platform;The Symphony of Algorithms:Harmonizing Hybrids for Stock Market Prognostication;Stock market prediction is a challenging task to perform, as we know the fluctuations that take place in the market makes it versatile and hard to predict the prices. In this research, we have explored the power of usage of hybrid ensemble algorithms to improve the predictive accuracy in the stock market forecasting. Our research comprises construction and evaluation of diverse hybrid models using different algorithms. The methodology presented in the paper involves comprehensive data preparation, feature engineering, and model normalization. Evaluating the different hybrid models, one stands out distinctly: LSTM (long short-term memory networks) + GRU (Gated recurrent units) + Conv1D (one-dimensional convolutional layer) hybrid. It illustrated its potential to revolutionize decision-making tools for investors and financial analysts in stock market analytics. The harmonious integration of algorithms not only underscores the effectiveness of hybrid modeling but also beckons for further exploration within the ever-evolving domain of predictive modeling, driven by the pursuit of precision and accuracy. This model shows a remarkable accuracy metrics including a Mean Absolute Error (MAE) of 0.95, a Mean Squared Error (MSE) of 2.1222, a Root Mean Squared Error (RMSE) of 1.52, and a R-squared (R2) score of 0.9982.
2023.10.31.15.57.10;31.10.2023;10;04;Supply Chain;Logistics, Supply Chains, Transportation et al.;repec;;http://nep.repec.org/rss/nep-com.rss.xml;http://d.repec.org/n?u=RePEc:nbr:nberwo:31739&r=com;;Gene M. GrossmanElhanan HelpmanAlejandro Sabal;Resilience in Vertical Supply Chains;Forward-looking investments determine the resilience of firms' supply chains. Such investments confer externalities on other firms in the production network. We compare the equilibrium and optimal allocations in a general equilibrium model with an arbitrary number of vertical production tiers. Our model features endogenous investments in resilience, endogenous formation of supply links, and sequential bargaining over quantities and payments between firms in successive tiers. We derive policies that implement the first-best allocation, allowing for subsidies to input purchases, network formation, and investments in resilience. The first-best policies depend only on production function parameters of the pertinent tier. When subsidies to transactions are infeasible, the second-best subsidies for resilience and network formation depend on production function parameters throughout the network, and subsidies are larger upstream than downstream whenever the bargaining weights of buyers are non-increasing along the chain.
2023.10.31.15.57.11;31.10.2023;11;04;Supply Chain;Logistics, Supply Chains, Transportation et al.;technologyreview;;;https://www.technologyreview.com/2023/10/30/1082627/unlocking-supply-chain-resiliency/;;;Unlocking supply chain resiliency;Tracking a Big Mac hamburger’s journey from ranch to fast-food restaurant isn’t easy. Today’s highly segmented beef supply chain consists of a wide array of ranches, feedlots, packers, processors, distribution centers, and restaurants, each with its own set of carefully collected data. Yet in today’s complex digital world, organizations need more visibility than ever to manage inventory, know where products are coming from, and maintain consumer trust, says Bob Carpenter, president and CEO of GS1 US, a not-for-profit, international supply-chain standards organization. ...
2023.10.31.15.57.12;31.10.2023;12;09;Human;Human Resource, Personal Assistance et al.;arxiv;2212.04717;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2212.04717.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1"">Joey Hong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bhatia_K/0/1/0/all/0/1"">Kush Bhatia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1"">Anca Dragan</a>";Joey Hong,Kush Bhatia,Anca Dragan;On the Sensitivity of Reward Inference to Misspecified Human Models.;Inferring reward functions from human behavior is at the center of value alignment - aligning AI objectives with what we, humans, actually want. But doing so relies on models of how humans behave given their objectives. After decades of research in cognitive science, neuroscience, and behavioral economics, obtaining accurate human models remains an open research topic. This begs the question: how accurate do these models need to be in order for the reward inference to be accurate? On the one hand, if small errors in the model can lead to catastrophic error in inference, the entire framework of reward learning seems ill-fated, as we will never have perfect models of human behavior. On the other hand, if as our models improve, we can have a guarantee that reward accuracy also improves, this would show the benefit of more work on the modeling side. We study this question both theoretically and empirically. We do show that it is unfortunately possible to construct small adversarial biases in behavior that lead to arbitrarily large errors in the inferred reward. However, and arguably more importantly, we are also able to identify reasonable assumptions under which the reward inference error can be bounded linearly in the error in the human model. Finally, we verify our theoretical insights in discrete and continuous control tasks with simulated and human data.
2023.10.31.15.57.13;31.10.2023;13;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;repec;;http://nep.repec.org/rss/nep-ind.rss.xml;http://d.repec.org/n?u=RePEc:frz:wpaper:wp2023_07.rdf&r=ind;;Federico Etro;e-Commerce Platforms and Self-preferencing;I survey the literature on eCommerce platforms with particular emphasis on the antitrust debate on self-preferencing by Amazon. The business model of hybrid marketplaces is based on monetization through commissions on third party sellers hosted on the platform and direct margins on own products. Recent theoretical and empirical work on endogenous marketplace structures has analyzed the welfare impact of the dual mode and of recommendation algorithms that have been associated with self-preferencing strategies. The trade offs are complex and one cannot easily conclude that Amazon entry is biased to expropriate third party sellers or that a ban on dual mode, self-preferencing or copycatting would benefit consumers.
2023.10.31.15.57.14;31.10.2023;14;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;repec;;http://nep.repec.org/rss/nep-com.rss.xml;http://d.repec.org/n?u=RePEc:dpr:wpaper:1151r&r=com;;Nobuyuki HanakiYutaka KayabaJun MaekawaHitoshi Matsushima;Two Experiments on Trading Information Goods in a Network;We examine the impact of a cycle path on the trading of a copyable information good in a network experimentally. A cycle path in a network allows a buyer to become a reseller who can compete against existing sellers by replicating the good. A theoretical prediction considers that the price of the information good, even with the first transaction where there is not yet a reseller competing with the original seller, will be lower in networks with a cycle path than otherwise. However, our experiment reveals that the observed price for the first transaction is significantly higher in networks with a cycle path. An additional experiment that enhances competition also does not support the theoretical prediction.
2023.10.31.15.57.15;31.10.2023;15;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;towardsai;;;https://pub.towardsai.net/building-an-end-to-end-recommendation-system-5a743eeeda17?source=rss----98111c9905da---4;;;Building an End-to-End Recommendation System;Leveraging transformer embeddings and a vector database to speed up inference ...
2023.10.31.15.57.16;31.10.2023;16;12;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.2071/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Towards Optimal Solar Energy Integration: A Deep Dive into AI-Enhanced Solar Irradiance Forecasting Models;Keywords: Artificial Neural Network (ANN), Support Vector Machine (SVM), Support Vector Regression (SVR), Lightweight Gradient Boosting Machines (Light GBM), Machine Learning, Solar Irradiance (SI), Solar forecasting
2023.10.31.15.57.17;31.10.2023;17;12;Energy;Electricity, Smart Grid et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Autonomous_multi-factor_Energy_Flows_Controller_AmEFC_Enhancing_Renewable_Energy_Management_with_Intelligent_Control_Systems_Integration_/24412588;;TechRxiv RSS Feed;Autonomous multi-factor Energy Flows Controller (AmEFC): Enhancing Renewable Energy Management with Intelligent Control Systems Integration;This paper presents the intricate architectural design and operational capabilities of the Autonomous multi-factor Energy Flow Controller (AmEFC) in managing energy flow within microgrids. Central to its function, the AmEFC Controller harmonizes software computations with hardware interfacing to guarantee optimal energy flow and system reliability. Notably, it factors in weather forecasting for predictive energy management and allows city-scale intercommunication between local AmEFC controllers for efficient energy surplus exchange. The framework is structured hierarchically, incorporating diverse energy sources and storage mechanisms, dynamic load management, supplemental energy, and advanced decision-making systems. A unique innovation lies in its adaptive response to surplus energy, directing it into gravitational potential energy via hydro pumps. The Simulink model of the on-grid AmEFC microgrid prototype is introduced, representing the integration of renewable energy sources, storage systems, and critical load distribution. Through scenario analysis in the Simulink model, the paper assesses the system's reliability in consistently powering critical loads and its strategy in managing surplus energy. Conclusively, the AmEFC system emerges as a promising solution for future resilient, adaptable, and efficient microgrids, further empowered by its predictive and collaborative capabilities.
2023.10.31.15.57.18;31.10.2023;18;14;Public Services;Public Services, Traffic et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:zbw:itse23:277947&r=pay;;Cagigas, DiegoClifton, JudithDiaz-Fuentes, Danielernández-Gutiérrez, MarcosHarpes, Carlo;Blockchain in Government: Towards an Evaluation Framework;The adoption of a new technology such as Distributed Ledger Technology (DLT) in government is a complex process with numerous potential benefits, but also costs and risks. Early pilots introducing DLT into the public sector show that its potential impact will likely vary depending on the context, including, the type of public service. Even within the same public service, the impact of DLT might be distinct for each of the stakeholders involved (the government, civil servants and citizens, among others). As the public sector is diverse, it is critical to get a proper analysis and understanding of the process of introduction of this technology, which encompasses the different dimensions that play a role in the process. This paper presents an original and multidimensional evaluation framework to analyse and compare the benefits, costs and risks of the introduction of DLT in the public sector. It considers a comprehensive set of factors, identified and extracted after conducting a systematic review of the literature, representing potential benefits, costs and risks of DLT in the public sector. These are categorised into four separate dimensions: technological, socio-economic, organisational-cultural, and institutional (legal and political). This evaluation framework has been designed to be used by policy-makers interested in analysing and comparing the benefits and risks of the introduction of DLT in real-world applications of this technology in the public sector.
2023.10.31.15.57.19;31.10.2023;19;14;Public Services;Public Services, Traffic et al.;arxiv;2310.19091;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2310.19091.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Abaigar_U/0/1/0/all/0/1"">Unai Fischer Abaigar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kern_C/0/1/0/all/0/1"">Christoph Kern</a>, <a href=""http://arxiv.org/find/cs/1/au:+Barda_N/0/1/0/all/0/1"">Noam Barda</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kreuter_F/0/1/0/all/0/1"">Frauke Kreuter</a>";Unai Fischer Abaigar,Christoph Kern,Noam Barda,Frauke Kreuter;Bridging the Gap: Towards an Expanded Toolkit for ML-Supported Decision-Making in the Public Sector.;Machine Learning (ML) systems are becoming instrumental in the public sector, with applications spanning areas like criminal justice, social welfare, financial fraud detection, and public health. While these systems offer great potential benefits to institutional decision-making processes, such as improved efficiency and reliability, they still face the challenge of aligning intricate and nuanced policy objectives with the precise formalization requirements necessitated by ML models. In this paper, we aim to bridge the gap between ML and public sector decision-making by presenting a comprehensive overview of key technical challenges where disjunctions between policy goals and ML models commonly arise. We concentrate on pivotal points of the ML pipeline that connect the model to its operational environment, delving into the significance of representative training data and highlighting the importance of a model setup that facilitates effective decision-making. Additionally, we link these challenges with emerging methodological advancements, encompassing causal ML, domain adaptation, uncertainty quantification, and multi-objective optimization, illustrating the path forward for harmonizing ML and public sector objectives.
2023.10.31.15.57.20;31.10.2023;20;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2107.03913;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2107.03913.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Blinov_P/0/1/0/all/0/1"">Pavel Blinov</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kokh_V/0/1/0/all/0/1"">Vladimir Kokh</a>";Pavel Blinov,Vladimir Kokh;Medical Profile Model: Scientific and Practical Applications in Healthcare.;The paper researches the problem of representation learning for electronic health records. We present the patient histories as temporal sequences of diseases for which embeddings are learned in an unsupervised setup with a transformer-based neural network model. Additionally the embedding space includes demographic parameters which allow the creation of generalized patient profiles and successful transfer of medical knowledge to other domains. The training of such a medical profile model has been performed on a dataset of more than one million patients. Detailed model analysis and its comparison with the state-of-the-art method show its clear advantage in the diagnosis prediction task. Further, we show two applications based on the developed profile model. First, a novel Harbinger Disease Discovery method allowing to reveal disease associated hypotheses and potentially are beneficial in the design of epidemiological studies. Second, the patient embeddings extracted from the profile model applied to the insurance scoring task allow significant improvement in the performance metrics.
2023.10.30.15.44.01;30.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.17680;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17680.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1"">Mukul Singh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cambronero_J/0/1/0/all/0/1"">Jos&#xe9; Cambronero</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1"">Sumit Gulwani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1"">Vu Le</a>, <a href=""http://arxiv.org/find/cs/1/au:+Negreanu_C/0/1/0/all/0/1"">Carina Negreanu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Verbruggen_G/0/1/0/all/0/1"">Gust Verbruggen</a>";Mukul Singh,José Cambronero,Sumit Gulwani,Vu Le,Carina Negreanu,Gust Verbruggen;CodeFusion: A Pre-trained Diffusion Model for Code Generation.;Imagine a developer who can only change their last line of code, how often would they have to start writing a function from scratch before it is correct? Auto-regressive models for code generation from natural language have a similar limitation: they do not easily allow reconsidering earlier tokens generated. We introduce CodeFusion, a pre-trained diffusion code generation model that addresses this limitation by iteratively denoising a complete program conditioned on the encoded natural language. We evaluate CodeFusion on the task of natural language to code generation for Bash, Python, and Microsoft Excel conditional formatting (CF) rules. Experiments show that CodeFusion (75M parameters) performs on par with state-of-the-art auto-regressive systems (350M-175B parameters) in top-1 accuracy and outperforms them in top-3 and top-5 accuracy due to its better balance in diversity versus quality.
2023.10.30.15.44.02;30.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.17894;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17894.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"">Weixu Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yifei Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1"">Yuanfeng Song</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wei_V/0/1/0/all/0/1"">Victor Junqiu Wei</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1"">Yuxing Tian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1"">Yiyan Qi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chan_J/0/1/0/all/0/1"">Jonathan H. Chan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wong_R/0/1/0/all/0/1"">Raymond Chi-Wing Wong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1"">Haiqin Yang</a>";Weixu Zhang,Yifei Wang,Yuanfeng Song,Victor Junqiu Wei,Yuxing Tian,Yiyan Qi,Jonathan H. Chan,Raymond Chi-Wing Wong,Haiqin Yang;Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey.;The emergence of natural language processing has revolutionized the way users interact with tabular data, enabling a shift from traditional query languages and manual plotting to more intuitive, language-based interfaces. The rise of large language models (LLMs) such as ChatGPT and its successors has further advanced this field, opening new avenues for natural language processing techniques. This survey presents a comprehensive overview of natural language interfaces for tabular data querying and visualization, which allow users to interact with data using natural language queries. We introduce the fundamental concepts and techniques underlying these interfaces with a particular emphasis on semantic parsing, the key technology facilitating the translation from natural language to SQL queries or data visualization commands. We then delve into the recent advancements in Text-to-SQL and Text-to-Vis problems from the perspectives of datasets, methodologies, metrics, and system designs. This includes a deep dive into the influence of LLMs, highlighting their strengths, limitations, and potential for future improvements. Through this survey, we aim to provide a roadmap for researchers and practitioners interested in developing and applying natural language interfaces for data interaction in the era of large language models.
2023.10.30.15.44.03;30.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.18025;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.18025.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Simmering_P/0/1/0/all/0/1"">Paul F. Simmering</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huoviala_P/0/1/0/all/0/1"">Paavo Huoviala</a>";Paul F. Simmering,Paavo Huoviala;Large language models for aspect-based sentiment analysis.;Large language models (LLMs) offer unprecedented text completion capabilities. As general models, they can fulfill a wide range of roles, including those of more specialized models. We assess the performance of GPT-4 and GPT-3.5 in zero shot, few shot and fine-tuned settings on the aspect-based sentiment analysis (ABSA) task. Fine-tuned GPT-3.5 achieves a state-of-the-art F1 score of 83.8 on the joint aspect term extraction and polarity classification task of the SemEval-2014 Task 4, improving upon InstructABSA [@scaria_instructabsa_2023] by 5.7%. However, this comes at the price of 1000 times more model parameters and thus increased inference cost. We discuss the the cost-performance trade-offs of different models, and analyze the typical errors that they make. Our results also indicate that detailed prompts improve performance in zero-shot and few-shot settings but are not necessary for fine-tuned models. This evidence is relevant for practioners that are faced with the choice of prompt engineering versus fine-tuning when using LLMs for ABSA.
2023.10.30.15.44.04;30.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.17784;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17784.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1"">Zhixuan Chu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1"">Huaiyu Guo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1"">Xinyuan Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yijia Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1"">Fei Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"">Hong Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1"">Wanqing Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1"">Xin Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cui_Q/0/1/0/all/0/1"">Qing Cui</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"">Longfei Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1"">Jun Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1"">Sheng Li</a>";Zhixuan Chu,Huaiyu Guo,Xinyuan Zhou,Yijia Wang,Fei Yu,Hong Chen,Wanqing Xu,Xin Lu,Qing Cui,Longfei Li,Jun Zhou,Sheng Li;Data-Centric Financial Large Language Models.;Large language models (LLMs) show promise for natural language tasks but struggle when applied directly to complex domains like finance. LLMs have difficulty reasoning about and integrating all relevant information. We propose a data-centric approach to enable LLMs to better handle financial tasks. Our key insight is that rather than overloading the LLM with everything at once, it is more effective to preprocess and pre-understand the data. We create a financial LLM (FLLM) using multitask prompt-based finetuning to achieve data pre-processing and pre-understanding. However, labeled data is scarce for each task. To overcome manual annotation costs, we employ abductive augmentation reasoning (AAR) to automatically generate training data by modifying the pseudo labels from FLLM's own outputs. Experiments show our data-centric FLLM with AAR substantially outperforms baseline financial LLMs designed for raw text, achieving state-of-the-art on financial analysis and interpretation tasks. We also open source a new benchmark for financial analysis and interpretation. Our methodology provides a promising path to unlock LLMs' potential for complex real-world domains.
2023.10.30.15.44.05;30.10.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.17788;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17788.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1"">Hao Xue</a>, <a href=""http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1"">Flora D. Salim</a>";Hao Xue,Flora D. Salim;Utilizing Language Models for Energy Load Forecasting.;Energy load forecasting plays a crucial role in optimizing resource allocation and managing energy consumption in buildings and cities. In this paper, we propose a novel approach that leverages language models for energy load forecasting. We employ prompting techniques to convert energy consumption data into descriptive sentences, enabling fine-tuning of language models. By adopting an autoregressive generating approach, our proposed method enables predictions of various horizons of future energy load consumption. Through extensive experiments on real-world datasets, we demonstrate the effectiveness and accuracy of our proposed method. Our results indicate that utilizing language models for energy load forecasting holds promise for enhancing energy efficiency and facilitating intelligent decision-making in energy systems.
2023.10.30.15.44.06;30.10.2023;06;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/no-coding-just-creativity-5-cool-things-you-can-do-with-gpt-4-c2fd71476712?source=rss----98111c9905da---4;;;No Coding, Just Creativity: 5 Cool Things You Can Do with GPT-4;Discover 5 Game-Changing Applications of GPT-4 and Llama-2 – No Coding Required! ...
2023.10.30.15.44.07;30.10.2023;07;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.14604;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2310.14604.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Jha_A/0/1/0/all/0/1"">Amit Kumar Jha</a>";Amit Kumar Jha;Beyond VaR and CVaR: Topological Risk Measures in Financial Markets.;This paper introduces a novel approach to financial risk assessment by incorporating topological data analysis (TDA), specifically cohomology groups, into the evaluation of equities portfolios. The study aims to go beyond traditional risk measures like Value at Risk (VaR) and Conditional Value at Risk (CVaR), offering a more nuanced understanding of market complexities. Using last one year daily real-world closing price return data for three equities Apple, Microsoft and Google , we developed a new topological riskmeasure, termed Topological VaR Distance (TVaRD). Preliminary results indicate a significant change in the density of the point cloud representing the financial time series during stress conditions, suggesting that TVaRD may offer additional insights into portfolio risk and has the potential to complement existing risk management tools.
2023.10.30.15.44.08;30.10.2023;08;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.17714;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17714.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Rajpoot_P/0/1/0/all/0/1"">Pawan Kumar Rajpoot</a>, <a href=""http://arxiv.org/find/cs/1/au:+Parikh_A/0/1/0/all/0/1"">Ankur Parikh</a>";Pawan Kumar Rajpoot,Ankur Parikh;Nearest Neighbor Search over Vectorized Lexico-Syntactic Patterns for Relation Extraction from Financial Documents.;Relation extraction (RE) has achieved remarkable progress with the help of pre-trained language models. However, existing RE models are usually incapable of handling two situations: implicit expressions and long-tail relation classes, caused by language complexity and data sparsity. Further, these approaches and models are largely inaccessible to users who don't have direct access to large language models (LLMs) and/or infrastructure for supervised training or fine-tuning. Rule-based systems also struggle with implicit expressions. Apart from this, Real world financial documents such as various 10-X reports (including 10-K, 10-Q, etc.) of publicly traded companies pose another challenge to rule-based systems in terms of longer and complex sentences. In this paper, we introduce a simple approach that consults training relations at test time through a nearest-neighbor search over dense vectors of lexico-syntactic patterns and provides a simple yet effective means to tackle the above issues. We evaluate our approach on REFinD and show that our method achieves state-of-the-art performance. We further show that it can provide a good start for human in the loop setup when a small number of annotations are available and it is also beneficial when domain experts can provide high quality patterns.
2023.10.30.15.44.09;30.10.2023;09;05;Industry;Industry 4.0, Production, Circular Economy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0437/v2;;Preprints.org - The Multidisciplinary Preprint Platform;PBEMS: A Permissioned Blockchain-based Equipment Maintenance System in Smart Manufacturing;In the realm of smart manufacturing, equipment plays a pivotal role, impacting the efficiency and quality of production. Ensuring equipment availability and optimal performance is crucial, necessitating effective maintenance strategies. This paper addresses the complexities of smart device maintenance, which often involves collaboration between multiple entities like device owners, manufacturers, suppliers, and external maintenance services. To enhance this cooperative maintenance, we propose a novel maintenance system based on permissioned blockchain technology, offering superior security and reliability compared to conventional cloud-based platforms. Our contributions include developing an integrated maintenance system framework for smart manufacturing, which facilitates interactions among diverse stakeholders. Additionally, we have developed a prototype of this maintenance system, serving as a practical model for real-world application. Our research primarily demonstrates the practicality and advantages of using permissioned blockchain for maintenance systems in the manufacturing sector, paving the way for more secure, efficient, and collaborative maintenance practices.
2023.10.30.15.44.10;30.10.2023;10;05;Industry;Industry 4.0, Production, Circular Economy et al.;arxiv;2303.07230;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2303.07230.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hadadi_F/0/1/0/all/0/1"">Fatemeh Hadadi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dawes_J/0/1/0/all/0/1"">Joshua H. Dawes</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shin_D/0/1/0/all/0/1"">Donghwan Shin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bianculli_D/0/1/0/all/0/1"">Domenico Bianculli</a>, <a href=""http://arxiv.org/find/cs/1/au:+Briand_L/0/1/0/all/0/1"">Lionel Briand</a>";Fatemeh Hadadi,Joshua H. Dawes,Donghwan Shin,Domenico Bianculli,Lionel Briand;Systematic Evaluation of Deep Learning Models for Failure Prediction.;With the increasing complexity and scope of software systems, their dependability is crucial. The analysis of log data recorded during system execution can enable engineers to automatically predict failures at run time. Several Machine Learning (ML) techniques, including traditional ML and Deep Learning (DL), have been proposed to automate such tasks. However, current empirical studies are limited in terms of covering all main DL types -- Recurrent Neural Network (RNN), Convolutional Neural network (CNN), and transformer -- as well as examining them on a wide range of diverse datasets. In this paper, we aim to address these issues by systematically investigating the combination of log data embedding strategies and DL types for failure prediction. To that end, we propose a modular architecture to accommodate various configurations of embedding strategies and DL-based encoders. To further investigate how dataset characteristics such as dataset size and failure percentage affect model accuracy, we synthesised 360 datasets, with varying characteristics, for three distinct system behavioral models, based on a systematic and automated generation approach. Using the F1 score metric, our results show that the best overall performing configuration is a CNN-based encoder with Logkey2vec. Additionally, we provide specific dataset conditions, namely a dataset size >350 or a failure percentage >7.5%, under which this configuration demonstrates high accuracy for failure prediction.
2023.10.30.15.44.11;30.10.2023;11;09;Human;Human Resource, Personal Assistance et al.;arxiv;2310.17909;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17909.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Elia_D/0/1/0/all/0/1"">Daniela Elia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1"">Fang Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zowghi_D/0/1/0/all/0/1"">Didar Zowghi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1"">Marian-Andrei Rizoiu</a>";Daniela Elia,Fang Chen,Didar Zowghi,Marian-Andrei Rizoiu;The Innovation-to-Occupations Ontology: Linking Business Transformation Initiatives to Occupations and Skills.;The fast adoption of new technologies forces companies to continuously adapt their operations making it harder to predict workforce requirements. Several recent studies have attempted to predict the emergence of new roles and skills in the labour market from online job ads. This paper aims to present a novel ontology linking business transformation initiatives to occupations and an approach to automatically populating it by leveraging embeddings extracted from job ads and Wikipedia pages on business transformation and emerging technologies topics. To our knowledge, no previous research explicitly links business transformation initiatives, like the adoption of new technologies or the entry into new markets, to the roles needed. Our approach successfully matches occupations to transformation initiatives under ten different scenarios, five linked to technology adoption and five related to business. This framework presents an innovative approach to guide enterprises and educational institutions on the workforce requirements for specific business transformation initiatives.
2023.10.30.15.44.12;30.10.2023;12;12;Energy;Electricity, Smart Grid et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Control_Frameworks_for_Transactive_Energy_Storage_Services_in_Energy_Communities/21305052;;TechRxiv RSS Feed;Control Frameworks for Transactive Energy Storage Services in Energy Communities;"Recently, the decreasing cost of storage technologies and the emergence of economy-driven mechanisms for energy exchange are contributing to the spread of energy communities. In this context, this paper aims at defining innovative transactive control frameworks for energy communities equipped with independent service-oriented energy storage systems. The addressed control problem consists in optimally scheduling the energy activities of a group of prosumers, characterized by their own demand and renewable generation, and a group of energy storage service providers, able to store the prosumers' energy surplus and, subsequently, release it upon a fee payment. We propose two novel resolution algorithms based on a game theoretical control formulation, a coordinated and an uncoordinated one, which can be alternatively used depending on the underlying communication architecture of the grid. The two proposed approaches are validated through numerical simulations on realistic scenarios. Results show that the use of a particular framework does not alter fairness, at least at the community level, i.e., no participant in the groups of prosumers or providers can strongly benefit from changing its strategy while compromising others’ welfare. Lastly, the approaches are compared with a centralized control method showing better computational results. This preprint has been accepted for publication in Control Engineering Practice, Elsevier. How to cite: Nicola Mignoni, Paolo Scarabaggio, Raffaele Carli, Mariagrazia Dotoli, ""Control frameworks for transactive energy storage services in energy communities"", Control Engineering Practice, Volume 130, 2023, 105364, ISSN 0967-0661, https://doi.org/10.1016/j.conengprac.2022.105364. © 2022. This manuscript version is made available under the CC-BY-NC-ND 4.0 license."
2023.10.30.15.44.13;30.10.2023;13;13;Mobility;Mobility, Automotive, Self Driving et al.;arxiv;2310.18215;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.18215.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ozeki_R/0/1/0/all/0/1"">Ren Ozeki</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yonekura_H/0/1/0/all/0/1"">Haruki Yonekura</a>, <a href=""http://arxiv.org/find/cs/1/au:+Baimbetova_A/0/1/0/all/0/1"">Aidana Baimbetova</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rizk_H/0/1/0/all/0/1"">Hamada Rizk</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yamaguchi_H/0/1/0/all/0/1"">Hirozumi Yamaguchi</a>";Ren Ozeki,Haruki Yonekura,Aidana Baimbetova,Hamada Rizk,Hirozumi Yamaguchi;One Model Fits All: Cross-Region Taxi-Demand Forecasting.;The growing demand for ride-hailing services has led to an increasing need for accurate taxi demand prediction. Existing systems are limited to specific regions, lacking generalizability to unseen areas. This paper presents a novel taxi demand forecasting system that leverages a graph neural network to capture spatial dependencies and patterns in urban environments. Additionally, the proposed system employs a region-neutral approach, enabling it to train a model that can be applied to any region, including unseen regions. To achieve this, the framework incorporates the power of Variational Autoencoder to disentangle the input features into region-specific and region-neutral components. The region-neutral features facilitate cross-region taxi demand predictions, allowing the model to generalize well across different urban areas. Experimental results demonstrate the effectiveness of the proposed system in accurately forecasting taxi demand, even in previously unobserved regions, thus showcasing its potential for optimizing taxi services and improving transportation efficiency on a broader scale.
2023.10.30.15.44.14;30.10.2023;14;13;Mobility;Mobility, Automotive, Self Driving et al.;towardsai;;;https://pub.towardsai.net/the-future-of-the-automotive-industry-might-be-talking-cars-078f71885f3b?source=rss----98111c9905da---4;;;The Future of the Automotive Industry Might be Talking Cars;Wayve, a UK company has announced their LINGO-1 model, a Vision-Language-Action (VLA) model that can explain and reason the decisions behind driving actions taken by an autonomous driving system. ...
2023.10.30.15.44.15;30.10.2023;15;14;Public Services;Public Services, Traffic et al.;repec;;http://nep.repec.org/rss/nep-ict.rss.xml;http://d.repec.org/n?u=RePEc:hal:journl:hal-04217917&r=ict;;Yu LiuShenle PanPauline FolzThomas HassanPhilippe Raipin- ParvedyEric Ballot;Smart City Logistics Enabled by Digital Twins and Semantic Technologies;This research explores sustainable city logistics, emphasizing the hurdles associated with scarce urban resources, including their under-and misutilization due to a lack of real-time information on the available infrastructure and intense competition between companies. To face these challenges, there is a crucial need to improve the visibility of urban resources and logistics assets, as an enabler of effective and efficient resource allocation and orchestration of resource utilization and logistics operations. The advent of Smart Cities provides innovation opportunities, leading to the concept of Smart City Logistics (SCL). SCL will offer dual benefits: firstly, it improves resource visibility by profiting from the various fundamental technologies of Smart Cities, i.e., IoT and ICT, to collect and transfer the data of the ever-changing state of resources. Second, enhanced by Digital Twins, the real-time objects' states can be synchronized and mirrored, which will support the decision-making in SCL to guide the allocation of urban resources to provide energy-efficient, cost-effective logistics services dynamically and responsively. This research primarily focuses on SCL's conceptualization and modeling, while discussing potential future advancements.
2023.10.30.15.44.16;30.10.2023;16;14;Public Services;Public Services, Traffic et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1936/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Exploring the Essence of Public Financial Accountability in the Public Sector: A Qualitative Analysis;The concept of public financial accountability, often associated with account-rendering, lacks a clear and comprehensive definition in the realm of accounting literature. Disentanglement the true essence of a phenomenon is essential, as formal definitions can only provide a superficial understanding. This study seeks to delve into the core principles of public financial accountability and their implications for financial reporting in the public sector. Applying a qualitative approach, data was gathered through in-depth interviews with 25 Nigerian scholars, professionals, and public affairs experts. The analysis reveals that the essence of public financial accountability lies in upholding citisens' trust in public officials, ensuring the responsible management of public financial resources for the greater public good, and effectively communicating financial decisions, actions, and outcomes to the public through a transparent reporting mechanism. This study sheds light on the fundamental nature of financial accountability in the public sector, enhancing our understanding of its significance in governance and financial reporting.
2023.10.30.15.44.17;30.10.2023;17;14;Public Services;Public Services, Traffic et al.;arxiv;2310.17654;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17654.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Batarseh_F/0/1/0/all/0/1"">Feras A. Batarseh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1"">Ajay Kulkarni</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sreng_C/0/1/0/all/0/1"">Chhayly Sreng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1"">Justice Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Maksud_S/0/1/0/all/0/1"">Siam Maksud</a>";Feras A. Batarseh,Ajay Kulkarni,Chhayly Sreng,Justice Lin,Siam Maksud;ACWA: An AI-driven Cyber-Physical Testbed for Intelligent Water Systems.;"This manuscript presents a novel state-of-the-art cyber-physical water testbed, namely: The AI and Cyber for Water and Agriculture testbed (ACWA). ACWA is motivated by the need to advance water supply management using AI and Cybersecurity experimentation. The main goal of ACWA is to address pressing challenges in the water and agricultural domains by utilising cutting-edge AI and data-driven technologies. These challenges include Cyberbiosecurity, resources management, access to water, sustainability, and data-driven decision-making, among others. To address such issues, ACWA consists of multiple topologies, sensors, computational nodes, pumps, tanks, smart water devices, as well as databases and AI models that control the system. Moreover, we present ACWA simulator, which is a software-based water digital twin. The simulator runs on fluid and constituent transport principles that produce theoretical time series of a water distribution system. This creates a good validation point for comparing the theoretical approach with real-life results via the physical ACWA testbed. ACWA data are available to AI and water domain researchers and are hosted in an online public repository. In this paper, the system is introduced in detail and compared with existing water testbeds; additionally, example use-cases are described along with novel outcomes such as datasets, software, and AI-related scenarios."
2023.10.30.15.44.18;30.10.2023;18;15;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1861/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Economic Management in Healthcare: A Critical Issue to Understand;The healthcare system is intricate and dynamic. For the purpose of organising and planning a system, where allocating funds appropriately is essential and therefore managerial skills play a critical role. A certain portion of each nation's GDP is allotted to the health sectors. Managers and decision-makers in the healthcare systems are using resources effectively, yet the quantity of funding they receive from the government or other stakeholders is insufficient sometimes. A sound understanding of both basic and advanced economics is necessary for the care management, to make cost-effective judgements in public health. Healthcare officials at all levels (regional, state, federal, or international), need to be knowledgeable about public health issues and the related modern economic climates. Business executives and healthcare managers need effective practical knowledge to handle partner-financial allocation (demand-supply chain) and handle economic volatility.
2023.10.30.15.44.19;30.10.2023;19;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.17956;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17956.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"">Junling Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"">Ziming Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1"">Qichen Ye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chong_D/0/1/0/all/0/1"">Dading Chong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1"">Peilin Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1"">Yining Hua</a>";Junling Liu,Ziming Wang,Qichen Ye,Dading Chong,Peilin Zhou,Yining Hua;Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare.;Large Language Models (LLMs) have introduced a new era of proficiency in comprehending complex healthcare and biomedical topics. However, there is a noticeable lack of models in languages other than English and models that can interpret multi-modal input, which is crucial for global healthcare accessibility. In response, this study introduces Qilin-Med-VL, the first Chinese large vision-language model designed to integrate the analysis of textual and visual data. Qilin-Med-VL combines a pre-trained Vision Transformer (ViT) with a foundational LLM. It undergoes a thorough two-stage curriculum training process that includes feature alignment and instruction tuning. This method enhances the model's ability to generate medical captions and answer complex medical queries. We also release ChiMed-VL, a dataset consisting of more than 1M image-text pairs. This dataset has been carefully curated to enable detailed and comprehensive interpretation of medical data using various types of images.
2023.10.30.15.44.20;30.10.2023;20;18;AgriCulture;Agriculture, Food, Nutrition et al.;arxiv;2310.18268;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.18268.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lopes_F/0/1/0/all/0/1"">Felipe A. Lopes</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sagan_V/0/1/0/all/0/1"">Vasit Sagan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Esposito_F/0/1/0/all/0/1"">Flavio Esposito</a>";Felipe A. Lopes,Vasit Sagan,Flavio Esposito;PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction.;Monitoring plantations is crucial for crop management and producing healthy harvests. Unmanned Aerial Vehicles (UAVs) have been used to collect multispectral images that aid in this monitoring. However, given the number of hectares to be monitored and the limitations of flight, plant disease signals become visually clear only in the later stages of plant growth and only if the disease has spread throughout a significant portion of the plantation. This limited amount of relevant data hampers the prediction models, as the algorithms struggle to generalize patterns with unbalanced or unrealistic augmented datasets effectively. To address this issue, we propose PlantPlotGAN, a physics-informed generative model capable of creating synthetic multispectral plot images with realistic vegetation indices. These indices served as a proxy for disease detection and were used to evaluate if our model could help increase the accuracy of prediction models. The results demonstrate that the synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art methods regarding the Fr\'echet inception distance. Moreover, prediction models achieve higher accuracy metrics when trained with synthetic and original imagery for earlier plant disease detection compared to the training processes based solely on real imagery.
2023.10.27.17.42.01;27.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2305.15064;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.15064.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1"">Siqi Ouyang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"">Lei Li</a>";Siqi Ouyang,Lei Li;AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models.;Recent large language models (LLMs) are promising for making decisions in grounded environments. However, LLMs frequently fail in complex decision-making tasks due to the misalignment between the pre-trained knowledge in LLMs and the actual rules in the environment. Existing methods require either costly gradient computation or lengthy in-context demonstrations. In this paper, we propose AutoPlan, an approach to guide LLM-based agents to accomplish interactive decision-making tasks. AutoPlan augments the LLM prompt with a task-solving plan and optimizes it through iterative experience collection and reflection. Our experiments show that AutoPlan, though using no in-context demonstrations, achieves success rates on par with the baselines using human-written demonstrations on ALFWorld and even outperforms them by 8% on HotpotQA. The code is available at https://github.com/owaski/AutoPlan.
2023.10.27.17.42.02;27.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.17025;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17025.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Guthula_S/0/1/0/all/0/1"">Satyandra Guthula</a>, <a href=""http://arxiv.org/find/cs/1/au:+Battula_N/0/1/0/all/0/1"">Navya Battula</a>, <a href=""http://arxiv.org/find/cs/1/au:+Beltiukov_R/0/1/0/all/0/1"">Roman Beltiukov</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1"">Wenbo Guo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1"">Arpit Gupta</a>";Satyandra Guthula,Navya Battula,Roman Beltiukov,Wenbo Guo,Arpit Gupta;netFound: Foundation Model for Network Security.;In ML for network security, traditional workflows rely on high-quality labeled data and manual feature engineering, but limited datasets and human expertise hinder feature selection, leading to models struggling to capture crucial relationships and generalize effectively. Inspired by recent advancements in ML application domains like GPT-4 and Vision Transformers, we have developed netFound, a foundational model for network security. This model undergoes pre-training using self-supervised algorithms applied to readily available unlabeled network packet traces. netFound's design incorporates hierarchical and multi-modal attributes of network traffic, effectively capturing hidden networking contexts, including application logic, communication protocols, and network conditions. With this pre-trained foundation in place, we can fine-tune netFound for a wide array of downstream tasks, even when dealing with low-quality, limited, and noisy labeled data. Our experiments demonstrate netFound's superiority over existing state-of-the-art ML-based solutions across three distinct network downstream tasks: traffic classification, network intrusion detection, and APT detection. Furthermore, we emphasize netFound's robustness against noisy and missing labels, as well as its ability to generalize across temporal variations and diverse network environments. Finally, through a series of ablation studies, we provide comprehensive insights into how our design choices enable netFound to more effectively capture hidden networking contexts, further solidifying its performance and utility in network security applications.
2023.10.27.17.42.03;27.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.17342;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17342.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1"">Hanchong Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1"">Ruisheng Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1"">Lu Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1"">Hongshen Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1"">Kai Yu</a>";Hanchong Zhang,Ruisheng Cao,Lu Chen,Hongshen Xu,Kai Yu;ACT-SQL: In-Context Learning for Text-to-SQL with Automatically-Generated Chain-of-Thought.;Recently Large Language Models (LLMs) have been proven to have strong abilities in various domains and tasks. We study the problem of prompt designing in the text-to-SQL task and attempt to improve the LLMs' reasoning ability when generating SQL queries. Besides the trivial few-shot in-context learning setting, we design our chain-of-thought (CoT) prompt with a similar method to schema linking. We provide a method named ACT-SQL to automatically generate auto-CoT exemplars and thus the whole process doesn't need manual labeling. Our approach is cost-saving since we only use the LLMs' API call once when generating one SQL query. Furthermore, we extend our in-context learning method to the multi-turn text-to-SQL task. The experiment results show that the LLMs' performance can benefit from our ACT-SQL approach. Our approach achieves SOTA performance on the Spider dev set among existing in-context learning approaches.
2023.10.27.17.42.04;27.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.17370;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17370.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+AlDahoul_N/0/1/0/all/0/1"">Nouar AlDahoul</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1"">Joseph Hong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Varvello_M/0/1/0/all/0/1"">Matteo Varvello</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zaki_Y/0/1/0/all/0/1"">Yasir Zaki</a>";Nouar AlDahoul,Joseph Hong,Matteo Varvello,Yasir Zaki;Exploring the Potential of Generative AI for the World Wide Web.;Generative Artificial Intelligence (AI) is a cutting-edge technology capable of producing text, images, and various media content leveraging generative models and user prompts. Between 2022 and 2023, generative AI surged in popularity with a plethora of applications spanning from AI-powered movies to chatbots. In this paper, we delve into the potential of generative AI within the realm of the World Wide Web, specifically focusing on image generation. Web developers already harness generative AI to help crafting text and images, while Web browsers might use it in the future to locally generate images for tasks like repairing broken webpages, conserving bandwidth, and enhancing privacy. To explore this research area, we have developed WebDiffusion, a tool that allows to simulate a Web powered by stable diffusion, a popular text-to-image model, from both a client and server perspective. WebDiffusion further supports crowdsourcing of user opinions, which we use to evaluate the quality and accuracy of 409 AI-generated images sourced from 60 webpages. Our findings suggest that generative AI is already capable of producing pertinent and high-quality Web images, even without requiring Web designers to manually input prompts, just by leveraging contextual information available within the webpages. However, we acknowledge that direct in-browser image generation remains a challenge, as only highly powerful GPUs, such as the A40 and A100, can (partially) compete with classic image downloads. Nevertheless, this approach could be valuable for a subset of the images, for example when fixing broken webpages or handling highly private content.
2023.10.27.17.42.05;27.10.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/a-step-by-step-guide-to-pdf-chatbots-with-langchain-and-ollama/;;;A Step-by-Step Guide to PDF Chatbots with Langchain and Ollama;In an era where technology continues to transform the way we interact with information, the concept of a PDF chatbot brings a new level of convenience and efficiency to the table. This article delves into the intriguing realm of creating a PDF chatbot using Langchain and Ollama, where open-source models become accessible with minimal configuration. Say goodbye to the complexities of framework selection and model parameter adjustments, as we embark on a journey to unlock the potential of PDF chatbots. Discover how to seamlessly install Ollama, download models, and craft a PDF chatbot that provides intelligent responses to your queries. Let’s explore this exciting fusion of technology and document processing, making information retrieval easier than ever. ...
2023.10.27.17.42.06;27.10.2023;06;04;Supply Chain;Logistics, Supply Chains, Transportation et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1744/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Modeling Role of Sustainable  Supply Management Practices on performance and sustainable development of South Africa’s listed companies.;The effective implementation of a sustainable supply chain leadership (SSCL) strategy at each organization’s level, positively impacts on corporation’s competitive advantage and sustainable development. While fears have been acknowledged in previous literature, the benefit of designing Sustainable supply chain models for operational excellence and sustainable development is a noteworthy exploration. The study collected statistical data using an online Survey- monkey questionnaire from 46 of the top 100 JSE-listed companies with the intention to elucidate the large firms’ transition from longstanding linear approaches to sustainable production and consumption to a more circular approach. A bivariate data analysis was used to generate the results in SPSS. The results indicate a positive contribution of SSCL strategy to operational excellence and sustainable development of large corporations if only the entire supply chain system is well-coordinated and implemented. This study makes a vital contribution by proposing a new SSCL model for fast-tracking corporate sustainability and enhancing corporate contributions to sustainable growth.
2023.10.27.17.42.07;27.10.2023;07;04;Supply Chain;Logistics, Supply Chains, Transportation et al.;arxiv;2310.17485;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17485.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Mak_S/0/1/0/all/0/1"">Stephen Mak</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1"">Liming Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pearce_T/0/1/0/all/0/1"">Tim Pearce</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ostroumov_M/0/1/0/all/0/1"">Michael Ostroumov</a>, <a href=""http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1"">Alexandra Brintrup</a>";Stephen Mak,Liming Xu,Tim Pearce,Michael Ostroumov,Alexandra Brintrup;Fair collaborative vehicle routing: A deep multi-agent reinforcement learning approach.;"Collaborative vehicle routing occurs when carriers collaborate through sharing their transportation requests and performing transportation requests on behalf of each other. This achieves economies of scale, thus reducing cost, greenhouse gas emissions and road congestion. But which carrier should partner with whom, and how much should each carrier be compensated? Traditional game theoretic solution concepts are expensive to calculate as the characteristic function scales exponentially with the number of agents. This would require solving the vehicle routing problem (NP-hard) an exponential number of times. We therefore propose to model this problem as a coalitional bargaining game solved using deep multi-agent reinforcement learning, where - crucially - agents are not given access to the characteristic function. Instead, we implicitly reason about the characteristic function; thus, when deployed in production, we only need to evaluate the expensive post-collaboration vehicle routing problem once. Our contribution is that we are the first to consider both the route allocation problem and gain sharing problem simultaneously - without access to the expensive characteristic function. Through decentralised machine learning, our agents bargain with each other and agree to outcomes that correlate well with the Shapley value - a fair profit allocation mechanism. Importantly, we are able to achieve a reduction in run-time of 88%."
2023.10.27.17.42.08;27.10.2023;08;05;Industry;Industry 4.0, Production, Circular Economy et al.;arxiv;2310.17316;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17316.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1"">Shuai Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"">Zhifei Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1"">Pengguang Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1"">Xi Fang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1"">Shu Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"">Yingcong Chen</a>";Shuai Yang,Zhifei Chen,Pengguang Chen,Xi Fang,Shu Liu,Yingcong Chen;Defect Spectrum: A Granular Look of Large-Scale Defect Datasets with Rich Semantics.;Defect inspection is paramount within the closed-loop manufacturing system. However, existing datasets for defect inspection often lack precision and semantic granularity required for practical applications. In this paper, we introduce the Defect Spectrum, a comprehensive benchmark that offers precise, semantic-abundant, and large-scale annotations for a wide range of industrial defects. Building on four key industrial benchmarks, our dataset refines existing annotations and introduces rich semantic details, distinguishing multiple defect types within a single image. Furthermore, we introduce Defect-Gen, a two-stage diffusion-based generator designed to create high-quality and diverse defective images, even when working with limited datasets. The synthetic images generated by Defect-Gen significantly enhance the efficacy of defect inspection models. Overall, The Defect Spectrum dataset demonstrates its potential in defect inspection research, offering a solid platform for testing and refining advanced models.
2023.10.27.17.42.09;27.10.2023;09;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;arxiv;2310.17488;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17488.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Mei_K/0/1/0/all/0/1"">Kai Mei</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yongfeng Zhang</a>";Kai Mei,Yongfeng Zhang;LightLM: A Lightweight Deep and Narrow Language Model for Generative Recommendation.;This paper presents LightLM, a lightweight Transformer-based language model for generative recommendation. While Transformer-based generative modeling has gained importance in various AI sub-fields such as NLP and vision, generative recommendation is still in its infancy due to its unique demand on personalized generative modeling. Existing works on generative recommendation often use NLP-oriented Transformer architectures such as T5, GPT, LLaMA and M6, which are heavy-weight and are not specifically designed for recommendation tasks. LightLM tackles the issue by introducing a light-weight deep and narrow Transformer architecture, which is specifically tailored for direct generation of recommendation items. This structure is especially apt for straightforward generative recommendation and stems from the observation that language model does not have to be too wide for this task, as the input predominantly consists of short tokens that are well-suited for the model's capacity. We also show that our devised user and item ID indexing methods, i.e., Spectral Collaborative Indexing (SCI) and Graph Collaborative Indexing (GCI), enables the deep and narrow Transformer architecture to outperform large-scale language models for recommendation. Besides, to address the hallucination problem of generating items as output, we propose the constrained generation process for generative recommenders. Experiments on real-world datasets show that LightLM outperforms various competitive baselines in terms of both recommendation accuracy and efficiency. The code can be found at https://github.com/dongyuanjushi/LightLM.
2023.10.27.17.42.10;27.10.2023;10;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.17506;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2310.17506.pdf;" <a href=""http://arxiv.org/find/stat/1/au:+Peng_R/0/1/0/all/0/1"">Roger D. Peng</a>";Roger D. Peng;Predicting Patient No-Shows in Community Health Clinics: A Case Study in Designing a Data Analytic Product.;The data science revolution has highlighted the varying roles that data analytic products can play in a different industries and applications. There has been particular interest in using analytic products coupled with algorithmic prediction models to aid in human decision-making. However, detailed descriptions of the decision-making process that leads to the design and development of analytic products are lacking in the statistical literature, making it difficult to accumulate a body of knowledge where students interested in the field of data science may look to learn about this process. In this paper, we present a case study describing the development of an analytic product for predicting whether patients will show up for scheduled appointments at a community health clinic. We consider the stakeholders involved and their interests, along with the real-world analytical and technical trade-offs involved in developing and deploying the product. Our goal here is to highlight the decisions made and evaluate them in the context of possible alternatives. We find that although this case study has some unique characteristics, there are lessons to be learned that could translate to other settings and applications.
2023.10.27.17.42.11;27.10.2023;11;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.17017;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.17017.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1"">Young Min Cho</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rai_S/0/1/0/all/0/1"">Sunny Rai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1"">Lyle Ungar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1"">Jo&#xe3;o Sedoc</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guntuku_S/0/1/0/all/0/1"">Sharath Chandra Guntuku</a>";Young Min Cho,Sunny Rai,Lyle Ungar,João Sedoc,Sharath Chandra Guntuku;An Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives.;Mental health conversational agents (a.k.a. chatbots) are widely studied for their potential to offer accessible support to those experiencing mental health challenges. Previous surveys on the topic primarily consider papers published in either computer science or medicine, leading to a divide in understanding and hindering the sharing of beneficial knowledge between both domains. To bridge this gap, we conduct a comprehensive literature review using the PRISMA framework, reviewing 534 papers published in both computer science and medicine. Our systematic review reveals 136 key papers on building mental health-related conversational agents with diverse characteristics of modeling and experimental design techniques. We find that computer science papers focus on LLM techniques and evaluating response quality using automated metrics with little attention to the application while medical papers use rule-based conversational agents and outcome metrics to measure the health outcomes of participants. Based on our findings on transparency, ethics, and cultural heterogeneity in this review, we provide a few recommendations to help bridge the disciplinary divide and enable the cross-disciplinary development of mental health conversational agents.
2023.10.26.19.37.01;26.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.16361;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.16361.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Fetahu_B/0/1/0/all/0/1"">Besnik Fetahu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"">Zhiyu Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rokhlenko_O/0/1/0/all/0/1"">Oleg Rokhlenko</a>, <a href=""http://arxiv.org/find/cs/1/au:+Malmasi_S/0/1/0/all/0/1"">Shervin Malmasi</a>";Besnik Fetahu,Zhiyu Chen,Oleg Rokhlenko,Shervin Malmasi;InstructPTS: Instruction-Tuning LLMs for Product Title Summarization.;E-commerce product catalogs contain billions of items. Most products have lengthy titles, as sellers pack them with product attributes to improve retrieval, and highlight key product aspects. This results in a gap between such unnatural products titles, and how customers refer to them. It also limits how e-commerce stores can use these seller-provided titles for recommendation, QA, or review summarization. Inspired by recent work on instruction-tuned LLMs, we present InstructPTS, a controllable approach for the task of Product Title Summarization (PTS). Trained using a novel instruction fine-tuning strategy, our approach is able to summarize product titles according to various criteria (e.g. number of words in a summary, inclusion of specific phrases, etc.). Extensive evaluation on a real-world e-commerce catalog shows that compared to simple fine-tuning of LLMs, our proposed approach can generate more accurate product name summaries, with an improvement of over 14 and 8 BLEU and ROUGE points, respectively.
2023.10.26.19.37.02;26.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.16390;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.16390.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1"">Ting Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Irsan_I/0/1/0/all/0/1"">Ivana Clairine Irsan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Thung_F/0/1/0/all/0/1"">Ferdian Thung</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lo_D/0/1/0/all/0/1"">David Lo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1"">Asankhaya Sharma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1"">Lingxiao Jiang</a>";Ting Zhang,Ivana Clairine Irsan,Ferdian Thung,David Lo,Asankhaya Sharma,Lingxiao Jiang;Evaluating Pre-trained Language Models for Repairing API Misuses.;API misuses often lead to software bugs, crashes, and vulnerabilities. While several API misuse detectors have been proposed, there are no automatic repair tools specifically designed for this purpose. In a recent study, test-suite-based automatic program repair (APR) tools were found to be ineffective in repairing API misuses. Still, since the study focused on non-learning-aided APR tools, it remains unknown whether learning-aided APR tools are capable of fixing API misuses. In recent years, pre-trained language models (PLMs) have succeeded greatly in many natural language processing tasks. There is a rising interest in applying PLMs to APR. However, there has not been any study that investigates the effectiveness of PLMs in repairing API misuse. To fill this gap, we conduct a comprehensive empirical study on 11 learning-aided APR tools, which include 9 of the state-of-the-art general-purpose PLMs and two APR tools. We evaluate these models with an API-misuse repair dataset, consisting of two variants. Our results show that PLMs perform better than the studied APR tools in repairing API misuses. Among the 9 pre-trained models tested, CodeT5 is the best performer in the exact match. We also offer insights and potential exploration directions for future research.
2023.10.26.19.37.03;26.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.16263;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.16263.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Jiexin Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1"">Liuwen Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1"">Xitong Luo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1"">Zhiping Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1"">Jiayuan Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jatowt_A/0/1/0/all/0/1"">Adam Jatowt</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1"">Yi Cai</a>";Jiexin Wang,Liuwen Cao,Xitong Luo,Zhiping Zhou,Jiayuan Xie,Adam Jatowt,Yi Cai;Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation.;Large language models (LLMs) have brought significant advancements to code generation, benefiting both novice and experienced developers. However, their training using unsanitized data from open-source repositories, like GitHub, introduces the risk of inadvertently propagating security vulnerabilities. To effectively mitigate this concern, this paper presents a comprehensive study focused on evaluating and enhancing code LLMs from a software security perspective. We introduce SecuCoGen\footnote{SecuCoGen has been uploaded as supplemental material and will be made publicly available after publication.}, a meticulously curated dataset targeting 21 critical vulnerability types. SecuCoGen comprises 180 samples and serves as the foundation for conducting experiments on three crucial code-related tasks: code generation, code repair and vulnerability classification, with a strong emphasis on security. Our experimental results reveal that existing models often overlook security concerns during code generation, leading to the generation of vulnerable code. To address this, we propose effective approaches to mitigate the security vulnerabilities and enhance the overall robustness of code generated by LLMs. Moreover, our study identifies weaknesses in existing models' ability to repair vulnerable code, even when provided with vulnerability information. Additionally, certain vulnerability types pose challenges for the models, hindering their performance in vulnerability classification. Based on these findings, we believe our study will have a positive impact on the software engineering community, inspiring the development of improved methods for training and utilizing LLMs, thereby leading to safer and more trustworthy model deployment.
2023.10.26.19.37.04;26.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.16673;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.16673.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bhattacharya_P/0/1/0/all/0/1"">Paheli Bhattacharya</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chakraborty_M/0/1/0/all/0/1"">Manojit Chakraborty</a>, <a href=""http://arxiv.org/find/cs/1/au:+Palepu_K/0/1/0/all/0/1"">Kartheek N S N Palepu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pandey_V/0/1/0/all/0/1"">Vikas Pandey</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dindorkar_I/0/1/0/all/0/1"">Ishan Dindorkar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rajpurohit_R/0/1/0/all/0/1"">Rakesh Rajpurohit</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1"">Rishabh Gupta</a>";Paheli Bhattacharya,Manojit Chakraborty,Kartheek N S N Palepu,Vikas Pandey,Ishan Dindorkar,Rakesh Rajpurohit,Rishabh Gupta;Exploring Large Language Models for Code Explanation.;Automating code documentation through explanatory text can prove highly beneficial in code understanding. Large Language Models (LLMs) have made remarkable strides in Natural Language Processing, especially within software engineering tasks such as code generation and code summarization. This study specifically delves into the task of generating natural-language summaries for code snippets, using various LLMs. The findings indicate that Code LLMs outperform their generic counterparts, and zero-shot methods yield superior results when dealing with datasets with dissimilar distributions between training and testing sets.
2023.10.26.19.37.05;26.10.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/empower-multiple-websites-with-langchains-chatbot-solution/;;;Empower Multiple Websites with Langchain’s Chatbot Solution;In this article, we will build Langchain’s Chatbot solution, like ChatGPT, on multiple custom websites and the Retrieval Augmented Generation (RAG) technique. To begin with the project, we will first understand a few critical components to build such an application. ...
2023.10.26.19.37.06;26.10.2023;06;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.16095;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.16095.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chun_Y/0/1/0/all/0/1"">Ye Eun Chun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1"">Sunjae Kwon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1"">Kyunghwan Sohn</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sung_N/0/1/0/all/0/1"">Nakwon Sung</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1"">Junyoup Lee</a>, <a href=""http://arxiv.org/find/cs/1/au:+Seo_B/0/1/0/all/0/1"">Byungki Seo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Compher_K/0/1/0/all/0/1"">Kevin Compher</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1"">Seung-won Hwang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1"">Jaesik Choi</a>";Ye Eun Chun,Sunjae Kwon,Kyunghwan Sohn,Nakwon Sung,Junyoup Lee,Byungki Seo,Kevin Compher,Seung-won Hwang,Jaesik Choi;CR-COPEC: Causal Rationale of Corporate Performance Changes to Learn from Financial Reports.;In this paper, we introduce CR-COPEC called Causal Rationale of Corporate Performance Changes from financial reports. This is a comprehensive large-scale domain-adaptation causal sentence dataset to detect financial performance changes of corporate. CR-COPEC contributes to two major achievements. First, it detects causal rationale from 10-K annual reports of the U.S. companies, which contain experts' causal analysis following accounting standards in a formal manner. This dataset can be widely used by both individual investors and analysts as material information resources for investing and decision making without tremendous effort to read through all the documents. Second, it carefully considers different characteristics which affect the financial performance of companies in twelve industries. As a result, CR-COPEC can distinguish causal sentences in various industries by taking unique narratives in each industry into consideration. We also provide an extensive analysis of how well CR-COPEC dataset is constructed and suited for classifying target sentences as causal ones with respect to industry characteristics. Our dataset and experimental codes are publicly available.
2023.10.26.19.37.07;26.10.2023;07;05;Industry;Industry 4.0, Production, Circular Economy et al.;repec;;http://nep.repec.org/rss/nep-ict.rss.xml;http://d.repec.org/n?u=RePEc:ags:iaae23:338535&r=ict;;Lence, Sergio H.Plastina, Alejandro;A Time-Series Examination of the Quality of Industry-Level U.S. Productivity Data;"A very large number of productivity analyses have focused on Total Factor Productivity (TFP), the volume of aggregate output produced per unit of aggregate input, as the measure of choice. For example, industry-level TFP data series have been widely used to investigate many important economic issues, including whether productivity gains have been concentrated in a few industries and whether such gains were linked to the use of information technology (Stiroh 2002), whether automation is labor-displacing (Autor and Salomons 2018), whether the recent rise in the capital share can be attributed to increasing automation (Aghion, Jones, and Jones 2019), how GDP growth has been impacted by sectoral trends in TFP and labor growth (Foerster et al. 2022), the contributions of individual industries to U.S. aggregate TFP growth (Jorgenson, Ho, and Samuels 2019), and the reasons for the productivity gap between Europe and the United States in the late 1990s and early 2000s (van Ark, O’Mahony and Timmer 2008). Recently, growing concerns about environmental degradation and climate change have spurred interest in “environmentally-adjusted” TFP indicators, which take into account the production of undesirable by-products and externalities, as well as how intensely natural resources are used (OECD 2020b). For the agricultural sector in particular, studies based on TFP have analyzed public investments (Fuglie, Wang, and Ball 2012; Fuglie 2018; Ortiz-Bobea et al. 2021), international trade (Garcia-Verdu et al. 2019; Yuan et al. 2021), and the design of policies aimed at decoupling productivity growth from environmental pressure (OECD 2020a), among other issues. In the United States, agricultural TFP measures have been extensively used to evaluate returns to public investments (Fuglie and Heisey 2007; Alston et al. 2011; Jin and Huffman 2016), identify the drivers of productivity growth (Capalbo 1988; Schimmelpfennig and Thirtle 1999; Huffman and Evenson 2006; Alston et al. 2010; Andersen, Alston and Pardey 2012; O’Donnell 2012, 2014; Plastina and Lence 2018), evaluate convergence in productivity across states (McCunn and Huffman 2000; Ball, Hallahan, and Nehring 2004; Poudel, Paudel, and Zilberman 2011), assess spillovers between agriculture and other sectors of the economy (Lence and Plastina 2020), and gauge the impact of weather and climate on aggregate productivity (Njuki, Bravo-Ureta, and O’Donnell 2018; Sabasi and Shumway 2018; Chambers and Pieralli 2020; Ortiz-Bobea, Knippenberg, and Chambers 2018; Plastina, Lence, and Ortiz-Bobea 2021; Ortiz-Bobea et al. 2021). Given the vast literature that has applied TFP to analyze issues concerning productivity, it is not surprising that significant efforts have been devoted to the development of proper measures of the individual components of TFP (OECD 2001; Fuglie, Wang, and Ball 2012; Fuglie 2015; Shumway et al. 2017; USDA-ERS 2021), as well as to the evaluation of the relative merits of alternative aggregation methods (Szulc 1964; Eltetö and Köves 1964; Jorgenson and Griliches 1967; Caves, Christensen, and Diewert 1982a, 1982b; Bjurek 1996; Balk and Althin 1996; O’Donnell 2012, 2016; Färe and Zelenyuk 2021). Contrastingly, there has been a dearth of studies exploring the quality of real-world TFP data series. Interestingly, studies analyzing productivity usually rely on a single source of TFP data, even in cases where more TFP sources are available. Typically, no robustness analyses are conducted to assess the extent to which inferences hold using alternative TFP data sources. Implicitly, such studies assume that the underlying TFP data being used is of sufficiently high quality to yield valid inferences. However, Alston (2018) and Andersen, Alston, and Pardey (2011) --among the few studies analyzing more than a single TFP source-- provide evidence that calls this assumption into question. The lack of studies concerning the quality of real-world TFP series provides the main motivation of the present investigation. We contribute to the literature by examining the industry-level TFP series for the United States obtained from three alternative sources, namely, (1) Jorgenson, Ho, and Samuels (JHS), (2) the U.S. Bureau of Labor Statistics (BLS), and (3) the U.S. Bureau of Economic Analysis (BEA). These three sources are of special interest because they are highly regarded and their series have been used extensively by researchers to analyze productivity (e.g., Stiroh 2002, Autor and Salomons 2018, Aghion, Jones, and Jones 2019, Foerster et al. 2022, Jorgenson, Ho, and Samuels 2019, van Ark, O’Mahony and Timmer 2008). Besides providing an empirical assessment of the relative quality of the aforementioned series, our study contributes to the literature by proposing a general method to examine the quality of alternative time series reportedly measuring the TFP of a particular entity or sector. The main goal of our study is to spur interest in the exploration of the quality of real-world TFP data series, with the aim of finding ways to enhance them and uncovering series whose quality may be deemed questionable. Our preliminary results show that, out of the 61 industry series for which TFP data from different sources are being compared, between 34 (for JHS vs. BEA) and 46 (for BEA vs. BLS) industries have inconsistent series across sources. In other words, only 31% to 64% of the industries have TFP data consistent between source pairs. These results strongly suggest that empirical analyses based on a single data source may not be sufficiently robust to draw strong inferences and implications. The results also demonstrate the need to devote greater attention to improving the reliability of TFP data."
2023.10.26.19.37.08;26.10.2023;08;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;repec;;http://nep.repec.org/rss/nep-ict.rss.xml;http://d.repec.org/n?u=RePEc:hal:journl:hal-04194657&r=ict;;Taoufiq DadouchBouchra BennaniMalika Haoucha;Consumer Acceptance of Mobile Shopping Apps, From Basic Apps to AI-Conversational Apps: A Literature Review;"The rapid proliferation of Digital marketing, due to recent digital transformation, has been accentuated by the effects of the Covid-19 pandemic. This can be noticed with changes in customer shopping behavior while adopting various digital marketing tools such as social media, E & M-commerce, and very recently AI enablers such as conversational agents/apps (Virtual Assistants & Chatbots). The purpose of this paper is to present some literature findings on consumer behavior toward mobile shopping via AI-Conversational-apps (Virtual Assistants & Chatbots), as compared to Mobile basic apps. Indeed, Mobile Shopping via AI-Conversational apps and their consumer acceptance behavior have become an important research issue worldwide in terms of involved predictors, theories, and methodologies. In summary, the literature showed that Anthropomorphism Construct (i.e., the degree to which a user perceives AI-Conversational apps to be humanlike) emerged as the primary additional predictor for acceptance of M-Shopping via AI-Conversational apps (AI-CA), in addition to mobile primary apps determinants. These determinants consist of utilitarian, hedonic & social antecedents adapted mainly from the UTAUT2 model (Unified theory of acceptance & use of technology), including mainly; performance expectation & effort expectation, hedonic motivation, social influence, and facilitating conditions. Literature findings also clarified the lack & importance of multimarket & multicultural research on M-Shopping apps' acceptance (mainly AI-CA). Indeed, not only developed markets but also developing ones, have seen surging rates of smartphone penetration conditions & mobile internet connectivity, along with changing consumer behaviors and dominating M-Shopping-apps activities. This offers great potential for research on M-Shopping-AI-CA acceptance behaviors in such developing countries, mainly in Morocco."
2023.10.26.19.37.09;26.10.2023;09;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;arxiv;2310.16409;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.16409.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"">Dui Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hou_X/0/1/0/all/0/1"">Xiangyu Hou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1"">Xiaohui Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1"">Bo Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1"">Renbing Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xue_D/0/1/0/all/0/1"">Daiyue Xue</a>";Dui Wang,Xiangyu Hou,Xiaohui Yang,Bo Zhang,Renbing Chen,Daiyue Xue;Multiple Key-value Strategy in Recommendation Systems Incorporating Large Language Model.;Recommendation system (RS) plays significant roles in matching users information needs for Internet applications, and it usually utilizes the vanilla neural network as the backbone to handle embedding details. Recently, the large language model (LLM) has exhibited emergent abilities and achieved great breakthroughs both in the CV and NLP communities. Thus, it is logical to incorporate RS with LLM better, which has become an emerging research direction. Although some existing works have made their contributions to this issue, they mainly consider the single key situation (e.g. historical interactions), especially in sequential recommendation. The situation of multiple key-value data is simply neglected. This significant scenario is mainstream in real practical applications, where the information of users (e.g. age, occupation, etc) and items (e.g. title, category, etc) has more than one key. Therefore, we aim to implement sequential recommendations based on multiple key-value data by incorporating RS with LLM. In particular, we instruct tuning a prevalent open-source LLM (Llama 7B) in order to inject domain knowledge of RS into the pre-trained LLM. Since we adopt multiple key-value strategies, LLM is hard to learn well among these keys. Thus the general and innovative shuffle and mask strategies, as an innovative manner of data argument, are designed. To demonstrate the effectiveness of our approach, extensive experiments are conducted on the popular and suitable dataset MovieLens which contains multiple keys-value. The experimental results demonstrate that our approach can nicely and effectively complete this challenging issue.
2023.10.26.19.37.10;26.10.2023;10;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;arxiv;2310.16566;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.16566.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"">Chengpeng Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1"">Zhengyi Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"">Jizhi Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"">Jiancan Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"">Dingxian Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1"">Xiangnan He</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"">Xiang Wang</a>";Chengpeng Li,Zhengyi Yang,Jizhi Zhang,Jiancan Wu,Dingxian Wang,Xiangnan He,Xiang Wang;Model-enhanced Contrastive Reinforcement Learning for Sequential Recommendation.;Reinforcement learning (RL) has been widely applied in recommendation systems due to its potential in optimizing the long-term engagement of users. From the perspective of RL, recommendation can be formulated as a Markov decision process (MDP), where recommendation system (agent) can interact with users (environment) and acquire feedback (reward signals).However, it is impractical to conduct online interactions with the concern on user experience and implementation complexity, and we can only train RL recommenders with offline datasets containing limited reward signals and state transitions. Therefore, the data sparsity issue of reward signals and state transitions is very severe, while it has long been overlooked by existing RL recommenders.Worse still, RL methods learn through the trial-and-error mode, but negative feedback cannot be obtained in implicit feedback recommendation tasks, which aggravates the overestimation problem of offline RL recommender. To address these challenges, we propose a novel RL recommender named model-enhanced contrastive reinforcement learning (MCRL). On the one hand, we learn a value function to estimate the long-term engagement of users, together with a conservative value learning mechanism to alleviate the overestimation problem.On the other hand, we construct some positive and negative state-action pairs to model the reward function and state transition function with contrastive learning to exploit the internal structure information of MDP. Experiments demonstrate that the proposed method significantly outperforms existing offline RL and self-supervised RL methods with different representative backbone networks on two real-world datasets.
2023.10.26.19.37.11;26.10.2023;11;15;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1662/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI;Large language models have proliferated across multiple domains in as short period of time. There is however hesitation in the medical and healthcare domain towards their adoption because of issues like factuality, coherence, and hallucinations. Give the high stakes nature of healthcare, many researchers have even cautioned against its usage until these issues are resolved. The key to the implementation and deployment of LLMs in healthcare is to make these models trustworthy, transparent (as much possible) and explainable. In this paper we describe the key elements in creating reliable, trustworthy, and unbiased models as a necessary condition for their adoption in healthcare. Specifically we focus on the quantification, validation, and mitigation of hallucinations in the context in healthcare. Lastly, we discuss how the future of LLMs in healthcare may look like.
2023.10.26.19.37.12;26.10.2023;12;15;Health;Medical, Health Care, Pharmacy et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/the-impact-of-large-language-models-on-medical-text-analysis/;;;The Impact of Large Language Models on Medical Text Analysis;This article delves into the realm of LLMs in the context of text-based medical applications and explores how these powerful AI models are revolutionizing the healthcare industry. ...
2023.10.26.19.37.13;26.10.2023;13;18;AgriCulture;Agriculture et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1697/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Combining AI Tools with Non-destructive Technologies for Crop-based Food Safety: A Comprehensive Review;On a global scale, food safety and security aspects entail to be considered throughout the farm to fork continuum considering food’s supply chain. Generally, the agri-food system is a multiplex network of interconnected features and processes, with a hard predictive rate, where maintaining the food’s safety is an indispensable element and is part of the Sustainable Development Goals (SDGs). It has led the scientific community to develop advanced applied analytical methods, such as Machine learning (ML) and Deep Learning (DL) techniques applied for assessing foodborne diseases. The main objective of this paper is to contribute to the development of the consensus version of ongoing research about the application of artificial intelligence tools in the domain of food-crops safety from an analytical point of view. Writing a comprehensive review for a more specific topic can also be challenging, especially when searching within the literature. To our knowledge, this review is the first to address this issue. This work consisted of conducting a unique and exhaustive study of the literature, using our TriScope Keywords-based Synthesis methodology. All available literature related to our topic was investigated according to our criteria of Inclusion and Exclusion. The final count of data papers was subject to deep reading and analysis to extract the necessary information to answer our research questions. Although many studies have been conducted, limited attention has been paid to outlining the applications of AI tools combined with analytical strategies for crop-based food safety specifically.
2023.10.25.16.06.01;25.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.15780;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.15780.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zhe Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1"">Chunyang Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Junjie Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1"">Mengzhuo Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1"">Boyu Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Che_X/0/1/0/all/0/1"">Xing Che</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"">Dandan Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1"">Qing Wang</a>";Zhe Liu,Chunyang Chen,Junjie Wang,Mengzhuo Chen,Boyu Wu,Xing Che,Dandan Wang,Qing Wang;Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions.;Automated Graphical User Interface (GUI) testing plays a crucial role in ensuring app quality, especially as mobile applications have become an integral part of our daily lives. Despite the growing popularity of learning-based techniques in automated GUI testing due to their ability to generate human-like interactions, they still suffer from several limitations, such as low testing coverage, inadequate generalization capabilities, and heavy reliance on training data. Inspired by the success of Large Language Models (LLMs) like ChatGPT in natural language understanding and question answering, we formulate the mobile GUI testing problem as a Q&A task. We propose GPTDroid, asking LLM to chat with the mobile apps by passing the GUI page information to LLM to elicit testing scripts, and executing them to keep passing the app feedback to LLM, iterating the whole process. Within this framework, we have also introduced a functionality-aware memory prompting mechanism that equips the LLM with the ability to retain testing knowledge of the whole process and conduct long-term, functionality-based reasoning to guide exploration. We evaluate it on 93 apps from Google Play and demonstrate that it outperforms the best baseline by 32% in activity coverage, and detects 31% more bugs at a faster rate. Moreover, GPTDroid identify 53 new bugs on Google Play, of which 35 have been confirmed and fixed.
2023.10.25.16.06.02;25.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2210.03116;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2210.03116.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1"">Daohan Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Sheng-Yu Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kumari_N/0/1/0/all/0/1"">Nupur Kumari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Agarwal_R/0/1/0/all/0/1"">Rohan Agarwal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1"">Mia Tang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1"">David Bau</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1"">Jun-Yan Zhu</a>";Daohan Lu,Sheng-Yu Wang,Nupur Kumari,Rohan Agarwal,Mia Tang,David Bau,Jun-Yan Zhu;Content-Based Search for Deep Generative Models.;The growing proliferation of customized and pretrained generative models has made it infeasible for a user to be fully cognizant of every model in existence. To address this need, we introduce the task of content-based model search: given a query and a large set of generative models, finding the models that best match the query. As each generative model produces a distribution of images, we formulate the search task as an optimization problem to select the model with the highest probability of generating similar content as the query. We introduce a formulation to approximate this probability given the query from different modalities, e.g., image, sketch, and text. Furthermore, we propose a contrastive learning framework for model retrieval, which learns to adapt features for various query modalities. We demonstrate that our method outperforms several baselines on Generative Model Zoo, a new benchmark we create for the model retrieval task.
2023.10.25.16.06.03;25.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.15455;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.15455.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1"">Yuwen Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tong_Z/0/1/0/all/0/1"">Ziang Tong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1"">Qinyi Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1"">Chengzhi Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1"">Toby Jia-Jun Li</a>";Yuwen Lu,Ziang Tong,Qinyi Zhao,Chengzhi Zhang,Toby Jia-Jun Li;UI Layout Generation with LLMs Guided by UI Grammar.;The recent advances in Large Language Models (LLMs) have stimulated interest among researchers and industry professionals, particularly in their application to tasks concerning mobile user interfaces (UIs). This position paper investigates the use of LLMs for UI layout generation. Central to our exploration is the introduction of UI grammar -- a novel approach we proposed to represent the hierarchical structure inherent in UI screens. The aim of this approach is to guide the generative capacities of LLMs more effectively and improve the explainability and controllability of the process. Initial experiments conducted with GPT-4 showed the promising capability of LLMs to produce high-quality user interfaces via in-context learning. Furthermore, our preliminary comparative study suggested the potential of the grammar-based approach in improving the quality of generative results in specific aspects.
2023.10.25.16.06.04;25.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.15205;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.15205.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1"">Wei Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1"">Qiushi Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Long_Z/0/1/0/all/0/1"">Zefei Long</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"">Xianyin Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1"">Zhongtian Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1"">Bingxuan Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Siyuan Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1"">Jiarong Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1"">Xiang Bai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1"">Xuanjing Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1"">Zhongyu Wei</a>";Wei Chen,Qiushi Wang,Zefei Long,Xianyin Zhang,Zhongtian Lu,Bingxuan Li,Siyuan Wang,Jiarong Xu,Xiang Bai,Xuanjing Huang,Zhongyu Wei;DISC-FinLLM: A Chinese Financial Large Language Model based on Multiple Experts Fine-tuning.;We propose Multiple Experts Fine-tuning Framework to build a financial large language model (LLM), DISC-FinLLM. Our methodology improves general LLMs by endowing them with multi-turn question answering abilities, domain text processing capabilities, mathematical computation skills, and retrieval-enhanced generation capabilities. We build a financial instruction-tuning dataset named DISC-FIN-SFT, including instruction samples of four categories (consulting, NLP tasks, computing and retrieval-augmented generation). Evaluations conducted on multiple benchmarks demonstrate that our model performs better than baseline models in various financial scenarios. Further resources can be found at https://github.com/FudanDISC/DISC-FinLLM.
2023.10.25.16.06.05;25.10.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/how-to-build-a-multi-modal-search-app-with-chroma/;;;How to Build a Multi-Modal Search App with Chroma?;Have you ever wondered how our intricate brains process the world? While the brain’s inner workings remain a mystery, we can liken it to a versatile neural network. Thanks to electrochemical signals, it handles various data types – audio, visuals, smells, tastes, and touch. As AI advances, multi-modal models emerge, revolutionizing search capabilities. This innovation opens up possibilities, enhancing search accuracy and relevance. Discover the fascinating realm of multi-modal search. ...
2023.10.25.16.06.06;25.10.2023;06;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2212.06808;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2212.06808.pdf;" <a href=""http://arxiv.org/find/math/1/au:+Jalan_A/0/1/0/all/0/1"">Akhil Jalan</a>, <a href=""http://arxiv.org/find/math/1/au:+Chakrabarti_D/0/1/0/all/0/1"">Deepayan Chakrabarti</a>, <a href=""http://arxiv.org/find/math/1/au:+Sarkar_P/0/1/0/all/0/1"">Purnamrita Sarkar</a>";Akhil Jalan,Deepayan Chakrabarti,Purnamrita Sarkar;Incentive-Aware Models of Financial Networks.;"Financial networks help firms manage risk but also enable financial shocks to spread. Despite their importance, existing models of financial networks have several limitations. Prior works often consider a static network with a simple structure (e.g., a ring) or a model that assumes conditional independence between edges. We propose a new model where the network emerges from interactions between heterogeneous utility-maximizing firms. Edges correspond to contract agreements between pairs of firms, with the contract size being the edge weight. We show that, almost always, there is a unique ""stable network."" All edge weights in this stable network depend on all firms' beliefs. Furthermore, firms can find the stable network via iterative pairwise negotiations. When beliefs change, the stable network changes. We show that under realistic settings, a regulator cannot pin down the changed beliefs that caused the network changes. Also, each firm can use its view of the network to inform its beliefs. For instance, it can detect outlier firms whose beliefs deviate from their peers. But it cannot identify the deviant belief: increased risk-seeking is indistinguishable from increased expected profits. Seemingly minor news may settle the dilemma, triggering significant changes in the network."
2023.10.25.16.06.07;25.10.2023;07;03;Finance;Finance, DeFi, Insurance, Banking et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/how-to-optimize-revenues-using-dynamic-pricing/;;;How to Optimize Revenues Using Dynamic Pricing?;Uber/Ola peak hour prices are higher than regular fares. In IRCTC, Rajdhani prices increase are booking rate increases, and in Amazon, prices for the exact product change multiple times. Who decides when to change these prices or to what extent? Who decides the right price at the right time? The answers to these questions fall under the realm of Dynamic Pricing. This article provides beginners with resources and theoretical understanding to build a basic Dynamic pricing algorithm. ...
2023.10.25.16.06.08;25.10.2023;08;09;Human;Human Resource, Personal Assistance et al.;repec;;http://nep.repec.org/rss/nep-bec.rss.xml;http://d.repec.org/n?u=RePEc:iza:izadps:dp16413&r=bec;;Zubanov, NickShakina, Elena;Performance Costs and Benefits of Collective Turnover: A Theory-Driven Measurement Framework and Applications;"Building on job matching theory, we model the effect of collective turnover on workplace performance as the total of its costs from operational disruptions and benefits from better job-worker match quality, each component varying with turnover level. The resulting theoretical turnover-performance relationship is generally curvilinear, nesting all the hitherto known patterns – linear, ""U-shape"" and ""inverted U-shape"" – as special cases, and lends itself to an empirically estimable regression model from which one can derive the implied costs and benefits of turnover. Applications to data from two retail firms reveal some benefits from turnover in one firm, and none in the other. Turnover costs exceed benefits in both firms."
2023.10.25.16.06.09;25.10.2023;09;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Toy_Matching_in_Amazon_E-commerce_by_Matching_Learning/24354799;;TechRxiv RSS Feed;Toy Matching in Amazon E-commerce by Matching Learning;This project is to detect categories from the toy product description and names. The data set is an Amazon (toy) data set with manufacturer specific model, names and description of children’s toys. The expected outcome includes labeling scheme and using CRF and bi-LSTM to measure the performance of our category extraction. As for the annotation, we performed the labeling and used product description decomposed into sequence of tokens labeled with BIO encoding, and the output of learning algorithm on a product description would be a sequence of labels. Three diffrent kinds of methods are used for our task. For the first method, We tried several traditional machine learning models like svm, logistic regression, and the linear svm for the second task. Linear svm gets the highest classification accuracy. Second model is CRF with hand-crafted features. And the last model is bi-directional LSTM. Note that there are too many categories in such a small dataset, which explains why even the best model results in relatively low accuracy.
2023.10.25.16.06.10;25.10.2023;10;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.15204;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.15204.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1"">Zhou Lan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1"">Ben Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1"">Yi Feng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1"">Danhuang Dong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1"">Peng Zhang</a>";Zhou Lan,Ben Liu,Yi Feng,Danhuang Dong,Peng Zhang;Mid-Long Term Daily Electricity Consumption Forecasting Based on Piecewise Linear Regression and Dilated Causal CNN.;Daily electricity consumption forecasting is a classical problem. Existing forecasting algorithms tend to have decreased accuracy on special dates like holidays. This study decomposes the daily electricity consumption series into three components: trend, seasonal, and residual, and constructs a two-stage prediction method using piecewise linear regression as a filter and Dilated Causal CNN as a predictor. The specific steps involve setting breakpoints on the time axis and fitting the piecewise linear regression model with one-hot encoded information such as month, weekday, and holidays. For the challenging prediction of the Spring Festival, distance is introduced as a variable using a third-degree polynomial form in the model. The residual sequence obtained in the previous step is modeled using Dilated Causal CNN, and the final prediction of daily electricity consumption is the sum of the two-stage predictions. Experimental results demonstrate that this method achieves higher accuracy compared to existing approaches.
2023.10.25.16.06.11;25.10.2023;11;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.15572;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.15572.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jeynes_J/0/1/0/all/0/1"">J. Charles G. Jeynes</a>, <a href=""http://arxiv.org/find/cs/1/au:+James_T/0/1/0/all/0/1"">Tim James</a>, <a href=""http://arxiv.org/find/cs/1/au:+Corney_M/0/1/0/all/0/1"">Matthew Corney</a>";J. Charles G. Jeynes,Tim James,Matthew Corney;Natural Language Processing for Drug Discovery Knowledge Graphs: promises and pitfalls.;Building and analysing knowledge graphs (KGs) to aid drug discovery is a topical area of research. A salient feature of KGs is their ability to combine many heterogeneous data sources in a format that facilitates discovering connections. The utility of KGs has been exemplified in areas such as drug repurposing, with insights made through manual exploration and modelling of the data. In this article, we discuss promises and pitfalls of using natural language processing (NLP) to mine unstructured text typically from scientific literature as a data source for KGs. This draws on our experience of initially parsing structured data sources such as ChEMBL as the basis for data within a KG, and then enriching or expanding upon them using NLP. The fundamental promise of NLP for KGs is the automated extraction of data from millions of documents a task practically impossible to do via human curation alone. However, there are many potential pitfalls in NLP-KG pipelines such as incorrect named entity recognition and ontology linking all of which could ultimately lead to erroneous inferences and conclusions.
2023.10.25.16.06.12;25.10.2023;12;15;Health;Medical, Health Care, Pharmacy et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/The_Future_of_Medicine_Large_Language_Models_Redefining_Healthcare_Dynamics/24354451;;TechRxiv RSS Feed;The Future of Medicine: Large Language Models Redefining Healthcare Dynamics;The medical care industry is on the cusp of an extraordinary period, with large language models (LLMs) arising as incredible assets for reclassifying medical care elements. This paper investigates the potential and effect of LLMs in different parts of medication, including diagnostics, patient consideration, drug revelation, and medical services organization. It dives into the open doors and difficulties introduced by LLMs, accentuating the moral contemplations and the requirement for capable reception. By looking at late turns of events and contextual investigations, this paper offers a brief look into the developing scene of medical services, where LLMs are ready to assume a focal part in reshaping the eventual fate of medication.
2023.10.25.16.06.13;25.10.2023;13;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.15472;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.15472.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ness_M/0/1/0/all/0/1"">Mike Van Ness</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bosschieter_T/0/1/0/all/0/1"">Tomas Bosschieter</a>, <a href=""http://arxiv.org/find/cs/1/au:+Din_N/0/1/0/all/0/1"">Natasha Din</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ambrosy_A/0/1/0/all/0/1"">Andrew Ambrosy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sandhu_A/0/1/0/all/0/1"">Alexander Sandhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Udell_M/0/1/0/all/0/1"">Madeleine Udell</a>";Mike Van Ness,Tomas Bosschieter,Natasha Din,Andrew Ambrosy,Alexander Sandhu,Madeleine Udell;Interpretable Survival Analysis for Heart Failure Risk Prediction.;Survival analysis, or time-to-event analysis, is an important and widespread problem in healthcare research. Medical research has traditionally relied on Cox models for survival analysis, due to their simplicity and interpretability. Cox models assume a log-linear hazard function as well as proportional hazards over time, and can perform poorly when these assumptions fail. Newer survival models based on machine learning avoid these assumptions and offer improved accuracy, yet sometimes at the expense of model interpretability, which is vital for clinical use. We propose a novel survival analysis pipeline that is both interpretable and competitive with state-of-the-art survival models. Specifically, we use an improved version of survival stacking to transform a survival analysis problem to a classification problem, ControlBurn to perform feature selection, and Explainable Boosting Machines to generate interpretable predictions. To evaluate our pipeline, we predict risk of heart failure using a large-scale EHR database. Our pipeline achieves state-of-the-art performance and provides interesting and novel insights about risk factors for heart failure.
2023.10.25.16.06.14;25.10.2023;14;16;Legal;Legal, Law, Contracting et al.;arxiv;2310.15799;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.15799.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1"">Sreyan Ghosh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Evuru_C/0/1/0/all/0/1"">Chandra Kiran Evuru</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1"">Sonal Kumar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ramaneswaran_S/0/1/0/all/0/1"">S Ramaneswaran</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sakshi_S/0/1/0/all/0/1"">S Sakshi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tyagi_U/0/1/0/all/0/1"">Utkarsh Tyagi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1"">Dinesh Manocha</a>";Sreyan Ghosh,Chandra Kiran Evuru,Sonal Kumar,S Ramaneswaran,S Sakshi,Utkarsh Tyagi,Dinesh Manocha;DALE: Generative Data Augmentation for Low-Resource Legal NLP.;We present DALE, a novel and effective generative Data Augmentation framework for low-resource LEgal NLP. DALE addresses the challenges existing frameworks pose in generating effective data augmentations of legal documents - legal language, with its specialized vocabulary and complex semantics, morphology, and syntax, does not benefit from data augmentations that merely rephrase the source sentence. To address this, DALE, built on an Encoder-Decoder Language Model, is pre-trained on a novel unsupervised text denoising objective based on selective masking - our masking strategy exploits the domain-specific language characteristics of templatized legal documents to mask collocated spans of text. Denoising these spans helps DALE acquire knowledge about legal concepts, principles, and language usage. Consequently, it develops the ability to generate coherent and diverse augmentations with novel contexts. Finally, DALE performs conditional generation to generate synthetic augmentations for low-resource Legal NLP tasks. We demonstrate the effectiveness of DALE on 13 datasets spanning 6 tasks and 4 low-resource settings. DALE outperforms all our baselines, including LLMs, qualitatively and quantitatively, with improvements of 1%-50%.
2023.10.24.18.52.01;24.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.12989;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.12989.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"">Yikuan Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"">Hanyin Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yerebakan_H/0/1/0/all/0/1"">Halid Yerebakan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shinagawa_Y/0/1/0/all/0/1"">Yoshihisa Shinagawa</a>, <a href=""http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1"">Yuan Luo</a>";Yikuan Li,Hanyin Wang,Halid Yerebakan,Yoshihisa Shinagawa,Yuan Luo;Enhancing Health Data Interoperability with Large Language Models: A FHIR Study.;In this study, we investigated the ability of the large language model (LLM) to enhance healthcare data interoperability. We leveraged the LLM to convert clinical texts into their corresponding FHIR resources. Our experiments, conducted on 3,671 snippets of clinical text, demonstrated that the LLM not only streamlines the multi-step natural language processing and human calibration processes but also achieves an exceptional accuracy rate of over 90% in exact matches when compared to human annotations.
2023.10.24.18.52.02;24.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.13540;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.13540.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Qu_Z/0/1/0/all/0/1"">Zekai Qu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1"">Ruobing Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1"">Chaojun Xiao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1"">Yuan Yao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zhiyuan Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lian_F/0/1/0/all/0/1"">Fengzong Lian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1"">Zhanhui Kang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1"">Jie Zhou</a>";Zekai Qu,Ruobing Xie,Chaojun Xiao,Yuan Yao,Zhiyuan Liu,Fengzong Lian,Zhanhui Kang,Jie Zhou;Thoroughly Modeling Multi-domain Pre-trained Recommendation as Language.;With the thriving of pre-trained language model (PLM) widely verified in various of NLP tasks, pioneer efforts attempt to explore the possible cooperation of the general textual information in PLM with the personalized behavioral information in user historical behavior sequences to enhance sequential recommendation (SR). However, despite the commonalities of input format and task goal, there are huge gaps between the behavioral and textual information, which obstruct thoroughly modeling SR as language modeling via PLM. To bridge the gap, we propose a novel Unified pre-trained language model enhanced sequential recommendation (UPSR), aiming to build a unified pre-trained recommendation model for multi-domain recommendation tasks. We formally design five key indicators, namely naturalness, domain consistency, informativeness, noise & ambiguity, and text length, to guide the text->item adaptation and behavior sequence->text sequence adaptation differently for pre-training and fine-tuning stages, which are essential but under-explored by previous works. In experiments, we conduct extensive evaluations on seven datasets with both tuning and zero-shot settings and achieve the overall best performance. Comprehensive model analyses also provide valuable insights for behavior modeling via PLM, shedding light on large pre-trained recommendation models. The source codes will be released in the future.
2023.10.24.18.52.03;24.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.13229;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.13229.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1"">Jae Yong Lee</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1"">Sungmin Kang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1"">Juyeon Yoon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1"">Shin Yoo</a>";Jae Yong Lee,Sungmin Kang,Juyeon Yoon,Shin Yoo;The GitHub Recent Bugs Dataset for Evaluating LLM-based Debugging Applications.;Large Language Models (LLMs) have demonstrated strong natural language processing and code synthesis capabilities, which has led to their rapid adoption in software engineering applications. However, details about LLM training data are often not made public, which has caused concern as to whether existing bug benchmarks are included. In lieu of the training data for the popular GPT models, we examine the training data of the open-source LLM StarCoder, and find it likely that data from the widely used Defects4J benchmark was included, raising the possibility of its inclusion in GPT training data as well. This makes it difficult to tell how well LLM-based results on Defects4J would generalize, as for any results it would be unclear whether a technique's performance is due to LLM generalization or memorization. To remedy this issue and facilitate continued research on LLM-based SE, we present the GitHub Recent Bugs (GHRB) dataset, which includes 76 real-world Java bugs that were gathered after the OpenAI data cut-off point.
2023.10.24.18.52.04;24.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2303.06573;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2303.06573.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Mao_K/0/1/0/all/0/1"">Kelong Mao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1"">Zhicheng Dou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mo_F/0/1/0/all/0/1"">Fengran Mo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1"">Jiewen Hou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"">Haonan Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1"">Hongjin Qian</a>";Kelong Mao,Zhicheng Dou,Fengran Mo,Jiewen Hou,Haonan Chen,Hongjin Qian;Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search.;Precisely understanding users' contextual search intent has been an important challenge for conversational search. As conversational search sessions are much more diverse and long-tailed, existing methods trained on limited data still show unsatisfactory effectiveness and robustness to handle real conversational search scenarios. Recently, large language models (LLMs) have demonstrated amazing capabilities for text generation and conversation understanding. In this work, we present a simple yet effective prompting framework, called LLM4CS, to leverage LLMs as a text-based search intent interpreter to help conversational search. Under this framework, we explore three prompting methods to generate multiple query rewrites and hypothetical responses, and propose to aggregate them into an integrated representation that can robustly represent the user's real contextual search intent. Extensive automatic evaluations and human evaluations on three widely used conversational search benchmarks, including CAsT-19, CAsT-20, and CAsT-21, demonstrate the remarkable performance of our simple LLM4CS framework compared with existing methods and even using human rewrites. Our findings provide important evidence to better understand and leverage LLMs for conversational search.
2023.10.24.18.52.05;24.10.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;turingpost;;;https://www.turingpost.com/p/fmusecases;;;Use Cases for Foundation Models and Key Benefits;Let's dig deeper into the world of foundation models and find out what makes them such game-changers. We also take a look at the cases when traditional ML is still the king.
2023.10.24.18.52.06;24.10.2023;06;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.13312;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.13312.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Choe_J/0/1/0/all/0/1"">Jaeyoung Choe</a>, <a href=""http://arxiv.org/find/cs/1/au:+Noh_K/0/1/0/all/0/1"">Keonwoong Noh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1"">Nayeon Kim</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1"">Seyun Ahn</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jung_W/0/1/0/all/0/1"">Woohwan Jung</a>";Jaeyoung Choe,Keonwoong Noh,Nayeon Kim,Seyun Ahn,Woohwan Jung;Exploring the Impact of Corpus Diversity on Financial Pretrained Language Models.;Over the past few years, various domain-specific pretrained language models (PLMs) have been proposed and have outperformed general-domain PLMs in specialized areas such as biomedical, scientific, and clinical domains. In addition, financial PLMs have been studied because of the high economic impact of financial data analysis. However, we found that financial PLMs were not pretrained on sufficiently diverse financial data. This lack of diverse training data leads to a subpar generalization performance, resulting in general-purpose PLMs, including BERT, often outperforming financial PLMs on many downstream tasks. To address this issue, we collected a broad range of financial corpus and trained the Financial Language Model (FiLM) on these diverse datasets. Our experimental results confirm that FiLM outperforms not only existing financial PLMs but also general domain PLMs. Furthermore, we provide empirical evidence that this improvement can be achieved even for unseen corpus groups.
2023.10.24.18.52.07;24.10.2023;07;04;Supply Chain;Logistics, Supply Chains, Transportation et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1449/v1;;Preprints.org - The Multidisciplinary Preprint Platform;A City Logistics Distribution Model: A Physical Internet Approach;As a new logistics system, Physical Internet (PI) provides a solution to cope with the continuous rise of urban logistics demand by exploring same-level and cross-level paths and flattening. This research suggests a PI-based urban logistics distribution cost minimization model based on the examination of the primary elements influencing PI distribution, intending to maintain the logistic transportation process' integrity. This proposed model enhances the flexibility of goods operation and reduces the global cost of logistics distribution using the interconnected and open PI logistics distribution mode. The experimental results show that the distribution cost of the PI logistics model is significantly better than that of a traditional logistics model. The elastic and cost advantages relatively grow as the infrastructure for distribution scales up and the interruptions from emergencies occur.
2023.10.24.18.52.08;24.10.2023;08;05;Industry;Industry 4.0, Production, Circular Economy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1493/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Research on the Digital Twin System of the Centring Process for High-Precision Lens;In the manufacturing of optical lenses, the lack of digital monitoring and inspection for centring processing not only results in product consistency not being guaranteed but also leads to inefficiency in processing. A centring processing digital twin system is proposed to address the problems of low virtual visualization and insufficient monitoring capability of centring processing of high-precision optical components. The layered architecture of the system is determined based on the five-dimensional model of the digital twin, coupled with a dimension-driven geometric model and a physical model that integrates data and turning mechanisms to improve the fidelity and interactivity of the virtual model of the centring lathe. The fusion of heterogeneous data from multiple sources in the centring machining process at the semantic and physical levels is realized by using an information model and an OPC UA-based data interaction method. The VMD-GRU method based on feature fusion is used to monitor the key components of the centring lathe. Finally, the feasibility and effectiveness of the proposed method are verified by a case study of the development of a digital twin system for centring lathe, which provides a reference for the digitization and intelligence of the machining process of high-precision optical components.
2023.10.24.18.52.09;24.10.2023;09;05;Industry;Industry 4.0, Production, Circular Economy et al.;towardsdatascience;;;https://towardsdatascience.com/black-box-chemical-process-optimization-5d7cbb9be0cf?source=rss----7f60cf5620c9---4;;;Black-Box Chemical Process Optimization;This article, however, is devoted to an alternative strategy, namely Bayesian optimization, which is related to reinforcement learning and has been successfully applied to the design of materials, chemical reactions, and drugs. It offers advantages like higher flexibility of models and processing of multi-fidelity information. The latter refers to the fact that mixed-quality data from different sources can be used for optimization, for example when physical models are at least rudimentarily available. ...
2023.10.24.18.52.10;24.10.2023;10;09;Human;Human Resource, Personal Assistance et al.;arxiv;2209.05112;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2209.05112.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Mashayekhi_Y/0/1/0/all/0/1"">Yoosof Mashayekhi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1"">Nan Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kang_B/0/1/0/all/0/1"">Bo Kang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lijffijt_J/0/1/0/all/0/1"">Jefrey Lijffijt</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bie_T/0/1/0/all/0/1"">Tijl De Bie</a>";Yoosof Mashayekhi,Nan Li,Bo Kang,Jefrey Lijffijt,Tijl De Bie;A challenge-based survey of e-recruitment recommendation systems.;E-recruitment recommendation systems recommend jobs to job seekers and job seekers to recruiters. The recommendations are generated based on the suitability of the job seekers for the positions as well as the job seekers' and the recruiters' preferences. Therefore, e-recruitment recommendation systems could greatly impact job seekers' careers. Moreover, by affecting the hiring processes of the companies, e-recruitment recommendation systems play an important role in shaping the companies' competitive edge in the market. Hence, the domain of e-recruitment recommendation deserves specific attention. Existing surveys on this topic tend to discuss past studies from the algorithmic perspective, e.g., by categorizing them into collaborative filtering, content based, and hybrid methods. This survey, instead, takes a complementary, challenge-based approach, which we believe might be more practical to developers facing a concrete e-recruitment design task with a specific set of challenges, as well as to researchers looking for impactful research projects in this domain. We first identify the main challenges in the e-recruitment recommendation research. Next, we discuss how those challenges have been studied in the literature. Finally, we provide future research directions that we consider promising in the e-recruitment recommendation domain.
2023.10.24.18.52.11;24.10.2023;11;10;Commerce;Commerce, Trading, Sales, Retail, Recommendation et al.;arxiv;2310.13198;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.13198.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Togru_S/0/1/0/all/0/1"">Said Togru</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1"">Jenny Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Moldovan_M/0/1/0/all/0/1"">Marco Moldovan</a>";Said Togru,Jenny Huang,Marco Moldovan;A Car Model Identification System for Streamlining the Automobile Sales Process.;This project presents an automated solution for the efficient identification of car models and makes from images, aimed at streamlining the vehicle listing process on online car-selling platforms. Through a thorough exploration encompassing various efficient network architectures including Convolutional Neural Networks (CNNs), Vision Transformers (ViTs), and hybrid models, we achieved a notable accuracy of 81.97% employing the EfficientNet (V2 b2) architecture. To refine performance, a combination of strategies, including data augmentation, fine-tuning pretrained models, and extensive hyperparameter tuning, were applied. The trained model offers the potential for automating information extraction, promising enhanced user experiences across car-selling websites.
2023.10.24.18.52.12;24.10.2023;12;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.13577;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.13577.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1"">Ying Zhang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Yue_M/0/1/0/all/0/1"">Meng Yue</a>";Ying Zhang,Meng Yue;Cooperative Multi-Agent Deep Reinforcement Learning for Adaptive Decentralized Emergency Voltage Control.;Under voltage load shedding (UVLS) for power grid emergency control builds the last defensive perimeter to prevent cascade outages and blackouts in case of contingencies. This letter proposes a novel cooperative multi-agent deep reinforcement learning (MADRL)-based UVLS algorithm in an adaptive decentralized way. With well-designed input signals reflecting the voltage deviation, newly structured neural networks are developed as intelligent agents to obtain control actions and their probabilities to accommodate high uncertainties in volatile power system operations. Moreover, the interaction among the agents for coordinated control is implemented and refined by a state-of-the-art attention mechanism, which helps agents concentratively learn effective interacted information. The proposed method realizes decentralized coordinated control, adapting to extremely high uncertainties. Case studies on an IEEE benchmark system indicate the superior performance of the proposed algorithm.
2023.10.24.18.52.13;24.10.2023;13;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.13254;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.13254.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Jiayi Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Motoki_M/0/1/0/all/0/1"">Matthew Motoki</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1"">Baosen Zhang</a>";Jiayi Li,Matthew Motoki,Baosen Zhang;Socially Optimal Energy Usage via Adaptive Pricing.;Using price signals to coordinate the electricity consumption of a group of users has been studied extensively. Typically, a system operator broadcasts a price, and users optimizes their own actions subject to the price and internal cost functions. A central challenge is the operator's lack of knowledge of the users, since users may not want to share private information. In addition, learning algorithms are being increasingly used to load control, and users maybe unable to provide their costs in analytical form. In this paper, we develop a two time-scale incentive mechanism that alternately updates between the users and a system operator. The system operator selects a price, and the users optimize their consumption. Based on the consumption, a new price is then computed by the system operator. As long as the users can optimize their own consumption for a given price, the operator does not need to know or attempt to learn any private information of the users. We show that under a wide range of assumptions, this iterative process converges to the social welfare solution. In particular, the cost of the users need not be strictly convex and its consumption can be the output of a learning algorithm.
2023.10.24.18.52.14;24.10.2023;14;13;Mobility;Mobility, Automotive, Self Driving et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1451/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Autonomous Vehicle Decision Making with Policy Prediction for Handling a Round Intersection;Autonomous shuttles have been used as end mile solutions for smart mobility in smart cities. The urban driving conditions of smart cities with many other actors sharing the road and the presence of intersections have posed challenges to the use of autonomous shuttles. Round intersections are more challenging as it is more difficult to perceive the other vehicles in and near the intersection. Thus, this paper focuses on decision making of autonomous vehicles for handling round intersections. The round intersection is introduced first, followed by introductions of the Markov Decision Process (MDP), the Partially Observable Markov Decision Process (POMDP) and the Object Oriented Partially Observable Markov Decision Process (OOPOMDP) which are used for decision making with uncertain knowledge of the motion of the other vehicles. The Partially Observable Monte-Carlo Planning (POMCP) algorithm is used as the solution method and OOPOMDP is applied to decision making for autonomous vehicles in round intersections. Decision making is formulated first as a POMDP problem, and the penalty function is formulated and set accordingly. This is followed by improvement of decision making with policy prediction. Augmented objective state and policy-based state transition are introduced and simulations are used to demonstrate the effectiveness of the proposed method for collision free handling of round intersections by the ego vehicle.
2023.10.24.18.52.15;24.10.2023;15;14;Public Services;Public Services, Traffic et al.;arxiv;2310.12997;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.12997.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1"">Andy Xiao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Doshi_D/0/1/0/all/0/1"">Deep Doshi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"">Lihao Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gorantla_H/0/1/0/all/0/1"">Harsha Gorantla</a>, <a href=""http://arxiv.org/find/cs/1/au:+Heitzmann_T/0/1/0/all/0/1"">Thomas Heitzmann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Groth_P/0/1/0/all/0/1"">Peter Groth</a>";Andy Xiao,Deep Doshi,Lihao Wang,Harsha Gorantla,Thomas Heitzmann,Peter Groth;Parking Spot Classification based on surround view camera system.;Surround-view fisheye cameras are commonly used for near-field sensing in automated driving scenarios, including urban driving and auto valet parking. Four fisheye cameras, one on each side, are sufficient to cover 360{\deg} around the vehicle capturing the entire near-field region. Based on surround view cameras, there has been much research on parking slot detection with main focus on the occupancy status in recent years, but little work on whether the free slot is compatible with the mission of the ego vehicle or not. For instance, some spots are handicap or electric vehicles accessible only. In this paper, we tackle parking spot classification based on the surround view camera system. We adapt the object detection neural network YOLOv4 with a novel polygon bounding box model that is well-suited for various shaped parking spaces, such as slanted parking slots. To the best of our knowledge, we present the first detailed study on parking spot detection and classification on fisheye cameras for auto valet parking scenarios. The results prove that our proposed classification approach is effective to distinguish between regular, electric vehicle, and handicap parking spots.
2023.10.24.18.52.16;24.10.2023;16;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2308.06920;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06920.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1"">Rui Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1"">Hongsong Feng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1"">Guo-Wei Wei</a>";Rui Wang,Hongsong Feng,Guo-Wei Wei;ChatGPT in Drug Discovery: A Case Study on Anti-Cocaine Addiction Drug Development with Chatbots.;The birth of ChatGPT, a cutting-edge language model-based chatbot developed by OpenAI, ushered in a new era in AI. However, due to potential pitfalls, its role in rigorous scientific research is not clear yet. This paper vividly showcases its innovative application within the field of drug discovery. Focused specifically on developing anti-cocaine addiction drugs, the study employs GPT-4 as a virtual guide, offering strategic and methodological insights to researchers working on generative models for drug candidates. The primary objective is to generate optimal drug-like molecules with desired properties. By leveraging the capabilities of ChatGPT, the study introduces a novel approach to the drug discovery process. This symbiotic partnership between AI and researchers transforms how drug development is approached. Chatbots become facilitators, steering researchers towards innovative methodologies and productive paths for creating effective drug candidates. This research sheds light on the collaborative synergy between human expertise and AI assistance, wherein ChatGPT's cognitive abilities enhance the design and development of potential pharmaceutical solutions. This paper not only explores the integration of advanced AI in drug discovery but also reimagines the landscape by advocating for AI-powered chatbots as trailblazers in revolutionizing therapeutic innovation.
2023.10.24.18.52.17;24.10.2023;17;16;Legal;Legal, Law, Contracting et al.;arxiv;2310.13092;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.13092.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Barale_C/0/1/0/all/0/1"">Claire Barale</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rovatsos_M/0/1/0/all/0/1"">Michael Rovatsos</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bhuta_N/0/1/0/all/0/1"">Nehal Bhuta</a>";Claire Barale,Michael Rovatsos,Nehal Bhuta;Do Language Models Learn about Legal Entity Types during Pretraining?.;Language Models (LMs) have proven their ability to acquire diverse linguistic knowledge during the pretraining phase, potentially serving as a valuable source of incidental supervision for downstream tasks. However, there has been limited research conducted on the retrieval of domain-specific knowledge, and specifically legal knowledge. We propose to explore the task of Entity Typing, serving as a proxy for evaluating legal knowledge as an essential aspect of text comprehension, and a foundational task to numerous downstream legal NLP applications. Through systematic evaluation and analysis and two types of prompting (cloze sentences and QA-based templates) and to clarify the nature of these acquired cues, we compare diverse types and lengths of entities both general and domain-specific entities, semantics or syntax signals, and different LM pretraining corpus (generic and legal-oriented) and architectures (encoder BERT-based and decoder-only with Llama2). We show that (1) Llama2 performs well on certain entities and exhibits potential for substantial improvement with optimized prompt templates, (2) law-oriented LMs show inconsistent performance, possibly due to variations in their training corpus, (3) LMs demonstrate the ability to type entities even in the case of multi-token entities, (4) all models struggle with entities belonging to sub-domains of the law (5) Llama2 appears to frequently overlook syntactic cues, a shortcoming less present in BERT-based architectures.
2023.10.21.14.45.01;21.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.12664;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.12664.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1"">Yue Guo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1"">Zian Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"">Yi Yang</a>";Yue Guo,Zian Xu,Yi Yang;Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing.;The emergence of Large Language Models (LLMs), such as ChatGPT, has revolutionized general natural language preprocessing (NLP) tasks. However, their expertise in the financial domain lacks a comprehensive evaluation. To assess the ability of LLMs to solve financial NLP tasks, we present FinLMEval, a framework for Financial Language Model Evaluation, comprising nine datasets designed to evaluate the performance of language models. This study compares the performance of encoder-only language models and the decoder-only language models. Our findings reveal that while some decoder-only LLMs demonstrate notable performance across most financial tasks via zero-shot prompting, they generally lag behind the fine-tuned expert models, especially when dealing with proprietary datasets. We hope this study provides foundation evaluations for continuing efforts to build more advanced LLMs in the financial domain.
2023.10.21.14.45.02;21.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.12443;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.12443.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1"">Xiang Shi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"">Jiawei Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Yinpeng Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1"">Qikai Cheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1"">Wei Lu</a>";Xiang Shi,Jiawei Liu,Yinpeng Liu,Qikai Cheng,Wei Lu;Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher.;"The advent of Large Language Models (LLMs) has shown the potential to improve relevance and provide direct answers in web searches. However, challenges arise in validating the reliability of generated results and the credibility of contributing sources, due to the limitations of traditional information retrieval algorithms and the LLM hallucination problem. Aiming to create a ""PageRank"" for the LLM era, we strive to transform LLM into a relevant, responsible, and trustworthy searcher. We propose a novel generative retrieval framework leveraging the knowledge of LLMs to foster a direct link between queries and online sources. This framework consists of three core modules: Generator, Validator, and Optimizer, each focusing on generating trustworthy online sources, verifying source reliability, and refining unreliable sources, respectively. Extensive experiments and evaluations highlight our method's superior relevance, responsibility, and trustfulness against various SOTA methods."
2023.10.21.14.45.03;21.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/web-scraping-to-data-visuals-with-gpt-4-an-introductory-tutorial-ab18e0c1a79d?source=rss----98111c9905da---4;;;Web Scraping to Data Visuals with GPT-4: An Introductory Tutorial;From website to charts and maps in less than 15 minutes. ...
2023.10.21.14.45.04;21.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/the-untold-side-of-rag-addressing-its-challenges-in-domain-specific-searches-808956e3ecc8?source=rss----7f60cf5620c9---4;;;The Untold Side of RAG: Addressing Its Challenges in Domain-Specific Searches;Using hybrid search, hierarchical ranking and instructor embedding to address domain-specific documents that bear similarities for our RAG setup. ...
2023.10.21.14.45.05;21.10.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/synergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801?source=rss----7f60cf5620c9---4;;;Synergy of LLM and GUI, Beyond the Chatbot;Use OpenAI GPT function calling to drive your mobile app. ...
2023.10.21.14.45.06;21.10.2023;06;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;1812.00595;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/1812.00595.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Hautsch_N/0/1/0/all/0/1"">Nikolaus Hautsch</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Scheuch_C/0/1/0/all/0/1"">Christoph Scheuch</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Voigt_S/0/1/0/all/0/1"">Stefan Voigt</a>";Nikolaus Hautsch,Christoph Scheuch,Stefan Voigt;Building Trust Takes Time: Limits to Arbitrage for Blockchain-Based Assets.;A blockchain replaces central counterparties with time-consuming consensus protocols to record the transfer of ownership. This settlement latency slows cross-exchange trading, exposing arbitrageurs to price risk. Off-chain settlement, instead, exposes arbitrageurs to costly default risk. We show with Bitcoin network and order book data that cross-exchange price differences coincide with periods of high settlement latency, asset flows chase arbitrage opportunities, and price differences across exchanges with low default risk are smaller. Blockchain-based trading thus faces a dilemma: Reliable consensus protocols require time-consuming settlement latency, leading to arbitrage limits. Circumventing such arbitrage costs is possible only by reinstalling trusted intermediation, which mitigates default risk.
2023.10.21.14.45.07;21.10.2023;07;09;Human;Human Resource, Personal Assistance et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/generative-ai-and-reinforcement-learning/;;;Integrating Generative AI and Reinforcement Learning for Self-Improvement;In the ever-evolving landscape of artificial intelligence, two key players have come together to break new ground: Generative AI and Reinforcement Learning. These cutting-edge technologies, Generative AI and Reinforcement Learning, have the potential to create self-improving AI systems, taking us one step closer to realizing the dream of machines that learn and adapt autonomously. These tools are paving the way for AI systems that can improve themselves, bringing us closer to the idea of machines that can learn and adapt on their own. ...
2023.10.21.14.45.08;21.10.2023;08;13;Mobility;Mobility, Automotive, Self Driving et al.;arxiv;2310.12174;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.12174.pdf;" <a href=""http://arxiv.org/find/physics/1/au:+Gupta_A/0/1/0/all/0/1"">Ananay Vikram Gupta</a>, <a href=""http://arxiv.org/find/physics/1/au:+Kattekola_A/0/1/0/all/0/1"">Aaditya Prakash Kattekola</a>, <a href=""http://arxiv.org/find/physics/1/au:+Gupta_A/0/1/0/all/0/1"">Ansh Vikram Gupta</a>, <a href=""http://arxiv.org/find/physics/1/au:+Abhiram_D/0/1/0/all/0/1"">Dacharla Venkata Abhiram</a>, <a href=""http://arxiv.org/find/physics/1/au:+Namuduri_K/0/1/0/all/0/1"">Kamesh Namuduri</a>, <a href=""http://arxiv.org/find/physics/1/au:+Subramanian_R/0/1/0/all/0/1"">Ravichandran Subramanian</a>";Ananay Vikram Gupta,Aaditya Prakash Kattekola,Ansh Vikram Gupta,Dacharla Venkata Abhiram,Kamesh Namuduri,Ravichandran Subramanian;A Traffic Control Framework for Uncrewed Aircraft Systems.;The exponential growth of Advanced Air Mobility (AAM) services demands assurances of safety in the airspace. This research a Traffic Control Framework (TCF) for developing digital flight rules for Uncrewed Aircraft System (UAS) flying in designated air corridors. The proposed TCF helps model, deploy, and test UAS control, agents, regardless of their hardware configurations. This paper investigates the importance of digital flight rules in preventing collisions in the context of AAM. TCF is introduced as a platform for developing strategies for managing traffic towards enhanced autonomy in the airspace. It allows for assessment and evaluation of autonomous navigation, route planning, obstacle avoidance, and adaptive decision making for UAS. It also allows for the introduction and evaluation of advance technologies Artificial Intelligence (AI) and Machine Learning (ML) in a simulation environment before deploying them in the real world. TCF can be used as a tool for comprehensive UAS traffic analysis, including KPI measurements. It offers flexibility for further testing and deployment laying the foundation for improved airspace safety - a vital aspect of UAS technological advancement. Finally, this papers demonstrates the capabilities of the proposed TCF in managing UAS traffic at intersections and its impact on overall traffic flow in air corridors, noting the bottlenecks and the inverse relationship safety and traffic volume.
2023.10.21.14.45.09;21.10.2023;09;16;Legal;Legal, Law, Contracting et al.;arxiv;2211.08238;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2211.08238.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1"">Leilei Gan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1"">Baokui Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1"">Kun Kuang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yating Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"">Lei Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1"">Anh Tuan Luu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"">Yi Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1"">Fei Wu</a>";Leilei Gan,Baokui Li,Kun Kuang,Yating Zhang,Lei Wang,Anh Tuan Luu,Yi Yang,Fei Wu;Exploiting Contrastive Learning and Numerical Evidence for Improving Confusing Legal Judgment Prediction.;Given the fact description text of a legal case, legal judgment prediction (LJP) aims to predict the case's charge, law article and penalty term. A core problem of LJP is how to distinguish confusing legal cases, where only subtle text differences exist. Previous studies fail to distinguish different classification errors with a standard cross-entropy classification loss, and ignore the numbers in the fact description for predicting the term of penalty. To tackle these issues, in this work, first, we propose a moco-based supervised contrastive learning to learn distinguishable representations, and explore the best strategy to construct positive example pairs to benefit all three subtasks of LJP simultaneously. Second, in order to exploit the numbers in legal cases for predicting the penalty terms of certain cases, we further enhance the representation of the fact description with extracted crime amounts which are encoded by a pre-trained numeracy model. Extensive experiments on public benchmarks show that the proposed method achieves new state-of-the-art results, especially on confusing legal cases. Ablation studies also demonstrate the effectiveness of each component.
2023.10.21.14.45.10;21.10.2023;10;16;Legal;Legal, Law, Contracting et al.;arxiv;2310.12766;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.12766.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Arimond_A/0/1/0/all/0/1"">Alexander Arimond</a>, <a href=""http://arxiv.org/find/cs/1/au:+Molteni_M/0/1/0/all/0/1"">Mauro Molteni</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jany_D/0/1/0/all/0/1"">Dominik Jany</a>, <a href=""http://arxiv.org/find/cs/1/au:+Manolova_Z/0/1/0/all/0/1"">Zornitsa Manolova</a>, <a href=""http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1"">Damian Borth</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hoepner_A/0/1/0/all/0/1"">Andreas G.F. Hoepner</a>";Alexander Arimond,Mauro Molteni,Dominik Jany,Zornitsa Manolova,Damian Borth,Andreas G.F. Hoepner;Transformer-based Entity Legal Form Classification.;We propose the application of Transformer-based language models for classifying entity legal forms from raw legal entity names. Specifically, we employ various BERT variants and compare their performance against multiple traditional baselines. Our evaluation encompasses a substantial subset of freely available Legal Entity Identifier (LEI) data, comprising over 1.1 million legal entities from 30 different legal jurisdictions. The ground truth labels for classification per jurisdiction are taken from the Entity Legal Form (ELF) code standard (ISO 20275). Our findings demonstrate that pre-trained BERT variants outperform traditional text classification approaches in terms of F1 score, while also performing comparably well in the Macro F1 Score. Moreover, the validity of our proposal is supported by the outcome of third-party expert reviews conducted in ten selected jurisdictions. This study highlights the significant potential of Transformer-based models in advancing data standardization and data integration. The presented approaches can greatly benefit financial institutions, corporations, governments and other organizations in assessing business relationships, understanding risk exposure, and promoting effective governance.
2023.10.20.18.10.01;20.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.12128;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.12128.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zala_A/0/1/0/all/0/1"">Abhay Zala</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1"">Han Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1"">Jaemin Cho</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1"">Mohit Bansal</a>";Abhay Zala,Han Lin,Jaemin Cho,Mohit Bansal;DiagrammerGPT: Generating Open-Domain, Open-Platform Diagrams via LLM Planning.;Text-to-image (T2I) generation has seen significant growth over the past few years. Despite this, there has been little work on generating diagrams with T2I models. A diagram is a symbolic/schematic representation that explains information using structurally rich and spatially complex visualizations (e.g., a dense combination of related objects, text labels, directional arrows, connection lines, etc.). Existing state-of-the-art T2I models often fail at diagram generation because they lack fine-grained object layout control when many objects are densely connected via complex relations such as arrows/lines and also often fail to render comprehensible text labels. To address this gap, we present DiagrammerGPT, a novel two-stage text-to-diagram generation framework that leverages the layout guidance capabilities of LLMs (e.g., GPT-4) to generate more accurate open-domain, open-platform diagrams. In the first stage, we use LLMs to generate and iteratively refine 'diagram plans' (in a planner-auditor feedback loop) which describe all the entities (objects and text labels), their relationships (arrows or lines), and their bounding box layouts. In the second stage, we use a diagram generator, DiagramGLIGEN, and a text label rendering module to generate diagrams following the diagram plans. To benchmark the text-to-diagram generation task, we introduce AI2D-Caption, a densely annotated diagram dataset built on top of the AI2D dataset. We show quantitatively and qualitatively that our DiagrammerGPT framework produces more accurate diagrams, outperforming existing T2I models. We also provide comprehensive analysis including open-domain diagram generation, vector graphic diagram generation in different platforms, human-in-the-loop diagram plan editing, and multimodal planner/auditor LLMs (e.g., GPT-4Vision). We hope our work can inspire further research on diagram generation via T2I models and LLMs.
2023.10.20.18.10.02;20.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.11761;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.11761.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shui_R/0/1/0/all/0/1"">Ruihao Shui</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"">Yixin Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"">Xiang Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1"">Tat-Seng Chua</a>";Ruihao Shui,Yixin Cao,Xiang Wang,Tat-Seng Chua;A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction.;Large language models (LLMs) have demonstrated great potential for domain-specific applications, such as the law domain. However, recent disputes over GPT-4's law evaluation raise questions concerning their performance in real-world legal tasks. To systematically investigate their competency in the law, we design practical baseline solutions based on LLMs and test on the task of legal judgment prediction. In our solutions, LLMs can work alone to answer open questions or coordinate with an information retrieval (IR) system to learn from similar cases or solve simplified multi-choice questions. We show that similar cases and multi-choice options, namely label candidates, included in prompts can help LLMs recall domain knowledge that is critical for expertise legal reasoning. We additionally present an intriguing paradox wherein an IR system surpasses the performance of LLM+IR due to limited gains acquired by weaker LLMs from powerful IR systems. In such cases, the role of LLMs becomes redundant. Our evaluation pipeline can be easily extended into other tasks to facilitate evaluations in other domains. Code is available at https://github.com/srhthu/LM-CompEval-Legal
2023.10.20.18.10.03;20.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.11770;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.11770.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Britto_R/0/1/0/all/0/1"">Ricardo Britto</a>, <a href=""http://arxiv.org/find/cs/1/au:+Murphy_T/0/1/0/all/0/1"">Timothy Murphy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Iovene_M/0/1/0/all/0/1"">Massimo Iovene</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jonsson_L/0/1/0/all/0/1"">Leif Jonsson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Erol_Kantarci_M/0/1/0/all/0/1"">Melike Erol-Kantarci</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kovacs_B/0/1/0/all/0/1"">Benedek Kov&#xe1;cs</a>";Ricardo Britto,Timothy Murphy,Massimo Iovene,Leif Jonsson,Melike Erol-Kantarci,Benedek Kovács;Telecom AI Native Systems in the Age of Generative AI -- An Engineering Perspective.;The rapid advancements in Artificial Intelligence (AI), particularly in generative AI and foundational models (FMs), have ushered in transformative changes across various industries. Large language models (LLMs), a type of FM, have demonstrated their prowess in natural language processing tasks and content generation, revolutionizing how we interact with software products and services. This article explores the integration of FMs in the telecommunications industry, shedding light on the concept of AI native telco, where AI is seamlessly woven into the fabric of telecom products. It delves into the engineering considerations and unique challenges associated with implementing FMs into the software life cycle, emphasizing the need for AI native-first approaches. Despite the enormous potential of FMs, ethical, regulatory, and operational challenges require careful consideration, especially in mission-critical telecom contexts. As the telecom industry seeks to harness the power of AI, a comprehensive understanding of these challenges is vital to thrive in a fiercely competitive market.
2023.10.20.18.10.04;20.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.11458;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.11458.pdf;" <a href=""http://arxiv.org/find/cond-mat/1/au:+Verduzco_J/0/1/0/all/0/1"">Juan C. Verduzco</a>, <a href=""http://arxiv.org/find/cond-mat/1/au:+Holbrook_E/0/1/0/all/0/1"">Ethan Holbrook</a>, <a href=""http://arxiv.org/find/cond-mat/1/au:+Strachan_A/0/1/0/all/0/1"">Alejandro Strachan</a>";Juan C. Verduzco,Ethan Holbrook,Alejandro Strachan;GPT-4 as an interface between researchers and computational software: improving usability and reproducibility.;Large language models (LLMs) are playing an increasingly important role in science and engineering. For example, their ability to parse and understand human and computer languages makes them powerful interpreters and their use in applications like code generation are well-documented. We explore the ability of the GPT-4 LLM to ameliorate two major challenges in computational materials science: i) the high barriers for adoption of scientific software associated with the use of custom input languages, and ii) the poor reproducibility of published results due to insufficient details in the description of simulation methods. We focus on a widely used software for molecular dynamics simulations, the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS), and quantify the usefulness of input files generated by GPT-4 from task descriptions in English and its ability to generate detailed descriptions of computational tasks from input files. We find that GPT-4 can generate correct and ready-to-use input files for relatively simple tasks and useful starting points for more complex, multi-step simulations. In addition, GPT-4's description of computational tasks from input files can be tuned from a detailed set of step-by-step instructions to a summary description appropriate for publications. Our results show that GPT-4 can reduce the number of routine tasks performed by researchers, accelerate the training of new users, and enhance reproducibility.
2023.10.20.18.10.05;20.10.2023;05;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.11815;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.11815.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Nabar_O/0/1/0/all/0/1"">Omkar Nabar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shroff_G/0/1/0/all/0/1"">Gautam Shroff</a>";Omkar Nabar,Gautam Shroff;Conservative Predictions on Noisy Financial Data.;Price movements in financial markets are well known to be very noisy. As a result, even if there are, on occasion, exploitable patterns that could be picked up by machine-learning algorithms, these are obscured by feature and label noise rendering the predictions less useful, and risky in practice. Traditional rule-learning techniques developed for noisy data, such as CN2, would seek only high precision rules and refrain from making predictions where their antecedents did not apply. We apply a similar approach, where a model abstains from making a prediction on data points that it is uncertain on. During training, a cascade of such models are learned in sequence, similar to rule lists, with each model being trained only on data on which the previous model(s) were uncertain. Similar pruning of data takes place at test-time, with (higher accuracy) predictions being made albeit only on a fraction (support) of test-time data. In a financial prediction setting, such an approach allows decisions to be taken only when the ensemble model is confident, thereby reducing risk. We present results using traditional MLPs as well as differentiable decision trees, on synthetic data as well as real financial market data, to predict fixed-term returns using commonly used features. We submit that our approach is likely to result in better overall returns at a lower level of risk. In this context we introduce an utility metric to measure the average gain per trade, as well as the return adjusted for downside risk, both of which are improved significantly by our approach.
2023.10.20.18.10.06;20.10.2023;06;09;Human;Human Resource, Personal Assistance et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/how-to-master-resume-ranking-with-langchain-ai/;;;How to Master Resume Ranking with Langchain?;In the ever-evolving job market, employers often find themselves overwhelmed with a deluge of resumes for every job opening. The process of sifting through these resumes to identify the most qualified candidates can be time-consuming and daunting. To address this challenge, we will delve into the creation of a sophisticated resume ranking with Langchain, a robust language processing tool. This application will automatically filter resumes based on specified key skills and rank them according to their skill match. ...
2023.10.20.18.10.07;20.10.2023;07;10;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2310.11270;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.11270.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Malitesta_D/0/1/0/all/0/1"">Daniele Malitesta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pomo_C/0/1/0/all/0/1"">Claudio Pomo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1"">Tommaso Di Noia</a>";Daniele Malitesta,Claudio Pomo,Tommaso Di Noia;Graph Neural Networks for Recommendation: Reproducibility, Graph Topology, and Node Representation.;Graph neural networks (GNNs) have gained prominence in recommendation systems in recent years. By representing the user-item matrix as a bipartite and undirected graph, GNNs have demonstrated their potential to capture short- and long-distance user-item interactions, thereby learning more accurate preference patterns than traditional recommendation approaches. In contrast to previous tutorials on the same topic, this tutorial aims to present and examine three key aspects that characterize GNNs for recommendation: (i) the reproducibility of state-of-the-art approaches, (ii) the potential impact of graph topological characteristics on the performance of these models, and (iii) strategies for learning node representations when training features from scratch or utilizing pre-trained embeddings as additional item information (e.g., multimodal features). The goal is to provide three novel theoretical and practical perspectives on the field, currently subject to debate in graph learning but long been overlooked in the context of recommendation systems.
2023.10.20.18.10.08;20.10.2023;08;10;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2310.12107;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.12107.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bolic_N/0/1/0/all/0/1"">Nata&#x161;a Boli&#x107;</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cesari_T/0/1/0/all/0/1"">Tommaso Cesari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Colomboni_R/0/1/0/all/0/1"">Roberto Colomboni</a>";"Nata&#x161;a Boli&#x107;,Tommaso Cesari,Roberto Colomboni";An Online Learning Theory of Brokerage.;We investigate brokerage between traders from an online learning perspective. At any round $t$, two traders arrive with their private valuations, and the broker proposes a trading price. Unlike other bilateral trade problems already studied in the online learning literature, we focus on the case where there are no designated buyer and seller roles: each trader will attempt to either buy or sell depending on the current price of the good. We assume the agents' valuations are drawn i.i.d. from a fixed but unknown distribution. If the distribution admits a density bounded by some constant $M$, then, for any time horizon $T$: $\bullet$ If the agents' valuations are revealed after each interaction, we provide an algorithm achieving regret $M \log T$ and show this rate is optimal, up to constant factors. $\bullet$ If only their willingness to sell or buy at the proposed price is revealed after each interaction, we provide an algorithm achieving regret $\sqrt{M T}$ and show this rate is optimal, up to constant factors. Finally, if we drop the bounded density assumption, we show that the optimal rate degrades to $\sqrt{T}$ in the first case, and the problem becomes unlearnable in the second.
2023.10.20.18.10.09;20.10.2023;09;13;Mobility;Mobility, Automotive, Self Driving et al.;arxiv;2207.13181;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2207.13181.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Osanlou_K/0/1/0/all/0/1"">Kevin Osanlou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guettier_C/0/1/0/all/0/1"">Christophe Guettier</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cazenave_T/0/1/0/all/0/1"">Tristan Cazenave</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jacopin_E/0/1/0/all/0/1"">Eric Jacopin</a>";Kevin Osanlou,Christophe Guettier,Tristan Cazenave,Eric Jacopin;Planning and Learning: Path-Planning for Autonomous Vehicles, a Review of the Literature.;This short review aims to make the reader familiar with state-of-the-art works relating to planning, scheduling and learning. First, we study state-of-the-art planning algorithms. We give a brief introduction of neural networks. Then we explore in more detail graph neural networks, a recent variant of neural networks suited for processing graph-structured inputs. We describe briefly the concept of reinforcement learning algorithms and some approaches designed to date. Next, we study some successful approaches combining neural networks for path-planning. Lastly, we focus on temporal planning problems with uncertainty.
2023.10.19.14.13.01;19.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.04809;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04809.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Touzeau_V/0/1/0/all/0/1"">Valentin Touzeau</a>, <a href=""http://arxiv.org/find/cs/1/au:+Reineke_J/0/1/0/all/0/1"">Jan Reineke</a>";Valentin Touzeau,Jan Reineke;Leveraging LLVM's ScalarEvolution for Symbolic Data Cache Analysis.;While instruction cache analysis is essentially a solved problem, data cache analysis is more challenging. In contrast to instruction fetches, the data accesses generated by a memory instruction may vary with the program's inputs and across dynamic occurrences of the same instruction in loops. We observe that the plain control-flow graph (CFG) abstraction employed in classical cache analyses is inadequate to capture the dynamic behavior of memory instructions. On top of plain CFGs, accurate analysis of the underlying program's cache behavior is impossible. Thus, our first contribution is the definition of a more expressive program abstraction coined symbolic control-flow graphs, which can be obtained from LLVM's ScalarEvolution analysis. To exploit this richer abstraction, our main contribution is the development of symbolic data cache analysis, a smooth generalization of classical LRU must analysis from plain to symbolic control-flow graphs. The experimental evaluation demonstrates that symbolic data cache analysis consistently outperforms classical LRU must analysis both in terms of accuracy and analysis runtime.
2023.10.19.14.13.02;19.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.11249;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.11249.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1"">Xu Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1"">Xiao Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1"">Weiqing Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Jinhui Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1"">Peng Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1"">Zeqi Ye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1"">Jiang Bian</a>";Xu Yang,Xiao Yang,Weiqing Liu,Jinhui Li,Peng Yu,Zeqi Ye,Jiang Bian;Leveraging Large Language Model for Automatic Evolving of Industrial Data-Centric R&D Cycle.;In the wake of relentless digital transformation, data-driven solutions are emerging as powerful tools to address multifarious industrial tasks such as forecasting, anomaly detection, planning, and even complex decision-making. Although data-centric R&D has been pivotal in harnessing these solutions, it often comes with significant costs in terms of human, computational, and time resources. This paper delves into the potential of large language models (LLMs) to expedite the evolution cycle of data-centric R&D. Assessing the foundational elements of data-centric R&D, including heterogeneous task-related data, multi-facet domain knowledge, and diverse computing-functional tools, we explore how well LLMs can understand domain-specific requirements, generate professional ideas, utilize domain-specific tools to conduct experiments, interpret results, and incorporate knowledge from past endeavors to tackle new challenges. We take quantitative investment research as a typical example of industrial data-centric R&D scenario and verified our proposed framework upon our full-stack open-sourced quantitative research platform Qlib and obtained promising results which shed light on our vision of automatic evolving of industrial data-centric R&D cycle.
2023.10.19.14.13.03;19.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.10996;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.10996.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Mu_F/0/1/0/all/0/1"">Fangwen Mu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1"">Lin Shi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Song Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1"">Zhuohao Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1"">Binquan Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1"">Chenxue Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1"">Shichao Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1"">Qing Wang</a>";Fangwen Mu,Lin Shi,Song Wang,Zhuohao Yu,Binquan Zhang,Chenxue Wang,Shichao Liu,Qing Wang;ClarifyGPT: Empowering LLM-based Code Generation with Intention Clarification.;We introduce a novel framework named ClarifyGPT, which aims to enhance code generation by empowering LLMs with the ability to identify ambiguous requirements and ask targeted clarifying questions. In particular, ClarifyGPT first detects whether a given requirement is ambiguous by performing a code consistency check. If it is ambiguous, ClarifyGPT prompts an LLM to generate targeted clarifying questions. After receiving question responses, ClarifyGPT refines the ambiguous requirement and inputs it into the same LLM to generate a final code solution. To evaluate our ClarifyGPT, we first conduct a human evaluation involving ten participants who use ClarifyGPT for code generation on two publicly available benchmarks: MBPP-sanitized and MBPP-ET. The results show that ClarifyGPT elevates the performance (Pass@1) of GPT-4 from 70.96% to 80.80% on MBPP-sanitized. Furthermore, to perform large-scale automated evaluations of ClarifyGPT across different LLMs and benchmarks without requiring user participation, we introduce a high-fidelity simulation method to simulate user responses. The automated evaluation results also demonstrate that ClarifyGPT can significantly enhance code generation performance compared to the baselines. In particular, ClarifyGPT improves the average performance of GPT-4 and ChatGPT across four benchmarks from 68.02% to 75.75% and from 58.55% to 67.22%, respectively. We believe that ClarifyGPT can effectively facilitate the practical application of LLMs in real-world development environments.
2023.10.19.14.13.04;19.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.10760;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.10760.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sarmah_B/0/1/0/all/0/1"">Bhaskarjit Sarmah</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1"">Tianjie Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mehta_D/0/1/0/all/0/1"">Dhagash Mehta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pasquali_S/0/1/0/all/0/1"">Stefano Pasquali</a>";Bhaskarjit Sarmah,Tianjie Zhu,Dhagash Mehta,Stefano Pasquali;Towards reducing hallucination in extracting information from financial reports using Large Language Models.;For a financial analyst, the question and answer (Q\&A) segment of the company financial report is a crucial piece of information for various analysis and investment decisions. However, extracting valuable insights from the Q\&A section has posed considerable challenges as the conventional methods such as detailed reading and note-taking lack scalability and are susceptible to human errors, and Optical Character Recognition (OCR) and similar techniques encounter difficulties in accurately processing unstructured transcript text, often missing subtle linguistic nuances that drive investor decisions. Here, we demonstrate the utilization of Large Language Models (LLMs) to efficiently and rapidly extract information from earnings report transcripts while ensuring high accuracy transforming the extraction process as well as reducing hallucination by combining retrieval-augmented generation technique as well as metadata. We evaluate the outcomes of various LLMs with and without using our proposed approach based on various objective metrics for evaluating Q\&A systems, and empirically demonstrate superiority of our method.
2023.10.19.14.13.05;19.10.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/i-tested-chatgpt-ada-for-a-data-cleaning-task-its-super-helpful-but-fails-logical-reasoning-ec2485d6e780?source=rss----98111c9905da---4;;;I Tested ChatGPT ADA for a Data Cleaning Task. It’s Super Helpful but Fails Logical Reasoning;"A big part of most data-related jobs is cleaning the data. There is usually no standard way of cleaning data, as it can come in numerous different ways. We encounter inconsistencies, data entry errors, and many other types of issues that need to be handled before the data can be used for downstream processes. I tested the ChatGPT Advanced Data Analysis (ADA) plugin for a data cleaning task involving a car dataset. TL;DR ChatGPT ADA is super helpful at using data cleaning libraries to do required tasks but fails to figure out what to do in some cases. ..."
2023.10.19.14.13.06;19.10.2023;06;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.11293;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2310.11293.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Danielsson_J/0/1/0/all/0/1"">Jon Danielsson</a>, <a href=""http://arxiv.org/find/econ/1/au:+Uthemann_A/0/1/0/all/0/1"">Andreas Uthemann</a>";Jon Danielsson,Andreas Uthemann;On the use of artificial intelligence in financial regulations and the impact on financial stability.;Artificial intelligence (AI) is making rapid inroads in financial regulations. It will benefit micro regulations, concerned with issues like consumer protection and routine banking regulations, because of ample data, short time horizons, clear objectives, and repeated decisions that leave plenty of data for AI to train on. It is different with macro regulations focused on the stability of the entire financial system. Here, infrequent and mostly unique events frustrate AI learning. Distributed human decision making in times of extreme stress has strong advantages over centralised AI decisions, which, coupled with the catastrophic cost of mistakes, raises questions about AI used in macro regulations. However, AI will likely become widely used by stealth as it takes over increasingly high level advice and decisions, driven by significant cost efficiencies, robustness and accuracy compared to human regulators. We propose six criteria against which to judge the suitability of AI use by the private sector and financial regulation.
2023.10.19.14.13.07;19.10.2023;07;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2207.07318;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2207.07318.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Thompson_R/0/1/0/all/0/1"">Ryan Thompson</a>, <a href=""http://arxiv.org/find/econ/1/au:+Qian_Y/0/1/0/all/0/1"">Yilin Qian</a>, <a href=""http://arxiv.org/find/econ/1/au:+Vasnev_A/0/1/0/all/0/1"">Andrey L. Vasnev</a>";Ryan Thompson,Yilin Qian,Andrey L. Vasnev;Flexible global forecast combinations.;Forecast combination -- the aggregation of individual forecasts from multiple experts or models -- is a proven approach to economic forecasting. To date, research on economic forecasting has concentrated on local combination methods, which handle separate but related forecasting tasks in isolation. Yet, it has been known for over two decades in the machine learning community that global methods, which exploit task-relatedness, can improve on local methods that ignore it. Motivated by the possibility for improvement, this paper introduces a framework for globally combining forecasts while being flexible to the level of task-relatedness. Through our framework, we develop global versions of several existing forecast combinations. To evaluate the efficacy of these new global forecast combinations, we conduct extensive comparisons using synthetic and real data. Our real data comparisons, which involve forecasts of core economic indicators in the Eurozone, provide empirical evidence that the accuracy of global combinations of economic forecasts can surpass local combinations.
2023.10.19.14.13.08;19.10.2023;08;03;Finance;Finance, DeFi, Insurance, Banking et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Platforms_Based_Approach_and_Strategy_for_Fintech_applications/24329533;;TechRxiv RSS Feed;Platforms Based Approach and Strategy for Fintech applications;Digitization has changed the way and ease of doing business which affects almost everything in today's enterprise organization. Digital Experience platforms (DXPs) are unified approach to integrate all technology stacks available in the market across every touchpoints such as Wearable devices, WEB, IVR, and Mobile etc. US Banking & Finance Industry have lot of potential to transform, digitize their banking and finance (Fintech) applications using unified approach such as DXPs. In this article, we have evaluated many digital strategy from various stakeholders in the industry. Enterprises uses various technology, tool, techniques and concepts to develop digital capabilities whereas DXPs has integrated approach to develop, implement and digitize the strategy to transform banking and finance industry. DXPs is gaining momentum & it is now used by banking & finance sector, such as Standard Bank, Citizen Bank, TP Bank etc.
2023.10.19.14.13.09;19.10.2023;09;05;Industry;Industry 4.0, Production, Circular Economy et al.;towardsdatascience;;;https://towardsdatascience.com/how-will-data-science-accelerate-the-circular-economy-61a1a22287e5?source=rss----7f60cf5620c9---4;;;How Will Data Science Accelerate the Circular Economy?;Actionable data science tips to overcome the operational challenges in transitioning to a circular economy. ...
2023.10.19.14.13.10;19.10.2023;10;12;Energy;Electricity, Smart Grid et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/An_Innovative_Toolbox_for_the_Optimal_Design_and_Operation_of_Integrated_Local_Energy_Communities/24249172;;TechRxiv RSS Feed;An Innovative Toolbox for the Optimal Design and Operation of Integrated Local Energy Communities;By providing important benefits such as reducing primary energy consumption, improving environmental conditions, and increasing resilience of energy supply, integrated local energy communities (ILECs) represent a viable option to centralized energy systems for fostering decarbonization, thanks to the exploitation of synergies coming from different energy carries beyond electricity and the active involvement of end-users through a collegial approach. To achieve these benefits, the optimisation of ILECs design and operation is as crucial as it is challenging. This paper presents the results from an activity of the eNeuron H2020 project (Nov 2020-Oct. 2024, ID: 957779), and aims to present an innovative toolbox for the optimal design and operation of ILECs integrating multiple energy carriers at different scales and considering different time horizons from long-term system planning to real-time operation. To achieve the short- and long-term sustainability of this new energy paradigm, a multi-objective economic-environmental approach is proposed, whereby a peer-to-peer market is established to promote end-users’ active involvement while guaranteeing that they are aligned with the overall ILEC’s objectives. This paper is a preprint of a paper submitted to and accepted at conference CIRED2023 and is subject to Institution of Engineering and Technology Copyright. The copy of record is available at IET Digital Library. DOI:.1049/icp.2023.0460
2023.10.19.14.13.11;19.10.2023;11;15;Health;Medical, Health Care, Pharmacy et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Fairness_in_Medical_Image_Analysis_and_Healthcare_A_Literature_Survey/24324979;;TechRxiv RSS Feed;Fairness in Medical Image Analysis and Healthcare: A Literature Survey;Machine learning-enabled medical imaging analysis has become a vital part of the automatic diagnosis system. However, machine learning, especially deep learning models have been shown to demonstrate a systematic bias towards certain subgroups of people. For instance, they yield a preferential predictive performance to males over females, which is unfair and potentially harmful especially in healthcare scenarios. In this literature survey, we give a comprehensive review of the current progress of fairness studies in medical image analysis (MedIA) and healthcare. Specifically, we first discuss the definitions of fairness, the source of unfairness and potential solutions. Then, we discuss current research on fairness for MedIA categorized by fairness evaluation and unfairness mitigation. Furthermore, we conduct extensive experiments to evaluate the fairness of different medical imaging tasks. Finally, we discuss the challenges and future directions in developing fair MedIA and healthcare applications.
2023.10.19.14.13.12;19.10.2023;12;15;Health;Medical, Health Care, Pharmacy et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/The_Future_of_Patient_Data_Blockchain_s_Promise_in_Health_Care_File_Security/24335542;;TechRxiv RSS Feed;The Future of Patient Data: Blockchain’s Promise in Health Care File Security;In the rapidly evolving landscape of health care, the security and management of patient data emerge as paramount concerns. Traditional centralized systems have shown vulnerabilities, leading to breaches and unauthorized access. This paper delves into the transformative potential of blockchain technology as a solution to these challenges. Blockchain, primarily recognized for its role in cryptocurrency, offers features such as decentralization, immutability, and transparency, making it a promising candidate for secure health care data management. Through an exploration of its fundamental principles and a comparative analysis of two case studies, the practical implementations and outcomes of blockchain in health care settings are highlighted. The findings suggest that while blockchain presents significant advantages, its integration into health care is accompanied by certain limitations and ethical considerations. As the health care industry stands on the cusp of a potential shift in data management, this paper provides insights, recommendations, and a vision for the future, emphasizing the promise and implications of blockchain technology.
2023.10.19.14.13.13;19.10.2023;13;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.09909;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.09909.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1"">Chaoyi Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1"">Jiayu Lei</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1"">Qiaoyu Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1"">Weike Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1"">Weixiong Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"">Xiaoman Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1"">Xiao Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1"">Ziheng Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Ya Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yanfeng Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1"">Weidi Xie</a>";Chaoyi Wu,Jiayu Lei,Qiaoyu Zheng,Weike Zhao,Weixiong Lin,Xiaoman Zhang,Xiao Zhou,Ziheng Zhao,Ya Zhang,Yanfeng Wang,Weidi Xie;Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for Multimodal Medical Diagnosis.;Driven by the large foundation models, the development of artificial intelligence has witnessed tremendous progress lately, leading to a surge of general interest from the public. In this study, we aim to assess the performance of OpenAI's newest model, GPT-4V(ision), specifically in the realm of multimodal medical diagnosis. Our evaluation encompasses 17 human body systems, including Central Nervous System, Head and Neck, Cardiac, Chest, Hematology, Hepatobiliary, Gastrointestinal, Urogenital, Gynecology, Obstetrics, Breast, Musculoskeletal, Spine, Vascular, Oncology, Trauma, Pediatrics, with images taken from 8 modalities used in daily clinic routine, e.g., X-ray, Computed Tomography (CT), Magnetic Resonance Imaging (MRI), Positron Emission Tomography (PET), Digital Subtraction Angiography (DSA), Mammography, Ultrasound, and Pathology. We probe the GPT-4V's ability on multiple clinical tasks with or without patent history provided, including imaging modality and anatomy recognition, disease diagnosis, report generation, disease localisation. Our observation shows that, while GPT-4V demonstrates proficiency in distinguishing between medical image modalities and anatomy, it faces significant challenges in disease diagnosis and generating comprehensive reports. These findings underscore that while large multimodal models have made significant advancements in computer vision and natural language processing, it remains far from being used to effectively support real-world medical applications and clinical decision-making. All images used in this report can be found in https://github.com/chaoyi-wu/GPT-4V_Medical_Evaluation.
2023.10.19.14.13.14;19.10.2023;14;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.10765;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.10765.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1"">Yu Gu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1"">Jianwei Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1"">Naoto Usuyama</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"">Chunyuan Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"">Sheng Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1"">Matthew P. Lungren</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1"">Jianfeng Gao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1"">Hoifung Poon</a>";Yu Gu,Jianwei Yang,Naoto Usuyama,Chunyuan Li,Sheng Zhang,Matthew P. Lungren,Jianfeng Gao,Hoifung Poon;BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys.;Rapid progress has been made in instruction-learning for image editing with natural-language instruction, as exemplified by InstructPix2Pix. In biomedicine, such methods can be applied to counterfactual image generation, which helps differentiate causal structure from spurious correlation and facilitate robust image interpretation for disease progression modeling. However, generic image-editing models are ill-suited for the biomedical domain, and counterfactual biomedical image generation is largely underexplored. In this paper, we present BiomedJourney, a novel method for counterfactual biomedical image generation by instruction-learning from multimodal patient journeys. Given a patient with two biomedical images taken at different time points, we use GPT-4 to process the corresponding imaging reports and generate a natural language description of disease progression. The resulting triples (prior image, progression description, new image) are then used to train a latent diffusion model for counterfactual biomedical image generation. Given the relative scarcity of image time series data, we introduce a two-stage curriculum that first pretrains the denoising network using the much more abundant single image-report pairs (with dummy prior image), and then continues training using the counterfactual triples. Experiments using the standard MIMIC-CXR dataset demonstrate the promise of our method. In a comprehensive battery of tests on counterfactual medical image generation, BiomedJourney substantially outperforms prior state-of-the-art methods in instruction image editing and medical image generation such as InstructPix2Pix and RoentGen. To facilitate future study in counterfactual medical generation, we plan to release our instruction-learning code and pretrained models.
2023.10.19.14.13.15;19.10.2023;15;16;Legal;Legal, Law, Contracting et al.;arxiv;2310.11049;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.11049.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Nigam_S/0/1/0/all/0/1"">Shubham Kumar Nigam</a>, <a href=""http://arxiv.org/find/cs/1/au:+Deroy_A/0/1/0/all/0/1"">Aniket Deroy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shallum_N/0/1/0/all/0/1"">Noel Shallum</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1"">Ayush Kumar Mishra</a>, <a href=""http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1"">Anup Roy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1"">Shubham Kumar Mishra</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1"">Arnab Bhattacharya</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1"">Saptarshi Ghosh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ghosh_K/0/1/0/all/0/1"">Kripabandhu Ghosh</a>";Shubham Kumar Nigam,Aniket Deroy,Noel Shallum,Ayush Kumar Mishra,Anup Roy,Shubham Kumar Mishra,Arnab Bhattacharya,Saptarshi Ghosh,Kripabandhu Ghosh;Nonet at SemEval-2023 Task 6: Methodologies for Legal Evaluation.;This paper describes our submission to the SemEval-2023 for Task 6 on LegalEval: Understanding Legal Texts. Our submission concentrated on three subtasks: Legal Named Entity Recognition (L-NER) for Task-B, Legal Judgment Prediction (LJP) for Task-C1, and Court Judgment Prediction with Explanation (CJPE) for Task-C2. We conducted various experiments on these subtasks and presented the results in detail, including data statistics and methodology. It is worth noting that legal tasks, such as those tackled in this research, have been gaining importance due to the increasing need to automate legal analysis and support. Our team obtained competitive rankings of 15$^{th}$, 11$^{th}$, and 1$^{st}$ in Task-B, Task-C1, and Task-C2, respectively, as reported on the leaderboard.
2023.10.19.14.13.16;19.10.2023;16;18;AgriCulture;Agriculture et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1162/v1;;Preprints.org - The Multidisciplinary Preprint Platform;RS Transformer: A Two-Stage Region Proposal Using the Swin Transformer for Few-Shot Pest Detection in Automated Agricultural Monitoring Systems;Agriculture is pivotal in national economies, with pest detection significantly influencing food quality and quantity. Pest classification remains challenging in automated agriculture monitoring systems, exacerbated by the non-uniform pest scales and the scarcity of high-quality datasets. In this study, we constructed a pest dataset by acquiring domain-agnostic images from the Internet and resizing them to a standardized 299x299 pixel format. Additionally, we employed diffusion models to generate supplementary data. While Convolutional Neural Networks (CNNs) are prevalent for prediction and classification, they often lack effective global information integration and discriminative feature representation. To address these limitations, we propose the RS Transformer, an innovative model that combines elements like the Region Proposal Network, Swin Transformer, and ROI Align. Additionally, we introduce the Randomly Generated Stable Diffusion Dataset (RGSDD) to augment the availability of high-quality pest datasets. Extensive experimental evaluations demonstrate the superiority of our approach compared to both two-stage models (SSD and Faster R-CNN) and one-stage models (YOLOv3, YOLOv4, YOLOv5m, YOLOv8, and DETR). We rigorously assess performance using metrics such as mean Average Precision (mAP), F1Score, Recall, and mean Detection Time (mDT). Our research contributes to advancing pest detection methodologies in automated agriculture systems, promising improved food production and quality.
2023.10.19.14.13.17;19.10.2023;17;18;AgriCulture;Agriculture et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1229/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Applications of Smart Agriculture to Improve Animal Production: Opportunities, Challenges, Solutions, and Benefits;Smart livestock farming leverages technology to boost production and meet food demand sustainably. This study delves into smart technologies in animal production, covering opportunities, challenges, and solutions. Smart agriculture employs modern technology to enhance efficiency, sustainability, and animal welfare in livestock farming. It includes remote monitoring, GPS-based animal care, robotic milking, smart health collars, predictive disease control, and other innovations to achieve these goals. While smart animal production holds great promise, it does face challenges related to cost, data management, and connectivity. To address these challenges, potential solutions include remote sensing, technology integration, and farmer education. Smart agriculture offers opportunities for increased efficiency, improved animal welfare, and enhanced environmental conservation. A well-planned approach is crucial to maximize the benefits of smart livestock production while ensuring its long-term sustainability. This study confirms the growing adoption of smart agriculture in livestock production, with the potential to support sustainable development goals and deliver benefits such as increased productivity and resource efficiency. To fully realize these benefits and ensure the sustainability of livestock farming, it is essential to address cost and education challenges. Therefore, this study recommends promoting a positive outlook among livestock stakeholders and embracing smart agriculture to enhance farm performance.
2023.10.18.16.33.01;18.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.09400;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.09400.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1"">Chen Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1"">Liangwei Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zhiwei Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1"">Xiaolong Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1"">Mingdai Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1"">Yueqing Liang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1"">Philip S. Yu</a>";Chen Wang,Liangwei Yang,Zhiwei Liu,Xiaolong Liu,Mingdai Yang,Yueqing Liang,Philip S. Yu;Collaborative Contextualization: Bridging the Gap between Collaborative Filtering and Pre-trained Language Model.;Traditional recommender systems have heavily relied on identity representations (IDs) to model users and items, while the ascendancy of pre-trained language model (PLM) encoders has enriched the modeling of contextual item descriptions. However, PLMs, although effective in addressing few-shot, zero-shot, or unified modeling scenarios, often neglect the crucial collaborative filtering signal. This neglect gives rise to two pressing challenges: (1) Collaborative Contextualization, the seamless integration of collaborative signals with contextual representations. (2) the imperative to bridge the representation gap between ID-based representations and contextual representations while preserving their contextual semantics. In this paper, we propose CollabContext, a novel model that adeptly combines collaborative filtering signals with contextual representations and aligns these representations within the contextual space, preserving essential contextual semantics. Experimental results across three real-world datasets demonstrate substantial improvements. Leveraging collaborative contextualization, CollabContext can also be effectively applied to cold-start scenarios, achieving remarkable enhancements in recommendation performance. The code is available after the conference accepts the paper.
2023.10.18.16.33.02;18.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2305.14302;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.14302.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1"">Shijie Geng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1"">Juntao Tan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1"">Shuchang Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1"">Zuohui Fu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yongfeng Zhang</a>";Shijie Geng,Juntao Tan,Shuchang Liu,Zuohui Fu,Yongfeng Zhang;VIP5: Towards Multimodal Foundation Models for Recommendation.;Computer Vision (CV), Natural Language Processing (NLP), and Recommender Systems (RecSys) are three prominent AI applications that have traditionally developed independently, resulting in disparate modeling and engineering methodologies. This has impeded the ability for these fields to directly benefit from each other's advancements. With the recent development of foundation models, large language models have emerged as a potential general-purpose interface for unifying different modalities and problem formulations. In light of this, we propose the development of a multimodal foundation model (MFM) considering visual, textual, and personalization modalities under the P5 recommendation paradigm, thus named VIP5 (Visual P5), to unify various modalities and recommendation tasks. This will enable the processing of multiple modalities in a shared architecture for improved recommendations. To achieve this, we introduce multimodal personalized prompts to accommodate multiple modalities under a shared format. Additionally, we propose a parameter-efficient training method for foundation models, which involves freezing the P5 backbone and fine-tuning lightweight adapters, resulting in improved recommendation performance and increased efficiency in terms of training time and memory usage. Code and data of VIP5 are available at https://github.com/jeykigung/VIP5.
2023.10.18.16.33.03;18.10.2023;03;03;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:cgd:wpaper:618&r=pay;;Alan GelbAnit MukherjeeBrian Webster;Can Digital G2P Transfers Drive Financial Inclusion and Digital Payments? Evidence from India;"Does channeling government-to-person (G2P) payments through bank accounts encourage financial inclusion and use? This paper explores the factors that have driven the adoption of digital payments in India by beneficiaries of PMGKY, the large-scale COVID-19 relief program launched in May 2020. India’s 2013 move to pay social benefits through direct transfers into bank accounts significantly increased account ownership, but uptake of digital payments has been slower, although it has accelerated more recently through smartphone-based apps. Recipient survey data shows that personal and household attributes influence the likelihood of adopting digital payments. Smartphone ownership and digital literacy improve the odds while being a woman reduces them. The strength of the local digital payments ecosystem also exerts significant influence on household adoption; favorable personal and ecosystem factors are needed for widespread use. The historical progression shows that G2P transfers create an entry point but that widespread access to low-cost mobile telecommunications, interoperability, and the entry of new players offering convenient payments interfaces have been vital to the growth of digital payments."
2023.10.18.16.33.04;18.10.2023;04;03;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2309.12704&r=pay;;Rasmus Ingemann Tuffveson JensenJoras FerwerdaChristian Remi Wewer;Searching for Smurfs: Testing if Money Launderers Know Alert Thresholds;To combat money laundering, banks raise and review alerts on transactions that exceed confidential thresholds. This paper presents a data-driven approach to detect smurfing, i.e., money launderers seeking to evade detection by breaking up large transactions into amounts under the secret thresholds. The approach utilizes the notion of a counterfactual distribution and relies on two assumptions: (i) smurfing is unfeasible for the very largest financial transactions and (ii) money launderers have incentives to make smurfed transactions close to the thresholds. Simulations suggest that the approach can detect smurfing when as little as 0.1-0.5\% of all bank transactions are subject to smurfing. An application to real data from a systemically important Danish bank finds no evidence of smurfing and, thus, no evidence of leaked confidential thresholds. An implementation of our approach will be available online, providing a free and easy-to-use tool for banks.
2023.10.18.16.33.05;18.10.2023;05;03;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:fip:fedgfe:2023-60&r=pay;;Francesca CarapellaGrace ChuanJacob GersztenNathan Swem;Tokenization: Overview and Financial Stability Implications;In this paper we outline tokenization, which is a new and rapidly growing financial innovation in crypto asset markets, and we discuss potential benefits and financial stability implications. Tokenization refers to the process of constructing digital representations (crypto tokens) for non-crypto assets (reference assets). As we discuss below, tokenizations create interconnections between the digital asset ecosystem and the traditional financial system. At sufficient scale, tokenized assets could transmit volatility from crypto asset markets to the markets for the crypto token's reference assets.
2023.10.18.16.33.06;18.10.2023;06;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.09621;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2310.09621.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Polychroniadou_A/0/1/0/all/0/1"">Antigoni Polychroniadou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Asharov_G/0/1/0/all/0/1"">Gilad Asharov</a>, <a href=""http://arxiv.org/find/cs/1/au:+Diamond_B/0/1/0/all/0/1"">Benjamin Diamond</a>, <a href=""http://arxiv.org/find/cs/1/au:+Balch_T/0/1/0/all/0/1"">Tucker Balch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Buehler_H/0/1/0/all/0/1"">Hans Buehler</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hua_R/0/1/0/all/0/1"">Richard Hua</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1"">Suwen Gu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gimler_G/0/1/0/all/0/1"">Greg Gimler</a>, <a href=""http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1"">Manuela Veloso</a>";Antigoni Polychroniadou,Gilad Asharov,Benjamin Diamond,Tucker Balch,Hans Buehler,Richard Hua,Suwen Gu,Greg Gimler,Manuela Veloso;Prime Match: A Privacy-Preserving Inventory Matching System.;Inventory matching is a standard mechanism/auction for trading financial stocks by which buyers and sellers can be paired. In the financial world, banks often undertake the task of finding such matches between their clients. The related stocks can be traded without adversely impacting the market price for either client. If matches between clients are found, the bank can offer the trade at advantageous rates. If no match is found, the parties have to buy or sell the stock in the public market, which introduces additional costs. A problem with the process as it is presently conducted is that the involved parties must share their order to buy or sell a particular stock, along with the intended quantity (number of shares), to the bank. Clients worry that if this information were to leak somehow, then other market participants would become aware of their intentions and thus cause the price to move adversely against them before their transaction finalizes. We provide a solution, Prime Match, that enables clients to match their orders efficiently with reduced market impact while maintaining privacy. In the case where there are no matches, no information is revealed. Our main cryptographic innovation is a two-round secure linear comparison protocol for computing the minimum between two quantities without preprocessing and with malicious security, which can be of independent interest. We report benchmarks of our Prime Match system, which runs in production and is adopted by J.P. Morgan. The system is designed utilizing a star topology network, which provides clients with a centralized node (the bank) as an alternative to the idealized assumption of point-to-point connections, which would be impractical and undesired for the clients to implement in reality. Prime Match is the first secure multiparty computation solution running live in the traditional financial world.
2023.10.18.16.33.07;18.10.2023;07;03;Finance;Finance, DeFi, Insurance, Banking et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/building-and-validating-simple-stock-trading-algorithms-using-python/;;;Building and Validating Simple Stock Trading Algorithms Using Python;Algorithmic trading is a widely adopted trading strategy that has revolutionized the way people trade stocks. More and more people are making money on the side by investing in stocks and automating their trading strategies. This tutorial will teach you how to build stock trading algorithms using primitive technical indicators like MACD, SMA, EMA, etc., and select the best strategies based on their actual performance/returns, completely using Python. ...
2023.10.18.16.33.08;18.10.2023;08;04;Supply Chain;Logistics, Supply Chains, Transportation et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Matching_Mechanism_Designs_for_Shared_Mobility_A_Review_of_the_Literature/24311152;;TechRxiv RSS Feed;Matching Mechanism Designs for Shared Mobility: A Review of the Literature;Shared mobility is an emerging urban logistics solution that aims to enhance transportation efficiency by leveraging underutilized transportation resources owned by individuals. In contrast to traditional urban logistics, the transportation resources are derived from self-employed individuals rather than company employees, rendering the design of appropriate matching mechanisms a pressing issue to be addressed. From this perspective, we have conducted a comprehensive review of the relevant literature and classified the literature based on information acquisition completeness. Our findings reveal that current research lacks analysis of the supply-side behavior, consideration of specific constraints in the shared mobility context, and performance evaluation of matching mechanisms in dynamic environments.
2023.10.18.16.33.09;18.10.2023;09;04;Supply Chain;Logistics, Supply Chains, Transportation et al.;arxiv;2310.09435;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.09435.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1"">Liming Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mak_S/0/1/0/all/0/1"">Stephen Mak</a>, <a href=""http://arxiv.org/find/cs/1/au:+Minaricova_M/0/1/0/all/0/1"">Maria Minaricova</a>, <a href=""http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1"">Alexandra Brintrup</a>";Liming Xu,Stephen Mak,Maria Minaricova,Alexandra Brintrup;On Implementing Autonomous Supply Chains: a Multi-Agent System Approach.;Trade restrictions, the COVID-19 pandemic, and geopolitical conflicts has significantly exposed vulnerabilities within traditional global supply chains. These events underscore the need for organisations to establish more resilient and flexible supply chains. To address these challenges, the concept of the autonomous supply chain (ASC), characterised by predictive and self-decision-making capabilities, has recently emerged as promising solution. However, research on ASCs is relatively limited, with no existing studies on their implementations. This paper aims to address this gap by presenting an implementation of ASC using a multi-agent approach. It proposes a methodology for the analysis and design of such an agent-based ASC system (A2SC). This paper provides a concrete case study, the autonomous meat supply chain, which showcases the practical implementation of the A2SC system using the proposed methodology. Additionally, a system architecture and a toolkit for developing A2SC systems are presented. Despite with limitations, this paper demonstrates a promising approach for implementing an effective ASC system.
2023.10.18.16.33.10;18.10.2023;10;04;Supply Chain;Logistics, Supply Chains, Transportation et al.;arxiv;2307.12906;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.12906.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jahin_M/0/1/0/all/0/1"">Md Abrar Jahin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shovon_M/0/1/0/all/0/1"">Md Sakib Hossain Shovon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1"">Md. Saiful Islam</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1"">Jungpil Shin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mridha_M/0/1/0/all/0/1"">M. F. Mridha</a>, <a href=""http://arxiv.org/find/cs/1/au:+Okuyama_Y/0/1/0/all/0/1"">Yuichi Okuyama</a>";Md Abrar Jahin,Md Sakib Hossain Shovon,Md. Saiful Islam,Jungpil Shin,M. F. Mridha,Yuichi Okuyama;QAmplifyNet: Pushing the Boundaries of Supply Chain Backorder Prediction Using Interpretable Hybrid Quantum-Classical Neural Network.;Supply chain management relies on accurate backorder prediction for optimizing inventory control, reducing costs, and enhancing customer satisfaction. However, traditional machine-learning models struggle with large-scale datasets and complex relationships, hindering real-world data collection. This research introduces a novel methodological framework for supply chain backorder prediction, addressing the challenge of handling large datasets. Our proposed model, QAmplifyNet, employs quantum-inspired techniques within a quantum-classical neural network to predict backorders effectively on short and imbalanced datasets. Experimental evaluations on a benchmark dataset demonstrate QAmplifyNet's superiority over classical models, quantum ensembles, quantum neural networks, and deep reinforcement learning. Its proficiency in handling short, imbalanced datasets makes it an ideal solution for supply chain management. To enhance model interpretability, we use Explainable Artificial Intelligence techniques. Practical implications include improved inventory control, reduced backorders, and enhanced operational efficiency. QAmplifyNet seamlessly integrates into real-world supply chain management systems, enabling proactive decision-making and efficient resource allocation. Future work involves exploring additional quantum-inspired techniques, expanding the dataset, and investigating other supply chain applications. This research unlocks the potential of quantum computing in supply chain optimization and paves the way for further exploration of quantum-inspired machine learning models in supply chain management. Our framework and QAmplifyNet model offer a breakthrough approach to supply chain backorder prediction, providing superior performance and opening new avenues for leveraging quantum-inspired techniques in supply chain management.
2023.10.18.16.33.11;18.10.2023;11;05;Industry;Industry 4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1151/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Data- and Knowledge-Driven Cycle Time Estimation in Offsite Construction;Cycle times at workstations in offsite construction factories fluctuate widely due to various influencing factors. Consequently, relying on average rates, such as length per unit of time, for estimating cycle times proves to be inaccurate, often leading to significant deviations between production schedules and actual operations. To address this issue, this study proposes an estimation system that leverages machine-learning-based prediction, statistical methods, 3D simulation, and computer vision to predict cycle times at the workstation level. Testing of the system on a semi-automated wood-wall framing workstation in a panelized construction factory shows that it reduces the mean absolute error and sum of errors by approximately 36% and 68%, respectively, compared to the fixed rate method. The results also highlight the efficacy of using computer vision data for training machine-learning models for cycle time estimation, the importance of identifying and understanding the factors influencing cycle times, and the impact of random delays on the accuracy of cycle time estimation systems.
2023.10.18.16.33.12;18.10.2023;12;05;Industry;Industry 4.0, Production et al.;arxiv;2310.09319;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.09319.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Uray_M/0/1/0/all/0/1"">Martin Uray</a>, <a href=""http://arxiv.org/find/cs/1/au:+Giunti_B/0/1/0/all/0/1"">Barbara Giunti</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kerber_M/0/1/0/all/0/1"">Michael Kerber</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huber_S/0/1/0/all/0/1"">Stefan Huber</a>";Martin Uray,Barbara Giunti,Michael Kerber,Stefan Huber;Topological Data Analysis in smart manufacturing processes -- A survey on the state of the art.;Topological Data Analysis (TDA) is a mathematical method using techniques from topology for the analysis of complex, multi-dimensional data that has been widely and successfully applied in several fields such as medicine, material science, biology, and others. This survey summarizes the state of the art of TDA in yet another application area: industrial manufacturing and production in the context of Industry 4.0. We perform a rigorous and reproducible literature search of applications of TDA on the setting of industrial production and manufacturing. The resulting works are clustered and analyzed based on their application area within the manufacturing process and their input data type. We highlight the key benefits of TDA and their tools in this area and describe its challenges, as well as future potential. Finally, we discuss which TDA methods are underutilized in (the specific area of) industry and the identified types of application, with the goal of prompting more research in this profitable area of application.
2023.10.18.16.33.13;18.10.2023;13;07;Software;Development, Software Engineering et al.;towardsai;;;https://pub.towardsai.net/build-your-full-stack-ai-application-with-reactpy-541e284757f2?source=rss----98111c9905da---4;;;Build your Full-stack AI Application with ReactPy;Learn how to use React to build beautiful UI in Python! ...
2023.10.18.16.33.14;18.10.2023;14;07;Software;Development, Software Engineering et al.;towardsdatascience;;;https://towardsdatascience.com/mastering-the-future-evaluating-llm-generated-data-architectures-leveraging-iac-technologies-dee75302a355?source=rss----7f60cf5620c9---4;;;Mastering the Future: Evaluating LLM-Generated Data Architectures leveraging IaC technologies;Evaluate the suitability of LLMs for the generation of Infrastructure as Code to provision, configure, and deploy modern applications. ...
2023.10.18.16.33.15;18.10.2023;15;09;Human;Human Resource, Personal Assistance et al.;acm;;http://cacm.acm.org/browse-by-subject/artificial-intelligence.rss;http://cacm.acm.org/careers/277280-ai-bots-call-out-the-problem-person-in-dull-work-meetings;;Communications of the ACM: Artificial Intelligence;AI Bots Call Out the Problem Person In Dull Work Meetings;Companies have begun using AI to take notes and summarize workplace meetings, and to point out behavior like talking nonstop or interrupting others.
2023.10.18.16.33.16;18.10.2023;16;10;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2310.09544;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2310.09544.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Hu_X/0/1/0/all/0/1"">Xiaoxiao Hu</a>, <a href=""http://arxiv.org/find/econ/1/au:+Lei_H/0/1/0/all/0/1"">Haoran Lei</a>";Xiaoxiao Hu,Haoran Lei;Credibility in Credence Goods Markets.;An expert seller chooses an experiment to influence a client's purchasing decision, but may manipulate the experiment result for personal gain. When credibility surpasses a critical threshold, the expert chooses a fully-revealing experiment and, if possible, manipulates the unfavorable result. In this case, a higher credibility strictly benefits the expert, whereas the client never benefits from the expert's services. We also discuss policies regarding monitoring expert's disclosure and price regulation. When prices are imposed exogenously, monitoring disclosure does not affect the client's highest equilibrium value. A lower price may harm the client when it discourages the expert from disclosing information.
2023.10.18.16.33.17;18.10.2023;17;12;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1002/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Optimizing Offshore Wind Power Generation in Extreme Climatic Scenarios;Portugal, in line with the European Union, is aiming for carbon neutrality by 2050 (Net 1 Zero), which implies a transition to sustainable energy sources. Climate change is all too evident, extreme weather periods are occurring in a cyclical manner, with greater brevity to such an extent that the grid operator must deal with production scenarios where it can no longer rely on hydroelectric production given the recurring drought situation. This situation increases dependence on thermal production using natural gas and imports. This has significant economic implications. Portugal has exploited its onshore wind potential, reaching an installed capacity of 5.671 MW by 2022. However, the expansion of onshore wind energy is limited to reinforcing existing infrastructure. To overcome these challenges, it is necessary to expand the exploitation of offshore wind potential that is already underway. This article proposes the location of offshore wind production platforms along the Portuguese coast. This allows for an analysis of offshore production and its optimization according to the minimum cost per MWh in the face of extreme scenarios, i.e., in periods of extreme drought where hydroelectric production capacity is practically non-existent. The model is fed by using market price indications and the amount of energy needed for the following day. Using forecast data, the model adapts offshore wind production for the following day according to the minimization of the average market price. The results of the simulations allow us to conclude that despite the high cost of offshore technology (in deep waters), in extreme climate scenarios, it enables cost reduction and a clear decrease in imports.
2023.10.18.16.33.18;18.10.2023;18;12;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1029/v1;;Preprints.org - The Multidisciplinary Preprint Platform;A Study on the Development of Prediction Model for Fleet Capacity of Dynamic Positioning Vessel in Response to Offshore Wind Farm Growth-Up;To address global warming, there is a worldwide effort to establish carbon-neutral energy plans. Given the characteristics of renewable energy generation, a diverse 'Energy Mix' consisting of various energy sources such as wind and solar power is crucial. In particular, the wind power is expected to continue expanding globally due to its sustainable nature. Furthermore, the expan-sion of offshore wind farm is making essential and a rapidly growing industry sector to be achieving carbon neutrality with limited land for construction. To facilitate the construction and operation of offshore wind farms, specialized vessels with dynamic positioning (DP) systems are essential such as Wind Turbine Installation Vessels (WTIVs) and Service Operating Vessels (SOVs). The purpose of this study is to predict and analyze the scale and structural changes in the fleet capacity of DP vessel, which is essential for offshore wind power construction as the offshore wind power industry develops using System Dynamics (SD) modeling. Specifically, this study aims to construct a demand forecasting model for DP vessel used in offshore wind farm con-struction based on SD methodology. The study aims to identify influencing factors by analyzing dynamic changes in system configurations over time and establishing causal relationships based on feedback structures. Instead of traditional time series analysis methods, causal relation-ship-based simulations were conducted for quantitative analysis. The results provide insights into the changes in the DP vessel market structure due to the emergence of the new industry and highlight areas that require improvement throughout the industry.
2023.10.18.16.33.19;18.10.2023;19;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.13567;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.13567.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1"">Kailai Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1"">Tianlin Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1"">Ziyan Kuang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1"">Qianqian Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ananiadou_S/0/1/0/all/0/1"">Sophia Ananiadou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1"">Jimin Huang</a>";Kailai Yang,Tianlin Zhang,Ziyan Kuang,Qianqian Xie,Sophia Ananiadou,Jimin Huang;MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models.;With the development of web technology, social media texts are becoming a rich source for automatic mental health analysis. As traditional discriminative methods bear the problem of low interpretability, the recent large language models have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions. The results show that ChatGPT can generate approaching-human explanations for its correct classifications. However, LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner. Domain-specific finetuning is an effective solution, but faces 2 challenges: 1) lack of high-quality training data. 2) no open-source LLMs for interpretable mental health analysis were released to lower the finetuning cost. To alleviate these problems, we build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset on social media, with 105K data samples. The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks. We use expert-written few-shot prompts and collected labels to prompt ChatGPT and obtain explanations from its responses. To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data. Based on the IMHI dataset and LLaMA2 foundation models, we train MentalLLaMA, the first open-source LLM series for interpretable mental health analysis with instruction-following capability. We also evaluate the performance of MentalLLaMA on the IMHI evaluation benchmark with 10 test sets, where their correctness for making predictions and the quality of explanations are examined. The results show that MentalLLaMA approaches state-of-the-art discriminative methods in correctness and generates high-quality explanations.
2023.10.18.16.33.20;18.10.2023;20;16;Legal;Legal, Law, Contracting et al.;arxiv;2305.15062;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.15062.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1"">Quzhe Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1"">Mingxu Tao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1"">Chen Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1"">Zhenwei An</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1"">Cong Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"">Zhibin Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1"">Zirui Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1"">Yansong Feng</a>";Quzhe Huang,Mingxu Tao,Chen Zhang,Zhenwei An,Cong Jiang,Zhibin Chen,Zirui Wu,Yansong Feng;Lawyer LLaMA Technical Report.;Large Language Models (LLMs), like LLaMA, have exhibited remarkable performance across various tasks. Nevertheless, when deployed to specific domains such as law or medicine, the models still confront the challenge of a deficiency in domain-specific knowledge and an inadequate capability to leverage that knowledge to resolve domain-related problems. In this paper, we propose a new framework to adapt LLMs to specific domains and build Lawyer LLaMA, a legal domain LLM, based on this framework. Specifically, we inject domain knowledge during the continual training stage and teach the model to learn professional skills using properly designed supervised fine-tuning tasks. Moreover, to alleviate the hallucination problem during the model's generation, we add a retrieval module and extract relevant legal articles before the model answers any queries. When learning domain-specific skills, we find that experts' experience is much more useful than experiences distilled from ChatGPT, where hundreds of expert-written data outperform tens of thousands of ChatGPT-generated ones. We will release our model and data.
2023.10.18.16.33.21;18.10.2023;21;18;AgriCulture;Agriculture et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.1009/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Agricultural IOT, Cloud Computing and Mobile Based Application Integration for the Total Discharge Predication of Two Farms Smart Agricultural System to Avoid Flooding;The information technology has brought in a revolution in the area of digital agriculture and hydrological modeling . With the advent of IOT and AI such as machine learning is now capable of Predicating flood forecast , drought forecast and farms based water predications. In this article various machine learning algorithms , multiple sensors for environmental and agricultural has been proposed and used . The purpose is to acquire data of soil moisture , temperature , crop stages, irrigation and precipitation on a region constitute of two farms and then performed machine learning predications for total discharge predications at farms outlets so that in case of excessive rainfall or an irrigation event the water is adjusted in the second nearby farm or reroute to a reservoir for future use to avoid flooding. The focus is mostly to work on the concept and building of an andriod -ardiuno based mobile application for the endusers (agricultural system analyst, farmers) to provide an ease. The whole system of smart agricultural based on two farms and reservoir will provide an efficient ,fully automatic, proactive and decision support system to save water waste and reuse. In future the work is also in progress for developing a desktop based application .
2023.10.18.16.33.22;18.10.2023;22;18;AgriCulture;Agriculture et al.;arxiv;2206.09649;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2206.09649.pdf;" <a href=""http://arxiv.org/find/physics/1/au:+Batchu_V/0/1/0/all/0/1"">Vishal Batchu</a>, <a href=""http://arxiv.org/find/physics/1/au:+Nearing_G/0/1/0/all/0/1"">Grey Nearing</a>, <a href=""http://arxiv.org/find/physics/1/au:+Gulshan_V/0/1/0/all/0/1"">Varun Gulshan</a>";Vishal Batchu,Grey Nearing,Varun Gulshan;A Machine Learning Data Fusion Model for Soil Moisture Retrieval.;We develop a deep learning based convolutional-regression model that estimates the volumetric soil moisture content in the top ~5 cm of soil. Input predictors include Sentinel-1 (active radar), Sentinel-2 (optical imagery), and SMAP (passive radar) as well as geophysical variables from SoilGrids and modelled soil moisture fields from GLDAS. The model was trained and evaluated on data from ~1300 in-situ sensors globally over the period 2015 - 2021 and obtained an average per-sensor correlation of 0.727 and ubRMSE of 0.054, and can be used to produce a soil moisture map at a nominal 320m resolution. These results are benchmarked against 13 other soil moisture works at different locations, and an ablation study was used to identify important predictors.
2023.10.18.16.33.23;18.10.2023;23;19;CrossTopic;Generic, Cross Topic, et al.;arxiv;2310.07652;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07652.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"">Lei Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"">Songheng Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yun Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1"">Ee-Peng Lim</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yong Wang</a>";Lei Wang,Songheng Zhang,Yun Wang,Ee-Peng Lim,Yong Wang;LLM4Vis: Explainable Visualization Recommendation using ChatGPT.;Data visualization is a powerful tool for exploring and communicating insights in various domains. To automate visualization choice for datasets, a task known as visualization recommendation has been proposed. Various machine-learning-based approaches have been developed for this purpose, but they often require a large corpus of dataset-visualization pairs for training and lack natural explanations for their results. To address this research gap, we propose LLM4Vis, a novel ChatGPT-based prompting approach to perform visualization recommendation and return human-like explanations using very few demonstration examples. Our approach involves feature description, demonstration example selection, explanation generation, demonstration example construction, and inference steps. To obtain demonstration examples with high-quality explanations, we propose a new explanation generation bootstrapping to iteratively refine generated explanations by considering the previous generation and template-based hint. Evaluations on the VizML dataset show that LLM4Vis outperforms or performs similarly to supervised learning models like Random Forest, Decision Tree, and MLP in both few-shot and zero-shot settings. The qualitative evaluation also shows the effectiveness of explanations generated by LLM4Vis. We make our code publicly available at \href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}.
2023.10.18.16.33.24;18.10.2023;24;20;Sports;Sports et al.;arxiv;2310.10553;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2310.10553.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"">Zhe Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1"">Petar Veli&#x10d;kovi&#x107;</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hennes_D/0/1/0/all/0/1"">Daniel Hennes</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tomasev_N/0/1/0/all/0/1"">Nenad Toma&#x161;ev</a>, <a href=""http://arxiv.org/find/cs/1/au:+Prince_L/0/1/0/all/0/1"">Laurel Prince</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kaisers_M/0/1/0/all/0/1"">Michael Kaisers</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bachrach_Y/0/1/0/all/0/1"">Yoram Bachrach</a>, <a href=""http://arxiv.org/find/cs/1/au:+Elie_R/0/1/0/all/0/1"">Romuald Elie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wenliang_L/0/1/0/all/0/1"">Li Kevin Wenliang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Piccinini_F/0/1/0/all/0/1"">Federico Piccinini</a>, <a href=""http://arxiv.org/find/cs/1/au:+Spearman_W/0/1/0/all/0/1"">William Spearman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Graham_I/0/1/0/all/0/1"">Ian Graham</a>, <a href=""http://arxiv.org/find/cs/1/au:+Connor_J/0/1/0/all/0/1"">Jerome Connor</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"">Yi Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Recasens_A/0/1/0/all/0/1"">Adri&#xe0; Recasens</a>, <a href=""http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1"">Mina Khan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Beauguerlange_N/0/1/0/all/0/1"">Nathalie Beauguerlange</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sprechmann_P/0/1/0/all/0/1"">Pablo Sprechmann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Moreno_P/0/1/0/all/0/1"">Pol Moreno</a>, <a href=""http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1"">Nicolas Heess</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bowling_M/0/1/0/all/0/1"">Michael Bowling</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hassabis_D/0/1/0/all/0/1"">Demis Hassabis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1"">Karl Tuyls</a>";"Zhe Wang,Petar Veli&#x10d;kovi&#x107;,Daniel Hennes,Nenad Toma&#x161;ev,Laurel Prince,Michael Kaisers,Yoram Bachrach,Romuald Elie,Li Kevin Wenliang,Federico Piccinini,William Spearman,Ian Graham,Jerome Connor,Yi Yang,Adrià Recasens,Mina Khan,Nathalie Beauguerlange,Pablo Sprechmann,Pol Moreno,Nicolas Heess,Michael Bowling,Demis Hassabis,Karl Tuyls";TacticAI: an AI assistant for football tactics.;Identifying key patterns of tactics implemented by rival teams, and developing effective responses, lies at the heart of modern football. However, doing so algorithmically remains an open research challenge. To address this unmet need, we propose TacticAI, an AI football tactics assistant developed and evaluated in close collaboration with domain experts from Liverpool FC. We focus on analysing corner kicks, as they offer coaches the most direct opportunities for interventions and improvements. TacticAI incorporates both a predictive and a generative component, allowing the coaches to effectively sample and explore alternative player setups for each corner kick routine and to select those with the highest predicted likelihood of success. We validate TacticAI on a number of relevant benchmark tasks: predicting receivers and shot attempts and recommending player position adjustments. The utility of TacticAI is validated by a qualitative study conducted with football domain experts at Liverpool FC. We show that TacticAI's model suggestions are not only indistinguishable from real tactics, but also favoured over existing tactics 90% of the time, and that TacticAI offers an effective corner kick retrieval system. TacticAI achieves these results despite the limited availability of gold-standard data, achieving data efficiency through geometric deep learning.
2023.10.18.16.33.25;18.10.2023;25;99;Other;Others;towardsdatascience;;;https://towardsdatascience.com/a-python-tool-for-fetching-air-pollution-data-from-google-maps-air-quality-apis-7cf58a7c63cb?source=rss----7f60cf5620c9---4;;;A Python Tool for Fetching Air Pollution Data from Google Maps Air Quality APIs;This article details how we can use the Google Maps Air Quality APIs in Python to fetch and explore live air pollution data, time series and maps. ...
2023.10.18.16.33.26;18.10.2023;26;99;Other;Others;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/empowering-logo-design-with-segminds-generative-ai/;;;Empowering Logo Design with Segmind’s Generative AI;This article delves into Segmind’s generative AI, unveiling its impact on logo design, from technical prowess to real-world applications. Discover how this fusion of technology and design is revolutionizing logo creation. ...
2023.10.16.17.19.01;16.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.03026;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03026.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sha_H/0/1/0/all/0/1"">Hao Sha</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1"">Yao Mu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1"">Yuxuan Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1"">Li Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1"">Chenfeng Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1"">Ping Luo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1"">Shengbo Eben Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1"">Masayoshi Tomizuka</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1"">Wei Zhan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1"">Mingyu Ding</a>";Hao Sha,Yao Mu,Yuxuan Jiang,Li Chen,Chenfeng Xu,Ping Luo,Shengbo Eben Li,Masayoshi Tomizuka,Wei Zhan,Mingyu Ding;LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving.;Existing learning-based autonomous driving (AD) systems face challenges in comprehending high-level information, generalizing to rare events, and providing interpretability. To address these problems, this work employs Large Language Models (LLMs) as a decision-making component for complex AD scenarios that require human commonsense understanding. We devise cognitive pathways to enable comprehensive reasoning with LLMs, and develop algorithms for translating LLM decisions into actionable driving commands. Through this approach, LLM decisions are seamlessly integrated with low-level controllers by guided parameter matrix adaptation. Extensive experiments demonstrate that our proposed method not only consistently surpasses baseline approaches in single-vehicle tasks, but also helps handle complex driving behaviors even multi-vehicle coordination, thanks to the commonsense reasoning capabilities of LLMs. This paper presents an initial step toward leveraging LLMs as effective decision-makers for intricate AD scenarios in terms of safety, efficiency, generalizability, and interoperability. We aspire for it to serve as inspiration for future research in this field. Project page: https://sites.google.com/view/llm-mpc
2023.10.16.17.19.02;16.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.08740;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08740.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1"">Tao Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1"">Gang Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1"">Zhiwei Deng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1"">Bryan Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"">Yang Li</a>";Tao Li,Gang Li,Zhiwei Deng,Bryan Wang,Yang Li;A Zero-Shot Language Agent for Computer Control with Structured Reflection.;Large language models (LLMs) have shown increasing capacity at planning and executing a high-level goal in a live computer environment (e.g. MiniWoB++). To perform a task, recent works often require a model to learn from trace examples of the task via either supervised learning or few/many-shot prompting. Without these trace examples, it remains a challenge how an agent can autonomously learn and improve its control on a computer, which limits the ability of an agent to perform a new task. We approach this problem with a zero-shot agent that requires no given expert traces. Our agent plans for executable actions on a partially observed environment, and iteratively progresses a task by identifying and learning from its mistakes via self-reflection and structured thought management. On the easy tasks of MiniWoB++, we show that our zero-shot agent often outperforms recent SoTAs, with more efficient reasoning. For tasks with more complexity, our reflective agent performs on par with prior best models, even though previous works had the advantages of accessing expert traces or additional screen information.
2023.10.16.17.19.03;16.10.2023;03;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.08672;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08672.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Athey_S/0/1/0/all/0/1"">Susan Athey</a>, <a href=""http://arxiv.org/find/econ/1/au:+Keleher_N/0/1/0/all/0/1"">Niall Keleher</a>, <a href=""http://arxiv.org/find/econ/1/au:+Spiess_J/0/1/0/all/0/1"">Jann Spiess</a>";Susan Athey,Niall Keleher,Jann Spiess;Machine Learning Who to Nudge: Causal vs Predictive Targeting in a Field Experiment on Student Financial Aid Renewal.;"In many settings, interventions may be more effective for some individuals than others, so that targeting interventions may be beneficial. We analyze the value of targeting in the context of a large-scale field experiment with over 53,000 college students, where the goal was to use ""nudges"" to encourage students to renew their financial-aid applications before a non-binding deadline. We begin with baseline approaches to targeting. First, we target based on a causal forest that estimates heterogeneous treatment effects and then assigns students to treatment according to those estimated to have the highest treatment effects. Next, we evaluate two alternative targeting policies, one targeting students with low predicted probability of renewing financial aid in the absence of the treatment, the other targeting those with high probability. The predicted baseline outcome is not the ideal criterion for targeting, nor is it a priori clear whether to prioritize low, high, or intermediate predicted probability. Nonetheless, targeting on low baseline outcomes is common in practice, for example because the relationship between individual characteristics and treatment effects is often difficult or impossible to estimate with historical data. We propose hybrid approaches that incorporate the strengths of both predictive approaches (accurate estimation) and causal approaches (correct criterion); we show that targeting intermediate baseline outcomes is most effective, while targeting based on low baseline outcomes is detrimental. In one year of the experiment, nudging all students improved early filing by an average of 6.4 percentage points over a baseline average of 37% filing, and we estimate that targeting half of the students using our preferred policy attains around 75% of this benefit."
2023.10.16.17.19.04;16.10.2023;04;04;Supply Chain;Logistics, Supply Chains, Transportation et al.;arxiv;2310.08988;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08988.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Oliveira_I/0/1/0/all/0/1"">&#xcd;talo Romani de Oliveira</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ayhan_S/0/1/0/all/0/1"">Samet Ayhan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Biglin_M/0/1/0/all/0/1"">Michael Biglin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Costas_P/0/1/0/all/0/1"">Pablo Costas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Neto_E/0/1/0/all/0/1"">Euclides C. Pinto Neto</a>";Ítalo Romani de Oliveira,Samet Ayhan,Michael Biglin,Pablo Costas,Euclides C. Pinto Neto;Reroute Prediction Service.;The cost of delays was estimated as 33 billion US dollars only in 2019 for the US National Airspace System, a peak value following a growth trend in past years. Aiming to address this huge inefficiency, we designed and developed a novel Data Analytics and Machine Learning system, which aims at reducing delays by proactively supporting re-routing decisions. Given a time interval up to a few days in the future, the system predicts if a reroute advisory for a certain Air Route Traffic Control Center or for a certain advisory identifier will be issued, which may impact the pertinent routes. To deliver such predictions, the system uses historical reroute data, collected from the System Wide Information Management (SWIM) data services provided by the FAA, and weather data, provided by the US National Centers for Environmental Prediction (NCEP). The data is huge in volume, and has many items streamed at high velocity, uncorrelated and noisy. The system continuously processes the incoming raw data and makes it available for the next step where an interim data store is created and adaptively maintained for efficient query processing. The resulting data is fed into an array of ML algorithms, which compete for higher accuracy. The best performing algorithm is used in the final prediction, generating the final results. Mean accuracy values higher than 90% were obtained in our experiments with this system. Our algorithm divides the area of interest in units of aggregation and uses temporal series of the aggregate measures of weather forecast parameters in each geographical unit, in order to detect correlations with reroutes and where they will most likely occur. Aiming at practical application, the system is formed by a number of microservices, which are deployed in the cloud, making the system distributed, scalable and highly available.
2023.10.16.17.19.05;16.10.2023;05;05;Industry;Industry 4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0948/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Multimodal Assessment of Cognitive Workload Using Neural, Subjective and Behavioural Measures in Smart Factory Settings;Collaborative robots (cobots) have largely replaced conventional industrial robots in today’s workplaces, particularly in manufacturing setups due to their improved performance and intelligent design. In the framework of Industry 5.0, humans are working alongside cobots to accomplish the required level of automation. However, human-robot interaction has brought up concerns regarding human factors (HF) and ergonomics. A human worker may experience cognitive stress as a result of cobots' irresponsive nature in unpredictably occurring situations, which adversely affects productivity. Therefore, there is a necessity to measure stress to enhance a human worker’s performance in a human-robot collaborative environment. In this study, factory workers’ mental workload has been assessed using physiological, behavioural, and subjective measures. Electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) signals have been collected to acquire brain signals and track hemodynamic activity, respectively. The effect of task complexity, cobot’s movement speed, and cobot’s payload capacity on the mental stress of a human worker have been observed, for a task designed in the context of a smart factory. Task complexity and cobot’s speed have proved to be more impactful. As physiological measures are unbiased and more authentic means to estimate stress, eventually, they may replace the other conventional measures if they prove to correlate with the results of traditional ones. Here, regression and artificial neural networks (ANN) have been utilised to determine the correlation between physiological data and subjective and behavioural measures. Regression has performed better for most of the targets and the best correlation (rsq-adj = 0.654146) has been achieved for predicting missed beeps, behavioural measure, using a combination of multiple EEG and fNIRS predictors. The k-nearest neighbours (KNN) algorithm has been used to evaluate the accuracy of correlation between traditional measures and physiological variables, with highest accuracy of 77.8% achieved for missed beeps as the target. Results show that physiological measures can be more insightful and have the tendency to replace other biased parameters.
2023.10.16.17.19.06;16.10.2023;06;07;Software;Development, Software Engineering et al.;arxiv;2310.09234;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.09234.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1"">Jianghao Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1"">Bo Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"">Hangyu Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xi_Y/0/1/0/all/0/1"">Yunjia Xi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1"">Yanru Qu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1"">Xinyi Dai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1"">Kangning Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1"">Ruiming Tang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1"">Yong Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"">Weinan Zhang</a>";Jianghao Lin,Bo Chen,Hangyu Wang,Yunjia Xi,Yanru Qu,Xinyi Dai,Kangning Zhang,Ruiming Tang,Yong Yu,Weinan Zhang;ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction.;Click-through rate (CTR) prediction has become increasingly indispensable for various Internet applications. Traditional CTR models convert the multi-field categorical data into ID features via one-hot encoding, and extract the collaborative signals among features. Such a paradigm suffers from the problem of semantic information loss. Another line of research explores the potential of pretrained language models (PLMs) for CTR prediction by converting input data into textual sentences through hard prompt templates. Although semantic signals are preserved, they generally fail to capture the collaborative information (e.g., feature interactions, pure ID features), not to mention the unacceptable inference overhead brought by the huge model size. In this paper, we aim to model both the semantic knowledge and collaborative knowledge for accurate CTR estimation, and meanwhile address the inference inefficiency issue. To benefit from both worlds and close their gaps, we propose a novel model-agnostic framework (i.e., ClickPrompt), where we incorporate CTR models to generate interaction-aware soft prompts for PLMs. We design a prompt-augmented masked language modeling (PA-MLM) pretraining task, where PLM has to recover the masked tokens based on the language context, as well as the soft prompts generated by CTR model. The collaborative and semantic knowledge from ID and textual features would be explicitly aligned and interacted via the prompt interface. Then, we can either tune the CTR model with PLM for superior performance, or solely tune the CTR model without PLM for inference efficiency. Experiments on four real-world datasets validate the effectiveness of ClickPrompt compared with existing baselines.
2023.10.16.17.19.07;16.10.2023;07;07;Software;Development, Software Engineering et al.;arxiv;2310.08992;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08992.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1"">Hung Le</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"">Hailin Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1"">Amrita Saha</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gokul_A/0/1/0/all/0/1"">Akash Gokul</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sahoo_D/0/1/0/all/0/1"">Doyen Sahoo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1"">Shafiq Joty</a>";Hung Le,Hailin Chen,Amrita Saha,Akash Gokul,Doyen Sahoo,Shafiq Joty;CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules.;Large Language Models (LLMs) have already become quite proficient at solving simpler programming tasks like those in HumanEval or MBPP benchmarks. However, solving more complex and competitive programming tasks is still quite challenging for these models - possibly due to their tendency to generate solutions as monolithic code blocks instead of decomposing them into logical sub-tasks and sub-modules. On the other hand, experienced programmers instinctively write modularized code with abstraction for solving complex tasks, often reusing previously developed modules. To address this gap, we propose CodeChain, a novel framework for inference that elicits modularized code generation through a chain of self-revisions, each being guided by some representative sub-modules generated in previous iterations. Concretely, CodeChain first instructs the LLM to generate modularized codes through chain-of-thought prompting. Then it applies a chain of self-revisions by iterating the two steps: 1) extracting and clustering the generated sub-modules and selecting the cluster representatives as the more generic and re-usable implementations, and 2) augmenting the original chain-of-thought prompt with these selected module-implementations and instructing the LLM to re-generate new modularized solutions. We find that by naturally encouraging the LLM to reuse the previously developed and verified sub-modules, CodeChain can significantly boost both modularity as well as correctness of the generated solutions, achieving relative pass@1 improvements of 35% on APPS and 76% on CodeContests. It is shown to be effective on both OpenAI LLMs as well as open-sourced LLMs like WizardCoder. We also conduct comprehensive ablation studies with different methods of prompting, number of clusters, model sizes, program qualities, etc., to provide useful insights that underpin CodeChain's success.
2023.10.16.17.19.08;16.10.2023;08;09;Human;Human Resource, Personal Assistance et al.;arxiv;2310.09136;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.09136.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Aldwairi_M/0/1/0/all/0/1"">Monther Aldwairi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Badra_M/0/1/0/all/0/1"">Mohamad Badra</a>, <a href=""http://arxiv.org/find/cs/1/au:+Borghol_R/0/1/0/all/0/1"">Rouba Borghol</a>";Monther Aldwairi,Mohamad Badra,Rouba Borghol;DocCert: Nostrification, Document Verification and Authenticity Blockchain Solution.;Many institutions and organizations require nostrification and verification of qualification as a prerequisite for hiring. The idea is to recognize the authenticity of a copy or digital document issued by an institution in a foreign country and detect forgeries. Certificates, financial records, health records, official papers and others are often required to be attested from multiple entities in distinct locations. However, in this digital era where most applications happen online, and document copies are uploaded, the traditional signature and seal methods are obsolete. In a matter of minutes and with a simple photo editor, a certificate or document copy may be plagiarized or forged. Blockchain technology offers a decentralized approach to record and verify transactions without the need for huge infrastructure investment. In this paper, we propose a blockchain based nostrification system, where awarding institutions generate a digital certificate, store in a public but permissioned blockchain, where students and other stakeholders may verify. We present a thorough discussion and formal evaluation of the proposed system.
2023.10.16.17.19.09;16.10.2023;09;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.08691;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08691.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Mirzapour_O/0/1/0/all/0/1"">Omid Mirzapour</a>, <a href=""http://arxiv.org/find/eess/1/au:+Rui_X/0/1/0/all/0/1"">Xinyang Rui</a>, <a href=""http://arxiv.org/find/eess/1/au:+Pruneau_B/0/1/0/all/0/1"">Brittany Pruneau</a>, <a href=""http://arxiv.org/find/eess/1/au:+Sahraei_Ardakani_M/0/1/0/all/0/1"">Mostafa Sahraei-Ardakani</a>";Omid Mirzapour,Xinyang Rui,Brittany Pruneau,Mostafa Sahraei-Ardakani;Flexible Transmission: A Comprehensive Review of Concepts, Technologies, and Market.;As global concerns regarding climate change are increasing worldwide, the transition towards clean energy sources has accelerated. Accounting for a large share of energy consumption, the electricity sector is experiencing a significant shift towards renewable energy sources. To accommodate this rapid shift, the transmission system requires major upgrades. Although enhancing grid capacity through transmission system expansion is always a solution, this solution is very costly and requires a protracted permitting process. The concept of flexible transmission encompasses a broad range of technologies and market tools that enable effective reconfiguration and manipulation of the power grid for leveraged dispatch of renewable energy resources. The proliferation of such technologies allows for enhanced transfer capability over the current transmission network, thus reducing the need for grid expansion projects. This paper comprehensively reviews flexible transmission technologies and their role in achieving a net-zero carbon emission grid vision. Flexible transmission definitions from different viewpoints are discussed, and mathematical measures to quantify grid flexibility are reviewed. An extensive range of technologies enhancing flexibility across the grid is introduced and explored in detail. The environmental impacts of flexible transmission, including renewable energy utilization and carbon emission reduction, are presented. Finally, market models required for creating proper incentives for the deployment of flexible transmission and regulatory barriers and challenges are discussed.
2023.10.16.17.19.10;16.10.2023;10;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.09020;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.09020.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Vishwakarma_A/0/1/0/all/0/1"">Amit kumar Vishwakarma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Singh_Y/0/1/0/all/0/1"">Yatindra Nath Singh</a>";Amit kumar Vishwakarma,Yatindra Nath Singh;Credit Blockchain for Faster Transactions in P2P Energy Trading.;P2P trading of energy can be a good alternative to incentivize distributed non-conventional energy production and meet the burgeoning energy demand. For efficient P2P trading, a free market for trading needs to be established while ensuring the information reliability, security, and privacy. Blockchain has been used to provide this framework, but it consumes very high energy and is slow. Further, until now, no blockchain model has considered the role of conventional electric utility companies in P2P trading. In this paper, we have introduced a credit blockchain that reduces energy consumption by employing a new mechanism to update transactions and increases speed by providing interest free loans to buyers. This model also integrates the electric utility companies within the P2P trading framework, thereby increasing members trading options. We have also discussed the pricing strategies for trading. All the above assertions have been verified through simulations, demonstrating that this model will promote P2P trading by providing enhanced security, speed, and greater trading options. The proposed model will also help trade energy at prices beneficial for both sellers and buyers.
2023.10.16.17.19.11;16.10.2023;11;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.09040;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.09040.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Menos_Aikateriniadis_C/0/1/0/all/0/1"">Christoforos Menos-Aikateriniadis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sykiotis_S/0/1/0/all/0/1"">Stavros Sykiotis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Georgilakis_P/0/1/0/all/0/1"">Pavlos S. Georgilakis</a>";Christoforos Menos-Aikateriniadis,Stavros Sykiotis,Pavlos S. Georgilakis;Optimal Scheduling of Electric Vehicle Charging with Deep Reinforcement Learning considering End Users Flexibility.;The rapid growth of decentralized energy resources and especially Electric Vehicles (EV), that are expected to increase sharply over the next decade, will put further stress on existing power distribution networks, increasing the need for higher system reliability and flexibility. In an attempt to avoid unnecessary network investments and to increase the controllability over distribution networks, network operators develop demand response (DR) programs that incentivize end users to shift their consumption in return for financial or other benefits. Artificial intelligence (AI) methods are in the research forefront for residential load scheduling applications, mainly due to their high accuracy, high computational speed and lower dependence on the physical characteristics of the models under development. The aim of this work is to identify households' EV cost-reducing charging policy under a Time-of-Use tariff scheme, with the use of Deep Reinforcement Learning, and more specifically Deep Q-Networks (DQN). A novel end users flexibility potential reward is inferred from historical data analysis, where households with solar power generation have been used to train and test the designed algorithm. The suggested DQN EV charging policy can lead to more than 20% of savings in end users electricity bills.
2023.10.16.17.19.12;16.10.2023;12;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.08712;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08712.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Banaei_M/0/1/0/all/0/1"">Mohsen Banaei</a>, <a href=""http://arxiv.org/find/eess/1/au:+Buygi_M/0/1/0/all/0/1"">Majid Oloomi Buygi</a>, <a href=""http://arxiv.org/find/eess/1/au:+Raouf_Sheybani_H/0/1/0/all/0/1"">Hani Raouf-Sheybani</a>, <a href=""http://arxiv.org/find/eess/1/au:+Ebrahimy_R/0/1/0/all/0/1"">Razgar Ebrahimy</a>, <a href=""http://arxiv.org/find/eess/1/au:+Madsen_H/0/1/0/all/0/1"">Henrik Madsen</a>";Mohsen Banaei,Majid Oloomi Buygi,Hani Raouf-Sheybani,Razgar Ebrahimy,Henrik Madsen;Nash Equilibrium of Joint Day-ahead Electricity Markets and Forward Contracts in Congested Power Systems.;Uncertainty in the output power of large-scale wind power plants (WPPs) can face the electricity market players with undesirable profit variations. Market players can hedge themselves against these risks by participating in forward contracts markets alongside the day-ahead markets. The participation of market players in these two markets affects their profits and also the prices and power quantities of each market. Moreover, limitations in the transmission grid can affect the optimal behavior of market players. In this paper, a Cournot Nash equilibrium model is proposed to study the behavior of market players in the forward contract market and the day-ahead electricity market in a congested power system with large-scale integration of WPPs. The proposed method is applied to a test system, and the results are discussed.
2023.10.16.17.19.13;16.10.2023;13;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.08650;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08650.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Most_A/0/1/0/all/0/1"">Alexander Most</a>, <a href=""http://arxiv.org/find/cs/1/au:+Eren_M/0/1/0/all/0/1"">Maksim Eren</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lawrence_N/0/1/0/all/0/1"">Nigel Lawrence</a>, <a href=""http://arxiv.org/find/cs/1/au:+Alexandrov_B/0/1/0/all/0/1"">Boian Alexandrov</a>";Alexander Most,Maksim Eren,Nigel Lawrence,Boian Alexandrov;Electrical Grid Anomaly Detection via Tensor Decomposition.;"Supervisory Control and Data Acquisition (SCADA) systems often serve as the nervous system for substations within power grids. These systems facilitate real-time monitoring, data acquisition, control of equipment, and ensure smooth and efficient operation of the substation and its connected devices. Previous work has shown that dimensionality reduction-based approaches, such as Principal Component Analysis (PCA), can be used for accurate identification of anomalies in SCADA systems. While not specifically applied to SCADA, non-negative matrix factorization (NMF) has shown strong results at detecting anomalies in wireless sensor networks. These unsupervised approaches model the normal or expected behavior and detect the unseen types of attacks or anomalies by identifying the events that deviate from the expected behavior. These approaches; however, do not model the complex and multi-dimensional interactions that are naturally present in SCADA systems. Differently, non-negative tensor decomposition is a powerful unsupervised machine learning (ML) method that can model the complex and multi-faceted activity details of SCADA events. In this work, we novelly apply the tensor decomposition method Canonical Polyadic Alternating Poisson Regression (CP-APR) with a probabilistic framework, which has previously shown state-of-the-art anomaly detection results on cyber network data, to identify anomalies in SCADA systems. We showcase that the use of statistical behavior analysis of SCADA communication with tensor decomposition improves the specificity and accuracy of identifying anomalies in electrical grid systems. In our experiments, we model real-world SCADA system data collected from the electrical grid operated by Los Alamos National Laboratory (LANL) which provides transmission and distribution service through a partnership with Los Alamos County, and detect synthetically generated anomalies."
2023.10.16.17.19.14;16.10.2023;14;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.08721;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2310.08721.pdf;" <a href=""http://arxiv.org/find/stat/1/au:+Pang_J/0/1/0/all/0/1"">Jincheng Pang</a>, <a href=""http://arxiv.org/find/stat/1/au:+Yan_H/0/1/0/all/0/1"">Hong Yan</a>, <a href=""http://arxiv.org/find/stat/1/au:+Hua_Z/0/1/0/all/0/1"">Zoe Hua</a>";Jincheng Pang,Hong Yan,Zoe Hua;Drug Supply Chain Optimization for Adaptive Clinical Trials.;With increasing interest in adaptive clinical trial designs, challenges are present to drug supply chain management which may offset the benefit of adaptive designs. Thus, it is necessary to develop an optimization tool to facilitate the decision making and analysis of drug supply chain planning. The challenges include the uncertainty of maximum drug supply needed, the shifting of supply requirement, and rapid availability of new supply at decision points. In this paper, statistical simulations are designed to optimize the pre-study medication supply strategy and monitor ongoing drug supply using real-time data collected with the progress of study. Particle swarm algorithm is applied when performing optimization, where feature extraction is implemented to reduce dimensionality and save computational cost.
2023.10.16.17.19.15;16.10.2023;15;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.08759;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08759.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bardhan_J/0/1/0/all/0/1"">Jayetri Bardhan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Roberts_K/0/1/0/all/0/1"">Kirk Roberts</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"">Daisy Zhe Wang</a>";Jayetri Bardhan,Kirk Roberts,Daisy Zhe Wang;Question Answering for Electronic Health Records: A Scoping Review of datasets and models.;Question Answering (QA) systems on patient-related data can assist both clinicians and patients. They can, for example, assist clinicians in decision-making and enable patients to have a better understanding of their medical history. Significant amounts of patient data are stored in Electronic Health Records (EHRs), making EHR QA an important research area. In EHR QA, the answer is obtained from the medical record of the patient. Because of the differences in data format and modality, this differs greatly from other medical QA tasks that employ medical websites or scientific papers to retrieve answers, making it critical to research EHR question answering. This study aimed to provide a methodological review of existing works on QA over EHRs. We searched for articles from January 1st, 2005 to September 30th, 2023 in four digital sources including Google Scholar, ACL Anthology, ACM Digital Library, and PubMed to collect relevant publications on EHR QA. 4111 papers were identified for our study, and after screening based on our inclusion criteria, we obtained a total of 47 papers for further study. Out of the 47 papers, 25 papers were about EHR QA datasets, and 37 papers were about EHR QA models. It was observed that QA on EHRs is relatively new and unexplored. Most of the works are fairly recent. Also, it was observed that emrQA is by far the most popular EHR QA dataset, both in terms of citations and usage in other papers. Furthermore, we identified the different models used in EHR QA along with the evaluation metrics used for these models.
2023.10.16.17.19.16;16.10.2023;16;20;Sports;Sports et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.0372/v3;;Preprints.org - The Multidisciplinary Preprint Platform;Machine Learning Tools Applied for Training Optimization in Handball;Analytics have become increasingly popular among sports in recent years, providing valuable information regarding physical and mental health. Many athletes have found that analytics during training can help to improve their performance, reduce the risk of injury, and enhance their overall well-being. This paper aims to improve the results of handball players by applying a method for measuring the influence of different trials on aggregate performance calculated per each athlete in order to qualify for the Olympic Games. By separating the isolated action of each trial, the result is an additional influence caused by the interaction of factors or the simultaneous action. That might explain why the neuromuscular feedback loop is utterly necessary to perform handball motor actions. Further on, the ML analysis can help identify areas for improvement, optimize training programs, and enhance overall team performance.
2023.10.14.18.50.01;14.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.04948;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04948.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1"">Defu Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1"">Furong Jia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1"">Sercan O Arik</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1"">Tomas Pfister</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1"">Yixiang Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1"">Wen Ye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Yan Liu</a>";Defu Cao,Furong Jia,Sercan O Arik,Tomas Pfister,Yixiang Zheng,Wen Ye,Yan Liu;TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting.;"The past decade has witnessed significant advances in time series modeling with deep learning. While achieving state-of-the-art results, the best-performing architectures vary highly across applications and domains. Meanwhile, for natural language processing, the Generative Pre-trained Transformer (GPT) has demonstrated impressive performance via training one general-purpose model across various textual datasets. It is intriguing to explore whether GPT-type architectures can be effective for time series, capturing the intrinsic dynamic attributes and leading to significant accuracy improvements. In this paper, we propose a novel framework, TEMPO, that can effectively learn time series representations. We focus on utilizing two essential inductive biases of the time series task for pre-trained models: (i) decomposition of the complex interaction between trend, seasonal and residual components; and (ii) introducing the selection-based prompts to facilitate distribution adaptation in non-stationary time series. TEMPO expands the capability for dynamically modeling real-world temporal phenomena from data within diverse domains. Our experiments demonstrate the superior performance of TEMPO over state-of-the-art methods on a number of time series benchmark datasets. This performance gain is observed not only in standard supervised learning settings but also in scenarios involving previously unseen datasets as well as in scenarios with multi-modal inputs. This compelling finding highlights TEMPO's potential to constitute a foundational model-building framework."
2023.10.14.18.50.02;14.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.07793;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07793.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1"">Ruotong Liao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1"">Xu Jia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1"">Yunpu Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1"">Volker Tresp</a>";Ruotong Liao,Xu Jia,Yunpu Ma,Volker Tresp;GenTKG: Generative Forecasting on Temporal Knowledge Graph.;The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional carefully designed embedding-based and rule-based models dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs. To address these challenges, we propose a novel retrieval augmented generation framework that performs generative forecasting on tKGs named GenTKG, which combines a temporal logical rule-based retrieval strategy and lightweight parameter-efficient instruction tuning. Extensive experiments have shown that GenTKG outperforms conventional methods of temporal relational forecasting under low computation resources. GenTKG also highlights remarkable transferability with exceeding performance on unseen datasets without re-training. Our work reveals the huge potential of LLMs in the tKG domain and opens a new frontier for generative forecasting on tKGs.
2023.10.14.18.50.03;14.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.08278;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08278.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Rasul_K/0/1/0/all/0/1"">Kashif Rasul</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ashok_A/0/1/0/all/0/1"">Arjun Ashok</a>, <a href=""http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1"">Andrew Robert Williams</a>, <a href=""http://arxiv.org/find/cs/1/au:+Khorasani_A/0/1/0/all/0/1"">Arian Khorasani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Adamopoulos_G/0/1/0/all/0/1"">George Adamopoulos</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bhagwatkar_R/0/1/0/all/0/1"">Rishika Bhagwatkar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bilos_M/0/1/0/all/0/1"">Marin Bilo&#x161;</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ghonia_H/0/1/0/all/0/1"">Hena Ghonia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hassen_N/0/1/0/all/0/1"">Nadhir Vincent Hassen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schneider_A/0/1/0/all/0/1"">Anderson Schneider</a>, <a href=""http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1"">Sahil Garg</a>, <a href=""http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1"">Alexandre Drouin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chapados_N/0/1/0/all/0/1"">Nicolas Chapados</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nevmyvaka_Y/0/1/0/all/0/1"">Yuriy Nevmyvaka</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1"">Irina Rish</a>";"Kashif Rasul,Arjun Ashok,Andrew Robert Williams,Arian Khorasani,George Adamopoulos,Rishika Bhagwatkar,Marin Bilo&#x161;,Hena Ghonia,Nadhir Vincent Hassen,Anderson Schneider,Sahil Garg,Alexandre Drouin,Nicolas Chapados,Yuriy Nevmyvaka,Irina Rish";Lag-Llama: Towards Foundation Models for Time Series Forecasting.;"Aiming to build foundation models for time-series forecasting and study their scaling behavior, we present here our work-in-progress on Lag-Llama, a general-purpose univariate probabilistic time-series forecasting model trained on a large collection of time-series data. The model shows good zero-shot prediction capabilities on unseen ""out-of-distribution"" time-series datasets, outperforming supervised baselines. We use smoothly broken power-laws to fit and predict model scaling behavior. The open source code is made available at https://github.com/kashif/pytorch-transformer-ts."
2023.10.14.18.50.04;14.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.08167;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08167.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Gunes_E/0/1/0/all/0/1"">Erkan Gunes</a>, <a href=""http://arxiv.org/find/cs/1/au:+Florczak_C/0/1/0/all/0/1"">Christoffer Koch Florczak</a>";Erkan Gunes,Christoffer Koch Florczak;Multiclass Classification of Policy Documents with Large Language Models.;Classifying policy documents into policy issue topics has been a long-time effort in political science and communication disciplines. Efforts to automate text classification processes for social science research purposes have so far achieved remarkable results, but there is still a large room for progress. In this work, we test the prediction performance of an alternative strategy, which requires human involvement much less than full manual coding. We use the GPT 3.5 and GPT 4 models of the OpenAI, which are pre-trained instruction-tuned Large Language Models (LLM), to classify congressional bills and congressional hearings into Comparative Agendas Project's 21 major policy issue topics. We propose three use-case scenarios and estimate overall accuracies ranging from %58-83 depending on scenario and GPT model employed. The three scenarios aims at minimal, moderate, and major human interference, respectively. Overall, our results point towards the insufficiency of complete reliance on GPT with minimal human intervention, an increasing accuracy along with the human effort exerted, and a surprisingly high accuracy achieved in the most humanly demanding use-case. However, the superior use-case achieved the %83 accuracy on the %65 of the data in which the two models agreed, suggesting that a similar approach to ours can be relatively easily implemented and allow for mostly automated coding of a majority of a given dataset. This could free up resources allowing manual human coding of the remaining %35 of the data to achieve an overall higher level of accuracy while reducing costs significantly.
2023.10.14.18.50.05;14.10.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.07944;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07944.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Pu_H/0/1/0/all/0/1"">Hongxu Pu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1"">Xincong Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Jing Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1"">Runhao Guo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1"">Heng Li</a>";Hongxu Pu,Xincong Yang,Jing Li,Runhao Guo,Heng Li;AutoRepo: A general framework for multi-modal LLM-based automated construction reporting.;Ensuring the safety, quality, and timely completion of construction projects is paramount, with construction inspections serving as a vital instrument towards these goals. Nevertheless, the predominantly manual approach of present-day inspections frequently results in inefficiencies and inadequate information management. Such methods often fall short of providing holistic, exhaustive assessments, consequently engendering regulatory oversights and potential safety hazards. To address this issue, this paper presents a novel framework named AutoRepo for automated generation of construction inspection reports. The unmanned vehicles efficiently perform construction inspections and collect scene information, while the multimodal large language models (LLMs) are leveraged to automatically generate the inspection reports. The framework was applied and tested on a real-world construction site, demonstrating its potential to expedite the inspection process, significantly reduce resource allocation, and produce high-quality, regulatory standard-compliant inspection reports. This research thus underscores the immense potential of multimodal large language models in revolutionizing construction inspection practices, signaling a significant leap forward towards a more efficient and safer construction management paradigm.
2023.10.14.18.50.06;14.10.2023;06;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.08034;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08034.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1"">Can Cui</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1"">Yunsheng Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1"">Xu Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1"">Wenqian Ye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"">Ziran Wang</a>";Can Cui,Yunsheng Ma,Xu Cao,Wenqian Ye,Ziran Wang;Receive, Reason, and React: Drive as You Say with Large Language Models in Autonomous Vehicles.;The fusion of human-centric design and artificial intelligence (AI) capabilities has opened up new possibilities for next-generation autonomous vehicles that go beyond transportation. These vehicles can dynamically interact with passengers and adapt to their preferences. This paper proposes a novel framework that leverages Large Language Models (LLMs) to enhance the decision-making process in autonomous vehicles. By utilizing LLMs' linguistic and contextual understanding abilities with specialized tools, we aim to integrate the language and reasoning capabilities of LLMs into autonomous vehicles. Our research includes experiments in HighwayEnv, a collection of environments for autonomous driving and tactical decision-making tasks, to explore LLMs' interpretation, interaction, and reasoning in various scenarios. We also examine real-time personalization, demonstrating how LLMs can influence driving behaviors based on verbal commands. Our empirical results highlight the substantial advantages of utilizing chain-of-thought prompting, leading to improved driving decisions, and showing the potential for LLMs to enhance personalized driving experiences through ongoing verbal feedback. The proposed framework aims to transform autonomous vehicle operations, offering personalized support, transparent decision-making, and continuous learning to enhance safety and effectiveness. We achieve user-centric, transparent, and adaptive autonomous driving ecosystems supported by the integration of LLMs into autonomous vehicles.
2023.10.14.18.50.07;14.10.2023;07;05;Industry;Industry 4.0, Production et al.;towardsai;;;https://pub.towardsai.net/inventory-optimization-with-data-science-hands-on-tutorial-with-python-1360ef044f18?source=rss----98111c9905da---4;;;Inventory Optimization with Data Science: Hands-On Tutorial with Python;Effective inventory management is important for businesses across various industries. ...
2023.10.14.18.50.08;14.10.2023;08;05;Industry;Industry 4.0, Production et al.;towardsai;;;https://pub.towardsai.net/explore-the-future-of-industry-4-0-unveiling-organizational-change-management-fe930d9fee2d?source=rss----98111c9905da---4;;;Explore the future of industry 4.0: unveiling organizational change management;The forthcoming case studies illustrate the fusion of process mining and business management principles. They showcase how smart and sustainable organizations, specifically those in Industry 4.0, can leverage data-driven insights from process mining tools to revamp their servitization systems and attain operational excellence. ...
2023.10.14.18.50.09;14.10.2023;09;07;Software;Development, Software Engineering et al.;arxiv;2310.08234;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.08234.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Frattini_J/0/1/0/all/0/1"">Julian Frattini</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fischbach_J/0/1/0/all/0/1"">Jannik Fischbach</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bauer_A/0/1/0/all/0/1"">Andreas Bauer</a>";Julian Frattini,Jannik Fischbach,Andreas Bauer;CiRA: An Open-Source Python Package for Automated Generation of Test Case Descriptions from Natural Language Requirements.;"Deriving acceptance tests from high-level, natural language requirements that achieve full coverage is a major manual challenge at the interface between requirements engineering and testing. Conditional requirements (e.g., ""If A or B then C."") imply causal relationships which - when extracted - allow to generate these acceptance tests automatically. This paper presents a tool from the CiRA (Causality In Requirements Artifacts) initiative, which automatically processes conditional natural language requirements and generates a minimal set of test case descriptions achieving full coverage. We evaluate the tool on a publicly available data set of 61 requirements from the requirements specification of the German Corona-Warn-App. The tool infers the correct test variables in 84.5% and correct variable configurations in 92.3% of all cases, which corroborates the feasibility of our approach."
2023.10.14.18.50.10;14.10.2023;10;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.07974;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07974.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Kim_H/0/1/0/all/0/1"">Hyun Joong Kim</a>, <a href=""http://arxiv.org/find/eess/1/au:+Song_Y/0/1/0/all/0/1"">Yong Hyun Song</a>, <a href=""http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1"">Jip Kim</a>";Hyun Joong Kim,Yong Hyun Song,Jip Kim;Causality-based Cost Allocation for Peer-to-Peer Energy Trading in Distribution System.;While peer-to-peer energy trading has the potential to harness the capabilities of small-scale energy resources, a peer-matching process often overlooks power grid conditions, yielding increased losses, line congestion, and voltage problems. This imposes a great challenge on the distribution system operator (DSO), which can eventually limit peer-to-peer energy trading. To align the peer-matching process with the physical grid conditions, this paper proposes a cost causality-based network cost allocation method and the grid-aware peer-matching process. Building on the cost causality principle, the proposed model utilizes the network cost (loss, congestion, and voltage) as a signal to encourage peers to adjust their preferences ensuring that matches are more in line with grid conditions, leading to enhanced social welfare. Additionally, this paper presents mathematical proof showing the superiority of the causality-based cost allocation over existing methods.
2023.10.14.18.50.11;14.10.2023;11;13;Mobility;Mobility, Automotive, Self Driving et al.;arxiv;2310.07794;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07794.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1"">Changhe Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pourkeshavarz_M/0/1/0/all/0/1"">Mozhgan Pourkeshavarz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rasouli_A/0/1/0/all/0/1"">Amir Rasouli</a>";Changhe Chen,Mozhgan Pourkeshavarz,Amir Rasouli;CRITERIA: a New Benchmarking Paradigm for Evaluating Trajectory Prediction Models for Autonomous Driving.;"Benchmarking is a common method for evaluating trajectory prediction models for autonomous driving. Existing benchmarks rely on datasets, which are biased towards more common scenarios, such as cruising, and distance-based metrics that are computed by averaging over all scenarios. Following such a regiment provides a little insight into the properties of the models both in terms of how well they can handle different scenarios and how admissible and diverse their outputs are. There exist a number of complementary metrics designed to measure the admissibility and diversity of trajectories, however, they suffer from biases, such as length of trajectories. In this paper, we propose a new benChmarking paRadIgm for evaluaTing trajEctoRy predIction Approaches (CRITERIA). Particularly, we propose 1) a method for extracting driving scenarios at varying levels of specificity according to the structure of the roads, models' performance, and data properties for fine-grained ranking of prediction models; 2) A set of new bias-free metrics for measuring diversity, by incorporating the characteristics of a given scenario, and admissibility, by considering the structure of roads and kinematic compliancy, motivated by real-world driving constraints. 3) Using the proposed benchmark, we conduct extensive experimentation on a representative set of the prediction models using the large scale Argoverse dataset. We show that the proposed benchmark can produce a more accurate ranking of the models and serve as a means of characterizing their behavior. We further present ablation studies to highlight contributions of different elements that are used to compute the proposed metrics."
2023.10.14.18.50.12;14.10.2023;12;18;AgriCulture;Agriculture et al.;arxiv;2210.11318;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2210.11318.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1"">Jiayun Luo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1"">Boyang Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Leung_C/0/1/0/all/0/1"">Cyril Leung</a>";Jiayun Luo,Boyang Li,Cyril Leung;A Survey of Computer Vision Technologies In Urban and Controlled-environment Agriculture.;In the evolution of agriculture to its next stage, Agriculture 5.0, artificial intelligence will play a central role. Controlled-environment agriculture, or CEA, is a special form of urban and suburban agricultural practice that offers numerous economic, environmental, and social benefits, including shorter transportation routes to population centers, reduced environmental impact, and increased productivity. Due to its ability to control environmental factors, CEA couples well with computer vision (CV) in the adoption of real-time monitoring of the plant conditions and autonomous cultivation and harvesting. The objective of this paper is to familiarize CV researchers with agricultural applications and agricultural practitioners with the solutions offered by CV. We identify five major CV applications in CEA, analyze their requirements and motivation, and survey the state of the art as reflected in 68 technical papers using deep learning methods. In addition, we discuss five key subareas of computer vision and how they related to these CEA problems, as well as eleven vision-based CEA datasets. We hope the survey will help researchers quickly gain a bird-eye view of the striving research area and will spark inspiration for new research and development.
2023.10.14.18.50.13;14.10.2023;13;19;CrossTopic;Generic, Cross Topic, et al.;arxiv;2310.04825;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04825.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Akola_D/0/1/0/all/0/1"">Denis Mbey Akola</a>";Denis Mbey Akola;Comparative study of multi-person tracking methods.;This paper presents a study of two tracking algorithms (SORT~\cite{7533003} and Tracktor++~\cite{2019}) that were ranked first positions on the MOT Challenge leaderboard (The MOTChallenge web page: https://motchallenge.net ). The purpose of this study is to discover the techniques used and to provide useful insights about these algorithms in the tracking pipeline that could improve the performance of MOT tracking algorithms. To this end, we adopted the popular tracking-by-detection approach. We trained our own Pedestrian Detection model using the MOT17Det dataset (MOT17Det : https://motchallenge.net/data/MOT17Det/ ). We also used a re-identification model trained on MOT17 dataset (MOT17 : https://motchallenge.net/data/MOT17/ ) for Tracktor++ to reduce the false re-identification alarms. We then present experimental results which shows that Tracktor++ is a better multi-person tracking algorithm than SORT. We also performed ablation studies to discover the contribution of re-identification(RE-ID) network and motion to the results of Tracktor++. We finally conclude by providing some recommendations for future research.
2023.10.13.14.05.01;13.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.07338;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07338.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1"">Han Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1"">Xumeng Wen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1"">Shun Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1"">Wei Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1"">Jiang Bian</a>";Han Zhang,Xumeng Wen,Shun Zheng,Wei Xu,Jiang Bian;Towards Foundation Models for Learning on Tabular Data.;Learning on tabular data underpins numerous real-world applications. Despite considerable efforts in developing effective learning models for tabular data, current transferable tabular models remain in their infancy, limited by either the lack of support for direct instruction following in new tasks or the neglect of acquiring foundational knowledge and capabilities from diverse tabular datasets. In this paper, we propose Tabular Foundation Models (TabFMs) to overcome these limitations. TabFMs harness the potential of generative tabular learning, employing a pre-trained large language model (LLM) as the base model and fine-tuning it using purpose-designed objectives on an extensive range of tabular datasets. This approach endows TabFMs with a profound understanding and universal capabilities essential for learning on tabular data. Our evaluations underscore TabFM's effectiveness: not only does it significantly excel in instruction-following tasks like zero-shot and in-context inference, but it also showcases performance that approaches, and in instances, even transcends, the renowned yet mysterious closed-source LLMs like GPT-4. Furthermore, when fine-tuning with scarce data, our model achieves remarkable efficiency and maintains competitive performance with abundant training data. Finally, while our results are promising, we also delve into TabFM's limitations and potential opportunities, aiming to stimulate and expedite future research on developing more potent TabFMs.
2023.10.13.14.05.02;13.10.2023;02;05;Industry;Industry 4.0, Production et al.;research;;;http://blog.research.google/2023/10/developing-industrial-use-cases-for.html;;;Developing industrial use cases for physical simulation on future error-corrected quantum computers;Below, we describe three industrially relevant applications for simulations with quantum computers. While running the algorithms will require an error-corrected quantum computer, which is still years away, working on this now will ensure that we are ready with efficient quantum algorithms when such a quantum computer is built. Already, our work has reduced the cost of compiling and running the algorithms significantly, as we have reported in the past. Our work is essential for demonstrating the potential of quantum computing, but it also provides our hardware team with target specifications for the number of qubits and time needed to run useful quantum algorithms in the future. ...
2023.10.13.14.05.03;13.10.2023;03;07;Software;Development, Software Engineering et al.;arxiv;2301.06577;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2301.06577.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lustosa_A/0/1/0/all/0/1"">Andre Lustosa</a>, <a href=""http://arxiv.org/find/cs/1/au:+Menzies_T/0/1/0/all/0/1"">Tim Menzies</a>";Andre Lustosa,Tim Menzies;Learning from Very Little Data: On the Value of Landscape Analysis for Predicting Software Project Health.;"When data is scarce, software analytics can make many mistakes. For example, consider learning predictors for open source project health (e.g. the number of closed pull requests in twelve months time). The training data for this task may be very small (e.g. five years of data, collected every month means just 60 rows of training data). The models generated from such tiny data sets can make many prediction errors. Those errors can be tamed by a {\em landscape analysis} that selects better learner control parameters. Our niSNEAK tool (a)~clusters the data to find the general landscape of the hyperparameters; then (b)~explores a few representatives from each part of that landscape. niSNEAK is both faster and more effective than prior state-of-the-art hyperparameter optimization algorithms (e.g. FLASH, HYPEROPT, OPTUNA). The configurations found by niSNEAK have far less error than other methods. For example, for project health indicators such as $C$= number of commits; $I$=number of closed issues, and $R$=number of closed pull requests, niSNEAK's 12 month prediction errors are \{I=0\%, R=33\%\,C=47\%\} Based on the above, we recommend landscape analytics (e.g. niSNEAK) especially when learning from very small data sets. This paper only explores the application of niSNEAK to project health. That said, we see nothing in principle that prevents the application of this technique to a wider range of problems. To assist other researchers in repeating, improving, or even refuting our results, all our scripts and data are available on GitHub at https://github.com/zxcv123456qwe/niSneak"
2023.10.13.14.05.04;13.10.2023;04;10;Commerce;Commerce, Trading, Sales, Retail et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/demand-based-hotel-room-pricing/;;;Implementing Demand Based Hotel Room Pricing in Data Science using MLOps;During Covid, the hospitality industry has suffered a massive drop in revenue. So when people are traveling more, getting the customer remains a challenge. We will develop an ML tool to solve this problem to counter this problem and set the fitting room to attract more customers. Using the hotel’s dataset, we will build an AI tool to select the correct room price, increase the occupancy rate, and increase the hotel revenue. ...
2023.10.13.14.05.05;13.10.2023;05;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.05052;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.05052.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1"">Han Zhang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1"">Yuqi Li</a>, <a href=""http://arxiv.org/find/eess/1/au:+Zheng_S/0/1/0/all/0/1"">Shun Zheng</a>, <a href=""http://arxiv.org/find/eess/1/au:+Lu_Z/0/1/0/all/0/1"">Ziheng Lu</a>, <a href=""http://arxiv.org/find/eess/1/au:+Gui_X/0/1/0/all/0/1"">Xiaofan Gui</a>, <a href=""http://arxiv.org/find/eess/1/au:+Xu_W/0/1/0/all/0/1"">Wei Xu</a>, <a href=""http://arxiv.org/find/eess/1/au:+Bian_J/0/1/0/all/0/1"">Jiang Bian</a>";Han Zhang,Yuqi Li,Shun Zheng,Ziheng Lu,Xiaofan Gui,Wei Xu,Jiang Bian;Learning Intra- and Inter-Cell Differences for Accurate Battery Lifespan Prediction across Diverse Conditions.;Battery life prediction holds significant practical value for battery research and development. Currently, many data-driven models rely on early electrical signals from specific target batteries to predict their lifespan. A common shortfall is that most existing methods are developed based on specific aging conditions, which not only limits their model's capability but also diminishes their effectiveness in predicting degradation under varied conditions. As a result, these models often miss out on fully benefiting from the rich historical data available under other conditions. Here, to address above, we introduce an approach that explicitly captures differences between electrical signals of a target battery and a reference battery, irrespective of their materials and aging conditions, to forecast the target battery life. Through this inter-cell difference, we not only enhance the feature space but also pave the way for a universal battery life prediction framework. Remarkably, our model that combines the inter- and intra-cell differences shines across diverse conditions, standing out in its efficiency and accuracy using all accessible datasets. An essential application of our approach is its capability to leverage data from older batteries effectively, enabling newer batteries to capitalize on insights gained from past batteries. This work not only enriches the battery data utilization strategy but also sets the stage for smarter battery management system in the future.
2023.10.13.14.05.06;13.10.2023;06;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.07103;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07103.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Mishra_S/0/1/0/all/0/1"">Sakshi Mishra</a>, <a href=""http://arxiv.org/find/eess/1/au:+Khatami_R/0/1/0/all/0/1"">Roohallah Khatami</a>, <a href=""http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1"">Yu Christine Chen</a>";Sakshi Mishra,Roohallah Khatami,Yu Christine Chen;Decentralization of Energy Systems with Blockchain: Bridging Top-down and Bottom-up Management of the Electricity Grid.;For more than a century, the grid has operated in a centralized top-down fashion. However, as distributed energy resources (DERs) penetration grows, the grid edge is increasingly infused with intelligent computing and communication capabilities. Thus, the bottom-up approach to grid operations inclined toward decentralizing energy systems will likely gain momentum alongside the existing centralized paradigm. Decentralization refers to transferring control and decision-making from a centralized entity (individual, organization, or group thereof) to a distributed network. It is not a new concept - in energy systems context or otherwise. In the energy systems context, however, the complexity of this multifaceted concept increases manifolds due to two major reasons - i) the nature of the commodity being traded (the electricity) and ii) the enormity of the traditional electricity sector's structure that builds, operates, and maintains this capital-intensive network. In this work, we aim to highlight the need for and outline a credible path toward restructuring the current operational architecture of the electricity grid in view of the ongoing decentralization trends with an emphasis on peer-to-peer energy trading. We further introduce blockchain technology in the context of decentralized energy systems problems. We also suggest that blockchain is an effective technology for facilitating the synergistic operations of top-down and bottom-up approaches to grid management.
2023.10.13.14.05.07;13.10.2023;07;13;Logistics;Logistics, Transport Equipment, Automotive, Self Driving et al.;arxiv;2310.06974;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.06974.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Schumann_O/0/1/0/all/0/1"">Oliver Schumann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Buchholz_M/0/1/0/all/0/1"">Michael Buchholz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dietmayer_K/0/1/0/all/0/1"">Klaus Dietmayer</a>";Oliver Schumann,Michael Buchholz,Klaus Dietmayer;Efficient Path Planning in Large Unknown Environments with Switchable System Models for Automated Vehicles.;Large environments are challenging for path planning algorithms as the size of the configuration space increases. Furthermore, if the environment is mainly unexplored, large amounts of the path are planned through unknown areas. Hence, a complete replanning of the entire path occurs whenever the path collides with newly discovered obstacles. We propose a novel method that stops the path planning algorithm after a certain distance. It is used to navigate the algorithm in large environments and is not prone to problems of existing navigation approaches. Furthermore, we developed a method to detect significant environment changes to allow a more efficient replanning. At last, we extend the path planner to be used in the U-Shift concept vehicle. It can switch to another system model and rotate around the center of its rear axis. The results show that the proposed methods generate nearly identical paths compared to the standard Hybrid A* while drastically reducing the execution time. Furthermore, we show that the extended path planning algorithm enables the efficient use of the maneuvering capabilities of the concept vehicle to plan concise paths in narrow environments.
2023.10.13.14.05.08;13.10.2023;08;13;Logistics;Logistics, Transport Equipment, Automotive, Self Driving et al.;arxiv;2310.00950;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.00950.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Soh_L/0/1/0/all/0/1"">Ling Shuang Soh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ho_H/0/1/0/all/0/1"">Hann Woei Ho</a>";Ling Shuang Soh,Hann Woei Ho;Autonomous Navigation of Micro Air Vehicles in Warehouses Using Vision-based Line Following.;In this paper, we propose a vision-based solution for indoor Micro Air Vehicle (MAV) navigation, with a primary focus on its application within autonomous warehouses. Our work centers on the utilization of a single camera as the primary sensor for tasks such as detection, localization, and path planning. To achieve these objectives, we implement the HSV color detection and the Hough Line Transform for effective line detection within warehouse environments. The integration of a Kalman filter into our system enables the camera to track yellow lines reliably. We evaluated the performance of our vision-based line following algorithm through various MAV flight tests conducted in the Gazebo 11 platform, utilizing ROS Noetic. The results of these simulations demonstrate the system capability to successfully navigate narrow indoor spaces. Our proposed system has the potential to significantly reduce labor costs and enhance overall productivity in warehouse operations. This work contributes to the growing field of MAV applications in autonomous warehouses, addressing the need for efficient logistics and supply chain solutions.
2023.10.13.14.05.09;13.10.2023;09;13;Logistics;Logistics, Transport Equipment, Automotive, Self Driving et al.;arxiv;2310.07116;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07116.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Zhang_N/0/1/0/all/0/1"">Nan Zhang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Bahsoon_R/0/1/0/all/0/1"">Rami Bahsoon</a>, <a href=""http://arxiv.org/find/eess/1/au:+Tziritas_N/0/1/0/all/0/1"">Nikos Tziritas</a>, <a href=""http://arxiv.org/find/eess/1/au:+Theodoropoulos_G/0/1/0/all/0/1"">Georgios Theodoropoulos</a>";Nan Zhang,Rami Bahsoon,Nikos Tziritas,Georgios Theodoropoulos;A Digital Twin Approach for Adaptive Compliance in Cyber-Physical Systems: Case of Smart Warehouse Logistics.;Engineering regulatory compliance in complex Cyber-Physical Systems (CPS), such as smart warehouse logistics, is challenging due to the open and dynamic nature of these systems, scales, and unpredictable modes of human-robot interactions that can be best learnt at runtime. Traditional offline approaches for engineering compliance often involve modelling at a higher, more abstract level (e.g. using languages like SysML). These abstract models only support analysis in offline-designed and simplified scenarios. However, open and complex systems may be unpredictable, and their behaviours are difficult to be fully captured by abstract models. These systems may also involve other business goals, possibly conflicting with regulatory compliance. To overcome these challenges, fine-grained simulation models are promising to complement abstract models and support accurate runtime predictions and performance evaluation with trade-off analysis. The novel contribution of this work is a Digital Twin-oriented architecture for adaptive compliance leveraging abstract goal modelling, fine-grained agent-based modelling and runtime simulation for managing compliance trade-offs. A case study from smart warehouse logistics is used to demonstrate the approach considering safety and productivity trade-offs.
2023.10.13.14.05.10;13.10.2023;10;14;Public Services;Public Services, Traffic et al.;arxiv;2310.07514;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2310.07514.pdf;" <a href=""http://arxiv.org/find/stat/1/au:+Zhang_N/0/1/0/all/0/1"">Nan Zhang</a>, <a href=""http://arxiv.org/find/stat/1/au:+Horcher_D/0/1/0/all/0/1"">Daniel Horcher</a>, <a href=""http://arxiv.org/find/stat/1/au:+Bansal_P/0/1/0/all/0/1"">Prateek Bansal</a>, <a href=""http://arxiv.org/find/stat/1/au:+Graham_D/0/1/0/all/0/1"">Daniel J. Graham</a>";Nan Zhang,Daniel Horcher,Prateek Bansal,Daniel J. Graham;Causal inference for disruption management in urban metro networks.;Urban metro systems can provide highly efficient and effective movements of vast passenger volumes in cities, but they are often affected by disruptions, causing delays, crowding, and ultimately a decline in passenger satisfaction and patronage. To manage and mitigate such adverse consequences, metro operators could benefit greatly from a quantitative understanding of the causal impact of disruptions. Such information would allow them to predict future delays, prepare effective recovery plans, and develop real-time information systems for passengers on trip re-routing options. In this paper, we develop a performance evaluation tool for metro operators that can quantify the causal effects of service disruptions on passenger flows, journey times, travel speeds and crowding densities. Our modelling framework is simple to implement, robust to statistical sources of bias, and can be used with high-frequency large-scale smart card data (over 4.85 million daily trips in our case) and train movement data. We recover disruption effects at the points of disruption (e.g. at disrupted stations) as well as spillover effects that propagate throughout the metro network. This allows us to deliver novel insights on the spatio-temporal propagation of delays in densely used urban public transport networks. We find robust empirical evidence that the causal impacts of disruptions adversely affect service quality throughout the network, in ways that would be hard to predict absent a causal model.
2023.10.13.14.05.11;13.10.2023;11;14;Public Services;Public Services, Traffic et al.;arxiv;2008.01674;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2008.01674.pdf;" <a href=""http://arxiv.org/find/stat/1/au:+Parmar_J/0/1/0/all/0/1"">Janak Parmar</a>, <a href=""http://arxiv.org/find/stat/1/au:+Das_P/0/1/0/all/0/1"">Pritikana Das</a>, <a href=""http://arxiv.org/find/stat/1/au:+Dave_S/0/1/0/all/0/1"">Sanjaykumar Dave</a>";Janak Parmar,Pritikana Das,Sanjaykumar Dave;A Machine Learning Approach for Modelling Parking Duration in Urban Land-use.;Parking is an inevitable issue in the fast-growing developing countries. Increasing number of vehicles require more and more urban land to be allocated for parking. However, a little attention has been conferred to the parking issues in developing countries like India. This study proposes a model for analysing the influence of car users' socioeconomic and travel characteristics on parking duration. Specifically, artificial neural networks (ANNs) is deployed to capture the interrelationship between driver characteristics and parking duration. ANNs are highly efficient in learning and recognizing connections between parameters for best prediction of an outcome. Since, utility of ANNs has been critically limited due to its Black Box nature, the study involves the use of Garson algorithm and Local interpretable model-agnostic explanations (LIME) for model interpretations. LIME shows the prediction for any classification, by approximating it locally with the developed interpretable model. This study is based on microdata collected on-site through interview surveys considering two land-uses: office-business and market/shopping. Results revealed the higher probability of prediction through LIME and therefore, the methodology can be adopted ubiquitously. Further, the policy implications are discussed based on the results for both land-uses. This unique study could lead to enhanced parking policy and management to achieve the sustainability goals.
2023.10.13.14.05.12;13.10.2023;12;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.07225;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07225.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Korgul_K/0/1/0/all/0/1"">Karolina Korgul</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bean_A/0/1/0/all/0/1"">Andrew M. Bean</a>, <a href=""http://arxiv.org/find/cs/1/au:+Krones_F/0/1/0/all/0/1"">Felix Krones</a>, <a href=""http://arxiv.org/find/cs/1/au:+McCraith_R/0/1/0/all/0/1"">Robert McCraith</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mahdi_A/0/1/0/all/0/1"">Adam Mahdi</a>";Karolina Korgul,Andrew M. Bean,Felix Krones,Robert McCraith,Adam Mahdi;Exploring the Landscape of Large Language Models In Medical Question Answering: Observations and Open Questions.;Large Language Models (LLMs) have shown promise in medical question answering by achieving passing scores in standardised exams and have been suggested as tools for supporting healthcare workers. Deploying LLMs into such a high-risk context requires a clear understanding of the limitations of these models. With the rapid development and release of new LLMs, it is especially valuable to identify patterns which exist across models and may, therefore, continue to appear in newer versions. In this paper, we evaluate a wide range of popular LLMs on their knowledge of medical questions in order to better understand their properties as a group. From this comparison, we provide preliminary observations and raise open questions for further research.
2023.10.13.14.05.13;13.10.2023;13;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.07282;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.07282.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sharaf_S/0/1/0/all/0/1"">Shyni Sharaf</a>, <a href=""http://arxiv.org/find/cs/1/au:+Anoop_V/0/1/0/all/0/1"">V. S. Anoop</a>";Shyni Sharaf,V. S. Anoop;An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT.;This paper conducts a comprehensive investigation into applying large language models, particularly on BioBERT, in healthcare. It begins with thoroughly examining previous natural language processing (NLP) approaches in healthcare, shedding light on the limitations and challenges these methods face. Following that, this research explores the path that led to the incorporation of BioBERT into healthcare applications, highlighting its suitability for addressing the specific requirements of tasks related to biomedical text mining. The analysis outlines a systematic methodology for fine-tuning BioBERT to meet the unique needs of the healthcare domain. This approach includes various components, including the gathering of data from a wide range of healthcare sources, data annotation for tasks like identifying medical entities and categorizing them, and the application of specialized preprocessing techniques tailored to handle the complexities found in biomedical texts. Additionally, the paper covers aspects related to model evaluation, with a focus on healthcare benchmarks and functions like processing of natural language in biomedical, question-answering, clinical document classification, and medical entity recognition. It explores techniques to improve the model's interpretability and validates its performance compared to existing healthcare-focused language models. The paper thoroughly examines ethical considerations, particularly patient privacy and data security. It highlights the benefits of incorporating BioBERT into healthcare contexts, including enhanced clinical decision support and more efficient information retrieval. Nevertheless, it acknowledges the impediments and complexities of this integration, encompassing concerns regarding data privacy, transparency, resource-intensive requirements, and the necessity for model customization to align with diverse healthcare domains.
2023.10.13.14.05.14;13.10.2023;14;15;Health;Medical, Health Care, Pharmacy et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/vertex-ai-med-palm-2/;;;Google Unveils Cutting-Edge Vertex AI Search: A Game-Changer for Healthcare Providers;In a groundbreaking announcement at HLTH 2023, Google has set the stage for a revolution in the healthcare industry by introducing Vertex AI Search capabilities tailored for health and life sciences providers. This innovation promises to transform how patient data is accessed and medical queries are answered. Let’s explore this exciting development in detail. ...
2023.10.13.14.05.15;13.10.2023;15;16;Legal;Legal, Law et al.;arxiv;2310.05680;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.05680.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Tuvey_O/0/1/0/all/0/1"">Oscar Tuvey</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sen_P/0/1/0/all/0/1"">Procheta Sen</a>";Oscar Tuvey,Procheta Sen;Automated Argument Generation from Legal Facts.;The count of pending cases has shown an exponential rise across nations (e.g., with more than 10 million pending cases in India alone). The main issue lies in the fact that the number of cases submitted to the law system is far greater than the available number of legal professionals present in a country. Given this worldwide context, the utilization of AI technology has gained paramount importance to enhance the efficiency and speed of legal procedures. In this study we partcularly focus on helping legal professionals in the process of analyzing a legal case. Our specific investigation delves into harnessing the generative capabilities of open-sourced large language models to create arguments derived from the facts present in legal cases. Experimental results show that the generated arguments from the best performing method have on average 63% overlap with the benchmark set gold standard annotations.
2023.10.12.18.50.01;12.10.2023;01;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2308.10974&r=cmp;;Xu HanZengqing WuChuan Xiao;"""Guinea Pig Trials"" Utilizing GPT: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion";Firm competition and collusion involve complex dynamics, particularly when considering communication among firms. Such issues can be modeled as problems of complex systems, traditionally approached through experiments involving human subjects or agent-based modeling methods. We propose an innovative framework called Smart Agent-Based Modeling (SABM), wherein smart agents, supported by GPT-4 technologies, represent firms, and interact with one another. We conducted a controlled experiment to study firm price competition and collusion behaviors under various conditions. SABM is more cost-effective and flexible compared to conducting experiments with human subjects. Smart agents possess an extensive knowledge base for decision-making and exhibit human-like strategic abilities, surpassing traditional ABM agents. Furthermore, smart agents can simulate human conversation and be personalized, making them ideal for studying complex situations involving communication. Our results demonstrate that, in the absence of communication, smart agents consistently reach tacit collusion, leading to prices converging at levels higher than the Bertrand equilibrium price but lower than monopoly or cartel prices. When communication is allowed, smart agents achieve a higher-level collusion with prices close to cartel prices. Collusion forms more quickly with communication, while price convergence is smoother without it. These results indicate that communication enhances trust between firms, encouraging frequent small price deviations to explore opportunities for a higher-level win-win situation and reducing the likelihood of triggering a price war. We also assigned different personas to firms to analyze behavioral differences and tested variant models under diverse market structures. The findings showcase the effectiveness and robustness of SABM and provide intriguing insights into competition and collusion.
2023.10.12.18.50.02;12.10.2023;02;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2308.16771&r=cmp;;Rick SteinertSaskia Altmann;Linking microblogging sentiments to stock price movement: An application of GPT-4;This paper investigates the potential improvement of the GPT-4 Language Learning Model (LLM) in comparison to BERT for modeling same-day daily stock price movements of Apple and Tesla in 2017, based on sentiment analysis of microblogging messages. We recorded daily adjusted closing prices and translated them into up-down movements. Sentiment for each day was extracted from messages on the Stocktwits platform using both LLMs. We develop a novel method to engineer a comprehensive prompt for contextual sentiment analysis which unlocks the true capabilities of modern LLM. This enables us to carefully retrieve sentiments, perceived advantages or disadvantages, and the relevance towards the analyzed company. Logistic regression is used to evaluate whether the extracted message contents reflect stock price movements. As a result, GPT-4 exhibited substantial accuracy, outperforming BERT in five out of six months and substantially exceeding a naive buy-and-hold strategy, reaching a peak accuracy of 71.47 % in May. The study also highlights the importance of prompt engineering in obtaining desired outputs from GPT-4's contextual abilities. However, the costs of deploying GPT-4 and the need for fine-tuning prompts highlight some practical considerations for its use.
2023.10.12.18.50.03;12.10.2023;03;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.04480;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04480.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Khuong_T/0/1/0/all/0/1"">Thanh Gia Hieu Khuong</a> (TAU, LISN), <a href=""http://arxiv.org/find/cs/1/au:+Rachmat_B/0/1/0/all/0/1"">Benedictus Kent Rachmat</a> (TAU, LISN)";"<a href=""http://arxiv.org/find/cs/1/au:+Khuong_T/0/1/0/all/0/1"">Thanh Gia Hieu Khuong</a> (TAU, LISN), <a href=""http://arxiv.org/find/cs/1/au:+Rachmat_B/0/1/0/all/0/1"">Benedictus Kent Rachmat</a> (TAU, LISN)";Auto-survey Challenge.;We present a novel platform for evaluating the capability of Large Language Models (LLMs) to autonomously compose and critique survey papers spanning a vast array of disciplines including sciences, humanities, education, and law. Within this framework, AI systems undertake a simulated peer-review mechanism akin to traditional scholarly journals, with human organizers serving in an editorial oversight capacity. Within this framework, we organized a competition for the AutoML conference 2023. Entrants are tasked with presenting stand-alone models adept at authoring articles from designated prompts and subsequently appraising them. Assessment criteria include clarity, reference appropriateness, accountability, and the substantive value of the content. This paper presents the design of the competition, including the implementation baseline submissions and methods of evaluation.
2023.10.12.18.50.04;12.10.2023;04;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.04870;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04870.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1"">Haoze Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Barrett_C/0/1/0/all/0/1"">Clark Barrett</a>, <a href=""http://arxiv.org/find/cs/1/au:+Narodytska_N/0/1/0/all/0/1"">Nina Narodytska</a>";Haoze Wu,Clark Barrett,Nina Narodytska;Lemur: Integrating Large Language Models in Automated Program Verification.;The demonstrated code-understanding capability of LLMs raises the question of whether they can be used for automated program verification, a task that often demands high-level abstract reasoning about program properties, which is challenging for verification tools. We propose a general methodology to combine the power of LLMs and automated reasoners for automated program verification. We formally describe this methodology as a set of derivation rules and prove its soundness. We instantiate the calculus as a sound automated verification procedure, which led to practical improvements on a set of synthetic and competition benchmarks.
2023.10.12.18.50.05;12.10.2023;05;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.06213;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.06213.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Manvi_R/0/1/0/all/0/1"">Rohin Manvi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Khanna_S/0/1/0/all/0/1"">Samar Khanna</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mai_G/0/1/0/all/0/1"">Gengchen Mai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Burke_M/0/1/0/all/0/1"">Marshall Burke</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lobell_D/0/1/0/all/0/1"">David Lobell</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1"">Stefano Ermon</a>";Rohin Manvi,Samar Khanna,Gengchen Mai,Marshall Burke,David Lobell,Stefano Ermon;GeoLLM: Extracting Geospatial Knowledge from Large Language Models.;The application of machine learning (ML) in a range of geospatial tasks is increasingly common but often relies on globally available covariates such as satellite imagery that can either be expensive or lack predictive power. Here we explore the question of whether the vast amounts of knowledge found in Internet language corpora, now compressed within large language models (LLMs), can be leveraged for geospatial prediction tasks. We first demonstrate that LLMs embed remarkable spatial information about locations, but naively querying LLMs using geographic coordinates alone is ineffective in predicting key indicators like population density. We then present GeoLLM, a novel method that can effectively extract geospatial knowledge from LLMs with auxiliary map data from OpenStreetMap. We demonstrate the utility of our approach across multiple tasks of central interest to the international community, including the measurement of population density and economic livelihoods. Across these tasks, our method demonstrates a 70% improvement in performance (measured using Pearson's $r^2$) relative to baselines that use nearest neighbors or use information directly from the prompt, and performance equal to or exceeding satellite-based benchmarks in the literature. With GeoLLM, we observe that GPT-3.5 outperforms Llama 2 and RoBERTa by 19% and 51% respectively, suggesting that the performance of our method scales well with the size of the model and its pretraining dataset. Our experiments reveal that LLMs are remarkably sample-efficient, rich in geospatial information, and robust across the globe. Crucially, GeoLLM shows promise in mitigating the limitations of existing geospatial covariates and complementing them well.
2023.10.12.18.50.06;12.10.2023;06;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.06266;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.06266.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Di_P/0/1/0/all/0/1"">Peng Di</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Jianguo Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1"">Hang Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1"">Wei Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1"">Wenting Cai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"">Yang Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1"">Chaoyu Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1"">Dajun Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"">Hongwei Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1"">Liang Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fan_G/0/1/0/all/0/1"">Gang Fan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gong_J/0/1/0/all/0/1"">Jie Gong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1"">Zi Gong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1"">Wen Hu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1"">Tingting Guo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1"">Zhichao Lei</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1"">Ting Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Zheng Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liang_M/0/1/0/all/0/1"">Ming Liang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1"">Cong Liao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1"">Bingchang Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"">Jiachen Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zhiwei Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1"">Shaojun Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1"">Min Shen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1"">Guangpei Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1"">Huan Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"">Zhi Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1"">Zhaogui Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1"">Jiawei Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1"">Qing Ye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1"">Gehao Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yu Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1"">Zelin Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1"">Xunjin Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1"">Hailian Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1"">Lifu Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1"">Xianying Zhu</a>";Peng Di,Jianguo Li,Hang Yu,Wei Jiang,Wenting Cai,Yang Cao,Chaoyu Chen,Dajun Chen,Hongwei Chen,Liang Chen,Gang Fan,Jie Gong,Zi Gong,Wen Hu,Tingting Guo,Zhichao Lei,Ting Li,Zheng Li,Ming Liang,Cong Liao,Bingchang Liu,Jiachen Liu,Zhiwei Liu,Shaojun Lu,Min Shen,Guangpei Wang,Huan Wang,Zhi Wang,Zhaogui Xu,Jiawei Yang,Qing Ye,Gehao Zhang,Yu Zhang,Zelin Zhao,Xunjin Zheng,Hailian Zhou,Lifu Zhu,Xianying Zhu;CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model.;Code Large Language Models (Code LLMs) have gained significant attention in the industry due to their wide applications in the full lifecycle of software engineering. However, the effectiveness of existing models in understanding non-English inputs for multi-lingual code-related tasks is still far from well studied. This paper introduces CodeFuse-13B, an open-sourced pre-trained code LLM. It is specifically designed for code-related tasks with both English and Chinese prompts and supports over 40 programming languages. CodeFuse achieves its effectiveness by utilizing a high quality pre-training dataset that is carefully filtered by program analyzers and optimized during the training process. Extensive experiments are conducted using real-world usage scenarios, the industry-standard benchmark HumanEval-x, and the specially designed CodeFuseEval for Chinese prompts. To assess the effectiveness of CodeFuse, we actively collected valuable human feedback from the AntGroup's software development process where CodeFuse has been successfully deployed. The results demonstrate that CodeFuse-13B achieves a HumanEval pass@1 score of 37.10%, positioning it as one of the top multi-lingual code LLMs with similar parameter sizes. In practical scenarios, such as code generation, code translation, code comments, and testcase generation, CodeFuse performs better than other models when confronted with Chinese prompts.
2023.10.12.18.50.07;12.10.2023;07;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/diverse-bar-chart-analysis-with-gpt-4s-advanced-data-analysis-tool-fc867e6af43b?source=rss----98111c9905da---4;;;Diverse Bar Chart Analysis with GPT-4’s Advanced Data Analysis Tool;In this tutorial, we’ll be using the GPT-4 Advanced Data Analysis tool to provide analysis of the Global Tree Cover Loss dataset using multiple bar chart visualizations. ...
2023.10.12.18.50.08;12.10.2023;08;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/generative-ai-for-sustainable-banking-reducing-carbon-footprints-and-promoting-eco-friendly-97a6645b591b?source=rss----98111c9905da---4;;;Generative AI for Sustainable Banking —  Reducing Carbon Footprints and Promoting Eco-Friendly…;This article explores a few use cases where Generative AI can empower bank customers to make eco-friendly choices and also enable banks to offer incentives for sustainable behavior. It also provides a reference architecture using AWS services for building a sustainable banking application for these use cases. ...
2023.10.12.18.50.09;12.10.2023;09;01;Foundation;Large Language and Foundation Models, Multi Modal Models et al.;facebook;;;https://www.facebook.com/business/news/generative-ai-features-for-ads-coming-to-all-advertisers;;;Generative AI features for ads coming to all advertisers;Today, we're announcing that we've begun rolling out our first generative AI-powered features for ad creatives in Meta's Ads Manager, with global rollout complete by next year. These unlock a new era of creativity that maximizes the productivity, personalization and performance for all advertisers. The new features - Background Generation, Image Expansion, and Text Variations - will add to the AI-powered experiences and tools we continue to build for businesses.
2023.10.12.18.50.10;12.10.2023;10;03;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:spa:wpaper:2023wpecon10&r=cmp;;Joao FelixMichel Alexandre, Gilberto Tadeu Lima;Applying Machine Learning Algorithms to Predict the Size of the Informal Economy;The use of machine learning models and techniques to predict economic variables has been growing lately, motivated by their better performance when compared to that of linear models. Although linear models have the advantage of considerable interpretive power, efforts have intensified in recent years to make machine learning models more interpretable. In this paper, tests are conducted to determine whether models based on machine learning algorithms have better performance relative to that of linear models for predicting the size of the informal economy. The paper also explores whether the determinants of such size detected as the most important by machine learning models are the same as those detected in the literature based on traditional linear models. For this purpose, observations were collected and processed for 122 countries from 2004 to 2014. Next, eleven models (four linear and seven based on machine learning algorithms) were used to predict the size of the informal economy in these countries. The relative importance of the predictive variables in determining the results yielded by the machine learning algorithms was calculated using Shapley values. The results suggest that (i) models based on machine learning algorithms have better predictive performance than that of linear models and (ii) the main determinants detected through the Shapley values coincide with those detected in the literature using traditional linear models.
2023.10.12.18.50.11;12.10.2023;11;03;Finance;Finance, DeFi, Insurance, Banking et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Software_Design_Flaw_and_Security_Assurance_Gap_in_Component-based_Application_Security_Privacy/24282658;;TechRxiv RSS Feed;Software Design Flaw and Security Assurance Gap in Component-based Application Security & Privacy;Using existing functional business logic in social e banking was always encouraged by the early methods of component reuse in banking. Although this concept is intriguing, it results in a functional logic design error in the program, which is why even the strongest security defenses can be readily circumvented by a few hacking attempts. As a result, the traditional approach does not meet contemporary business criteria for e-commerce and e-business interfaces in modern banking. The research team has evaluated and targeted banking domain to serve as an example of the issue reuse of business logic and has then proposed a method of secure reuse of business function and component reuse through existing banking application. In terms of social interaction logic in order to meet modern banking requirements in the context of a modern economy is based on a comprehensive security assurance process, which this paper has attempted to cover.
2023.10.12.18.50.12;12.10.2023;12;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2106.14005;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2106.14005.pdf;" <a href=""http://arxiv.org/find/physics/1/au:+Alexopoulos_A/0/1/0/all/0/1"">Angelos Alexopoulos</a>, <a href=""http://arxiv.org/find/physics/1/au:+Dellaportas_P/0/1/0/all/0/1"">Petros Dellaportas</a>, <a href=""http://arxiv.org/find/physics/1/au:+Gyoshev_S/0/1/0/all/0/1"">Stanley Gyoshev</a>, <a href=""http://arxiv.org/find/physics/1/au:+Kotsogiannis_C/0/1/0/all/0/1"">Christos Kotsogiannis</a>, <a href=""http://arxiv.org/find/physics/1/au:+Olhede_S/0/1/0/all/0/1"">Sofia C. Olhede</a>, <a href=""http://arxiv.org/find/physics/1/au:+Pavkov_T/0/1/0/all/0/1"">Trifon Pavkov</a>";Angelos Alexopoulos,Petros Dellaportas,Stanley Gyoshev,Christos Kotsogiannis,Sofia C. Olhede,Trifon Pavkov;A network and machine learning approach to detect Value Added Tax fraud.;Value Added Tax (VAT) fraud erodes public revenue and puts legitimate businesses at a disadvantaged position thereby impacting inequality. Identifying and combating VAT fraud before it occurs is therefore important for welfare. This paper proposes flexible machine learning algorithms which detect fraudulent transactions, utilising the information provided by the complex VAT network structure of a large dimension. VAT fraud detection is implemented through a combination of a suitably constructed Laplacian matrix with classification algorithms that rely on scalable machine learning techniques. The method is implemented on the universe of Bulgarian VAT data and detects around 50 percent of the VAT fraud, outperforming well-known techniques that ignore the information provided by the network of VAT transactions. Importantly, the proposed methods are automated, and can be implemented following the taxpayers submission of their VAT returns. This allows tax revenue authorities to prevent large losses of tax revenues through performing early identification of fraud between business-to-business transactions within the VAT system.
2023.10.12.18.50.13;12.10.2023;13;04;Supply Chain;Supply Chains, Transportation et al.;arxiv;2310.06300;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.06300.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Tran_N/0/1/0/all/0/1"">Nguyen Khoi Tran</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pallewatta_S/0/1/0/all/0/1"">Samodha Pallewatta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Babar_M/0/1/0/all/0/1"">M. Ali Babar</a>";Nguyen Khoi Tran,Samodha Pallewatta,M. Ali Babar;Toward a Reference Architecture for Software Supply Chain Metadata Management.;An Software Supply Chain (SSC) attack combines an upstream attack, where malicious codes are injected into a software artefact via a compromised life cycle activity, and a downstream attack on the consumers who use the compromised artefact. Organisations need thorough and trustworthy visibility over the entire SSC of their software inventory to detect risks early and rapidly identify compromised assets in the event of an SSC attack. One way to achieve such visibility is through SSC metadata, machine-readable and authenticated documents describing an artefact's lifecycle, such as how it was constructed and the utilised ``ingredients''. Adopting SSC metadata requires organisations to procure or develop a Software Supply Chain Metadata Management system (SCM2), a suite of software tools for performing life cycle activities of SSC metadata documents such as creation, signing, distribution, and consumption. Selecting or developing an SCM2 is challenging due to the lack of a comprehensive domain model and architectural blueprint to aid practitioners in navigating the vast design space of SSC metadata terminologies, frameworks, and solutions. This paper addresses the above-mentioned challenge with a Systematisation of Knowledge about SSC metadata and SCM2, presented as a Reference Architecture (RA). The RA comprises a domain model and an architectural blueprint for SCM2 systems, constructed from the concepts and building blocks scattered across existing SSC security frameworks and standards. Our evaluation shows that the RA framework is effective for analysing existing SCM2 solutions and guiding the engineering of new SCM2.
2023.10.12.18.50.14;12.10.2023;14;05;Industry;Industry 4.0, Production et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:zbw:esprep:275738&r=cmp;;Reinking, ErnstBecker, Marco;Opportunities for business use of today's AI models - Rapidly achievable personalization of Large Language Models (like ChatGPT) in times of Industry 5.0;The introduction of ChatGPT as one of the best-known Large Language Models not only opened a new chapter in artificial intelligence in the general perception – some authors even speak of an era of (business) informatics. It also heralds the fifth industrial revolution (Industry 5.0). The aim of this working paper is not only to objectify the contradiction between hype and reality in the context of artificial intelligence, but also to show the opportunities and perspectives for the analysis of unstructured, internal company data. To this end, the authors have developed several prototypes based on their own research work, which form the basis of this working paper.
2023.10.12.18.50.15;12.10.2023;15;05;Industry;Industry 4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0729/v1;;Preprints.org - The Multidisciplinary Preprint Platform;On the Definition, Assessment and Enhancement of Circular Economy across Various Industrial Sectors: A Literature Review;"Circular economy has recently emerged as a key strategy for promoting sustainability and reducing waste in various industrial sectors. This paper provides an overview of circularity in aerospace, wind energy, transportation, automotive and sports goods using data and information from the literature and the EC funded project ""RECREATE"". The survey reviews the different definitions, assessment methods and metrics used to explore and evaluate circularity, including assessment frameworks such as Life Cycle Assessment (LCA) and assessment indicators. Furthermore, explores the challenges, possibilities and the available tools for enhancing circularity, such as digital tools. The survey highlights the importance of a holistic and systemic technique to circularity, concerning all stakeholders along the value chain. Overall, this study aims to contribute to a better understanding of circular economy and provides insights for future research."
2023.10.12.18.50.16;12.10.2023;16;05;Industry;Industry 4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0798/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Using Python to Analyze and Model Chemical Engineering Processes: A Case Study of MSS Drying;This study investigates the use of programming language Python to analyse and model chemical engineering processes. Using municipal sewage sludge (MSS) drying as an example, the study demonstrates how Python can support analyses and model drying data. The drying process was performed on a flat plate while maintaining a uniform, parallel drying air speed of 1.15 m s-1. The Python program helped to analyse the digitalised weight measurements from each sample. The program enables sorting input data, determining the drying critical point and evaluating the first and second drying periods.
2023.10.12.18.50.17;12.10.2023;17;08;Customer Relation;Customers, CRM, Management, Service et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/a-mlops-enhanced-customer-churn-prediction-project/;;;A MLOps-Enhanced Customer Churn Prediction Project;When we hear data science, the first thing that comes to mind is building a model on notebooks and training the data. But this is not the situation in real-world data science. In the real world, data scientists build models and put them into production. The production environment has a gap between the development, deployment, and reliability of the model and to facilitate efficient and scalable operations This is where data scientists use MLOps (Machine Learning Operations) to build and deploy ML applications in a production environment. In this article, we will build and deploy a customer churn prediction project using MLOps. ...
2023.10.12.18.50.18;12.10.2023;18;09;Human;Human Resource, Personal Assistance et al.;arxiv;2310.06176;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.06176.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1"">Jihwan Jeong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chow_Y/0/1/0/all/0/1"">Yinlam Chow</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tennenholtz_G/0/1/0/all/0/1"">Guy Tennenholtz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1"">Chih-Wei Hsu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tulepbergenov_A/0/1/0/all/0/1"">Azamat Tulepbergenov</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1"">Mohammad Ghavamzadeh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1"">Craig Boutilier</a>";Jihwan Jeong,Yinlam Chow,Guy Tennenholtz,Chih-Wei Hsu,Azamat Tulepbergenov,Mohammad Ghavamzadeh,Craig Boutilier;Factual and Personalized Recommendations using Language Models and Reinforcement Learning.;Recommender systems (RSs) play a central role in connecting users to content, products, and services, matching candidate items to users based on their preferences. While traditional RSs rely on implicit user feedback signals, conversational RSs interact with users in natural language. In this work, we develop a comPelling, Precise, Personalized, Preference-relevant language model (P4LM) that recommends items to users while putting emphasis on explaining item characteristics and their relevance. P4LM uses the embedding space representation of a user's preferences to generate compelling responses that are factually-grounded and relevant w.r.t. the user's preferences. Moreover, we develop a joint reward function that measures precision, appeal, and personalization, which we use as AI-based feedback in a reinforcement learning-based language model framework. Using the MovieLens 25M dataset, we demonstrate that P4LM delivers compelling, personalized movie narratives to users.
2023.10.12.18.50.19;12.10.2023;19;09;Human;Human Resource, Personal Assistance et al.;towardsai;;;https://pub.towardsai.net/inside-linkedins-embedding-architecture-powering-its-job-search-capabilities-d4dd61e8089b?source=rss----98111c9905da---4;;;Inside LinkedIn’s Embedding Architecture Powering its Job Search Capabilities;Details about one of the most comprehensive embedding architectures ever created. ...
2023.10.12.18.50.20;12.10.2023;20;12;Energy;Electricity, Smart Grid et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/AdaptEdge_Targeted_Universal_Adversarial_Attacks_on_Time_Series_Data_in_Smart_Grids/23542215;;TechRxiv RSS Feed;AdaptEdge: Targeted Universal Adversarial Attacks on Time Series Data in Smart Grids;Deep learning (DL) has emerged as a key technique in smart grid operations for task classification of power quality disturbances (PQDs). Even though these models have considerably improved the efficiency of power infrastructure, their susceptibility to adversarial attacks presents potential difficulties. For the first time, we introduce a novel algorithm called Adaptive Edge (AdaptEdge), which effectively employs targeted universal adversarial attacks to deceive DL models working with time series data. The unique contribution of this algorithm is its ability to maintain a delicate balance between the fooling rate and the imperceptibility of perturbations to human observers. Our results demonstrate a fooling rate of up to 90.78% in the ResNet50 model—the highest achieved thus far—while maintaining an optimal signal-to-noise ratio (SNR) of 3dB and ensuring signal integrity. We implemented our algorithm across various advanced DL models and found considerable efficacy, demonstrating its adaptability and versatility across diverse architectures. The results of our study highlight the pressing need for developing more robust DL model implementations in the context of the smart grid. Additionally, our proposed approach demonstrates its effectiveness in addressing this need.
2023.10.12.18.50.21;12.10.2023;21;12;Energy;Electricity, Smart Grid et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Closed-form_Solution_for_Multi-Objective_Optimal_Analytical_Balance_Control_Strategy_for_a_Single-Stage_Isolated_MVAC-LVDC_Converter/24272290;;TechRxiv RSS Feed;Closed-form Solution for Multi-Objective Optimal Analytical Balance Control Strategy for a Single-Stage Isolated MVAC-LVDC Converter;The inevitable issue of parameter mismatch in single-stage isolated multilevel medium-voltage AC - low-voltage DC (MVAC-LVDC) converters leads to unbalanced power transfer and losses in the constituting submodules. This paper analyses the drawbacks of the conventional power balance control (PBC) approach and proposes a multi-objective optimal analytical balance control (MOABC) as a remedy. The analysis of PBC strategy reveals its non-optimal pulse-width and phase-shift evaluation, leading to imbalance in losses (due to dissimilar ZVS modulations) and current stresses in the constituting submodules. The proposed MOABC follows an analytical solution approach to fulfill multiple objectives of LVDC bus voltage tracking, maximizing ZVS range of front-end (FE) and back-end (BE) MOSFETs, equalizing conduction losses among submodules and restricting grid-side current harmonics as per grid-code limits. An 11.7 kVA(pk) experimental setup is used where the proposed MOABC is implemented directly on a commercial microprocessor, and the test results verify each objective’s accomplishment. Experimental comparison of MOABC with other control methods clearly present the proposed method’s advantages.
2023.10.12.18.50.22;12.10.2023;22;14;Public Services;Public Services, Traffic et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Mitigating_Road_Traffic_Crashes_in_Urban_Environments_A_Case_Study_and_Literature_Review-based_Approach/24265186;;TechRxiv RSS Feed;Mitigating Road Traffic Crashes in Urban Environments: A Case Study and Literature Review-based Approach;Road traffic crashes in urban areas pose significant safety and efficiency challenges. This paper presents an approach, merging case studies and literature reviews, to mitigate urban road traffic crashes and enhance safety. The study commences with an extensive literature review, delving into existing research on road traffic crashes. This review establishes the groundwork for comprehending urban road safety solutions, insights into ongoing research trends, and guiding case study selection. Three case studies parallel analogous cities where Intelligent Transportation Systems and other smart city initiatives targeting road safety succeeded. Each case dissects safety interventions, accomplishments, and lessons learned. Scrutinizing these studies aims to unveil trends underpinning a holistic road safety strategy. From literature and case studies, a comprehensive road safety strategy emerges. It leverages advanced technology, data insights, and proactive measures to enhance road safety, curtail accidents, and optimize urban traffic. This research yields an all?encompassing road safety strategy for policymakers, planners, and safety practitioners to elevate urban road safety. It promotes secure, efficient, technologically advanced urban areas, endorsing sustainable transportation, elevating residents’ lives, and positioning cities as urban mobility leaders. Furthermore, this study contributes to the academic literature on road safety and urban transportation. Through case studies and literature reviews, it supplements knowledge about effective road traffic crash mitigation strategies. These insights have the potential to guide future research, advancing road safety and urban transportation domains.
2023.10.12.18.50.23;12.10.2023;23;14;Public Services;Public Services, Traffic et al.;arxiv;2310.06713;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2310.06713.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yuan_T/0/1/0/all/0/1"">Tong Yuan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1"">Jian Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1"">Zeyi Wen</a>";Tong Yuan,Jian Yang,Zeyi Wen;Interpretable Traffic Event Analysis with Bayesian Networks.;Although existing machine learning-based methods for traffic accident analysis can provide good quality results to downstream tasks, they lack interpretability which is crucial for this critical problem. This paper proposes an interpretable framework based on Bayesian Networks for traffic accident prediction. To enable the ease of interpretability, we design a dataset construction pipeline to feed the traffic data into the framework while retaining the essential traffic data information. With a concrete case study, our framework can derive a Bayesian Network from a dataset based on the causal relationships between weather and traffic events across the United States. Consequently, our framework enables the prediction of traffic accidents with competitive accuracy while examining how the probability of these events changes under different conditions, thus illustrating transparent relationships between traffic and weather events. Additionally, the visualization of the network simplifies the analysis of relationships between different variables, revealing the primary causes of traffic accidents and ultimately providing a valuable reference for reducing traffic accidents.
2023.10.12.18.50.24;12.10.2023;24;14;Public Services;Public Services, Traffic et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0697/v1;;Preprints.org - The Multidisciplinary Preprint Platform;EDDformer: A New Decoder for Efficient Semantic Segmentation of Remote Sensing Urban Scene Imagery;Semantic segmentation of remote sensing urban scene imagery is a pixel-wise prediction, which is applied to identify the land-cover or land-use category. However, semantic segmentation demands huge computation cost. In order to reduce the huge computation cost, a common method is to introduce transformer and CNN hybrid method to have a good trade-off between accuracy and computation cost. However, recent CNN-transformer hybrid methods often capture local-global context and cross-window interaction information simultaneously. Then they introduce the local-global context to fuse the local feature, which repeat fuse the local and global feature and result in the additional computation cost. And previous methods often ignore to filter the local and global feature. To fix the problem, we design a lightweight decoder-EDDformer, which is Efficient Global Value Transformer with Dynamic Gatefusion module. Efficient global value transformer only response for extracting global feature. Dynamic Gatefusion module filter the local and global semantic feature and fuse them to capture the local-global context in one time. Extensive experiments reveal that our method not only runs faster but also achieves higher accuracy compared with other state-of-the-art lightweight models.
2023.10.12.18.50.25;12.10.2023;25;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.06083;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.06083.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bran_A/0/1/0/all/0/1"">Andres M Bran</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schwaller_P/0/1/0/all/0/1"">Philippe Schwaller</a>";Andres M Bran,Philippe Schwaller;Transformers and Large Language Models for Chemistry and Drug Discovery.;Language modeling has seen impressive progress over the last years, mainly prompted by the invention of the Transformer architecture, sparking a revolution in many fields of machine learning, with breakthroughs in chemistry and biology. In this chapter, we explore how analogies between chemical and natural language have inspired the use of Transformers to tackle important bottlenecks in the drug discovery process, such as retrosynthetic planning and chemical space exploration. The revolution started with models able to perform particular tasks with a single type of data, like linearised molecular graphs, which then evolved to include other types of data, like spectra from analytical instruments, synthesis actions, and human language. A new trend leverages recent developments in large language models, giving rise to a wave of models capable of solving generic tasks in chemistry, all facilitated by the flexibility of natural language. As we continue to explore and harness these capabilities, we can look forward to a future where machine learning plays an even more integral role in accelerating scientific discovery.
2023.10.12.18.50.26;12.10.2023;26;19;CrossTopic;Generic, Cross Topic, et al.;towardsdatascience;;;https://towardsdatascience.com/how-data-science-can-deliver-value-f2d4a1ea3a49?source=rss----7f60cf5620c9---4;;;How Data Science Can Deliver Value;Most tech workers would agree the current economic environment is not great. Many companies laid off staff earlier in the year including the company I work at. Tighter cash flow often means greater scrutiny of teams’ performance and value-add to the organization. So it becomes more important that you and your team can clearly articulate how you contribute to the business’s goals. ...
2023.10.10.18.47.01;10.10.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.01412;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.01412.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1"">Zhenhua Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yujia Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1"">Enze Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1"">Zhen Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1"">Yong Guo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1"">Kwan-Yee. K. Wong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Zhenguo Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1"">Hengshuang Zhao</a>";Zhenhua Xu,Yujia Zhang,Enze Xie,Zhen Zhao,Yong Guo,Kwan-Yee. K. Wong,Zhenguo Li,Hengshuang Zhao;DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model.;In the past decade, autonomous driving has experienced rapid development in both academia and industry. However, its limited interpretability remains a significant unsolved problem, severely hindering autonomous vehicle commercialization and further development. Previous approaches utilizing small language models have failed to address this issue due to their lack of flexibility, generalization ability, and robustness. Recently, multimodal large language models (LLMs) have gained considerable attention from the research community for their capability to process and reason non-text data (e.g., images and videos) by text. In this paper, we present DriveGPT4, an interpretable end-to-end autonomous driving system utilizing LLMs. DriveGPT4 is capable of interpreting vehicle actions and providing corresponding reasoning, as well as answering diverse questions posed by human users for enhanced interaction. Additionally, DriveGPT4 predicts vehicle low-level control signals in an end-to-end fashion. These capabilities stem from a customized visual instruction tuning dataset specifically designed for autonomous driving. To the best of our knowledge, DriveGPT4 is the first work focusing on interpretable end-to-end autonomous driving. When evaluated on multiple tasks alongside conventional methods and video understanding LLMs, DriveGPT4 demonstrates superior qualitative and quantitative performance. Additionally, DriveGPT4 can be generalized in a zero-shot fashion to accommodate more unseen scenarios. The project page is available at https://tonyxuqaq.github.io/projects/DriveGPT4/ .
2023.10.10.18.47.02;10.10.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2306.07207;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.07207.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1"">Ruipu Luo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1"">Ziwang Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1"">Min Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1"">Junwei Dong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1"">Da Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1"">Pengcheng Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1"">Tao Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1"">Linmei Hu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qiu_M/0/1/0/all/0/1"">Minghui Qiu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1"">Zhongyu Wei</a>";Ruipu Luo,Ziwang Zhao,Min Yang,Junwei Dong,Da Li,Pengcheng Lu,Tao Wang,Linmei Hu,Minghui Qiu,Zhongyu Wei;Valley: Video Assistant with Large Language model Enhanced abilitY.;Large language models (LLMs), with their remarkable conversational capabilities, have demonstrated impressive performance across various applications and have emerged as formidable AI assistants. In view of this, it raises an intuitive question: Can we harness the power of LLMs to build multimodal AI assistants for visual applications? Recently, several multi-modal models have been developed for this purpose. They typically pre-train an adaptation module to align the semantics of the vision encoder and language model, followed by fine-tuning on instruction-following data. However, despite the success of this pipeline in image and language understanding, its effectiveness in joint video and language understanding has not been widely explored. In this paper, we aim to develop a novel multi-modal foundation model capable of comprehending video, image, and language within a general framework. To achieve this goal, we introduce Valley, a Video Assistant with Large Language model Enhanced abilitY. The Valley consists of a LLM, a temporal modeling module, a visual encoder, and a simple projection module designed to bridge visual and textual modes. To empower Valley with video comprehension and instruction-following capabilities, we construct a video instruction dataset and adopt a two-stage tuning procedure to train it. Specifically, we employ ChatGPT to facilitate the construction of task-oriented conversation data encompassing various tasks, including multi-shot captions, long video descriptions, action recognition, causal relationship inference, etc. Subsequently, we adopt a pre-training-then-instructions-tuned pipeline to align visual and textual modalities and improve the instruction-following capability of Valley. Qualitative experiments demonstrate that Valley has the potential to function as a highly effective video assistant that can make complex video understanding scenarios easy.
2023.10.10.18.47.03;10.10.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2305.13225;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.13225.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yue Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1"">Leyang Cui</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1"">Deng Cai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1"">Xinting Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1"">Tao Fang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1"">Wei Bi</a>";Yue Zhang,Leyang Cui,Deng Cai,Xinting Huang,Tao Fang,Wei Bi;Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A Preliminary Study on Writing Assistance.;Proprietary Large Language Models (LLMs), such as ChatGPT, have garnered significant attention due to their exceptional capabilities in handling a diverse range of tasks. Recent studies demonstrate that open-sourced smaller foundational models, such as 7B-size LLaMA, can also display remarkable proficiency in tackling diverse tasks when fine-tuned using instruction-driven data. In this work, we investigate a practical problem setting where the primary focus is on one or a few particular tasks rather than general-purpose instruction following, and explore whether LLMs can be beneficial and further improved for such targeted scenarios. We choose the writing-assistant scenario as the testbed, which includes seven writing tasks. We collect training data for these tasks, reframe them in an instruction-following format, and subsequently refine the LLM, specifically LLaMA, via instruction tuning. Experimental results show that fine-tuning LLaMA on writing instruction data significantly improves its ability on writing tasks. We also conduct more experiments and analyses to offer insights for future work on effectively fine-tuning LLaMA for specific scenarios. Finally, we initiate a discussion regarding the necessity of employing LLMs for only one targeted task, taking into account the efforts required for tuning and the resources consumed during deployment.
2023.10.10.18.47.04;10.10.2023;04;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.04793;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2310.04793.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1"">Neng Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1"">Hongyang Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1"">Christina Dan Wang</a>";Neng Wang,Hongyang Yang,Christina Dan Wang;FinGPT: Instruction Tuning Benchmark for Open-Source Large Language Models in Financial Datasets.;In the swiftly expanding domain of Natural Language Processing (NLP), the potential of GPT-based models for the financial sector is increasingly evident. However, the integration of these models with financial datasets presents challenges, notably in determining their adeptness and relevance. This paper introduces a distinctive approach anchored in the Instruction Tuning paradigm for open-source large language models, specifically adapted for financial contexts. Through this methodology, we capitalize on the interoperability of open-source models, ensuring a seamless and transparent integration. We begin by explaining the Instruction Tuning paradigm, highlighting its effectiveness for immediate integration. The paper presents a benchmarking scheme designed for end-to-end training and testing, employing a cost-effective progression. Firstly, we assess basic competencies and fundamental tasks, such as Named Entity Recognition (NER) and sentiment analysis to enhance specialization. Next, we delve into a comprehensive model, executing multi-task operations by amalgamating all instructional tunings to examine versatility. Finally, we explore the zero-shot capabilities by earmarking unseen tasks and incorporating novel datasets to understand adaptability in uncharted terrains. Such a paradigm fortifies the principles of openness and reproducibility, laying a robust foundation for future investigations in open-source financial large language models (FinLLMs).
2023.10.10.18.47.05;10.10.2023;05;03;Finance;Finance, DeFi, Insurance, Banking et al.;towardsdatascience;;;https://towardsdatascience.com/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=rss----7f60cf5620c9---4;;;Bridging Domains: Infusing Financial, Privacy, and Software Best Practices into ML Risk Management;Understanding strategies that go beyond traditional Model Risk Management. ...
2023.10.10.18.47.06;10.10.2023;06;05;Industry;I4.0, Production et al.;arxiv;2310.04427;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04427.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ghimire_P/0/1/0/all/0/1"">Prashnna Ghimire</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1"">Kyungki Kim</a>, <a href=""http://arxiv.org/find/cs/1/au:+Acharya_M/0/1/0/all/0/1"">Manoj Acharya</a>";Prashnna Ghimire,Kyungki Kim,Manoj Acharya;Generative AI in the Construction Industry: Opportunities & Challenges.;In the last decade, despite rapid advancements in artificial intelligence (AI) transforming many industry practices, construction largely lags in adoption. Recently, the emergence and rapid adoption of advanced large language models (LLM) like OpenAI's GPT, Google's PaLM, and Meta's Llama have shown great potential and sparked considerable global interest. However, the current surge lacks a study investigating the opportunities and challenges of implementing Generative AI (GenAI) in the construction sector, creating a critical knowledge gap for researchers and practitioners. This underlines the necessity to explore the prospects and complexities of GenAI integration. Bridging this gap is fundamental to optimizing GenAI's early-stage adoption within the construction sector. Given GenAI's unprecedented capabilities to generate human-like content based on learning from existing content, we reflect on two guiding questions: What will the future bring for GenAI in the construction industry? What are the potential opportunities and challenges in implementing GenAI in the construction industry? This study delves into reflected perception in literature, analyzes the industry perception using programming-based word cloud and frequency analysis, and integrates authors' opinions to answer these questions. This paper recommends a conceptual GenAI implementation framework, provides practical recommendations, summarizes future research questions, and builds foundational literature to foster subsequent research expansion in GenAI within the construction and its allied architecture & engineering domains.
2023.10.10.18.47.07;10.10.2023;07;05;Industry;I4.0, Production et al.;arxiv;2107.12809;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2107.12809.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1"">Mimi Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Parnell_A/0/1/0/all/0/1"">Andrew Parnell</a>, <a href=""http://arxiv.org/find/cs/1/au:+Brabazon_D/0/1/0/all/0/1"">Dermot Brabazon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Benavoli_A/0/1/0/all/0/1"">Alessio Benavoli</a>";Mimi Zhang,Andrew Parnell,Dermot Brabazon,Alessio Benavoli;Bayesian Optimisation for Sequential Experimental Design with Applications in Additive Manufacturing.;"Bayesian optimization (BO) is an approach to globally optimizing black-box objective functions that are expensive to evaluate. BO-powered experimental design has found wide application in materials science, chemistry, experimental physics, drug development, etc. This work aims to bring attention to the benefits of applying BO in designing experiments and to provide a BO manual, covering both methodology and software, for the convenience of anyone who wants to apply or learn BO. In particular, we briefly explain the BO technique, review all the applications of BO in additive manufacturing, compare and exemplify the features of different open BO libraries, unlock new potential applications of BO to other types of data (e.g., preferential output). This article is aimed at readers with some understanding of Bayesian methods, but not necessarily with knowledge of additive manufacturing; the software performance overview and implementation instructions are instrumental for any experimental-design practitioner. Moreover, our review in the field of additive manufacturing highlights the current knowledge and technological trends of BO. This article has a supplementary material online."
2023.10.10.18.47.08;10.10.2023;08;06;Information;Knowledge, Understanding, Information etc.;arxiv;2305.14835;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.14835.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1"">Haopeng Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1"">Xiao Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"">Jiawei Zhang</a>";Haopeng Zhang,Xiao Liu,Jiawei Zhang;SummIt: Iterative Text Summarization via ChatGPT.;Text summarization systems have made significant progress in recent years, but typically generate summaries in one single step. However, the one-shot summarization setting is sometimes inadequate, as the generated summary may contain hallucinations or overlook essential details related to the reader's interests. This paper addresses this limitation by proposing SummIt, an iterative text summarization framework based on large language models like ChatGPT. Our framework enables the model to refine the generated summary iteratively through self-evaluation and feedback, resembling humans' iterative process when drafting and revising summaries. Furthermore, we explore the potential benefits of integrating knowledge and topic extractors into the framework to enhance summary faithfulness and controllability. We automatically evaluate the performance of our framework on three benchmark summarization datasets. We also conduct a human evaluation to validate the effectiveness of the iterative refinements and identify a potential issue of over-correction.
2023.10.10.18.47.09;10.10.2023;09;09;Human;Human Resource, Personal Assistance et al.;oreilly;;;https://www.oreilly.com/radar/automated-mentoring-with-chatgpt/;;;Automated Mentoring with ChatGPT;Ethan and Lilach Mollick’s paper Assigning AI: Seven Approaches for Students with Prompts explores seven ways to use AI in teaching. (While this paper is eminently readable, there is a non-academic version in Ethan Mollick’s Substack.) The article describes seven roles that an AI bot like ChatGPT might play in the education process: Mentor, Tutor, Coach, Student, Teammate, Student, Simulator, and Tool. For each role, it includes a detailed example of a prompt that can be used to implement that role, along with an example of a ChatGPT session using the prompt, risks of using the prompt, guidelines for teachers, instructions for students, and instructions to help teacher build their own prompts. ...
2023.10.10.18.47.10;10.10.2023;10;10;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2211.13777;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2211.13777.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Lucchese_L/0/1/0/all/0/1"">Lorenzo Lucchese</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Pakkanen_M/0/1/0/all/0/1"">Mikko Pakkanen</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Veraart_A/0/1/0/all/0/1"">Almut Veraart</a>";Lorenzo Lucchese,Mikko Pakkanen,Almut Veraart;The Short-Term Predictability of Returns in Order Book Markets: a Deep Learning Perspective.;In this paper, we conduct a systematic large-scale analysis of order book-driven predictability in high-frequency returns by leveraging deep learning techniques. First, we introduce a new and robust representation of the order book, the volume representation. Next, we carry out an extensive empirical experiment to address various questions regarding predictability. We investigate if and how far ahead there is predictability, the importance of a robust data representation, the advantages of multi-horizon modeling, and the presence of universal trading patterns. We use model confidence sets, which provide a formalized statistical inference framework particularly well suited to answer these questions. Our findings show that at high frequencies predictability in mid-price returns is not just present, but ubiquitous. The performance of the deep learning models is strongly dependent on the choice of order book representation, and in this respect, the volume representation appears to have multiple practical advantages.
2023.10.10.18.47.11;10.10.2023;11;10;Commerce;Commerce, Trading, Sales, Retail et al.;blog;;;https://blog.google/products/ads-commerce/demand-more-from-social-with-ai-powered-ads/;;;Demand more from social with AI-powered ads;Learn how Demand Gen campaigns can help you extend your social strategy and drive demand across YouTube and Google. Explore new insights, customer success stories and more. ...
2023.10.10.18.47.12;10.10.2023;12;12;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1345/v2;;Preprints.org - The Multidisciplinary Preprint Platform;A Survey of Numerical Simulation Tools for Offshore Wind Turbine Systems;Design, analysis, manufacture, and deployment of offshore wind turbines mounted on a floating base is a novel industry that is attracting interest from both academia and industry. In an effort to comprehend the sophisticated aerodynamics and hydrodynamics of the floating offshore wind turbines (FOWTs), numerical and physical modelling of these complex systems began to develop with their appearance. The strong coupling between the aerodynamics of the rotor-nacelle assembly (RNA) and the hydrodynamics of the floating platform makes modelling FOWTs a challenging task. However, the scaling mismatch between Froude scaling and Reynolds scaling made it more difficult to physically test scaled-down prototypes of FOWTs, whether in a wind tunnel or an ocean basin. In this regard, developing high-fidelity numerical modelling that is both cost-effective and accurate has been receiving increased attention as a potential replacement for or complement to physical testing. However, numerical engineering tools, which are frequently used in the offshore oil and gas industry, are known as mid-fidelity to low-fidelity tools and lack the degree of accuracy that is desirable for FOWTs. In recent years, a variety of numerical tools have been established or developed to uncover the complex nature of the dynamics of FOWTs. This study aims to provide a comprehensive survey of numerical tools available for simulating FOWTs, with a particular emphasis on horizontal axis wind turbines (HAWTs), assessing their capabilities and limitations.
2023.10.10.18.47.13;10.10.2023;13;12;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0605/v1;;Preprints.org - The Multidisciplinary Preprint Platform;A Comprehensive Overview of Photovoltaic Technologies and their Efficiency for a Climate Neutrality;Solar photovoltaic (PV) technology is a cornerstone of the global effort to transition towards cleaner and more sustainable energy systems. This paper explores the pivotal role of PV technology in re-ducing greenhouse gas emissions and combatting the pressing issue of climate change. At the heart of its efficacy lies the efficiency of PV materials, which dictates the extent to which sunlight is transformed into electricity. Over the last decade, substantial advancements in PV efficiency have propelled the widespread adoption of solar PV technology on a global scale. The efficiency of PV materials is a critical factor, determining how effectively sunlight is transformed into electricity. Enhanced efficiency, achieved through a decade of progress, has driven the global expansion of solar PV. Multi-junction photovoltaic materials have now exceeded 40% efficiency in lab tests. China leads the world in solar PV installations, boasting over 253 GW of installed capacity by the end of 2021. Other prominent countries in this sector are the United States, Japan, Germany, and India. Supportive policies like feed-in tariffs, net metering, tax incentives, and cost reductions in PV modules have made solar PV increasingly competitive against fossil fuel-based power generation. Solar PV technology holds immense potential for creating a cleaner, reliable, scalable, and cost-effective electricity system. To expedite its deployment and foster a more sustainable energy future, continued investment in research and development, along with supportive policies and market mechanisms, is essential. This paper underscores the pivotal role of solar PV technology in the global energy transition and advocates for a concerted effort to unlock its full potential in achieving a more sustainable and resilient energy future.
2023.10.10.18.47.14;10.10.2023;14;13;Logistics;Logistics, Transport Equipment, Automotive, Self Driving et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202202.0123/v2;;Preprints.org - The Multidisciplinary Preprint Platform;Practical Autonomous Driving: A Survey of Challenges and Opportunities;Autonomous Driving (AD) has become a prominent research area in the field of Artificial Intelligence (AI) and Machine Learning (ML) in recent years. This opens the door wider for self-driving cars to surpass conventional vehicles in the current market share. Despite its apparent simplicity, AD is composed of complex and heterogeneous systems, which are in need of a high level of coordination and alignment to ensure both full automation and safety. Therefore, numerous research studies have been conducted over the last few years to facilitate such coordination and accelerate the capacity of these types of vehicles to be self-managed in complex situations. The paper summarises these approaches that led to building what is known nowadays as the autonomous driving pipeline. Moreover, although skepticism exists regarding the practicality of AD as a viable alternative to traditional vehicles, extensive research suggests the multiple benefits of relying on them for mobility. While challenges remain in implementing AD in the real world, including regulation and technical issues, substantial progress in recent years indicates a growing acceptance of AD in the near future. This paper further explores the advantages and opportunities of the conducted such systems in facilitating the practicality of Autonomous Driving.
2023.10.10.18.47.15;10.10.2023;15;13;Logistics;Logistics, Transport Equipment, Automotive, Self Driving et al.;arxiv;2008.01302;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2008.01302.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1"">Teng Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"">Yuyou Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1"">Wenxuan Xiao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1"">Xiaolin Tang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1"">Mingzhu Yin</a>";Teng Liu,Yuyou Yang,Wenxuan Xiao,Xiaolin Tang,Mingzhu Yin;A Comparative Analysis of Deep Reinforcement Learning-enabled Freeway Decision-making for Automated Vehicles.;Deep reinforcement learning (DRL) has emerged as a pervasive and potent methodology for addressing artificial intelligence challenges. Due to its substantial potential for autonomous self-learning and self-improvement, DRL finds broad applications across various research domains. This article undertakes a comprehensive comparison of several DRL approaches con-cerning the decision-making challenges encountered by autono-mous vehicles on freeways. These techniques encompass common deep Q-learning (DQL), double deep Q-learning (DDQL), dueling deep Q-learning, and prioritized replay deep Q-learning. Initially, the reinforcement learning (RL) framework is introduced, fol-lowed by a mathematical establishment of the implementations of the aforementioned DRL methods. Subsequently, a freeway driving scenario for automated vehicles is constructed, wherein the decision-making problem is reformulated as a control opti-mization challenge. Finally, a series of simulation experiments are conducted to assess the control performance of these DRL-enabled decision-making strategies. This culminates in a comparative analysis, which seeks to elucidate the connection between autonomous driving outcomes and the learning char-acteristics inherent to these DRL techniques.
2023.10.10.18.47.16;10.10.2023;16;13;Logistics;Logistics, Transport Equipment, Automotive, Self Driving et al.;arxiv;2104.14106;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2104.14106.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hartzer_J/0/1/0/all/0/1"">Jacob Hartzer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Saripalli_S/0/1/0/all/0/1"">Srikanth Saripalli</a>";Jacob Hartzer,Srikanth Saripalli;Vehicular Teamwork: Collaborative localization of Autonomous Vehicles.;This paper develops a distributed collaborative localization algorithm based on an extended kalman filter. This algorithm incorporates Ultra-Wideband (UWB) measurements for vehicle to vehicle ranging, and shows improvements in localization accuracy where GPS typically falls short. The algorithm was first tested in a newly created open-source simulation environment that emulates various numbers of vehicles and sensors while simultaneously testing multiple localization algorithms. Predicted error distributions for various algorithms are quickly producible using the Monte-Carlo method and optimization techniques within MatLab. The simulation results were validated experimentally in an outdoor, urban environment. Improvements of localization accuracy over a typical extended kalman filter ranged from 2.9% to 9.3% over 180 meter test runs. When GPS was denied, these improvements increased up to 83.3% over a standard kalman filter. In both simulation and experimentally, the DCL algorithm was shown to be a good approximation of a full state filter, while reducing required communication between vehicles. These results are promising in showing the efficacy of adding UWB ranging sensors to cars for collaborative and landmark localization, especially in GPS-denied environments. In the future, additional moving vehicles with additional tags will be tested in other challenging GPS denied environments.
2023.10.10.18.47.17;10.10.2023;17;13;Logistics;Logistics, Transport Equipment, Automotive, Self Driving et al.;acm;;http://cacm.acm.org/browse-by-subject/computer-applications.rss;http://cacm.acm.org/news/277133-dubai-to-start-robotaxi-trials;;Communications of the ACM: Computer Applications;Dubai to Start Robotaxi Trials;The U.A.E. city of Dubai will launch its first wave of robotaxis this month in a bid to reduce congestion and accidents.
2023.10.10.18.47.18;10.10.2023;18;13;Logistics;Logistics, Transport Equipment, Automotive, Self Driving et al.;blog;;;https://blog.google/outreach-initiatives/sustainability/google-transportation-energy-emissions-reduction/;;;New ways we’re helping reduce transportation and energy emissions;These new product features and expansions help people, city planners and policymakers take action toward a sustainable future. ...
2023.10.10.18.47.19;10.10.2023;19;14;Public Services;Public Services;arxiv;2305.15187;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.15187.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Schumann_J/0/1/0/all/0/1"">Julian F. Schumann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1"">Aravinda Ramakrishnan Srinivasan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kober_J/0/1/0/all/0/1"">Jens Kober</a>, <a href=""http://arxiv.org/find/cs/1/au:+Markkula_G/0/1/0/all/0/1"">Gustav Markkula</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zgonnikov_A/0/1/0/all/0/1"">Arkady Zgonnikov</a>";Julian F. Schumann,Aravinda Ramakrishnan Srinivasan,Jens Kober,Gustav Markkula,Arkady Zgonnikov;Using Models Based on Cognitive Theory to Predict Human Behavior in Traffic: A Case Study.;The development of automated vehicles has the potential to revolutionize transportation, but they are currently unable to ensure a safe and time-efficient driving style. Reliable models predicting human behavior are essential for overcoming this issue. While data-driven models are commonly used to this end, they can be vulnerable in safety-critical edge cases. This has led to an interest in models incorporating cognitive theory, but as such models are commonly developed for explanatory purposes, this approach's effectiveness in behavior prediction has remained largely untested so far. In this article, we investigate the usefulness of the \emph{Commotions} model -- a novel cognitively plausible model incorporating the latest theories of human perception, decision-making, and motor control -- for predicting human behavior in gap acceptance scenarios, which entail many important traffic interactions such as lane changes and intersections. We show that this model can compete with or even outperform well-established data-driven prediction models across several naturalistic datasets. These results demonstrate the promise of incorporating cognitive theory in behavior prediction models for automated vehicles.
2023.10.10.18.47.20;10.10.2023;20;15;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0463/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Quantifying Digital Biomarkers for Well-Being: Stress, Anxiety, Positive and Negative Affect via Wearable Devices and Their Time-Based Predictions;Wearable devices have become ubiquitous, collecting rich temporal data that offers valuable insights into human activities, health monitoring, and behavior analysis. Leveraging this data, researchers have developed innovative approaches to classify and predict time-based patterns and events in human life. Time-based techniques allow the capture of intricate temporal dependencies, which is the nature of the data coming from wearable devices. This paper focuses on predicting well-being factors, such as stress, anxiety, positive and negative affect, on the Tesserae dataset collected from office workers. We examine the performance of different methodologies, including deep learning architectures, LSTM, ensemble techniques, Random Forest (RF) and XGBoost and compare their performances for time-based and non-time-based versions. In time-based versions, we investigate the effect of previous records of well-being factors on the upcoming ones. The overall results show that time-based LSTM performs the best among conventional (non-time-based) RF, XGBoost, and LSTM. The performance even increases when we consider a more extended previous period, in this case, 3 past-days rather than 1 past-day to predict the next day. Furthermore, we explore the corresponding biomarkers for each well-being factor using feature ranking. The obtained rankings are compatible with the psychological literature. In this work, we validated them based on device measurements rather than subjective survey responses.
2023.10.10.18.47.21;10.10.2023;21;15;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0553/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Application of Blockchain Technology & Integration of Differential Privacy: Issues in E-Health Domains;"A systematic and comprehensive review of critical applications of Blockchain Technol-ogy with Differential Privacy integration lies within the privacy and security enhancement. This paper aims to highlight the research issues in the e-health domain (e.g., Electronic Medical Rec-ords) and to review the current research directions in Differential Privacy integration with Blockchain Technology.(1) Background: The current state of the art in the e-health domain is identified as follows: (a) healthcare information poses a high level of security and privacy concerns due to its sensitivity; (b) due to vulnerabilities surrounding the healthcare system, a data breach is common and presents a risk for attacks by an adversary; and (c) the current privacy and security apparatus needs further fortification. (2) Methods: The methodology uses a systematic literature review (SLR) to identify and select relevant research papers and academic journals in DP and BT. (3) Results: The results are categorized into: e-Health Record Privacy, Real-Time Health Data, and Health Survey Data Protection to identify inherent issues with Differential Privacy integra-tion with Blockchain and technical challenges.(4) Conclusion: This review thoroughly surveyed and summarized Differential Privacy mechanisms in EMR privacy, real-time health data, and health survey data protection while highlighting challenges."
2023.10.10.18.47.22;10.10.2023;22;15;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.05238;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.05238.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Shuai Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Scells_H/0/1/0/all/0/1"">Harrisen Scells</a>, <a href=""http://arxiv.org/find/cs/1/au:+Potthast_M/0/1/0/all/0/1"">Martin Potthast</a>, <a href=""http://arxiv.org/find/cs/1/au:+Koopman_B/0/1/0/all/0/1"">Bevan Koopman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zuccon_G/0/1/0/all/0/1"">Guido Zuccon</a>";Shuai Wang,Harrisen Scells,Martin Potthast,Bevan Koopman,Guido Zuccon;Generating Natural Language Queries for More Effective Systematic Review Screening Prioritisation.;Screening prioritisation in medical systematic reviews aims to rank the set of documents retrieved by complex Boolean queries. Prioritising the most important documents ensures that subsequent review steps can be carried out more efficiently and effectively. The current state of the art uses the final title of the review as a query to rank the documents using BERT-based neural rankers. However, the final title is only formulated at the end of the review process, which makes this approach impractical as it relies on ex post facto information. At the time of screening, only a rough working title is available, with which the BERT-based ranker performs significantly worse than with the final title. In this paper, we explore alternative sources of queries for prioritising screening, such as the Boolean query used to retrieve the documents to be screened and queries generated by instruction-based generative large-scale language models such as ChatGPT and Alpaca. Our best approach is not only viable based on the information available at the time of screening, but also has similar effectiveness to the final title.
2023.10.10.18.47.23;10.10.2023;23;18;AgriCulture;Agriculture et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0490/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Assessment of Soil Management Practices Enhancing Soil Resilience in Small-Scale Agroecosystems: Case of Mount-Lebanon;Soil resilience has become a central theme in research aimed at understanding the impacts of human activities on the environment and mitigating the negative effects of soil disturbance. To evaluate how soil management practices affect soil resilience, 26 small farms were studied in a mountainous district of Lebanon. Farms were categorized into conventional (C), neutral (N), and regenerative (R), based on the practices adopted including tillage, amendments, rotation, cover crops, residues management, and pest control. Common practices included intercropping (85%), residue retention (73%), cover crops (61%), and organic amendments (46%). Qualitative assessment of soil health used indicators from Latin American Society for Agroecology (SOCLA) as well as from ‘Tool for Agroecological Performance Evaluation’ of the FAO. The indicators aligned with the classification of farms into their respective C/N/R groups. The sustainability scores were 4.28 (Low) for conventional, 6.34 (Moderate) for neutral, and 7.88 (Good) for regenerative farms. Quantitative analysis determined for 15 selected farms showed significant differences in soil organic matter (1.86% C, 2.75% N, 3.32% R), soil respiration (156C, 296N, 380R mg C-CO₂. week⁻¹), and earthworm abundance/liter (2.92C, 4.24N, 5.72R). The Soil Quality Index (SQI) provided an accurate representation of the current soil health condition, with increment from 0.05, 0.27 (low), to 0.49 (good) in conventional, neutral, and regenerative farms, respectively. The research highlights that soil resilience is influenced by a combination of intricate factors, encompassing biotic interactions, as well as physical, chemical, and biological processes. Particularly in regions like the Mediterranean basin, adopting sustainable soil management practices contributes to enduring productivity while preserving the functional integrity and resilience characteristics of the soil.
2023.10.10.18.47.24;10.10.2023;24;99;Other;Others;arxiv;2209.03434;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2209.03434.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhu_Tian_C/0/1/0/all/0/1"">Chen Zhu-Tian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1"">Qisen Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1"">Xiao Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Beyer_J/0/1/0/all/0/1"">Johanna Beyer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1"">Haijun Xia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1"">Yingcai Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1"">Hanspeter Pfister</a>";Chen Zhu-Tian,Qisen Yang,Xiao Xie,Johanna Beyer,Haijun Xia,Yingcai Wu,Hanspeter Pfister;Sporthesia: Augmenting Sports Videos Using Natural Language.;Augmented sports videos, which combine visualizations and video effects to present data in actual scenes, can communicate insights engagingly and thus have been increasingly popular for sports enthusiasts around the world. Yet, creating augmented sports videos remains a challenging task, requiring considerable time and video editing skills. On the other hand, sports insights are often communicated using natural language, such as in commentaries, oral presentations, and articles, but usually lack visual cues. Thus, this work aims to facilitate the creation of augmented sports videos by enabling analysts to directly create visualizations embedded in videos using insights expressed in natural language. To achieve this goal, we propose a three-step approach - 1) detecting visualizable entities in the text, 2) mapping these entities into visualizations, and 3) scheduling these visualizations to play with the video - and analyzed 155 sports video clips and the accompanying commentaries for accomplishing these steps. Informed by our analysis, we have designed and implemented Sporthesia, a proof-of-concept system that takes racket-based sports videos and textual commentaries as the input and outputs augmented videos. We demonstrate Sporthesia's applicability in two exemplar scenarios, i.e., authoring augmented sports videos using text and augmenting historical sports videos based on auditory comments. A technical evaluation shows that Sporthesia achieves high accuracy (F1-score of 0.9) in detecting visualizable entities in the text. An expert evaluation with eight sports analysts suggests high utility, effectiveness, and satisfaction with our language-driven authoring method and provides insights for future improvement and opportunities.
2023.10.09.19.46.01;09.10.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.04304;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04304.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sadik_A/0/1/0/all/0/1"">Ahmed R. Sadik</a>, <a href=""http://arxiv.org/find/cs/1/au:+Brulin_S/0/1/0/all/0/1"">Sebastian Brulin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Olhofer_M/0/1/0/all/0/1"">Markus Olhofer</a>";Ahmed R. Sadik,Sebastian Brulin,Markus Olhofer;Coding by Design: GPT-4 empowers Agile Model Driven Development.;"Generating code from a natural language using Large Language Models (LLMs) such as ChatGPT, seems groundbreaking. Yet, with more extensive use, it's evident that this approach has its own limitations. The inherent ambiguity of natural language presents challenges for complex software designs. Accordingly, our research offers an Agile Model-Driven Development (MDD) approach that enhances code auto-generation using OpenAI's GPT-4. Our work emphasizes ""Agility"" as a significant contribution to the current MDD method, particularly when the model undergoes changes or needs deployment in a different programming language. Thus, we present a case-study showcasing a multi-agent simulation system of an Unmanned Vehicle Fleet. In the first and second layer of our approach, we constructed a textual representation of the case-study using Unified Model Language (UML) diagrams. In the next layer, we introduced two sets of constraints that minimize model ambiguity. Object Constraints Language (OCL) is applied to fine-tune the code constructions details, while FIPA ontology is used to shape communication semantics and protocols. Ultimately, leveraging GPT-4, our last layer auto-generates code in both Java and Python. The Java code is deployed within the JADE framework, while the Python code is deployed in PADE framework. Concluding our research, we engaged in a comprehensive evaluation of the generated code. From a behavioural standpoint, the auto-generated code aligned perfectly with the expected UML sequence diagram. Structurally, we compared the complexity of code derived from UML diagrams constrained solely by OCL to that influenced by both OCL and FIPA-ontology. Results indicate that ontology-constrained model produce inherently more intricate code, but it remains manageable and low-risk for further testing and maintenance."
2023.10.09.19.46.02;09.10.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/how-to-build-your-first-ai-agent-with-langchain-and-openai-gpt-a2a483096d71?source=rss----98111c9905da---4;;;How to Build Your First AI Agent with LangChain and OpenAI GPT.;So in this article, I’ll show you how to build your first AI Agent. It won’t be as impressive as AutoGPT or Microsoft’s AutoGen… But after reading this article, you will: 1.Understand the difference between the standard Large Language Models and AI Agents, 2. learn how AI Agents “reason & act” with the ReAct type of prompting, 3. know how to implement a basic AI Agent with LangChain for OpenAI language models. ...
2023.10.09.19.46.03;09.10.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/visual-question-answering-with-frozen-large-language-models-353d42791054?source=rss----7f60cf5620c9---4;;;Visual Question Answering with Frozen Large Language Models;Talking with LLMs about images, without training LLMs on images. ...
2023.10.09.19.46.04;09.10.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/your-own-personal-llama-8cf24a9237cb?source=rss----7f60cf5620c9---4;;;Your Own Personal LLaMa;How you can find, retrieve, and feed your custom data into LLaMa 2 to improve responses. ...
2023.10.09.19.46.05;09.10.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/do-all-the-roads-lead-to-rome-5b6756ce7d52?source=rss----7f60cf5620c9---4;;;Do All the Roads Lead to Rome?;Quantifying the Ancient Question with Python, Network Science, and Geospatial Data. ...
2023.10.09.19.46.06;09.10.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/five-things-genai-can-and-cant-do-d8117aad82f4?source=rss----7f60cf5620c9---4;;;Five Things GenAI Can and Can’t Do;An introductory guide for business leaders as to what Generative AI can or cannot do. ...
2023.10.09.19.46.07;09.10.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/5-generative-ai-use-cases-companies-can-implement-today-f458707bfbbe?source=rss----7f60cf5620c9---4;;;5 Generative AI Use Cases Companies Can Implement Today;Getting started with LLMs? Here are 5 popular applications data teams at OpenAI, Vimeo, and other companies are putting into practice today. ...
2023.10.09.19.46.08;09.10.2023;08;02;Processes;Business Processes, Planning, Control et al.;arxiv;2310.03919;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03919.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1"">Chin-Chia Michael Yeh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"">Huiyuan Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1"">Xin Dai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1"">Yan Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Junpeng Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lai_V/0/1/0/all/0/1"">Vivian Lai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1"">Yujie Fan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Der_A/0/1/0/all/0/1"">Audrey Der</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1"">Zhongfang Zhuang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"">Liang Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"">Wei Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Phillips_J/0/1/0/all/0/1"">Jeff M. Phillips</a>";Chin-Chia Michael Yeh,Huiyuan Chen,Xin Dai,Yan Zheng,Junpeng Wang,Vivian Lai,Yujie Fan,Audrey Der,Zhongfang Zhuang,Liang Wang,Wei Zhang,Jeff M. Phillips;An Efficient Content-based Time Series Retrieval System.;A Content-based Time Series Retrieval (CTSR) system is an information retrieval system for users to interact with time series emerged from multiple domains, such as finance, healthcare, and manufacturing. For example, users seeking to learn more about the source of a time series can submit the time series as a query to the CTSR system and retrieve a list of relevant time series with associated metadata. By analyzing the retrieved metadata, users can gather more information about the source of the time series. Because the CTSR system is required to work with time series data from diverse domains, it needs a high-capacity model to effectively measure the similarity between different time series. On top of that, the model within the CTSR system has to compute the similarity scores in an efficient manner as the users interact with the system in real-time. In this paper, we propose an effective and efficient CTSR model that outperforms alternative models, while still providing reasonable inference runtimes. To demonstrate the capability of the proposed method in solving business problems, we compare it against alternative models using our in-house transaction data. Our findings reveal that the proposed model is the most suitable solution compared to others for our transaction data problem.
2023.10.09.19.46.09;09.10.2023;09;03;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2308.09968&r=big;;"Tim MatthiesThomas L\""ohdenStephan LeibleJun-Patrick Raabe";To the Moon: Analyzing Collective Trading Events on the Wings of Sentiment Analysis;This research investigates the growing trend of retail investors participating in certain stocks by organizing themselves on social media platforms, particularly Reddit. Previous studies have highlighted a notable association between Reddit activity and the volatility of affected stocks. This study seeks to expand the analysis to Twitter, which is among the most impactful social media platforms. To achieve this, we collected relevant tweets and analyzed their sentiment to explore the correlation between Twitter activity, sentiment, and stock volatility. The results reveal a significant relationship between Twitter activity and stock volatility but a weak link between tweet sentiment and stock performance. In general, Twitter activity and sentiment appear to play a less critical role in these events than Reddit activity. These findings offer new theoretical insights into the impact of social media platforms on stock market dynamics, and they may practically assist investors and regulators in comprehending these phenomena better.
2023.10.09.19.46.10;09.10.2023;10;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.04356;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04356.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Carpentier_Desjardins_C/0/1/0/all/0/1"">Catherine Carpentier-Desjardins</a>, <a href=""http://arxiv.org/find/cs/1/au:+Paquet_Clouston_M/0/1/0/all/0/1"">Masarah Paquet-Clouston</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kitzler_S/0/1/0/all/0/1"">Stefan Kitzler</a>, <a href=""http://arxiv.org/find/cs/1/au:+Haslhofer_B/0/1/0/all/0/1"">Bernhard Haslhofer</a>";Catherine Carpentier-Desjardins,Masarah Paquet-Clouston,Stefan Kitzler,Bernhard Haslhofer;Mapping the DeFi Crime Landscape: An Evidence-based Picture.;Over the past years, decentralized finance (DeFi) has been the target of numerous profit-driven crimes. However, until now, the full prevalence and cumulative impact of these crimes have not been assessed. This study provides a first comprehensive assessment of profit-driven crimes targeting the DeFi sector. To achieve this, we collected data on 1155 crime events from 2017 to 2022. Of these, 1050 were related to the DeFi industry and 105 to the centralized finance (CeFi) industry. Focusing on the former, a taxonomy was developed to clarify the similarities and differences among these crimes. All events were mapped onto the DeFi stack to assess the impacted technical layers, and the financial damages were quantified to gauge their scale. The findings show that the entire cryptoasset industry has suffered a minimum loss of US$30B, with two thirds related to centralized finance (CeFi) and one third to DeFi. Focusing solely on the latter, the results highlight that during an attack, a DeFi actor (an entity developing a DeFi technology) can serve as a direct target, as a perpetrator, or as an intermediary. The findings show that DeFi actors are the first victims of crimes targeting the DeFi industry: 52% of crime events targeted them, primarily due to technical vulnerabilities at the protocol layer, and these events accounted for 83% of all recorded financial damages. On the other hand, in 40% of crime events, DeFi actors were themselves malicious perpetrators, predominantly misusing contracts at the cryptoasset layer (e.g., rug pull scams). However, these events accounted for only 17% of all financial damages. The study's findings offer a preliminary assessment of the size and scope of crime events within the DeFi sector and highlight the vulnerable position of DeFi actors in the ecosystem.
2023.10.09.19.46.11;09.10.2023;11;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.04336;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04336.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Stoiljkovic_Z/0/1/0/all/0/1"">Zoran Stoiljkovic</a>";Zoran Stoiljkovic;Applying Reinforcement Learning to Option Pricing and Hedging.;This thesis provides an overview of the recent advances in reinforcement learning in pricing and hedging financial instruments, with a primary focus on a detailed explanation of the Q-Learning Black Scholes approach, introduced by Halperin (2017). This reinforcement learning approach bridges the traditional Black and Scholes (1973) model with novel artificial intelligence algorithms, enabling option pricing and hedging in a completely model-free and data-driven way. This paper also explores the algorithm's performance under different state variables and scenarios for a European put option. The results reveal that the model is an accurate estimator under different levels of volatility and hedging frequency. Moreover, this method exhibits robust performance across various levels of option's moneyness. Lastly, the algorithm incorporates proportional transaction costs, indicating diverse impacts on profit and loss, affected by different statistical properties of the state variables.
2023.10.09.19.46.12;09.10.2023;12;03;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.04027;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04027.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1"">Boyu Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1"">Hongyang Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1"">Tianyu Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Babar_A/0/1/0/all/0/1"">Ali Babar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1"">Xiao-Yang Liu</a>";Boyu Zhang,Hongyang Yang,Tianyu Zhou,Ali Babar,Xiao-Yang Liu;Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models.;Financial sentiment analysis is critical for valuation and investment decision-making. Traditional NLP models, however, are limited by their parameter size and the scope of their training datasets, which hampers their generalization capabilities and effectiveness in this field. Recently, Large Language Models (LLMs) pre-trained on extensive corpora have demonstrated superior performance across various NLP tasks due to their commendable zero-shot abilities. Yet, directly applying LLMs to financial sentiment analysis presents challenges: The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs' sentiment analysis. To address these challenges, we introduce a retrieval-augmented LLMs framework for financial sentiment analysis. This framework includes an instruction-tuned LLMs module, which ensures LLMs behave as predictors of sentiment labels, and a retrieval-augmentation module which retrieves additional context from reliable external sources. Benchmarked against traditional models and LLMs like ChatGPT and LLaMA, our approach achieves 15\% to 48\% performance gain in accuracy and F1 score.
2023.10.09.19.46.13;09.10.2023;13;05;Industry;I4.0, Production et al.;arxiv;2310.04280;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2310.04280.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Papenkov_M/0/1/0/all/0/1"">Maksim Papenkov</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Meredith_C/0/1/0/all/0/1"">Chris Meredith</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Noel_C/0/1/0/all/0/1"">Claire Noel</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Padalkar_J/0/1/0/all/0/1"">Jai Padalkar</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Hendrickson_T/0/1/0/all/0/1"">Temple Hendrickson</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Nitiutomo_D/0/1/0/all/0/1"">Daniel Nitiutomo</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Farrell_T/0/1/0/all/0/1"">Thomas Farrell</a>";Maksim Papenkov,Chris Meredith,Claire Noel,Jai Padalkar,Temple Hendrickson,Daniel Nitiutomo,Thomas Farrell;Multi-Industry Simplex : A Probabilistic Extension of GICS.;Accurate industry classification is a critical tool for many asset management applications. While the current industry gold-standard GICS (Global Industry Classification Standard) has proven to be reliable and robust in many settings, it has limitations that cannot be ignored. Fundamentally, GICS is a single-industry model, in which every firm is assigned to exactly one group - regardless of how diversified that firm may be. This approach breaks down for large conglomerates like Amazon, which have risk exposure spread out across multiple sectors. We attempt to overcome these limitations by developing MIS (Multi-Industry Simplex), a probabilistic model that can flexibly assign a firm to as many industries as can be supported by the data. In particular, we utilize topic modeling, an natural language processing approach that utilizes business descriptions to extract and identify corresponding industries. Each identified industry comes with a relevance probability, allowing for high interpretability and easy auditing, circumventing the black-box nature of alternative machine learning approaches. We describe this model in detail and provide two use-cases that are relevant to asset management - thematic portfolios and nearest neighbor identification. While our approach has limitations of its own, we demonstrate the viability of probabilistic industry classification and hope to inspire future research in this field.
2023.10.09.19.46.14;09.10.2023;14;05;Industry;I4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0467/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Extruder Machine Gear Fault Detection Using Autoencoder LSTM via Senor Fusion Approach;In industrial settings, gears play a crucial role by assisting various machinery functions such as speed control, torque manipulation, and altering motion direction.The malfunction or failure of these gear components can have serious repercussions, resulting in production halts and financial losses. As a result, there is an increasing requirement to monitor the state of these components in order to avoid such issues from occurring. To address this need, research efforts have focused on early defect detection in gears in order to reduce the impact of possible failures. This study focused on analyzing vibration and thermal datasets from two extruder machine gearboxes using an autoencoder Long Short-Term Memory (LSTM) model. The major goal is to implement an outlier detection approach to detect and classify defects. The results of this study highlighted the extraordinary performance of the Autoencoder LSTM model, which achieved an impressive accuracy rate of 94.42% in recognizing malfunctioning gearboxes within the extruder machine system. Furthermore, the study used a thorough global metrics evaluation methodology to further test the model’s dependability and efficacy, consequently substantiating the proposed approach’s validity.
2023.10.09.19.46.15;09.10.2023;15;06;Information;Knowledge, Understanding, Information etc.;arxiv;2310.00785;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.00785.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1"">Yapei Chang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1"">Kyle Lo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Goyal_T/0/1/0/all/0/1"">Tanya Goyal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1"">Mohit Iyyer</a>";Yapei Chang,Kyle Lo,Tanya Goyal,Mohit Iyyer;BooookScore: A systematic exploration of book-length summarization in the era of LLMs.;Summarizing book-length documents (>100K tokens) that exceed the context window size of large language models (LLMs) requires first breaking the input document into smaller chunks and then prompting an LLM to merge, update, and compress chunk-level summaries. Despite the complexity and importance of this task, it has yet to be meaningfully studied due to the challenges of evaluation: existing book-length summarization datasets (e.g., BookSum) are in the pretraining data of most public LLMs, and existing evaluation methods struggle to capture errors made by modern LLM summarizers. In this paper, we present the first study of the coherence of LLM-based book-length summarizers implemented via two prompting workflows: (1) hierarchically merging chunk-level summaries, and (2) incrementally updating a running summary. We obtain 1193 fine-grained human annotations on GPT-4 generated summaries of 100 recently-published books and identify eight common types of coherence errors made by LLMs. Because human evaluation is expensive and time-consuming, we develop an automatic metric, BooookScore, that measures the proportion of sentences in a summary that do not contain any of the identified error types. BooookScore has high agreement with human annotations and allows us to systematically evaluate the impact of many other critical parameters (e.g., chunk size, base LLM) while saving $15K and 500 hours in human evaluation costs. We find that closed-source LLMs such as GPT-4 and Claude 2 produce summaries with higher BooookScore than the oft-repetitive ones generated by LLaMA 2. Incremental updating yields lower BooookScore but higher level of detail than hierarchical merging, a trade-off sometimes preferred by human annotators. We release code and annotations after blind review to spur more principled research on book-length summarization.
2023.10.09.19.46.16;09.10.2023;16;08;Customer Relation;Management, Service et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2308.11138&r=big;;Peiheng GaoNing SunXuefeng WangChen YangRi\v{c}ardas Zitikis;NLP-based detection of systematic anomalies among the narratives of consumer complaints;We develop an NLP-based procedure for detecting systematic nonmeritorious consumer complaints, simply called systematic anomalies, among complaint narratives. While classification algorithms are used to detect pronounced anomalies, in the case of smaller and frequent systematic anomalies, the algorithms may falter due to a variety of reasons, including technical ones as well as natural limitations of human analysts. Therefore, as the next step after classification, we convert the complaint narratives into quantitative data, which are then analyzed using an algorithm for detecting systematic anomalies. We illustrate the entire procedure using complaint narratives from the Consumer Complaint Database of the Consumer Financial Protection Bureau.
2023.10.09.19.46.17;09.10.2023;17;09;Human;Human Resource, Personal Assistance et al.;repec;;http://nep.repec.org/rss/nep-tid.rss.xml;http://d.repec.org/n?u=RePEc:pra:mprapa:118300&r=tid;;Oschinski, Matthias;Assessing the Impact of Artificial Intelligence on Germany's Labor Market: Insights from a ChatGPT Analysis;We assess the impact of artificial intelligence (AI) on Germany’s labour market applying the methodology on suitability for machine learning (SML) scores established by Brynjolfsson et al., (2018). However, this study introduces two innovative approaches to the conventional methodology. Instead of relying on traditional crowdsourcing platforms for obtaining ratings on automatability, this research exploits the chatbot capabilities of OpenAI's ChatGPT. Additionally, in alignment with the focus on the German labor market, the study extends the application of SML scores to the European Classification of Skills, Competences, Qualifications and Occupations (ESCO). As such, a distinctive contribution of this study lies in the assessment of ChatGPT's effectiveness in gauging the automatability of skills and competencies within the evolving landscape of AI. Furthermore, the study enhances the applicability of its findings by directly mapping SML scores to the European ESCO classification, rendering the results more pertinent for labor market analyses within the European Union. Initial findings indicate a measured impact of AI on a majority of the 13, 312 distinct ESCO skills and competencies examined. A more detailed analysis reveals that AI exhibits a more pronounced influence on tasks related to computer utilization and information processing. Activities involving decision-making, communication, research, collaboration, and specific technical proficiencies related to medical care, food preparation, construction, and precision equipment operation receive relatively lower scores. Notably, the study highlights the comparative advantage of human employees in transversal skills like creative thinking, collaboration, leadership, the application of general knowledge, attitudes, values, and specific manual and physical skills. Applying our rankings to German labour force data at the 2-digit ISCO level suggests that, in contrast to previous waves of automation, AI may also impact non-routine cognitive occupations. In fact, our results show that business and administration professionals as well as science and engineering associate professionals receive relatively higher rankings compared to teaching professionals, health associate professionals and personal service workers. Ultimately, the research underscores that the overall ramifications of AI on the labor force will be contingent upon the underlying motivations for its deployment. If the primary impetus is cost reduction, AI implementation might follow historical patterns of employment losses with limited gains in productivity. As such, public policy has an important role to play in recalibrating incentives to prioritize machine usefulness over machine intelligence.
2023.10.09.19.46.18;09.10.2023;18;09;Human;Human Resource, Personal Assistance et al.;arxiv;2310.03976;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03976.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1"">Yue Fu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Foell_S/0/1/0/all/0/1"">Sami Foell</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"">Xuhai Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hiniker_A/0/1/0/all/0/1"">Alexis Hiniker</a>";Yue Fu,Sami Foell,Xuhai Xu,Alexis Hiniker;From Text to Self: Users' Perceptions of Potential of AI on Interpersonal Communication and Self.;In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users' perceptions of these tools' ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, and finding precise language to express their thoughts, navigating linguistic and cultural barriers. However, the study also uncovers current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. Furthermore, we identified four key communication spaces delineated by communication stakes (high or low) and relationship dynamics (formal or informal) that differentially predict users' attitudes toward AIMC tools. Specifically, participants found the tool is more suitable for communicating in formal relationships than informal ones and more beneficial in high-stakes than low-stakes communication.
2023.10.09.19.46.19;09.10.2023;19;10;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2310.04367;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04367.pdf;" <a href=""http://arxiv.org/find/stat/1/au:+Sarpal_A/0/1/0/all/0/1"">Akshit Sarpal</a>, <a href=""http://arxiv.org/find/stat/1/au:+Kang_Q/0/1/0/all/0/1"">Qiwen Kang</a>, <a href=""http://arxiv.org/find/stat/1/au:+Huang_F/0/1/0/all/0/1"">Fangping Huang</a>, <a href=""http://arxiv.org/find/stat/1/au:+Song_Y/0/1/0/all/0/1"">Yang Song</a>, <a href=""http://arxiv.org/find/stat/1/au:+Wan_L/0/1/0/all/0/1"">Lijie Wan</a>";Akshit Sarpal,Qiwen Kang,Fangping Huang,Yang Song,Lijie Wan;A Marketplace Price Anomaly Detection System at Scale.;Online marketplaces execute large volume of price updates that are initiated by individual marketplace sellers each day on the platform. This price democratization comes with increasing challenges with data quality. Lack of centralized guardrails that are available for a traditional online retailer causes a higher likelihood for inaccurate prices to get published on the website, leading to poor customer experience and potential for revenue loss. We present MoatPlus (Masked Optimal Anchors using Trees, Proximity-based Labeling and Unsupervised Statistical-features), a scalable price anomaly detection framework for a growing marketplace platform. The goal is to leverage proximity and historical price trends from unsupervised statistical features to generate an upper price bound. We build an ensemble of models to detect irregularities in price-based features, exclude irregular features and use optimized weighting scheme to build a reliable price bound in real-time pricing pipeline. We observed that our approach improves precise anchor coverage by up to 46.6% in high-vulnerability item subsets
2023.10.09.19.46.20;09.10.2023;20;10;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2310.04230;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04230.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1"">Jiarui Jin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"">Xianyu Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ye_F/0/1/0/all/0/1"">Fanghua Ye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1"">Mengyue Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1"">Yue Feng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1"">Weinan Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1"">Yong Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Jun Wang</a>";Jiarui Jin,Xianyu Chen,Fanghua Ye,Mengyue Yang,Yue Feng,Weinan Zhang,Yong Yu,Jun Wang;Lending Interaction Wings to Recommender Systems with Conversational Agents.;"Recommender systems trained on offline historical user behaviors are embracing conversational techniques to online query user preference. Unlike prior conversational recommendation approaches that systemically combine conversational and recommender parts through a reinforcement learning framework, we propose CORE, a new offline-training and online-checking paradigm that bridges a COnversational agent and REcommender systems via a unified uncertainty minimization framework. It can benefit any recommendation platform in a plug-and-play style. Here, CORE treats a recommender system as an offline relevance score estimator to produce an estimated relevance score for each item; while a conversational agent is regarded as an online relevance score checker to check these estimated scores in each session. We define uncertainty as the summation of unchecked relevance scores. In this regard, the conversational agent acts to minimize uncertainty via querying either attributes or items. Based on the uncertainty minimization framework, we derive the expected certainty gain of querying each attribute and item, and develop a novel online decision tree algorithm to decide what to query at each turn. Experimental results on 8 industrial datasets show that CORE could be seamlessly employed on 9 popular recommendation approaches. We further demonstrate that our conversational agent could communicate as a human if empowered by a pre-trained large language model."
2023.10.09.19.46.21;09.10.2023;21;12;Energy;Electricity, Smart Grid et al.;repec;;http://nep.repec.org/rss/nep-eff.rss.xml;http://d.repec.org/n?u=RePEc:pra:mprapa:118326&r=eff;;ANDREI, Dalina-Maria;The energy efficiency issue in the European Union: perspectives, objectives and challenges;This paper discusses the energy issue in the European Union and the EU’s progress on energy efficiency since the Energy Efficiency related Directive of 2012 (EED): (i) The energy consumption dynamic (primary and final energy consumption), (ii) Directives and other regulations adopted by the EU’s institutions between 2012-2022, for energy consumption and efficiency targets established for both the Union, on aggregate, and for its individual member states, (iii) The National Energy and Climate Plans (NECPs) face to corresponding 2020 accomplishments and to 2030 projections, (iv) The same 2030 forecasts in the long-term context of climate neutrality to be ensured up to 2050. All these will be approached below in our argumentation. Effective energy consumption data are retrieved from Eurostat and International Energy Agency (IEA). Optimism comes up for the 2030 perspective, since the 2020 specific performances was done, partly despite the recent COVID-19 pandemic related circumstances of 2020. A list of possible responses to some questions will conclude this paper: ‘How receptive will the member states be in the future for transposing the EU's energy efficiency ambitions into their own strategies?’ and ‘Will the European policies be rigorous enough, but also flexible to achieve long-term objectives?’.
2023.10.09.19.46.22;09.10.2023;22;12;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0543/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Ensemble Machine Learning Approaches for Prediction of Türkiye's Energy Demand;Energy demand forecasting is a fundamental aspect of modern energy management. It impacts resource planning, economic stability, environmental sustainability, and energy security. This importance is making it critical for countries worldwide, particularly in cases like Türkiye, where the energy dependency ratio is notably high. The goal of this study is to propose ensemble machine learning methods such as boosting, bagging, blending, and stacking with hyperparameter tuning and k-fold cross-validation, and investigate the application of these methods for predicting Türkiye's energy demand. This study utilizes population, GDP per capita, imports and exports as input parameters based on historical data from 1979 to 2021 in Türkiye. Eleven combinations of all predictor variables were analyzed, and the best one was selected. It was observed that a very high correlation exists among population, GDP, imports, exports, and energy demand. In the first phase, the preliminary performance was investigated of 19 different machine learning algorithms using 5-fold cross-validation and measured their performance using five different metrics: MSE, RMSE, MAE, R-squared, and MAPE. Secondly, ensemble models were constructed by utilizing individual machine learning algorithms, and the performance of these ensemble models was compared with both each other and the best-performing individual machine learning algorithm. The analysis of the results revealed that placing Ridge as the meta-learner and using ET, RF and Ridge as the base learners in the stacking ensemble model produced superior results compared to the other models across performance metrics. It is anticipated that the findings of this research can be applied globally and prove valuable for energy policy planning in any country. The results obtained not only highlight the accuracy and effectiveness of our predictive model but also underscore the broader implications of this study within the framework of the United Nations' Sustainable Development Goals (SDGs).
2023.10.09.19.46.23;09.10.2023;23;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.00763;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.00763.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Pareek_P/0/1/0/all/0/1"">Parikshit Pareek</a>, <a href=""http://arxiv.org/find/cs/1/au:+Deka_D/0/1/0/all/0/1"">Deepjyoti Deka</a>, <a href=""http://arxiv.org/find/cs/1/au:+Misra_S/0/1/0/all/0/1"">Sidhant Misra</a>";Parikshit Pareek,Deepjyoti Deka,Sidhant Misra;Data-Efficient Power Flow Learning for Network Contingencies.;This work presents an efficient data-driven method to learn power flows in grids with network contingencies and to estimate corresponding probabilistic voltage envelopes (PVE). First, a network-aware Gaussian process (GP) termed Vertex-Degree Kernel (VDK-GP), developed in prior work, is used to estimate voltage-power functions for a few network configurations. The paper introduces a novel multi-task vertex degree kernel (MT-VDK) that amalgamates the learned VDK-GPs to determine power flows for unseen networks, with a significant reduction in the computational complexity and hyperparameter requirements compared to alternate approaches. Simulations on the IEEE 30-Bus network demonstrate the retention and transfer of power flow knowledge in both N-1 and N-2 contingency scenarios. The MT-VDK-GP approach achieves over 50% reduction in mean prediction error for novel N-1 contingency network configurations in low training data regimes (50-250 samples) over VDK-GP. Additionally, MT-VDK-GP outperforms a hyper-parameter based transfer learning approach in over 75% of N-2 contingency network structures, even without historical N-2 outage data. The proposed method demonstrates the ability to achieve PVEs using sixteen times fewer power flow solutions compared to Monte-Carlo sampling-based methods.
2023.10.09.19.46.24;09.10.2023;24;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.04213;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04213.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Nakiganda_A/0/1/0/all/0/1"">Agnes M. Nakiganda</a>, <a href=""http://arxiv.org/find/eess/1/au:+Cheylan_C/0/1/0/all/0/1"">Catherine Cheylan</a>, <a href=""http://arxiv.org/find/eess/1/au:+Chatzivasileiadis_S/0/1/0/all/0/1"">Spyros Chatzivasileiadis</a>";Agnes M. Nakiganda,Catherine Cheylan,Spyros Chatzivasileiadis;Topology-Aware Neural Networks for Fast Contingency Analysis of Power Systems.;Training Neural Networks able to capture the topology changes of the power grid is one of the significant challenges towards the adoption of machine learning techniques for N-k security computations and a wide range of other operations that involve grid reconfiguration. As the number of N-k scenarios increases exponentially with increasing system size, such problems are extremely time-consuming to solve with traditional solvers. In this paper, we combine Physics-Informed Neural Networks with both a Guided-Dropout (GD) (which associates dedicated neurons with specific line connections/disconnections) and an edge-varying Graph Neural Neural Network (GNN) architecture to learn the setpoints for a grid that considers all probable single-line reconfigurations (all critical N-1 scenarios) and subsequently apply the trained models to N-k scenarios. We demonstrate how incorporating the underlying physical equations for the network equations along with the GD and the GNN methods, performs with N-1, N-2, and N-3 case studies. Using the AC Power Flow as a guiding application, we test our methods on the 14-bus, 30-bus, 57-bus, and 118-bus systems, and we compare the models in terms of the accuracy and computational performance that each one achieves for each study and provide recommendations on their adoption for contingency analysis of power systems.
2023.10.09.19.46.25;09.10.2023;25;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.04239;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04239.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Moradi_Sepahvand_M/0/1/0/all/0/1"">Mojtaba Moradi-Sepahvand</a>, <a href=""http://arxiv.org/find/eess/1/au:+Tindemans_S/0/1/0/all/0/1"">Simon H. Tindemans</a>";Mojtaba Moradi-Sepahvand,Simon H. Tindemans;Representative Days and Hours with Piecewise Linear Transitions for Power System Planning.;Electric demand and renewable power are highly variable, and the solution of a planning model relies on capturing this variability. This paper proposes a hybrid multi-area method that effectively captures both the intraday and interday chronology of real data considering extreme values, using a limited number of representative days, and time points within each day. An optimization-based representative extraction method is proposed to improve intraday chronology capturing. It ensures higher precision in preserving data chronology and extreme values than hierarchical clustering methods. The proposed method is based on a piecewise linear demand and supply representation, which reduces approximation errors compared to the traditional piecewise constant formulation. Additionally, sequentially linked day blocks with identical representatives, created through a mapping process, are employed for interday chronology capturing. To evaluate the efficiency of the proposed method, a comprehensive expansion co-planning model is developed, including transmission lines, energy storage systems, and wind farms.
2023.10.09.19.46.26;09.10.2023;26;12;Energy;Electricity, Smart Grid et al.;arxiv;2310.04244;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.04244.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Moradi_Sepahvand_M/0/1/0/all/0/1"">Mojtaba Moradi-Sepahvand</a>, <a href=""http://arxiv.org/find/eess/1/au:+Tindemans_S/0/1/0/all/0/1"">Simon H. Tindemans</a>";Mojtaba Moradi-Sepahvand,Simon H. Tindemans;Capturing Chronology and Extreme Values of Representative Days for Planning of Transmission Lines and Long-Term Energy Storage Systems.;The growing penetration of renewable energy sources (RESs) is inevitable to reach net zero emissions. In this regard, optimal planning and operation of power systems are becoming more critical due to the need for modeling the short-term variability of RES output power and load demand. Considering hourly time steps of one or more years to model the operational details in a long-term expansion planning scheme can lead to a practically unsolvable model. Therefore, a clustering-based hybrid time series aggregation algorithm is proposed in this paper to capture both extreme values and temporal dynamics of input data by some extracted representatives. The proposed method is examined in a complex co-planning model for transmission lines, wind power plants (WPPs), short-term battery and long-term pumped hydroelectric energy storage systems. The effectiveness of proposed mixed-integer linear programming (MILP) model is evaluated using a modified 6-bus Garver test system. The simulation results confirm the proposed model efficacy, especially in modeling long-term energy storage systems.
2023.10.09.19.46.27;09.10.2023;27;13;Logistics;Transport Equipment, Automotive, Self Driving et al.;repec;;http://nep.repec.org/rss/nep-tre.rss.xml;http://d.repec.org/n?u=RePEc:cdl:itsrrp:qt4cw749bp&r=tre;;Dion, Francois PhDYang, MingyuanPatire, Anthony PhD;New Data and Methods for Estimating Regional Truck Movements;This report describes how current methods of estimating truck traffic volumes from existing fixed roadway sensors could be improved by using tracking data collected from commercial truck fleets and other connected technology sources (e.g., onboard GPS-enabled navigation systems and smartphones supplied by third-party vendors). Using Caltrans District 1 in Northern California as an example, the study first reviews existing fixed-location data collection capabilities and highlights gaps in the ability to monitor truck movements. It then reviews emerging data sources and analyzes the analytical capabilities of StreetLight 2021, a commercial software package. The study then looks at the Sample Trip Count and uncalibrated Index values obtained from three weigh-in-motion (WIM) and twelve Traffic Census stations operated by Caltrans in District 1. The study suggests improvements to StreetLight’s “single-factor” calibration process which limits its ability to convert raw truck count data into accurate traffic volume estimates across an area, and suggests how improved truck-related calibration data can be extracted from the truck classification counts obtained from Caltrans’ WIM and Traffic Census stations. The report compares uncalibrated StreetLight Index values to observed truck counts to assess data quality and evaluates the impacts of considering alternate calibration data sets and analysis periods. Two test cases are presented to highlight issues with the single-factor calibration process. The report concludes that probe data analytical platforms such as StreetLight can be used to obtain rough estimates of truck volumes on roadway segments or to analyze routing patterns. The results further indicate that the accuracy of volume estimates depends heavily on the availability of sufficiently large samples of tracking data and stable and representative month-by-month calibration data across multiple reference locations.
2023.10.09.19.46.28;09.10.2023;28;13;Logistics;Transport Equipment, Automotive, Self Driving et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0413/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Enhancing Urban Air Mobility Integration in Cargo Transportation through Tiltrotor Technology ;The burgeoning field of Urban Air Mobility (UAM) promises transformative solutions to urban transportation challenges, with the potential to revolutionize cargo logistics in metropolitan areas. This research investigates the role of tiltrotor technology as a pivotal enabler of seamless UAM integration for efficient cargo transportation within urban environments. The study delves into the existing challenges within UAM, such as infrastructure limitations and the need for adaptable aerial vehicles that can navigate confined spaces while maintaining payload capacity. Tiltrotor Unmanned Aerial Vehicles (UAVs) are examined as a solution to these challenges due to their unique capabilities, combining vertical takeoff and landing (VTOL) with efficient forward flight. This research evaluates the potential of tiltrotor UAVs for urban cargo transportation, focusing on their operational efficiency, safety, and economic viability. Furthermore, the study explores the potential impact of tiltrotor technology on urban cargo logistics, considering factors such as reduced congestion, shorter delivery times, and environmentally sustainable operations. Real-world case studies and practical implementation strategies are discussed, shedding light on the importance of integration of tiltrotor UAVs into existing cargo transportation networks.The findings of this research underscore the transformative potential of tiltrotor technology in enhancing UAM for cargo transportation within urban areas. The study contributes valuable insights to the ongoing discourse on UAM integration and lays the groundwork for future developments in autonomous aerial cargo delivery systems.
2023.10.09.19.46.29;09.10.2023;29;13;Logistics;Transport Equipment, Automotive, Self Driving et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0415/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Hydrogen: An Integral Player in the Future of Sustainable Transportation. A survey of Fuel Cell Vehicle Technologies, Adoption Patterns, and Challenges;The increasing global demand for energy and the pressing challenge of environmental pollution necessitates a paradigm shift towards sustainable energy sources. Hydrogen, a viable renewable energy carrier, has the potential to substantially alleviate these concerns. This review offers a comprehensive exploration of the technologies imperative to the production and operation of fuel cell vehicles (FCVs), ranging from various fuel cell types, hydrogen storage methods, fueling station logistics, batteries in hydrogen vehicles, and the emerging influence of artificial intelligence and quantum computing. An analytical overview of global adoption patterns reveals significant geographical disparities, with the United States and South Korea at the forefront of FCV integration, primarily in the form of passenger cars, followed by buses and trucks. Asia emerges as the region with the highest proportion of FCVs. This paper also delves into the diverse challenges facing FCV implementation, shedding light on the essential role of continued investment in the evolution of sustainable transportation systems. Furthermore, it provides insights into the varying contributions of different companies in the field, demonstrating the collective effort required to advance this promising technology. The comprehensive exploration provided in this review aids in understanding the opportunities, challenges, and potential of hydrogen as an integral player in the future of sustainable transportation. The increasing need for energy carriers and the rise of environmental pollution have driven the exploration of renewable energy sources, with hydrogen being a promising option.
2023.10.09.19.46.30;09.10.2023;30;14;Public Services;Public Services;repec;;http://nep.repec.org/rss/nep-tre.rss.xml;http://d.repec.org/n?u=RePEc:cdl:itsdav:qt6c60v3h7&r=tre;;Bento, Antonio MHall, Jonathan DHeilmann, Kilian;Evaluating Alternative Strategies for Traffic Reduction in Los Angeles;Traffic congestion is a major problem in large cities worldwide. This project uses high-frequency data from the Los Angeles metropolitan area combined with an instrument that varies spatially and temporally to estimate the causal impact of an additional vehicle mile traveled on travel times. Specifically, the research team exploits the network structure of the Los Angeles highway system and uses crashes on close alternative routes as exogenous shocks to traffic demand. To do so, the team relies on Google Maps to determine the ideal route and alternatives for over 19, 000 real-world commutes. The researchers estimate that at peak times an additional trip reduces speed by, on average, 0.22%. They find the optimal toll at peak times is 33 cents per mile, with the toll being lower, even zero, off-peak. The researchers show how this toll varies over space and time, as well as report on its distributional effects. This toll would more than double highway speeds during peak times and only requires reducing vehicle miles traveled (VMT) at the peak by 10%. The resulting social welfare gains are over two billion dollars per year. View the NCST Project Webpage
2023.10.07.15.17.01;07.10.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.03666;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03666.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Matentzoglu_N/0/1/0/all/0/1"">Nicolas Matentzoglu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Caufield_J/0/1/0/all/0/1"">J. Harry Caufield</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hegde_H/0/1/0/all/0/1"">Harshad B. Hegde</a>, <a href=""http://arxiv.org/find/cs/1/au:+Reese_J/0/1/0/all/0/1"">Justin T. Reese</a>, <a href=""http://arxiv.org/find/cs/1/au:+Moxon_S/0/1/0/all/0/1"">Sierra Moxon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1"">Hyeongsik Kim</a>, <a href=""http://arxiv.org/find/cs/1/au:+Harris_N/0/1/0/all/0/1"">Nomi L. Harris</a>, <a href=""http://arxiv.org/find/cs/1/au:+Haendel_M/0/1/0/all/0/1"">Melissa A Haendel</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mungall_C/0/1/0/all/0/1"">Christopher J. Mungall</a>";Nicolas Matentzoglu,J. Harry Caufield,Harshad B. Hegde,Justin T. Reese,Sierra Moxon,Hyeongsik Kim,Nomi L. Harris,Melissa A Haendel,Christopher J. Mungall;MapperGPT: Large Language Models for Linking and Mapping Entities.;Aligning terminological resources, including ontologies, controlled vocabularies, taxonomies, and value sets is a critical part of data integration in many domains such as healthcare, chemistry, and biomedical research. Entity mapping is the process of determining correspondences between entities across these resources, such as gene identifiers, disease concepts, or chemical entity identifiers. Many tools have been developed to compute such mappings based on common structural features and lexical information such as labels and synonyms. Lexical approaches in particular often provide very high recall, but low precision, due to lexical ambiguity. As a consequence of this, mapping efforts often resort to a labor intensive manual mapping refinement through a human curator. Large Language Models (LLMs), such as the ones employed by ChatGPT, have generalizable abilities to perform a wide range of tasks, including question-answering and information extraction. Here we present MapperGPT, an approach that uses LLMs to review and refine mapping relationships as a post-processing step, in concert with existing high-recall methods that are based on lexical and structural heuristics. We evaluated MapperGPT on a series of alignment tasks from different domains, including anatomy, developmental biology, and renal diseases. We devised a collection of tasks that are designed to be particularly challenging for lexical methods. We show that when used in combination with high-recall methods, MapperGPT can provide a substantial improvement in accuracy, beating state-of-the-art (SOTA) methods such as LogMap.
2023.10.07.15.17.02;07.10.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.03473;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03473.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Kurisinkel_L/0/1/0/all/0/1"">Litton J Kurisinkel</a>, <a href=""http://arxiv.org/find/cs/1/au:+chen_N/0/1/0/all/0/1"">Nancy F chen</a>";Litton J Kurisinkel,Nancy F chen;Controllable Multi-document Summarization: Coverage & Coherence Intuitive Policy with Large Language Model Based Rewards.;Memory-efficient large language models are good at refining text input for better readability. However, controllability is a matter of concern when it comes to text generation tasks with long inputs, such as multi-document summarization. In this work, we investigate for a generic controllable approach for multi-document summarization that leverages the capabilities of LLMs to refine the text. In particular, we train a controllable content extraction scheme to extract the text that will be refined by an LLM. The scheme is designed with a novel coverage and coherence intuitive policy, which is duly rewarded by a passively trained LLM. Our approach yields competitive results in the evaluation using ROUGE metrics and outperforms potential baselines in coherence, as per human evaluation.
2023.10.07.15.17.03;07.10.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.03533;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03533.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1"">Angela Fan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gokkaya_B/0/1/0/all/0/1"">Beliz Gokkaya</a>, <a href=""http://arxiv.org/find/cs/1/au:+Harman_M/0/1/0/all/0/1"">Mark Harman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lyubarskiy_M/0/1/0/all/0/1"">Mitya Lyubarskiy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1"">Shubho Sengupta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1"">Shin Yoo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"">Jie M. Zhang</a>";Angela Fan,Beliz Gokkaya,Mark Harman,Mitya Lyubarskiy,Shubho Sengupta,Shin Yoo,Jie M. Zhang;Large Language Models for Software Engineering: Survey and Open Problems.;"This paper provides a survey of the emerging area of Large Language Models (LLMs) for Software Engineering (SE). It also sets out open research challenges for the application of LLMs to technical problems faced by software engineers. LLMs' emergent properties bring novelty and creativity with applications right across the spectrum of Software Engineering activities including coding, design, requirements, repair, refactoring, performance improvement, documentation and analytics. However, these very same emergent properties also pose significant technical challenges; we need techniques that can reliably weed out incorrect solutions, such as hallucinations. Our survey reveals the pivotal role that hybrid techniques (traditional SE plus LLMs) have to play in the development and deployment of reliable, efficient and effective LLM-based SE."
2023.10.07.15.17.04;07.10.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.03560;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03560.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Imrie_F/0/1/0/all/0/1"">Fergus Imrie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rauba_P/0/1/0/all/0/1"">Paulius Rauba</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1"">Mihaela van der Schaar</a>";Fergus Imrie,Paulius Rauba,Mihaela van der Schaar;Redefining Digital Health Interfaces with Large Language Models.;Digital health tools have the potential to significantly improve the delivery of healthcare services. However, their use remains comparatively limited due, in part, to challenges surrounding usability and trust. Recently, Large Language Models (LLMs) have emerged as general-purpose models with the ability to process complex information and produce human-quality text, presenting a wealth of potential applications in healthcare. Directly applying LLMs in clinical settings is not straightforward, with LLMs susceptible to providing inconsistent or nonsensical answers. We demonstrate how LLMs can utilize external tools to provide a novel interface between clinicians and digital technologies. This enhances the utility and practical impact of digital healthcare tools and AI models while addressing current issues with using LLM in clinical settings such as hallucinations. We illustrate our approach with examples from cardiovascular disease and diabetes risk prediction, highlighting the benefit compared to traditional interfaces for digital tools.
2023.10.07.15.17.05;07.10.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.03400;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03400.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1"">Huan Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1"">Changqing Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1"">Huazhu Fu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1"">Peilin Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1"">Bingzhe Wu</a>";Huan Ma,Changqing Zhang,Huazhu Fu,Peilin Zhao,Bingzhe Wu;Adapting Large Language Models for Content Moderation: Pitfalls in Data Engineering and Supervised Fine-tuning.;Nowadays, billions of people engage in communication and express their opinions on the internet daily. Unfortunately, not all of these expressions are friendly or compliant, making content moderation an indispensable task. With the successful development of Large Language Models (LLMs) in recent years, LLM-based methods have become a feasible solution for handling tasks in various domains. However, in the field of content moderation, there is still a lack of detailed work that systematically introduces implementation details. In this paper, we introduce how to fine-tune an LLM model that can be privately deployed for content moderation. Specifically, we discuss whether incorporating reasons during the fine-tuning process would be better or if it should be treated as a classification task directly. We also explore the benefits of utilizing reasons generated by more powerful LLMs for fine-tuning privately deployed models and the impact of different processing approaches when the answers generated by the more powerful LLMs are incorrect. We report the entire research process and the key findings in this paper, hoping to provide valuable experience for researchers who are fine-tuning privately deployed models in their domain-specific research.
2023.10.07.15.17.06;07.10.2023;06;02;Energy;Electricity, Smart Grid et al.;arxiv;2310.03657;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03657.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Austnes_P/0/1/0/all/0/1"">P&#xe5;l Forr Austnes</a>, <a href=""http://arxiv.org/find/eess/1/au:+Garcia_Pareja_C/0/1/0/all/0/1"">Celia Garc&#xed;a-Pareja</a>, <a href=""http://arxiv.org/find/eess/1/au:+Nobile_F/0/1/0/all/0/1"">Fabio Nobile</a>, <a href=""http://arxiv.org/find/eess/1/au:+Paolone_M/0/1/0/all/0/1"">Mario Paolone</a>";Pål Forr Austnes,Celia García-Pareja,Fabio Nobile,Mario Paolone;Probabilistic Load Forecasting of Distribution Power Systems based on Empirical Copulas.;Accurate and reliable electricity load forecasts are becoming increasingly important as the share of intermittent resources in the system increases. Distribution System Operators (DSOs) are called to accurately forecast their production and consumption to place optimal bids in the day-ahead market. Violations of their dispatch-plan requires activation of reserve-power which has a direct cost for the DSO, and also necessitate available reserve-capacity. Forecasts must account for the volatility of weather-parameters that impacts both the production and consumption of electricity. If DSO-loads are small or lower-granularity forecasts are needed, traditional statistical methods may fail to provide reliable performance since they rely on a priori statistical distributions of the variables to forecast. In this paper we introduce a probabilistic load forecast (PLF) method based on empirical copulas. Our model is data-driven, does not need a priori assumption on parametric distribution for variables, nor the dependence structure (copula), but employs a kernel density estimate of the underlying distribution using beta kernels that have bounded support on the unit hypercube. The method naturally supports variables with widely different distributions, such as weather data (including forecasted ones) and historic electricity consumption, and produces a conditional probability distribution for every time step in the forecast, which allows inferring the quantiles of interest. The proposed non-parametric approach is highly flexible and can produce meaningful forecasts even at very low aggregated levels (e.g. neighborhoods). We present results from an open dataset and showcase the strength of the model with respect to Quantile Regression using standard probabilistic evaluation metrics.
2023.10.07.15.17.07;07.10.2023;07;06;Public Services;Public Services;arxiv;2310.03687;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03687.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ikram_Z/0/1/0/all/0/1"">Zarif Ikram</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1"">Ling Pan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1"">Dianbo Liu</a>";Zarif Ikram,Ling Pan,Dianbo Liu;Probabilistic Generative Modeling for Procedural Roundabout Generation for Developing Countries.;Due to limited resources and fast economic growth, designing optimal transportation road networks with traffic simulation and validation in a cost-effective manner is vital for developing countries, where extensive manual testing is expensive and often infeasible. Current rule-based road design generators lack diversity, a key feature for design robustness. Generative Flow Networks (GFlowNets) learn stochastic policies to sample from an unnormalized reward distribution, thus generating high-quality solutions while preserving their diversity. In this work, we formulate the problem of linking incident roads to the circular junction of a roundabout by a Markov decision process, and we leverage GFlowNets as the Junction-Art road generator. We compare our method with related methods and our empirical results show that our method achieves better diversity while preserving a high validity score.
2023.10.07.15.17.08;07.10.2023;08;07;Industry;I4.0, Production et al.;arxiv;2310.03591;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03591.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Victor_N/0/1/0/all/0/1"">Nwosu Obinnaya Chikezie Victor</a>";Nwosu Obinnaya Chikezie Victor;Impact of Artificial Intelligence on Electrical and Electronics Engineering Productivity in the Construction Industry.;Artificial intelligence (AI) can revolutionize the development industry, primarily electrical and electronics engineering. By automating recurring duties, AI can grow productivity and efficiency in creating. For instance, AI can research constructing designs, discover capability troubles, and generate answers, reducing the effort and time required for manual analysis. AI also can be used to optimize electricity consumption in buildings, which is a critical difficulty in the construction enterprise. Via machines gaining knowledge of algorithms to investigate electricity usage patterns, AI can discover areas wherein power may be stored and offer guidelines for enhancements. This can result in significant value financial savings and reduced carbon emissions. Moreover, AI may be used to improve the protection of creation websites. By studying statistics from sensors and cameras, AI can locate capacity dangers and alert workers to take suitable action. This could help save you from injuries and accidents on production sites, lowering the chance for workers and enhancing overall safety in the enterprise. The impact of AI on electric and electronics engineering productivity inside the creation industry is enormous. AI can transform how we layout, build, and function buildings by automating ordinary duties, optimising electricity intake, and enhancing safety. However, ensuring that AI is used ethically and responsibly and that the advantages are shared fairly throughout the enterprise is essential.
2023.10.07.15.17.09;07.10.2023;09;07;Industry;I4.0, Production et al.;arxiv;2310.03392;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03392.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bach_T/0/1/0/all/0/1"">Tita A. Bach</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kristiansen_J/0/1/0/all/0/1"">Jenny K. Kristiansen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Babic_A/0/1/0/all/0/1"">Aleksandar Babic</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jacovi_A/0/1/0/all/0/1"">Alon Jacovi</a>";Tita A. Bach,Jenny K. Kristiansen,Aleksandar Babic,Alon Jacovi;Unpacking Human-AI Interaction in Safety-Critical Industries: A Systematic Literature Review.;Ensuring quality human-AI interaction (HAII) in safety-critical industries is essential. Failure to do so can lead to catastrophic and deadly consequences. Despite this urgency, what little research there is on HAII is fragmented and inconsistent. We present here a survey of that literature and recommendations for research best practices that will improve the field. We divided our investigation into the following research areas: (1) terms used to describe HAII, (2) primary roles of AI-enabled systems, (3) factors that influence HAII, and (4) how HAII is measured. Additionally, we described the capabilities and maturity of the AI-enabled systems used in safety-critical industries discussed in these articles. We found that no single term is used across the literature to describe HAII and some terms have multiple meanings. According to our literature, five factors influence HAII: user characteristics and background (e.g., user personality, perceptions), AI interface and features (e.g., interactive UI design), AI output (e.g., accuracy, actionable recommendations), explainability and interpretability (e.g., level of detail, user understanding), and usage of AI (e.g., heterogeneity of environments and user needs). HAII is most commonly measured with user-related subjective metrics (e.g., user perception, trust, and attitudes), and AI-assisted decision-making is the most common primary role of AI-enabled systems. Based on this review, we conclude that there are substantial research gaps in HAII. Researchers and developers need to codify HAII terminology, involve users throughout the AI lifecycle (especially during development), and tailor HAII in safety-critical industries to the users and environments.
2023.10.07.15.17.10;07.10.2023;10;07;Industry;I4.0, Production et al.;arxiv;2310.03195;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.03195.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Khadivi_M/0/1/0/all/0/1"">Maziyar Khadivi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Charter_T/0/1/0/all/0/1"">Todd Charter</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yaghoubi_M/0/1/0/all/0/1"">Marjan Yaghoubi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jalayer_M/0/1/0/all/0/1"">Masoud Jalayer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ahang_M/0/1/0/all/0/1"">Maryam Ahang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shojaeinasab_A/0/1/0/all/0/1"">Ardeshir Shojaeinasab</a>, <a href=""http://arxiv.org/find/cs/1/au:+Najjaran_H/0/1/0/all/0/1"">Homayoun Najjaran</a>";Maziyar Khadivi,Todd Charter,Marjan Yaghoubi,Masoud Jalayer,Maryam Ahang,Ardeshir Shojaeinasab,Homayoun Najjaran;Deep reinforcement learning for machine scheduling: Methodology, the state-of-the-art, and future directions.;Machine scheduling aims to optimize job assignments to machines while adhering to manufacturing rules and job specifications. This optimization leads to reduced operational costs, improved customer demand fulfillment, and enhanced production efficiency. However, machine scheduling remains a challenging combinatorial problem due to its NP-hard nature. Deep Reinforcement Learning (DRL), a key component of artificial general intelligence, has shown promise in various domains like gaming and robotics. Researchers have explored applying DRL to machine scheduling problems since 1995. This paper offers a comprehensive review and comparison of DRL-based approaches, highlighting their methodology, applications, advantages, and limitations. It categorizes these approaches based on computational components: conventional neural networks, encoder-decoder architectures, graph neural networks, and metaheuristic algorithms. Our review concludes that DRL-based methods outperform exact solvers, heuristics, and tabular reinforcement learning algorithms in terms of computation speed and generating near-global optimal solutions. These DRL-based approaches have been successfully applied to static and dynamic scheduling across diverse machine environments and job characteristics. However, DRL-based schedulers face limitations in handling complex operational constraints, configurable multi-objective optimization, generalization, scalability, interpretability, and robustness. Addressing these challenges will be a crucial focus for future research in this field. This paper serves as a valuable resource for researchers to assess the current state of DRL-based machine scheduling and identify research gaps. It also aids experts and practitioners in selecting the appropriate DRL approach for production scheduling.
2023.10.07.15.17.11;07.10.2023;11;12;Health;Medical, Health Care, Pharmacy et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/AI_Models_for_Early_Detection_and_Mortality_Prediction_in_Cardiovascular_Diseases/24248827;;TechRxiv RSS Feed;AI Models for Early Detection and Mortality Prediction in Cardiovascular Diseases;Abstract- Cardiovascular diseases (CVDs) remain a sig- nificant global health challenge, emphasizing the critical need for accurate predictive models to address early detec- tion and intervention. This study presents a comprehensive framework for heart disease prediction using advanced ma- chine learning techniques. Background: CVDs are a leading cause of mortality worldwide, with early detection being crucial for effective treatment. Machine learning has emerged as a vital tool in healthcare due to its potential to enhance prediction accuracy. This study addresses the pressing need for accurate predictive models to combat CVDs, taking into account the existing challenges in the field. Objective: The primary objective of this research is to develop a robust prediction model for Major Adverse Cardiovascular and Cerebrovascular Events (MACCE), a key indicator in evaluating coronary heart disease surgery’s success. The study leverages machine learning, focusing on feature selection, data balancing, and ensemble learning techniques. Dataset Details: The study utilizes a real-world dataset comprising 303 samples and 13 features, derived from actual pathological data from cardiac patients. This dataset spans multiple years of return visits, providing valuable insights into the predictive capabilities of the model. Model Validations: To ensure the model’s reliability, rig- orous validation techniques, including cross-validation, were employed. The dataset was carefully partitioned into training and testing sets, with the model achieving an accuracy of 87% in logistic regression, 95% in XGBoost, 83% in decision tree, and 90% in random forest, randomized search CV random forest, and grid search XGBoost, and 91% in the ensemble model. And after making sophisticated model the user interface platform leverage the AI algorithm and shown impressive accuracy 97 percent. Fig. 2 said so. Comparison to Previous Works: This research contributes to the existing body of knowledge by proposing an innova- tive predictive model for heart disease. While comparing with previous methodologies, our approach demonstrates significant improvements in accuracy and effectiveness. Clinical Implications: The developed model holds sub- stantial promise for clinical applications, aiding healthcare practitioners in early detection and risk assessment for heart diseases. The model’s implementation in real-world clinical settings has the potential to improve patient outcomes and reduce the burden of CVDs. Limitations and Future Work: The study acknowledges potential limitations and emphasizes the need for further re-search to address these challenges. Future work may involve exploring additional techniques, expanding the dataset, and conducting clinical trials for practical deployment. Conclusion: In conclusion, this research represents a significant step forward in the field of CVD prediction. The developed model showcases impressive accuracy and holds promise for clinical use. It underscores the vital role of machine learning in addressing the global challenge of cardiovascular diseases, with potential implications for improved patient care and outcomes.
2023.10.07.15.17.12;07.10.2023;12;13;Customer Relation;Management, Service et al.;arxiv;2301.06421;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2301.06421.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1"">Pei-Yu Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tielman_M/0/1/0/all/0/1"">Myrthe L. Tielman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Heylen_D/0/1/0/all/0/1"">Dirk K.J. Heylen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1"">Catholijn M. Jonker</a>, <a href=""http://arxiv.org/find/cs/1/au:+Riemsdijk_M/0/1/0/all/0/1"">M. Birna van Riemsdijk</a>";Pei-Yu Chen,Myrthe L. Tielman,Dirk K.J. Heylen,Catholijn M. Jonker,M. Birna van Riemsdijk;AI Alignment Dialogues: An Interactive Approach to AI Alignment in Support Agents.;AI alignment is about ensuring AI systems only pursue goals and activities that are beneficial to humans. Most of the current approach to AI alignment is to learn what humans value from their behavioural data. This paper proposes a different way of looking at the notion of alignment, namely by introducing AI Alignment Dialogues: dialogues with which users and agents try to achieve and maintain alignment via interaction. We argue that alignment dialogues have a number of advantages in comparison to data-driven approaches, especially for behaviour support agents, which aim to support users in achieving their desired future behaviours rather than their current behaviours. The advantages of alignment dialogues include allowing the users to directly convey higher-level concepts to the agent, and making the agent more transparent and trustworthy. In this paper we outline the concept and high-level structure of alignment dialogues. Moreover, we conducted a qualitative focus group user study from which we developed a model that describes how alignment dialogues affect users, and created design suggestions for AI alignment dialogues. Through this we establish foundations for AI alignment dialogues and shed light on what requires further development and research.
2023.10.06.13.54.01;06.10.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.02982;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02982.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1"">Jun Ho Choi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Garrod_O/0/1/0/all/0/1"">Oliver Garrod</a>, <a href=""http://arxiv.org/find/cs/1/au:+Atherton_P/0/1/0/all/0/1"">Paul Atherton</a>, <a href=""http://arxiv.org/find/cs/1/au:+Joyce_Gibbons_A/0/1/0/all/0/1"">Andrew Joyce-Gibbons</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mason_Sesay_M/0/1/0/all/0/1"">Miriam Mason-Sesay</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bjorkegren_D/0/1/0/all/0/1"">Daniel Bj&#xf6;rkegren</a>";Jun Ho Choi,Oliver Garrod,Paul Atherton,Andrew Joyce-Gibbons,Miriam Mason-Sesay,Daniel Björkegren;Are LLMs Useful in the Poorest Schools? theTeacherAI in Sierra Leone.;Education systems in developing countries have few resources to serve large, poor populations. How might generative AI integrate into classrooms? This paper introduces an AI chatbot designed to assist teachers in Sierra Leone with professional development to improve their instruction. We describe initial findings from early implementation across 122 schools and 193 teachers, and analyze its use with qualitative observations and by analyzing queries. Teachers use the system for lesson planning, classroom management, and subject matter. A subset of teachers use the system intensively. We draw conclusions from these findings about how generative AI systems can be integrated into school systems in low income countries.
2023.10.06.13.54.02;06.10.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.02739;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02739.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Azzuni_H/0/1/0/all/0/1"">Hussam Azzuni</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jamal_S/0/1/0/all/0/1"">Sharim Jamal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Elsaddik_A/0/1/0/all/0/1"">Abdulmotaleb Elsaddik</a>";Hussam Azzuni,Sharim Jamal,Abdulmotaleb Elsaddik;uTalk: Bridging the Gap Between Humans and AI.;Large Language Models (LLMs) have revolutionized various industries by harnessing their power to improve productivity and facilitate learning across different fields. One intriguing application involves combining LLMs with visual models to create a novel approach to Human-Computer Interaction. The core idea behind this system is to develop an interactive platform that allows the general public to leverage the capabilities of ChatGPT in their daily lives. This is achieved by integrating several technologies such as Whisper, ChatGPT, Microsoft Speech Services, and the state-of-the-art (SOTA) talking head system, SadTalker, resulting in uTalk, an intelligent AI system. Users will be able to converse with this portrait, receiving answers to whatever questions they have in mind. Additionally, they could use uTalk for content generation by providing an input and their image. This system is hosted on Streamlit, where the user will initially be requested to provide an image to serve as their AI assistant. Then, users could choose whether to have a conversation or generate content based on their preferences. Either way, it starts by providing an input, where a set of operations will be done, and the avatar will provide a precise response. The paper discusses how SadTalker is optimized to improve its running time by 27.72% based on 25FPS generated videos. In addition, the system's initial performance, uTalk, improved further by 9.8% after SadTalker was integrated and parallelized with Streamlit.
2023.10.06.13.54.03;06.10.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.02759;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02759.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+S_B/0/1/0/all/0/1"">Bagiya Lakshmi S</a>, <a href=""http://arxiv.org/find/cs/1/au:+R_S/0/1/0/all/0/1"">Sanjjushri Varshini R</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mahadevan_R/0/1/0/all/0/1"">Rohith Mahadevan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Raman_R/0/1/0/all/0/1"">Raja CSP Raman</a>";Bagiya Lakshmi S,Sanjjushri Varshini R,Rohith Mahadevan,Raja CSP Raman;Comparative Study and Framework for Automated Summariser Evaluation: LangChain and Hybrid Algorithms.;Automated Essay Score (AES) is proven to be one of the cutting-edge technologies. Scoring techniques are used for various purposes. Reliable scores are calculated based on influential variables. Such variables can be computed by different methods based on the domain. The research is concentrated on the user's understanding of a given topic. The analysis is based on a scoring index by using Large Language Models. The user can then compare and contrast the understanding of a topic that they recently learned. The results are then contributed towards learning analytics and progression is made for enhancing the learning ability. In this research, the focus is on summarizing a PDF document and gauging a user's understanding of its content. The process involves utilizing a Langchain tool to summarize the PDF and extract the essential information. By employing this technique, the research aims to determine how well the user comprehends the summarized content.
2023.10.06.13.54.04;06.10.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.02655;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02655.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Perrina_F/0/1/0/all/0/1"">Filippo Perrina</a>, <a href=""http://arxiv.org/find/cs/1/au:+Marchiori_F/0/1/0/all/0/1"">Francesco Marchiori</a>, <a href=""http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1"">Mauro Conti</a>, <a href=""http://arxiv.org/find/cs/1/au:+Verde_N/0/1/0/all/0/1"">Nino Vincenzo Verde</a>";Filippo Perrina,Francesco Marchiori,Mauro Conti,Nino Vincenzo Verde;AGIR: Automating Cyber Threat Intelligence Reporting with Natural Language Generation.;Cyber Threat Intelligence (CTI) reporting is pivotal in contemporary risk management strategies. As the volume of CTI reports continues to surge, the demand for automated tools to streamline report generation becomes increasingly apparent. While Natural Language Processing techniques have shown potential in handling text data, they often struggle to address the complexity of diverse data sources and their intricate interrelationships. Moreover, established paradigms like STIX have emerged as de facto standards within the CTI community, emphasizing the formal categorization of entities and relations to facilitate consistent data sharing. In this paper, we introduce AGIR (Automatic Generation of Intelligence Reports), a transformative Natural Language Generation tool specifically designed to address the pressing challenges in the realm of CTI reporting. AGIR's primary objective is to empower security analysts by automating the labor-intensive task of generating comprehensive intelligence reports from formal representations of entity graphs. AGIR utilizes a two-stage pipeline by combining the advantages of template-based approaches and the capabilities of Large Language Models such as ChatGPT. We evaluate AGIR's report generation capabilities both quantitatively and qualitatively. The generated reports accurately convey information expressed through formal language, achieving a high recall value (0.99) without introducing hallucination. Furthermore, we compare the fluency and utility of the reports with state-of-the-art approaches, showing how AGIR achieves higher scores in terms of Syntactic Log-Odds Ratio (SLOR) and through questionnaires. By using our tool, we estimate that the report writing time is reduced by more than 40%, therefore streamlining the CTI production of any organization and contributing to the automation of several CTI tasks.
2023.10.06.13.54.05;06.10.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.02374;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02374.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Abbasian_M/0/1/0/all/0/1"">Mahyar Abbasian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Azimi_I/0/1/0/all/0/1"">Iman Azimi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rahmani_A/0/1/0/all/0/1"">Amir M. Rahmani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1"">Ramesh Jain</a>";Mahyar Abbasian,Iman Azimi,Amir M. Rahmani,Ramesh Jain;Conversational Health Agents: A Personalized LLM-Powered Agent Framework.;Conversational Health Agents (CHAs) are interactive systems designed to enhance personal healthcare services by engaging in empathetic conversations and processing multimodal data. While current CHAs, especially those utilizing Large Language Models (LLMs), primarily focus on conversation, they often lack comprehensive agent capabilities. This includes the ability to access personal user health data from wearables, 24/7 data collection sources, and electronic health records, as well as integrating the latest published health insights and connecting with established multimodal data analysis tools. We are developing a framework to empower CHAs by equipping them with critical thinking, knowledge acquisition, and problem-solving abilities. Our CHA platform, powered by LLMs, seamlessly integrates healthcare tools, enables multilingual and multimodal conversations, and interfaces with a variety of user data analysis tools. We illustrate its proficiency in handling complex healthcare tasks, such as stress level estimation, showcasing the agent's cognitive and operational capabilities.
2023.10.06.13.54.06;06.10.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;technologyreview;;;https://www.technologyreview.com/2023/10/05/1079726/driving-companywide-efficiencies-with-ai/;;;Driving companywide efficiencies with AI;Autonomous shopping carts that follow grocery store customers and robots that pick ripe cucumbers faster than humans may grab headlines, but the most compelling applications of AI and ML technology are behind the scenes. Increasingly, organizations are finding substantial efficiency gains by applying AI- and ML-powered tools to back-office procedures such as document processing, data entry, employee onboarding, and workflow automation. The power of automation to augment productivity in the back office has been clear for decades, but the recent emergence of advanced AI and ML tools offers a step change in what automation can accomplish, including in highly regulated industries such as health care. ...
2023.10.06.13.54.07;06.10.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/gpt-4-advanced-data-analysis-a-beginners-guide-to-charts-and-maps-d59763487750?source=rss----98111c9905da---4;;;GPT-4 Advanced Data Analysis: A Beginner’s Guide to Charts and Maps;With the GPT-4 Advanced Data Analysis tool (don’t be fooled by the name), novice programmers are able to generate meaningful representations in the form of charts and maps, without writing any code. This article walks you through every step needed to enable the Advanced Data Analysis tool in GPT-4 to upload a data set and display charts and maps — without having to write a single line of code. ...
2023.10.06.13.54.08;06.10.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/introducing-keyllm-keyword-extraction-with-llms-39924b504813?source=rss----7f60cf5620c9---4;;;Introducing KeyLLM — Keyword Extraction with LLMs;Large Language Models (LLMs) are becoming smaller, faster, and more efficient. Up to the point where I started to consider them for iterative tasks, like keyword extraction. Having created KeyBERT, I felt that it was time to extend the package to also include LLMs. They are quite powerful and I wanted to prepare the package for when these models can be run on smaller GPUs. As such, introducing KeyLLM, an extension to KeyBERT that allows you to use any LLM to extract, create, or even fine-tune the keywords! In this tutorial, we will go through keyword extraction with KeyLLM using the recently released Mistral 7B model. ...
2023.10.06.13.54.09;06.10.2023;09;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/retro-engineering-a-database-schema-gpt-vs-bard-vs-llama2-episode-2-e7f144a6753b?source=rss----7f60cf5620c9---4;;;Retro-Engineering a Database Schema: GPT vs. Bard vs. LLama2 (Episode 2);In my previous article, I benchmarked GPT-4 model against Bard. Now Llama-2 enters the arena and it’s high time we see how it performs against its competitors! ...
2023.10.06.13.54.10;06.10.2023;10;02;Energy;Electricity, Smart Grid et al.;arxiv;2310.02867;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2310.02867.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Barunik_J/0/1/0/all/0/1"">Jozef Barunik</a>, <a href=""http://arxiv.org/find/econ/1/au:+Hanus_L/0/1/0/all/0/1"">Lubos Hanus</a>";Jozef Barunik,Lubos Hanus;Learning Probability Distributions of Intraday Electricity Prices.;We propose a novel machine learning approach to probabilistic forecasting of hourly intraday electricity prices. In contrast to recent advances in data-rich probabilistic forecasting that approximate the distributions with some features such as moments, our method is non-parametric and selects the best distribution from all possible empirical distributions learned from the data. The model we propose is a multiple output neural network with a monotonicity adjusting penalty. Such a distributional neural network can learn complex patterns in electricity prices from data-rich environments and it outperforms state-of-the-art benchmarks.
2023.10.06.13.54.11;06.10.2023;11;02;Energy;Electricity, Smart Grid et al.;arxiv;2310.02494;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02494.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Dinh_N/0/1/0/all/0/1"">Nam Trong Dinh</a>, <a href=""http://arxiv.org/find/eess/1/au:+Karimi_Arpanahi_S/0/1/0/all/0/1"">Sahand Karimi-Arpanahi</a>, <a href=""http://arxiv.org/find/eess/1/au:+Pourmousavi_S/0/1/0/all/0/1"">S. Ali Pourmousavi</a>, <a href=""http://arxiv.org/find/eess/1/au:+Guo_M/0/1/0/all/0/1"">Mingyu Guo</a>, <a href=""http://arxiv.org/find/eess/1/au:+Lemos_Vinasco_J/0/1/0/all/0/1"">Julian Lemos-Vinasco</a>, <a href=""http://arxiv.org/find/eess/1/au:+Liisberg_J/0/1/0/all/0/1"">Jon A. R. Liisberg</a>";Nam Trong Dinh,Sahand Karimi-Arpanahi,S. Ali Pourmousavi,Mingyu Guo,Julian Lemos-Vinasco,Jon A. R. Liisberg;On the Financial Consequences of Simplified Battery Sizing Models without Considering Operational Details.;Optimal battery sizing studies tend to overly simplify the practical aspects of battery operation within the battery sizing framework. Such assumptions may lead to a suboptimal battery capacity, resulting in significant financial losses for a battery project that could last more than a decade. In this paper, we compare the most common existing sizing methods in the literature with a battery sizing model that incorporates the practical operation of a battery, that is, receding horizon operation. Consequently, we quantify the financial losses caused by the suboptimal capacities obtained by these models for a realistic case study related to community battery storage (CBS). We develop the case study by constructing a mathematical framework for the CBS and local end users. Our results show that existing sizing methods can lead to financial losses of up to 22%.
2023.10.06.13.54.12;06.10.2023;12;02;Energy;Electricity, Smart Grid et al.;arxiv;2310.02605;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02605.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sar_E/0/1/0/all/0/1"">Erica van der Sar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zocca_A/0/1/0/all/0/1"">Alessandro Zocca</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bhulai_S/0/1/0/all/0/1"">Sandjai Bhulai</a>";Erica van der Sar,Alessandro Zocca,Sandjai Bhulai;Multi-Agent Reinforcement Learning for Power Grid Topology Optimization.;Recent challenges in operating power networks arise from increasing energy demands and unpredictable renewable sources like wind and solar. While reinforcement learning (RL) shows promise in managing these networks, through topological actions like bus and line switching, efficiently handling large action spaces as networks grow is crucial. This paper presents a hierarchical multi-agent reinforcement learning (MARL) framework tailored for these expansive action spaces, leveraging the power grid's inherent hierarchical nature. Experimental results indicate the MARL framework's competitive performance with single-agent RL methods. We also compare different RL algorithms for lower-level agents alongside different policies for higher-order agents.
2023.10.06.13.54.13;06.10.2023;13;04;Finance;Finance, DeFi, Insurance, Banking et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0316/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Deep Neural Network: Predicting Future Prices of Cryptocurency Using LSTM and GRU;"Predicting the prices of cryptocurrency owing to its volatility, instability, and other factors has been challenging; investors and traders especially in Nigeria have been on a constant look for a more reliable way of knowing market trends and prices and while there has been so many research conducted using deep learning, the results for which has fall short of what investors could called a strong predictor. This research reviewed the results of many works that had been done and proposed two types of recurrent neural network (RNNs) namely Long Short-Term Memory and Gated Recurrent Unit (GRU) for predicting the future prices of two of the most common crypto assets namely Bitcoin (BTC) and Ethereum (ETH), these two were selected based on their popularity, the volume traded and their market capitalization. The experiment was conducted in a GPU Jupyter Notebook environment and the performance of our experiment was evaluated on a test set using root mean square error (RMSE) and based on its values, the LSTM presented a better performance with rsme scores of 654.66, and 80.30 respectively for BTC and ETH as compared to GRU. The paper proceeds further to compare the results of this experiment with other related works and we discovered that its performance is a great improvement."
2023.10.06.13.54.14;06.10.2023;14;06;Public Services;Public Services;arxiv;2310.02447;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02447.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1"">Wencheng Bao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1"">Shi Feng</a>";Wencheng Bao,Shi Feng;Machine learning assist nyc subway navigation safer and faster.;Mainstream navigation software, like Google and Apple Maps, often lacks the ability to provide routes prioritizing safety. However, safety remains a paramount concern for many. Our aim is to strike a balance between safety and efficiency. To achieve this, we're devising an Integer Programming model that takes into account both the shortest path and the safest route. We will harness machine learning to derive safety coefficients, employing methodologies such as generalized linear models, linear regression, and recurrent neural networks. Our evaluation will be based on the Root Mean Square Error (RMSE) across various subway stations, helping us identify the most accurate model for safety coefficient estimation. Furthermore, we'll conduct a comprehensive review of different shortest-path algorithms, assessing them based on time complexity and real-world data to determine their appropriateness in merging both safety and time efficiency.
2023.10.06.13.54.15;06.10.2023;15;06;Public Services;Public Services;arxiv;2310.02435;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02435.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bokade_R/0/1/0/all/0/1"">Rohit Bokade</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1"">Xiaoning Jin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1"">Christopher Amato</a>";Rohit Bokade,Xiaoning Jin,Christopher Amato;Multi-Agent Reinforcement Learning Based on Representational Communication for Large-Scale Traffic Signal Control.;"Traffic signal control (TSC) is a challenging problem within intelligent transportation systems and has been tackled using multi-agent reinforcement learning (MARL). While centralized approaches are often infeasible for large-scale TSC problems, decentralized approaches provide scalability but introduce new challenges, such as partial observability. Communication plays a critical role in decentralized MARL, as agents must learn to exchange information using messages to better understand the system and achieve effective coordination. Deep MARL has been used to enable inter-agent communication by learning communication protocols in a differentiable manner. However, many deep MARL communication frameworks proposed for TSC allow agents to communicate with all other agents at all times, which can add to the existing noise in the system and degrade overall performance. In this study, we propose a communication-based MARL framework for large-scale TSC. Our framework allows each agent to learn a communication policy that dictates ""which"" part of the message is sent ""to whom"". In essence, our framework enables agents to selectively choose the recipients of their messages and exchange variable length messages with them. This results in a decentralized and flexible communication mechanism in which agents can effectively use the communication channel only when necessary. We designed two networks, a synthetic $4 \times 4$ grid network and a real-world network based on the Pasubio neighborhood in Bologna. Our framework achieved the lowest network congestion compared to related methods, with agents utilizing $\sim 47-65 \%$ of the communication channel. Ablation studies further demonstrated the effectiveness of the communication policies learned within our framework."
2023.10.06.13.54.16;06.10.2023;16;07;Industry;I4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0301/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Energy Efficient Buildings in the Industry 4.0 Era: A Review;The fourth industrial revolution has resulted in the digitalization of projects and operations across all sectors. Accordingly, efforts are being made to utilize advanced technologies to improve the energy efficiency of the building sector. This study has reviewed the current application and limitations of cutting-edge technologies in this regard. An overview of the use of the Internet of Things (IoT), artificial intelligence (AI), digital twin (DT), and building information modeling (BIM) for energy efficiency of buildings has been provided. It has been found that the use of Industry 4.0 technologies, during the construction and operational phase of buildings, has a great potential to reduce energy consumption and emissions of the sector. This study may help stakeholders of the built environment to understand the role of industry 4.0 tools for energy efficiency of the sector.
2023.10.06.13.54.17;06.10.2023;17;07;Industry;I4.0, Production et al.;arxiv;2310.02812;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02812.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Farahani_M/0/1/0/all/0/1"">Mojtaba A. Farahani</a>, <a href=""http://arxiv.org/find/cs/1/au:+McCormick_M/0/1/0/all/0/1"">M. R. McCormick</a>, <a href=""http://arxiv.org/find/cs/1/au:+Harik_R/0/1/0/all/0/1"">Ramy Harik</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wuest_T/0/1/0/all/0/1"">Thorsten Wuest</a>";Mojtaba A. Farahani,M. R. McCormick,Ramy Harik,Thorsten Wuest;Time-Series Classification in Smart Manufacturing Systems: An Experimental Evaluation of State-of-the-Art Machine Learning Algorithms.;Manufacturing is gathering extensive amounts of diverse data, thanks to the growing number of sensors and rapid advances in sensing technologies. Among the various data types available in SMS settings, time-series data plays a pivotal role. Hence, TSC emerges is crucial in this domain. The objective of this study is to fill this gap by providing a rigorous experimental evaluation of the SoTA ML and DL algorithms for TSC tasks in manufacturing and industrial settings. We first explored and compiled a comprehensive list of more than 92 SoTA algorithms from both TSC and manufacturing literature. Following, we selected the 36 most representative algorithms from this list. To evaluate their performance across various manufacturing classification tasks, we curated a set of 22 manufacturing datasets, representative of different characteristics that cover diverse manufacturing problems. Subsequently, we implemented and evaluated the algorithms on the manufacturing benchmark datasets, and analyzed the results for each dataset. Based on the results, ResNet, DrCIF, InceptionTime, and ARSENAL are the top-performing algorithms, boasting an average accuracy of over 96.6% across all 22 manufacturing TSC datasets. These findings underscore the robustness, efficiency, scalability, and effectiveness of convolutional kernels in capturing temporal features in time-series data, as three out of the top four performing algorithms leverage these kernels for feature extraction. Additionally, LSTM, BiLSTM, and TS-LSTM algorithms deserve recognition for their effectiveness in capturing features within time-series data using RNN-based structures.
2023.10.06.13.54.18;06.10.2023;18;07;Industry;I4.0, Production et al.;arxiv;2310.02821;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02821.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1"">Dong Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pan_K/0/1/0/all/0/1"">Kaihang Pan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1"">Guoming Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1"">Yueting Zhuang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1"">Siliang Tang</a>";Dong Chen,Kaihang Pan,Guoming Wang,Yueting Zhuang,Siliang Tang;Improving Vision Anomaly Detection with the Guidance of Language Modality.;Recent years have seen a surge of interest in anomaly detection for tackling industrial defect detection, event detection, etc. However, existing unsupervised anomaly detectors, particularly those for the vision modality, face significant challenges due to redundant information and sparse latent space. Conversely, the language modality performs well due to its relatively single data. This paper tackles the aforementioned challenges for vision modality from a multimodal point of view. Specifically, we propose Cross-modal Guidance (CMG), which consists of Cross-modal Entropy Reduction (CMER) and Cross-modal Linear Embedding (CMLE), to tackle the redundant information issue and sparse space issue, respectively. CMER masks parts of the raw image and computes the matching score with the text. Then, CMER discards irrelevant pixels to make the detector focus on critical contents. To learn a more compact latent space for the vision anomaly detector, CMLE learns a correlation structure matrix from the language modality, and then the latent space of vision modality will be learned with the guidance of the matrix. Thereafter, the vision latent space will get semantically similar images closer. Extensive experiments demonstrate the effectiveness of the proposed methods. Particularly, CMG outperforms the baseline that only uses images by 16.81%. Ablation experiments further confirm the synergy among the proposed methods, as each component depends on the other to achieve optimal performance.
2023.10.06.13.54.19;06.10.2023;19;07;Industry;I4.0, Production et al.;arxiv;2310.02379;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02379.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+John_J/0/1/0/all/0/1"">Jobish John</a>, <a href=""http://arxiv.org/find/cs/1/au:+Noor_A_Rahim_M/0/1/0/all/0/1"">Md. Noor-A-Rahim</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vijayan_A/0/1/0/all/0/1"">Aswathi Vijayan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1"">H. Vincent Poor</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pesch_D/0/1/0/all/0/1"">Dirk Pesch</a>";Jobish John,Md. Noor-A-Rahim,Aswathi Vijayan,H. Vincent Poor,Dirk Pesch;Industry 4.0 and Beyond: The Role of 5G, WiFi 7, and TSN in Enabling Smart Manufacturing.;This paper explores the role that 5G, WiFi-7, and Time-Sensitive Networking (TSN) can play in driving smart manufacturing as a fundamental part of the Industry 4.0 vision. The paper provides an in-depth analysis of each technology's application in industrial communications, with a focus on TSN and its key elements that enable reliable and secure communication in industrial networks. In addition, the paper includes a comparative study of these technologies, analyzing them based on a number of industrial use-cases, supported secondary applications, industry adoption, and current market trends. The paper concludes by highlighting the challenges and future directions for the adoption of these technologies in industrial networks and emphasizes their importance in realizing the Industry 4.0 vision within the context of smart manufacturing.
2023.10.06.13.54.20;06.10.2023;20;12;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0255/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Healthcare Sustainability: Educating Clinicians through Telementoring;Climate Change is the most serious planetary emergency of our time. Carbon emissions secondary to the healthcare industry account for about ten percent of all emissions in the United States. Health professionals, therefore, need to understand how they can make a difference in their profession, by understanding the health-related impacts of climate change and the importance of healthcare sustainability. An 8-week telementoring Climate Change Healthcare Sustainability ECHO series was developed to educate healthcare professionals in these topics such as the health-related effects of climate change, healthcare sustainability, quality healthcare and carbon accounting. A total of 376 participants from throughout the US and 16 other countries- completed this 8-week series and received no-cost continuing medical education credits. The evaluation consisted of pre and post Zoom polls, weekly post-session surveys and the registration demographics. Participants were primarily physicians and public health professionals who significantly improved their knowledge and communication skills after the course as compared to starting the training.
2023.10.06.13.54.21;06.10.2023;21;12;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0246/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Impact of Telemedicine and Telediagnostics on Risk Management in Healthcare;Telemedicine has been increasingly considered an effective strategy to support patients with several diagnosis and therapies, avoiding the on-site visit and drastically reducing the risks to share infections. In the recent years, a number of different technologies have been developed and applied to clinical studies, with the aim to investigate new ways for increase the early diagnoses and monitor the clinical evolution of the most predictable diseases directly from the patients’ home. Telemedicine refers to all those technological interfaces used to remotely perform clinical procedures. Telemedicine applications could be useful in several medical fields, such as preventive medicine, home patient care, education for healthcare professionals and patients, research, public health, and health management. On the other hand, the synergy of these different technologies has a significant impact on the clinical risks analysis, particularly useful in frail patients. Although Telemedicine shows to have important advantages, undoubtedly important issues still remain. The present work aims to shed light on the main advantages and disadvantages related to of each application’s features, which may serve as a useful tool for researchers.
2023.10.06.13.54.22;06.10.2023;22;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.02874;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02874.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1"">Fan Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kreuter_D/0/1/0/all/0/1"">Daniel Kreuter</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"">Yichen Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dittmer_S/0/1/0/all/0/1"">S&#xf6;ren Dittmer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tull_S/0/1/0/all/0/1"">Samuel Tull</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shadbahr_T/0/1/0/all/0/1"">Tolou Shadbahr</a>, <a href=""http://arxiv.org/find/cs/1/au:+Collaboration_BloodCounts%21/0/1/0/all/0/1"">BloodCounts! Collaboration</a>, <a href=""http://arxiv.org/find/cs/1/au:+Preller_J/0/1/0/all/0/1"">Jacobus Preller</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rudd_J/0/1/0/all/0/1"">James H.F. Rudd</a>, <a href=""http://arxiv.org/find/cs/1/au:+Aston_J/0/1/0/all/0/1"">John A.D. Aston</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1"">Carola-Bibiane Sch&#xf6;nlieb</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gleadall_N/0/1/0/all/0/1"">Nicholas Gleadall</a>, <a href=""http://arxiv.org/find/cs/1/au:+Roberts_M/0/1/0/all/0/1"">Michael Roberts</a>";Fan Zhang,Daniel Kreuter,Yichen Chen,Sören Dittmer,Samuel Tull,Tolou Shadbahr,BloodCounts! Collaboration,Jacobus Preller,James H.F. Rudd,John A.D. Aston,Carola-Bibiane Schönlieb,Nicholas Gleadall,Michael Roberts;Recent Methodological Advances in Federated Learning for Healthcare.;For healthcare datasets, it is often not possible to combine data samples from multiple sites due to ethical, privacy or logistical concerns. Federated learning allows for the utilisation of powerful machine learning algorithms without requiring the pooling of data. Healthcare data has many simultaneous challenges which require new methodologies to address, such as highly-siloed data, class imbalance, missing data, distribution shifts and non-standardised variables. Federated learning adds significant methodological complexity to conventional centralised machine learning, requiring distributed optimisation, communication between nodes, aggregation of models and redistribution of models. In this systematic review, we consider all papers on Scopus that were published between January 2015 and February 2023 and which describe new federated learning methodologies for addressing challenges with healthcare data. We performed a detailed review of the 89 papers which fulfilled these criteria. Significant systemic issues were identified throughout the literature which compromise the methodologies in many of the papers reviewed. We give detailed recommendations to help improve the quality of the methodology development for federated learning in healthcare.
2023.10.06.13.54.23;06.10.2023;23;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.02778;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02778.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1"">Rui Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Marrese_Taylor_E/0/1/0/all/0/1"">Edison Marrese-Taylor</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ke_Y/0/1/0/all/0/1"">Yuhe Ke</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1"">Lechao Cheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1"">Qingyu Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1"">Irene Li</a>";Rui Yang,Edison Marrese-Taylor,Yuhe Ke,Lechao Cheng,Qingyu Chen,Irene Li;A UMLS-Augmented Framework for Improving Factuality in Large Language Models within Healthcare.;Large language models (LLMs) have demonstrated powerful text generation capabilities, bringing unprecedented innovation to the healthcare field. While LLMs hold immense promise for applications in healthcare, applying them to real clinical scenarios presents significant challenges, as these models may generate content that deviates from established medical facts and even exhibit potential biases. In our research, we develop an augmented LLM framework based on the Unified Medical Language System (UMLS), aiming to better serve the healthcare community. We employ LLaMa2-13b-chat and ChatGPT-3.5 as our benchmark models, and conduct automatic evaluations using the ROUGE Score and BERTScore on 104 questions from the LiveQA test set. Additionally, we establish criteria for physician-evaluation based on four dimensions: Factuality, Completeness, Readability and Relevancy. ChatGPT-3.5 is used for physician evaluation with 20 questions on the LiveQA test set. Multiple resident physicians conducted blind reviews to evaluate the generated content, and the results indicate that this framework effectively enhances the factuality, completeness, and relevance of generated content. Our research demonstrates the effectiveness of using UMLS-augmented LLMs and highlights the potential application value of LLMs in in medical question-answering.
2023.10.05.13.38.01;05.10.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;towardsdatascience;;;https://towardsdatascience.com/coin-counting-using-lang-sam-b469827808a7?source=rss----7f60cf5620c9---4;;;Coin Counting using Lang-SAM;In the latest developments of computer vision, image segmentation has seen impressive progress. A standout example is the “Segment Anything”Model (SAM), a dynamic deep-learning tool that predicts object masks from images using input prompts. Thanks to its advanced encoding and decoding capabilities, SAM can manage diverse segmentation challenges, proving invaluable for both researchers and developers. Lang-SAM is a project built on SAM. It extracts the masks of all instances of the objects within the image we want with a text prompt. It intelligently incorporates textual descriptions, bridging the gap between natural language processing and computer vision. This fusion allows for more context-aware, precise, and detailed segmentations, expanding the scope of intricate imaging challenges beyond traditional capabilities. ...
2023.10.05.13.38.02;05.10.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.00710;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.00710.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Ying Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1"">Wenjia Song</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1"">Zhengjie Ji</a>, <a href=""http://arxiv.org/find/cs/1/au:+Danfeng/0/1/0/all/0/1"">Danfeng</a> (Daphne)Yao, <a href=""http://arxiv.org/find/cs/1/au:+Meng_N/0/1/0/all/0/1"">Na Meng</a>";Ying Zhang,Wenjia Song,Zhengjie Ji,Danfeng;How well does LLM generate security tests?.;"Developers often build software on top of third-party libraries (Libs) to improve programmer productivity and software quality. The libraries may contain vulnerabilities exploitable by hackers to attack the applications (Apps) built on top of them. People refer to such attacks as supply chain attacks, the documented number of which has increased 742% in 2022. People created tools to mitigate such attacks, by scanning the library dependencies of Apps, identifying the usage of vulnerable library versions, and suggesting secure alternatives to vulnerable dependencies. However, recent studies show that many developers do not trust the reports by these tools; they ask for code or evidence to demonstrate how library vulnerabilities lead to security exploits, in order to assess vulnerability severity and modification necessity. Unfortunately, manually crafting demos of application-specific attacks is challenging and time-consuming, and there is insufficient tool support to automate that procedure. In this study, we used ChatGPT-4.0 to generate security tests, and to demonstrate how vulnerable library dependencies facilitate the supply chain attacks to given Apps. We explored various prompt styles/templates, and found that ChatGPT-4.0 generated tests for all 55 Apps, demonstrating 24 attacks successfully. It outperformed two state-of-the-art security test generators -- TRANSFER and SIEGE -- by generating a lot more tests and achieving more exploits. ChatGPT-4.0 worked better when prompts described more on the vulnerabilities, possible exploits, and code context. Our research will shed light on new research in security test generation. The generated tests will help developers create secure by design and secure by default software."
2023.10.05.13.38.03;05.10.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.02003;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.02003.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Holt_S/0/1/0/all/0/1"">Samuel Holt</a>, <a href=""http://arxiv.org/find/cs/1/au:+Luyten_M/0/1/0/all/0/1"">Max Ruiz Luyten</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1"">Mihaela van der Schaar</a>";Samuel Holt,Max Ruiz Luyten,Mihaela van der Schaar;L2MAC: Large Language Model Automatic Computer for Unbounded Code Generation.;Transformer-based large language models (LLMs) are constrained by the fixed context window of the underlying transformer architecture, hindering their ability to produce long and logically consistent code. Memory-augmented LLMs are a promising solution, but current approaches cannot handle long code generation tasks since they (1) only focus on reading memory and reduce its evolution to the concatenation of new memories or (2) use very specialized memories that cannot adapt to other domains. This paper presents L2MAC, the first practical LLM-based stored-program automatic computer for long and consistent code generation. Its memory has two components: the instruction registry, which is populated with a prompt program to solve the user-given task, and a file store, which will contain the final and intermediate outputs. Each instruction is executed by a separate LLM instance, whose context is managed by a control unit capable of precise memory reading and writing to ensure effective interaction with the file store. These components enable L2MAC to generate virtually unbounded code structures, bypassing the constraints of the finite context window while producing code that fulfills complex user-specified requirements. We empirically show that L2MAC succeeds in generating large code bases for system design tasks where other coding methods fall short in implementing user requirements and provide insight into the reasons for this performance gap.
2023.10.05.13.38.04;05.10.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.01728;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.01728.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1"">Ming Jin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Shiyu Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1"">Lintao Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1"">Zhixuan Chu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"">James Y. Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1"">Xiaoming Shi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1"">Pin-Yu Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1"">Yuxuan Liang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"">Yuan-Fang Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1"">Shirui Pan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1"">Qingsong Wen</a>";Ming Jin,Shiyu Wang,Lintao Ma,Zhixuan Chu,James Y. Zhang,Xiaoming Shi,Pin-Yu Chen,Yuxuan Liang,Yuan-Fang Li,Shirui Pan,Qingsong Wen;Time-LLM: Time Series Forecasting by Reprogramming Large Language Models.;Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process (NLP) and computer vision (CV), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in NLP and CV, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-LLM, a reprogramming framework to repurpose LLMs for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen LLM to align the two modalities. To augment the LLM's ability to reason with time series data, we propose Prompt-as-Prefix (PaP), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the LLM are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-LLM is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-LLM excels in both few-shot and zero-shot learning scenarios.
2023.10.05.13.38.05;05.10.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.01796;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.01796.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1"">Zhihan Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"">Jinyang Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"">Zhuangbin Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"">Yichen Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1"">Junjie Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1"">Yintong Huo</a>, <a href=""http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1"">Pinjia He</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1"">Jiazhen Gu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1"">Michael R. Lyu</a>";Zhihan Jiang,Jinyang Liu,Zhuangbin Chen,Yichen Li,Junjie Huang,Yintong Huo,Pinjia He,Jiazhen Gu,Michael R. Lyu;LLMParser: A LLM-based Log Parsing Framework.;The process of log parsing, which converts log messages into structured formats, is a crucial step for various log analysis tasks. Although numerous log parsers have been proposed, their effectiveness on complex log data is often hindered due to reliance on human-made rules or learning-based models with limited training data. The recent rise of powerful large language models (LLMs) shows potential for log parsing due to their extensive pre-trained knowledge related to code and logging. However, their accuracy is currently limited due to the lack of specialized log parsing capabilities. Additionally, the inconsistency of their answers and significant overhead obstruct the practical implementation of LLM-based log parsing. To tackle these challenges, we introduce LLMParser, the first practical LLM-based log parsing framework. LLMParser enables accurate and robust log parsing by leveraging the in-context learning (ICL) capability of the LLM, employing a hierarchical candidate sampling algorithm, and selecting high-quality demonstrations. LLMParser also includes a novel adaptive parsing cache component to store and refine the templates generated by the LLM. This design aids in addressing the inefficiency of LLMs by rapid matching to previously parsed log templates. LLMParser also adaptively updates the templates in the parsing cache to ensure consistent parsed results. Extensive evaluation on large-scale public datasets demonstrates that LLMParser surpasses the state-of-the-art methods. Furthermore, LLMParser significantly reduces the query times to LLMs, achieving efficiency comparable to the most efficient baseline, Drain.
2023.10.05.13.38.06;05.10.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.01429;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.01429.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Unlu_E/0/1/0/all/0/1"">Eren Unlu</a>";Eren Unlu;Chatmap : Large Language Model Interaction with Cartographic Data.;The swift advancement and widespread availability of foundational Large Language Models (LLMs), complemented by robust fine-tuning methodologies, have catalyzed their adaptation for innovative and industrious applications. Enabling LLMs to recognize and interpret geospatial data, while offering a linguistic access to vast cartographic datasets, is of significant importance. OpenStreetMap (OSM) is the most ambitious open-source global initiative offering detailed urban and rural geographic data, curated by a community of over 10 million contributors, which constitutes a great potential for LLM applications. In this study, we demonstrate the proof of concept and details of the process of fine-tuning a relatively small scale (1B parameters) LLM with a relatively small artificial dataset curated by a more capable teacher model, in order to provide a linguistic interface to the OSM data of an arbitrary urban region. Through this interface, users can inquire about a location's attributes, covering a wide spectrum of concepts, such as its touristic appeal or the potential profitability of various businesses in that vicinity. The study aims to provide an initial guideline for such generative artificial intelligence (AI) adaptations and demonstrate early signs of useful emerging abilities in this context even in minimal computational settings. The embeddings of artificially curated prompts including OSM data are also investigated in detail, which might be instrumental for potential geospatially aware urban Retrieval Augmented Generation (RAG) applications.
2023.10.05.13.38.07;05.10.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;wired;;;https://www.wired.com/story/generative-ai-chatgpt-is-coming-for-sales-jobs/;;;Generative AI Is Coming for Sales Execs’ Jobs—and They’re Celebrating;ChatGPT-style AI can tackle the drudge work of responding to RFPs faster than humans. Sales teams at Google, Twilio, and others say productivity is spiking. ...
2023.10.05.13.38.08;05.10.2023;08;02;Energy;Electricity, Smart Grid et al.;arxiv;2310.01661;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.01661.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Charbonnier_F/0/1/0/all/0/1"">Flora Charbonnier</a>, <a href=""http://arxiv.org/find/eess/1/au:+Morstyn_T/0/1/0/all/0/1"">Thomas Morstyn</a>, <a href=""http://arxiv.org/find/eess/1/au:+McCulloch_M/0/1/0/all/0/1"">Malcolm McCulloch</a>";Flora Charbonnier,Thomas Morstyn,Malcolm McCulloch;Home Electricity Data Generator (HEDGE): An open-access tool for the generation of electric vehicle, residential demand, and PV generation profiles.;In this paper, we present the Home Electricity Data Generator (HEDGE), an open-access tool for the random generation of realistic residential energy data. HEDGE generates realistic daily profiles of residential PV generation, household electric loads, and electric vehicle consumption and at-home availability, based on real-life UK datasets. The lack of usable data is a major hurdle for research on residential distributed energy resources characterisation and coordination, especially when using data-driven methods such as machine learning-based forecasting and reinforcement learning-based control. A key issue is that while large data banks are available, they are not in a usable format, and numerous subsequent days of data for a given single home are unavailable. We fill these gaps with the open-access HEDGE tool which generates data sequences of energy data for several days in a way that is consistent for single homes, both in terms of profile magnitude and behavioural clusters. From raw datasets, pre-processing steps are conducted, including filling in incomplete data sequences and clustering profiles into behaviour clusters. Generative adversarial networks (GANs) are then trained to generate realistic synthetic data representative of each behaviour groups consistent with real-life behavioural and physical patterns.
2023.10.05.13.38.09;05.10.2023;09;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2310.01519;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.01519.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1"">Guangyao Shi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shek_C/0/1/0/all/0/1"">Chak Lam Shek</a>, <a href=""http://arxiv.org/find/cs/1/au:+Karapetyan_N/0/1/0/all/0/1"">Nare Karapetyan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tokekar_P/0/1/0/all/0/1"">Pratap Tokekar</a>";Guangyao Shi,Chak Lam Shek,Nare Karapetyan,Pratap Tokekar;Decision-Oriented Intervention Cost Prediction for Multi-robot Persistent Monitoring.;In this paper, we present a differentiable, decision-oriented learning technique for a class of vehicle routing problems. Specifically, we consider a scenario where a team of Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) are persistently monitoring an environment. The UGVs are occasionally taken over by humans to take detours to recharge the depleted UAVs. The goal is to select routes for the UGVs so that they can efficiently monitor the environment while reducing the cost of interventions. The former is modeled as a monotone, submodular function whereas the latter is a linear function of the routes of the UGVs. We consider a scenario where the former is known but the latter depends on the context (e.g., wind and terrain conditions) that must be learned. Typically, we first learn to predict the cost function and then solve the optimization problem. However, the loss function used in prediction may be misaligned with our final goal of finding good routes. We propose a \emph{decision-oriented learning} framework that incorporates task optimization as a differentiable layer in the prediction phase. To make the task optimization (which is a non-monotone submodular function) differentiable, we propose the Differentiable Cost Scaled Greedy algorithm. We demonstrate the efficacy of the proposed framework through numerical simulations. The results show that the proposed framework can result in better performance than the traditional approach.
2023.10.05.13.38.10;05.10.2023;10;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2310.01900;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.01900.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Naeem_N/0/1/0/all/0/1"">Nabih Naeem</a>, <a href=""http://arxiv.org/find/eess/1/au:+Ratei_P/0/1/0/all/0/1"">Patrick Ratei</a>, <a href=""http://arxiv.org/find/eess/1/au:+Prakasha_P/0/1/0/all/0/1"">Prajwal Shiva Prakasha</a>, <a href=""http://arxiv.org/find/eess/1/au:+Asmer_L/0/1/0/all/0/1"">Lukas Asmer</a>, <a href=""http://arxiv.org/find/eess/1/au:+Jaksche_R/0/1/0/all/0/1"">Roman Jaksche</a>, <a href=""http://arxiv.org/find/eess/1/au:+Pak_H/0/1/0/all/0/1"">Henry Pak</a>, <a href=""http://arxiv.org/find/eess/1/au:+Schweiger_K/0/1/0/all/0/1"">Karolin Schweiger</a>, <a href=""http://arxiv.org/find/eess/1/au:+Velieva_A/0/1/0/all/0/1"">Asija Velieva</a>, <a href=""http://arxiv.org/find/eess/1/au:+Naser_F/0/1/0/all/0/1"">Fares Naser</a>, <a href=""http://arxiv.org/find/eess/1/au:+Swaid_M/0/1/0/all/0/1"">Majed Swaid</a>, <a href=""http://arxiv.org/find/eess/1/au:+Pertz_J/0/1/0/all/0/1"">Jan Pertz</a>, <a href=""http://arxiv.org/find/eess/1/au:+Niklass_M/0/1/0/all/0/1"">Malte Niklass</a>";Nabih Naeem,Patrick Ratei,Prajwal Shiva Prakasha,Lukas Asmer,Roman Jaksche,Henry Pak,Karolin Schweiger,Asija Velieva,Fares Naser,Majed Swaid,Jan Pertz,Malte Niklass;A Collaborative System of Systems Simulation of Urban Air Mobility.;The implementation of Urban Air Mobility represents a complex challenge in aviation due to the high degree of innovation required across various domains to realize it. From the use of advanced aircraft powered by novel technologies, the management of the air space to enable high density operations, to the operation of vertidromes serving as a start and end point of the flights, Urban Air Mobility paradigm necessitates significant innovation in many aspects of civil aviation as we know it today. In order to understand and assess the many facets of this new paradigm, a Collaborative Agent-Based Simulation is developed to holistically evaluate the System of Systems through the modeling of the stakeholders and their interactions as per the envisioned Concept of Operations. To this end, models of vertidrome air-side operations, unmanned/manned air space management, demand estimation and passenger mode choice, vehicle operator cost and revenues, vehicle design, and fleet management are brought together into a System of Systems Simulation of Urban Air Mobility. Through collaboration, higher fidelity models of each domain can be integrated into a single environment achieving fidelity levels not easily achievable otherwise. Furthermore, the integration enables the capture of cross-domain effects and allows domain-specific studies to be evaluated at a holistic level. This work demonstrates the Collaborative Simulation and the process of building it through the integration of several geographically distributed tools into an Agent-Based Simulation without the need for sharing code.
2023.10.05.13.38.11;05.10.2023;11;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2310.01957;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.01957.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1"">Long Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sinavski_O/0/1/0/all/0/1"">Oleg Sinavski</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hunermann_J/0/1/0/all/0/1"">Jan H&#xfc;nermann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Karnsund_A/0/1/0/all/0/1"">Alice Karnsund</a>, <a href=""http://arxiv.org/find/cs/1/au:+Willmott_A/0/1/0/all/0/1"">Andrew James Willmott</a>, <a href=""http://arxiv.org/find/cs/1/au:+Birch_D/0/1/0/all/0/1"">Danny Birch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Maund_D/0/1/0/all/0/1"">Daniel Maund</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shotton_J/0/1/0/all/0/1"">Jamie Shotton</a>";Long Chen,Oleg Sinavski,Jan Hünermann,Alice Karnsund,Andrew James Willmott,Danny Birch,Daniel Maund,Jamie Shotton;Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving.;Large Language Models (LLMs) have shown promise in the autonomous driving sector, particularly in generalization and interpretability. We introduce a unique object-level multimodal LLM architecture that merges vectorized numeric modalities with a pre-trained LLM to improve context understanding in driving situations. We also present a new dataset of 160k QA pairs derived from 10k driving scenarios, paired with high quality control commands collected with RL agent and question answer pairs generated by teacher LLM (GPT-3.5). A distinct pretraining strategy is devised to align numeric vector modalities with static LLM representations using vector captioning language data. We also introduce an evaluation metric for Driving QA and demonstrate our LLM-driver's proficiency in interpreting driving scenarios, answering questions, and decision-making. Our findings highlight the potential of LLM-based driving action generation in comparison to traditional behavioral cloning. We make our benchmark, datasets, and model available for further exploration.
2023.10.05.13.38.12;05.10.2023;12;12;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0276/v1;;Preprints.org - The Multidisciplinary Preprint Platform;The Role of ChatGPT in the  Advancement of Diagnosis, Management, and Prognosis of Cardiovascular and Cerebrovascular Disease;Cardiovascular and cerebrovascular disease incidence has risen mainly due to poor control of preventable risk factors and still constitutes a significant financial and health burden worldwide. ChatGPT is an artificial intelligence language-based model developed by OpenAI. Due to the model’s unique cognitive capabilities beyond data processing and the production of high-quality text, there has been a surge of research interest concerning its role in the scientific community and contemporary clinical practice. To fully exploit ChatGPT's potential benefits and reduce its possi-ble misuse, extreme caution must be taken to ensure its implications ethically and equitably. In this article, we explore the language model's possible applications and limitations while empha-sizing its potential value for diagnosing, managing, and prognosis cardiovascular and cerebro-vascular disease.
2023.10.05.13.38.13;05.10.2023;13;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2310.01733;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.01733.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Siu_V/0/1/0/all/0/1"">Vince S. Siu</a>, <a href=""http://arxiv.org/find/eess/1/au:+Hsieh_K/0/1/0/all/0/1"">Kuan Yu Hsieh</a>, <a href=""http://arxiv.org/find/eess/1/au:+Buleje_I/0/1/0/all/0/1"">Italo Buleje</a>, <a href=""http://arxiv.org/find/eess/1/au:+Itoh_T/0/1/0/all/0/1"">Takashi Itoh</a>, <a href=""http://arxiv.org/find/eess/1/au:+Hao_T/0/1/0/all/0/1"">Tian Hao</a>, <a href=""http://arxiv.org/find/eess/1/au:+Civjan_B/0/1/0/all/0/1"">Ben Civjan</a>, <a href=""http://arxiv.org/find/eess/1/au:+Hinds_N/0/1/0/all/0/1"">Nigel Hinds</a>, <a href=""http://arxiv.org/find/eess/1/au:+Dang_B/0/1/0/all/0/1"">Bing Dang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Rogers_J/0/1/0/all/0/1"">Jeffrey L. Rogers</a>, <a href=""http://arxiv.org/find/eess/1/au:+Wen_B/0/1/0/all/0/1"">Bo Wen</a>";Vince S. Siu,Kuan Yu Hsieh,Italo Buleje,Takashi Itoh,Tian Hao,Ben Civjan,Nigel Hinds,Bing Dang,Jeffrey L. Rogers,Bo Wen;Health Guardian: Using Multi-modal Data to Understand Individual Health.;Artificial intelligence (AI) has shown great promise in revolutionizing the field of digital health by improving disease diagnosis, treatment, and prevention. This paper describes the Health Guardian platform, a non-commercial, scientific research-based platform developed by the IBM Digital Health team to rapidly translate AI research into cloud-based microservices. The platform can collect health-related data from various digital devices, including wearables and mobile applications. Its flexible architecture supports microservices that accept diverse data types such as text, audio, and video, expanding the range of digital health assessments and enabling holistic health evaluations by capturing voice, facial, and motion bio-signals. These microservices can be deployed to a clinical cohort specified through the Clinical Task Manager (CTM). The CTM then collects multi-modal, clinical data that can iteratively improve the accuracy of AI predictive models, discover new disease mechanisms, or identify novel biomarkers. This paper highlights three microservices with different input data types, including a text-based microservice for depression assessment, a video-based microservice for sit-to-stand mobility assessment, and a wearable-based microservice for functional mobility assessment. The CTM is also discussed as a tool to help design and set up clinical studies to unlock the full potential of the platform. Today, the Health Guardian platform is being leveraged in collaboration with research partners to optimize the development of AI models by utilizing a multitude of input sources. This approach streamlines research efforts, enhances efficiency, and facilitates the development and validation of digital health applications.
2023.10.05.13.38.14;05.10.2023;14;20;Information;Knowledge, Understanding, Information etc.;towardsdatascience;;;https://towardsdatascience.com/topic-modelling-using-chatgpt-api-8775b0891d16?source=rss----7f60cf5620c9---4;;;Topic Modelling using ChatGPT API;Comprehensive guide to ChatGPT API for newbies. ...
2023.10.05.13.38.15;05.10.2023;15;20;Information;Knowledge, Understanding, Information etc.;towardsdatascience;;;https://towardsdatascience.com/textual-novelty-detection-ce81d2e689bf?source=rss----7f60cf5620c9---4;;;Textual Novelty Detection;Novelty detection refers to the task of identifying new or unknown data that differs from previously seen data. It is an unsupervised learning technique used to detect anomalies, outliers, or new patterns in data. The key idea is to build a model of “normal” data, and then use that model to identify data points that deviate from normal. ...
2023.10.05.13.38.16;05.10.2023;16;99;Other;Others;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0247/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Scents of AI: Harnessing Graph Neural Networks to Craft Fragrances Based on Consumer Feedback;"In this research, we present a comprehensive methodology to categorize perfumes based on their fragrance profiles and subsequently aid in creating innovative odoriferous molecules using advanced neural networks. Drawing from data on Parfumo and the Good Scents Company webpage (Parfumo, 2008; The Good Scents Company, 2021), the study employs sophisticated web scraping techniques to gather diverse perfume attributes. Following this, a k-means algorithm is applied for perfume clustering, paving the way for recommending similar scents to consumers. The process then bridges customer preferences to molecular design by incorporating their feedback into generating new molecules via graph neural networks (GNNs). Through converting the Simple Molecular Input Line Entry System (SMILES) representation into graph structures, the GNN facilitates the creation of new molecular designs attuned to consumer desires. The proposed approach offers promising avenues for consumers to pinpoint similar perfume choices, incorporating feedback, and for manufacturers to conceptualize new fragrant molecules with a high likelihood of market resonance."
2023.10.04.17.32.01;04.10.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2307.12856;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.12856.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Gur_I/0/1/0/all/0/1"">Izzeddin Gur</a>, <a href=""http://arxiv.org/find/cs/1/au:+Furuta_H/0/1/0/all/0/1"">Hiroki Furuta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1"">Austin Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Safdari_M/0/1/0/all/0/1"">Mustafa Safdari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Matsuo_Y/0/1/0/all/0/1"">Yutaka Matsuo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Eck_D/0/1/0/all/0/1"">Douglas Eck</a>, <a href=""http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1"">Aleksandra Faust</a>";Izzeddin Gur,Hiroki Furuta,Austin Huang,Mustafa Safdari,Yutaka Matsuo,Douglas Eck,Aleksandra Faust;A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis.;"Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web automation. However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML. We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions. WebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via Python programs generated from those. We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization. We empirically demonstrate that our modular recipe improves the success on real websites by over 50%, and that HTML-T5 is the best model to solve various HTML understanding tasks; achieving 18.7% higher success rate than the prior method on MiniWoB web automation benchmark, and SoTA performance on Mind2Web, an offline task planning evaluation."
2023.10.04.17.32.02;04.10.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2305.15090;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.15090.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1"">Mingyu Derek Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"">Xiaoxuan Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kung_P/0/1/0/all/0/1"">Po-Nien Kung</a>, <a href=""http://arxiv.org/find/cs/1/au:+Brantingham_P/0/1/0/all/0/1"">P. Jeffrey Brantingham</a>, <a href=""http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1"">Nanyun Peng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1"">Wei Wang</a>";Mingyu Derek Ma,Xiaoxuan Wang,Po-Nien Kung,P. Jeffrey Brantingham,Nanyun Peng,Wei Wang;STAR: Improving Low-Resource Information Extraction by Structure-to-Text Data Generation with Large Language Models.;Information extraction tasks such as event extraction require an in-depth understanding of the output structure and sub-task dependencies. They heavily rely on task-specific training data in the form of (passage, target structure) pairs to obtain reasonable performance. However, obtaining such data through human annotation is costly, leading to a pressing need for low-resource information extraction approaches that require minimal human labeling for real-world applications. Fine-tuning supervised models with synthesized training data would be a generalizable method, but the existing data generation methods either still rely on large-scale ground-truth data or cannot be applied to complicated IE tasks due to their poor performance. To address these challenges, we propose STAR, a data generation method that leverages Large Language Models (LLMs) to synthesize data instances given limited seed demonstrations, thereby boosting low-resource information extraction performance. Our approach involves generating target structures (Y) followed by generating passages (X), all accomplished with the aid of LLMs. We design fine-grained step-by-step instructions to obtain the initial data instances. We further reduce errors and improve data quality through self-reflection error identification and self-refinement with iterative revision. Our experiments show that the data generated by STAR significantly improves the performance of low-resource event extraction and relation extraction tasks, even surpassing the effectiveness of human-curated data. Human assessment of the data quality shows STAR-generated data exhibits higher passage quality and better align with the task definitions compared with the human-curated data.
2023.10.04.17.32.03;04.10.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2310.00166;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.00166.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Klissarov_M/0/1/0/all/0/1"">Martin Klissarov</a>, <a href=""http://arxiv.org/find/cs/1/au:+DOro_P/0/1/0/all/0/1"">Pierluca D&#x27;Oro</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sodhani_S/0/1/0/all/0/1"">Shagun Sodhani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1"">Roberta Raileanu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bacon_P/0/1/0/all/0/1"">Pierre-Luc Bacon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1"">Pascal Vincent</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1"">Amy Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Henaff_M/0/1/0/all/0/1"">Mikael Henaff</a>";Martin Klissarov,Pierluca D'Oro,Shagun Sodhani,Roberta Raileanu,Pierre-Luc Bacon,Pascal Vincent,Amy Zhang,Mikael Henaff;Motif: Intrinsic Motivation from Artificial Intelligence Feedback.;Exploring rich environments and evaluating one's actions without prior knowledge is immensely challenging. In this paper, we propose Motif, a general method to interface such prior knowledge from a Large Language Model (LLM) with an agent. Motif is based on the idea of grounding LLMs for decision-making without requiring them to interact with the environment: it elicits preferences from an LLM over pairs of captions to construct an intrinsic reward, which is then used to train agents with reinforcement learning. We evaluate Motif's performance and behavior on the challenging, open-ended and procedurally-generated NetHack game. Surprisingly, by only learning to maximize its intrinsic reward, Motif achieves a higher game score than an algorithm directly trained to maximize the score itself. When combining Motif's intrinsic reward with the environment reward, our method significantly outperforms existing approaches and makes progress on tasks where no advancements have ever been made without demonstrations. Finally, we show that Motif mostly generates intuitive human-aligned behaviors which can be steered easily through prompt modifications, while scaling well with the LLM size and the amount of information given in the prompt.
2023.10.04.17.32.04;04.10.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;;;;https://www.kdnuggets.com/leveraging-gpt-models-to-transform-natural-language-to-sql-queries;;;Leveraging GPT Models to Transform Natural Language to SQL Queries;By training GPT to query with few-shot prompting.
2023.10.04.17.32.05;04.10.2023;05;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.2079/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Energy literacy: a systematic review of scientific literature;The world is facing an energy crisis. Governments are seeking to provide universal energy access and guarantee energy security while trying to mitigate climate change. One possible solution is energy transitions towards low carbon energy systems. Among other things (physical infrastructure, public policy and regulatory enablers and knowledge and capacities) changes in the energy systems require a well informed and participative citizenship. Within this context the concept of energy literacy appears. Energy literacy is the understanding of how energy is generated, transported, stored, distributed and used, awareness about its environmental and social impacts and the knowledge to use it efficiently in the different sectors of the economy. This paper provides a systematic literature review in the Web of Science’s Core Collection. Most of the work done around energy literacy addresses its evaluation among different groups, particularly students at different levels, and the construction, application and evaluation of tools for improving energy literacy. Other frequently studied issues are the influence of energy literacy in decision making, its drivers and conceptual research about the topic. Energy enables citizens to effectively contribute to energy efficiency and sustainable development, nevertheless energy literacy is not strongly correlated to energy consumption habits.
2023.10.04.17.32.06;04.10.2023;06;02;Energy;Electricity, Smart Grid et al.;arxiv;2306.10080;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.10080.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jami_N/0/1/0/all/0/1"">Naga Venkata Sai Jitin Jami</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kardos_J/0/1/0/all/0/1"">Juraj Kardo&#x161;</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schenk_O/0/1/0/all/0/1"">Olaf Schenk</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kostler_H/0/1/0/all/0/1"">Harald K&#xf6;stler</a>";"Naga Venkata Sai Jitin Jami,Juraj Kardo&#x161;,Olaf Schenk,Harald Köstler";AI Driven Near Real-time Locational Marginal Pricing Method: A Feasibility and Robustness Study.;Accurate price predictions are essential for market participants in order to optimize their operational schedules and bidding strategies, especially in the current context where electricity prices become more volatile and less predictable using classical approaches. The Locational Marginal Pricing (LMP) pricing mechanism is used in many modern power markets, where the traditional approach utilizes optimal power flow (OPF) solvers. However, for large electricity grids this process becomes prohibitively time-consuming and computationally intensive. Machine learning (ML) based predictions could provide an efficient tool for LMP prediction, especially in energy markets with intermittent sources like renewable energy. This study evaluates the performance of popular machine learning and deep learning models in predicting LMP on multiple electricity grids. The accuracy and robustness of these models in predicting LMP is assessed considering multiple scenarios. The results show that ML models can predict LMP 4-5 orders of magnitude faster than traditional OPF solvers with 5-6\% error rate, highlighting the potential of ML models in LMP prediction for large-scale power models with the assistance of hardware infrastructure like multi-core CPUs and GPUs in modern HPC clusters.
2023.10.04.17.32.07;04.10.2023;07;02;Energy;Electricity, Smart Grid et al.;arxiv;2310.00129;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2310.00129.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shaham_S/0/1/0/all/0/1"">Sina Shaham</a>, <a href=""http://arxiv.org/find/cs/1/au:+Krishnamachari_B/0/1/0/all/0/1"">Bhaskar Krishnamachari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kahn_M/0/1/0/all/0/1"">Matthew Kahn</a>";Sina Shaham,Bhaskar Krishnamachari,Matthew Kahn;ILB: Graph Neural Network Enabled Emergency Demand Response Program For Electricity.;Demand Response (DR) programs have become a crucial component of smart electricity grids as they shift the flexibility of electricity consumption from supply to demand in response to the ever-growing demand for electricity. In particular, in times of crisis, an emergency DR program is required to manage unexpected spikes in energy demand. In this paper, we propose the Incentive-Driven Load Balancer (ILB), a program designed to efficiently manage demand and response during crisis situations. By offering incentives to flexible households likely to reduce demand, the ILB facilitates effective demand reduction and prepares them for unexpected events. To enable ILB, we introduce a two-step machine learning-based framework for participant selection, which employs a graph-based approach to identify households capable of easily adjusting their electricity consumption. This framework utilizes two Graph Neural Networks (GNNs): one for pattern recognition and another for household selection. Through extensive experiments on household-level electricity consumption in California, Michigan, and Texas, we demonstrate the ILB program's significant effectiveness in supporting communities during emergencies.
2023.10.04.17.32.08;04.10.2023;08;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.00490;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2310.00490.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Namaki_A/0/1/0/all/0/1"">Ali Namaki</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Eyvazloo_R/0/1/0/all/0/1"">Reza Eyvazloo</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Ramtinnia_S/0/1/0/all/0/1"">Shahin Ramtinnia</a>";Ali Namaki,Reza Eyvazloo,Shahin Ramtinnia;A systematic review of early warning systems in finance.;Early warning systems (EWSs) are critical for forecasting and preventing economic and financial crises. EWSs are designed to provide early warning signs of financial troubles, allowing policymakers and market participants to intervene before a crisis expands. The 2008 financial crisis highlighted the importance of detecting financial distress early and taking preventive measures to mitigate its effects. In this bibliometric review, we look at the research and literature on EWSs in finance. Our methodology included a comprehensive examination of academic databases and a stringent selection procedure, which resulted in the final selection of 616 articles published between 1976 and 2023. Our findings show that more than 90\% of the papers were published after 2006, indicating the growing importance of EWSs in financial research. According to our findings, recent research has shifted toward machine learning techniques, and EWSs are constantly evolving. We discovered that research in this area could be divided into four categories: bankruptcy prediction, banking crisis, currency crisis and emerging markets, and machine learning forecasting. Each cluster offers distinct insights into the approaches and methodologies used for EWSs. To improve predictive accuracy, our review emphasizes the importance of incorporating both macroeconomic and microeconomic data into EWS models. To improve their predictive performance, we recommend more research into incorporating alternative data sources into EWS models, such as social media data, news sentiment analysis, and network analysis.
2023.10.04.17.32.09;04.10.2023;09;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2310.01063;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2310.01063.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Michankow_J/0/1/0/all/0/1"">Jakub Micha&#x144;k&#xf3;w</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Kwiatkowski_L/0/1/0/all/0/1"">&#x141;ukasz Kwiatkowski</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Morajda_J/0/1/0/all/0/1"">Janusz Morajda</a>";"Jakub Michańków,&#x141;ukasz Kwiatkowski,Janusz Morajda";Combining Deep Learning and GARCH Models for Financial Volatility and Risk Forecasting.;In this paper, we develop a hybrid approach to forecasting the volatility and risk of financial instruments by combining common econometric GARCH time series models with deep learning neural networks. For the latter, we employ Gated Recurrent Unit (GRU) networks, whereas four different specifications are used as the GARCH component: standard GARCH, EGARCH, GJR-GARCH and APARCH. Models are tested using daily logarithmic returns on the S&P 500 index as well as gold price Bitcoin prices, with the three assets representing quite distinct volatility dynamics. As the main volatility estimator, also underlying the target function of our hybrid models, we use the price-range-based Garman-Klass estimator, modified to incorporate the opening and closing prices. Volatility forecasts resulting from the hybrid models are employed to evaluate the assets' risk using the Value-at-Risk (VaR) and Expected Shortfall (ES) at two different tolerance levels of 5% and 1%. Gains from combining the GARCH and GRU approaches are discussed in the contexts of both the volatility and risk forecasts. In general, it can be concluded that the hybrid solutions produce more accurate point volatility forecasts, although it does not necessarily translate into superior VaR and ES forecasts.
2023.10.04.17.32.10;04.10.2023;10;07;Industry;I4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1965/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Advances in 3D Printing Technology: An Overview;3D printing technology has brought about a paradigm shift in the delivery of clinical care in medicine and dentistry. There are several different 3D printing technologies, which, along with different printable materials with unique biomechanical properties, allows for a wide range of applications for 3D printing in dentistry. The clinical use of 3D printing has created versatile applications which streamline our digital workflow. Technological advancements have also paved the way for the integration of new dental materials in dentistry. This paper provides an overview of the mechanisms of 3D printing, the dental materials relevant to each mechanism and the possible applications of these materials within different areas of dentistry. Understanding the existing spectrum of 3D printing applications in dentistry will serve to further expand its use in the dental field.
2023.10.04.17.32.11;04.10.2023;11;08;Supply Chain;Supply Chains, Transportation et al.;arxiv;2310.00446;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2310.00446.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Mungo_L/0/1/0/all/0/1"">Luca Mungo</a>, <a href=""http://arxiv.org/find/econ/1/au:+Brintrup_A/0/1/0/all/0/1"">Alexandra Brintrup</a>, <a href=""http://arxiv.org/find/econ/1/au:+Garlaschelli_D/0/1/0/all/0/1"">Diego Garlaschelli</a>, <a href=""http://arxiv.org/find/econ/1/au:+Lafond_F/0/1/0/all/0/1"">Fran&#xe7;ois Lafond</a>";Luca Mungo,Alexandra Brintrup,Diego Garlaschelli,François Lafond;Reconstructing supply networks.;Network reconstruction is a well-developed sub-field of network science, but it has only recently been applied to production networks, where nodes are firms and edges represent customer-supplier relationships. We review the literature that has flourished to infer the topology of these networks by partial, aggregate, or indirect observation of the data. We discuss why this is an important endeavour, what needs to be reconstructed, what makes it different from other network reconstruction problems, and how different researchers have approached the problem. We conclude with a research agenda.
2023.10.04.17.32.12;04.10.2023;12;16;Human;Human Resource, Personal Assistance et al.;;;;https://www.kdnuggets.com/job-trends-in-data-analytics-nlp-for-job-trend-analysis;;;Job Trends in Data Analytics: NLP for Job Trend Analysis;NLP for Job Trend Analysis.
2023.10.03.14.13.01;03.10.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;google;;;https://workspace.google.com/blog/product-announcements/duet-ai-in-workspace-now-available;;;Now Available: Duet AI for Google Workspace;Today we're making Duet AI for Google Workspace generally available, and you can get started now with a no-cost trial. With over 3 billion users and more than 10 million paying customers who rely on it every day to get things done, Google Workspace is the world's most popular productivity tool. Our pioneering technology makes collaborating with people easy, fun, and ubiquitously available. With the introduction of Duet AI, we added AI as a real-time collaborator. Since its launch, thousands of companies and more than a million trusted testers have used Duet AI as a powerful collaboration partner that can act as a coach, source of inspiration, and productivity booster — all while ensuring every user and organization has control over their data.
2023.10.03.14.13.02;03.10.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.05463;;https://arxiv.org/pdf/2309.05463.pdf;;;Textbooks Are All You Need II: phi-1.5 technical report;We continue the investigation into the power of smaller Transformer-based language models as initiated by \textbf{TinyStories} -- a 10 million parameter model that can produce coherent English -- and the follow-up work on \textbf{phi-1}, a 1.3 billion parameter model with Python coding performance close to the state-of-the-art. The latter work proposed to use existing Large Language Models (LLMs) to generate ``textbook quality' data as a way to enhance the learning process compared to traditional web data. We follow the ``Textbooks Are All You Need' approach, focusing this time on common sense reasoning in natural language, and create a new 1.3 billion parameter model named \textbf{phi-1.5}, with performance on natural language tasks comparable to models 5x larger, and surpassing most non-frontier LLMs on more complex reasoning tasks such as grade-school mathematics and basic coding. More generally, \textbf{phi-1.5} exhibits many of the traits of much larger LLMs, both good -- such as the ability to ``think step by step' or perform some rudimentary in-context learning -- and bad, including hallucinations and the potential for toxic and biased generations -- encouragingly though, we are seeing improvement on that front thanks to the absence of web data. We open-source \textbf{phi-1.5} to promote further research on these urgent topics.
2023.10.03.14.13.03;03.10.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2306.11644;;https://arxiv.org/pdf/2306.11644.pdf;;;Textbooks Are All You Need;We introduce phi-1, a new large language model for code, with significantly smaller size than competing models: phi-1 is a Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook quality' data from the web (6B tokens) and synthetically generated textbooks and exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains pass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays surprising emergent properties compared to phi-1-base, our model before our finetuning stage on a dataset of coding exercises, and phi-1-small, a smaller model with 350M parameters trained with the same pipeline as phi-1 that still achieves 45% on HumanEval.
2023.10.03.14.13.04;03.10.2023;04;02;Energy;Electricity, Smart Grid et al.;repec;;http://nep.repec.org/rss/nep-ppm.rss.xml;http://d.repec.org/n?u=RePEc:ehl:lserod:112757&r=ppm;;Lerner, Michael;Local power: understanding the adoption and design of county wind energy regulation;The majority of U.S. states have set targets for renewable energy, but the prospects for meeting most of these goals hinge on the willingness of local governments to allow large-scale renewable energy projects in their communities. In this paper, I investigate how exposure to lobbying by wind developers and the actions of neighboring jurisdictions inform the adoption and design of rules for siting commercial wind farms. Using data collected from 1603 counties in 23 states, I find local policymakers are more likely to enact wind ordinances when they have more time to interact with wind developers and when neighboring counties have adopted wind ordinances or approved the construction of wind farms. I also observe that counties tend to adopt more stringent rules when more wind farms have been built in neighboring counties. This evidence suggests that efforts to scale up renewable energy generation may encounter increasing resistance from local governments.
2023.10.03.14.13.05;03.10.2023;05;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.16857;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16857.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Lambrichts_W/0/1/0/all/0/1"">Willem Lambrichts</a>, <a href=""http://arxiv.org/find/eess/1/au:+Paolone_M/0/1/0/all/0/1"">Mario Paolone</a>";Willem Lambrichts,Mario Paolone;General and Unified Model of the Power Flow Problem in Multiterminal AC/DC Networks.;This paper proposes a generic and unified model of the power flow (PF) problem for multiterminal hybrid AC/DC networks. The proposed model is an extension of the standard AC-PF. The DC network is treated as an AC one and, in addition to the Slack, PV and PQ nodes, four new node types are introduced to model the DC buses and the buses connecting the AC/DC interfacing converters (IC). The unified model is solved using the Newton-Raphson method. The extended PF equations can be used in the presence of multiple ICs operating under different control modes. Compared to other recent works, the proposed method allows multiple ICs to regulate the DC voltage simultaneously. This corresponds to more realistic operational conditions that ensure redundancy and allow for more flexible control of the hybrid grid. The proposed model can be used for networks under unbalanced conditions and allows for an intentionally negative sequence power injection. In addition to the operational advantages of this method, it is shown that the computational performance of the proposed method is one order of magnitude better than that of other methods presented in the existing recent literature while having the same accuracy.
2023.10.03.14.13.06;03.10.2023;06;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.16868;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16868.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Lambrichts_W/0/1/0/all/0/1"">Willem Lambrichts</a>, <a href=""http://arxiv.org/find/eess/1/au:+Paolone_M/0/1/0/all/0/1"">Mario Paolone</a>";Willem Lambrichts,Mario Paolone;Analytically Computation of Sensitivity Coefficients in Hybrid AC/DC Micro-Grid.;In this paper, we present a generic and exact (i.e. non-approximated) method for the analytical computation of the sensitivity coefficient (SC) of hybrid AC-DC micro-grids. The sensitivity coefficients are used to linearize the grid constraints in the Optimal Power Flow (OPF) problem and are traditionally computed by computing the inverse of the Jacobian of the power flow equations. The proposed method allows for a fast computation of the SC in hybrid AC/DC systems and allows to solve the OPF problem with a sub-second time resolution. The proposed method is an extension of the standard AC-SC theory. The DC network is treated as an AC one and, in addition to the Slack, PV and PQ nodes, four new node types are introduced. The methodology can be used in the presence of multiple AC/DC interfacing converters operating under different control modes.
2023.10.03.14.13.07;03.10.2023;07;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;repec;;http://nep.repec.org/rss/nep-ppm.rss.xml;http://d.repec.org/n?u=RePEc:hhs:vtiwps:2023_010&r=ppm;;Nilsson, Jan-EricOdolinski, KristoferNyström, Johan;Using a self-selection mechanism for tendering in the construction industry: A case study of railway renewal contracts;One of the consequences of the institutional separation of railway infrastructure from train operations in Europe is a misalignment of incentives in which the actions of one party may create costs for the other. To internalise otherwise external costs of track-works experienced by train operators and customers, it is essential to reform the way in which project contracts are tendered. This study suggests a self-selection mechanism for tendering rail infrastructure activities. Bidders may therefore submit bids based on the industry’s standard Unit Price Contract or a Fixed-Price Contract. The mechanism is designed to increase the possibility for a welfare maximising trade-off between construction and user costs. Using standard Benefit-Cost principles and parameter values, a case study where five switches are replaced provides substance to the discussion. The study provides a starting point for addressing risk in the construction industry and a blueprint for further development by professionals to fill in gaps and to test the approach under a controlled format before full-scale implementation.
2023.10.03.14.13.08;03.10.2023;08;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.17080;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.17080.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1"">Anthony Hu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Russell_L/0/1/0/all/0/1"">Lloyd Russell</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yeo_H/0/1/0/all/0/1"">Hudson Yeo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Murez_Z/0/1/0/all/0/1"">Zak Murez</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fedoseev_G/0/1/0/all/0/1"">George Fedoseev</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kendall_A/0/1/0/all/0/1"">Alex Kendall</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shotton_J/0/1/0/all/0/1"">Jamie Shotton</a>, <a href=""http://arxiv.org/find/cs/1/au:+Corrado_G/0/1/0/all/0/1"">Gianluca Corrado</a>";Anthony Hu,Lloyd Russell,Hudson Yeo,Zak Murez,George Fedoseev,Alex Kendall,Jamie Shotton,Gianluca Corrado;GAIA-1: A Generative World Model for Autonomous Driving.;Autonomous driving promises transformative improvements to transportation, but building systems capable of safely navigating the unstructured complexity of real-world scenarios remains challenging. A critical problem lies in effectively predicting the various potential outcomes that may emerge in response to the vehicle's actions as the world evolves. To address this challenge, we introduce GAIA-1 ('Generative AI for Autonomy'), a generative world model that leverages video, text, and action inputs to generate realistic driving scenarios while offering fine-grained control over ego-vehicle behavior and scene features. Our approach casts world modeling as an unsupervised sequence modeling problem by mapping the inputs to discrete tokens, and predicting the next token in the sequence. Emerging properties from our model include learning high-level structures and scene dynamics, contextual awareness, generalization, and understanding of geometry. The power of GAIA-1's learned representation that captures expectations of future events, combined with its ability to generate realistic samples, provides new possibilities for innovation in the field of autonomy, enabling enhanced and accelerated training of autonomous driving technology.
2023.10.03.14.13.09;03.10.2023;09;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.17089;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.17089.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Falkner_J/0/1/0/all/0/1"">Jonas K. Falkner</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schmidt_Thieme_L/0/1/0/all/0/1"">Lars Schmidt-Thieme</a>";Jonas K. Falkner,Lars Schmidt-Thieme;Too Big, so Fail? -- Enabling Neural Construction Methods to Solve Large-Scale Routing Problems.;In recent years new deep learning approaches to solve combinatorial optimization problems, in particular NP-hard Vehicle Routing Problems (VRP), have been proposed. The most impactful of these methods are sequential neural construction approaches which are usually trained via reinforcement learning. Due to the high training costs of these models, they usually are trained on limited instance sizes (e.g. serving 100 customers) and later applied to vastly larger instance size (e.g. 2000 customers). By means of a systematic scale-up study we show that even state-of-the-art neural construction methods are outperformed by simple heuristics, failing to generalize to larger problem instances. We propose to use the ruin recreate principle that alternates between completely destroying a localized part of the solution and then recreating an improved variant. In this way, neural construction methods like POMO are never applied to the global problem but just in the reconstruction step, which only involves partial problems much closer in size to their original training instances. In thorough experiments on four datasets of varying distributions and modalities we show that our neural ruin recreate approach outperforms alternative forms of improving construction methods such as sampling and beam search and in several experiments also advanced local search approaches.
2023.10.03.14.13.10;03.10.2023;10;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.17114;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.17114.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Seo_T/0/1/0/all/0/1"">Toru Seo</a>";Toru Seo;UXsim: An open source macroscopic and mesoscopic traffic simulator in Python -- a technical overview.;This note describes a technical overview of UXsim, an open source macro/mesoscopic traffic simulator in pure Python programming language. UXsim is based on Kinematic Wave model (more specifically, mesoscopic version of Newell's simplified car-following model) and dynamic user optimum-like route choice principle, which are well established methodology in the transportation research field. It can compute dynamical network traffic flow and have basic visualization and analysis capability. Furthermore, users can implement their own models and control methods into the simulator by using Python, thanks to the flexibility of the language. The simulator and its codes are freely available at https://github.com/toruseo/UXsim under the MIT license.
2023.10.03.14.13.11;03.10.2023;11;04;Finance;Finance, DeFi, Insurance, Banking et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Corporate_Asset_Management_in_the_Digital_Age_A_Blockchain_Perspective/24220675;;TechRxiv RSS Feed;Corporate Asset Management in the Digital Age: A Blockchain Perspective;The digital transformation has ushered in a new era of asset management, particularly with the advent of blockchain technology. This study explores the integration and implications of blockchain technology in corporate asset management. Through a comprehensive literature review, theoretical framework development, and case studies of two corporations, the research unveils the potential of blockchain in enhancing transparency, security, and efficiency in asset management processes. A comparative analysis between traditional asset management systems and blockchain-based systems reveals significant advancements in real-time asset tracking, reduced operational costs, and enhanced trust among stakeholders. However, challenges such as technological maturity, regulatory acceptance, and initial implementation costs are identified. The findings suggest that with a strategic approach, corporations can overcome these challenges and significantly benefit from blockchain-enabled asset management systems. This study contributes to the growing body of knowledge on blockchain technology’s application in corporate sectors and provides a foundation for future research in this realm. The implications of these findings are discussed, providing a roadmap for corporations aiming to transition to blockchain-based asset management systems.
2023.10.03.14.13.12;03.10.2023;12;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.16741;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16741.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bamford_T/0/1/0/all/0/1"">Tom Bamford</a>, <a href=""http://arxiv.org/find/cs/1/au:+Coletta_A/0/1/0/all/0/1"">Andrea Coletta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fons_E/0/1/0/all/0/1"">Elizabeth Fons</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gopalakrishnan_S/0/1/0/all/0/1"">Sriram Gopalakrishnan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vyetrenko_S/0/1/0/all/0/1"">Svitlana Vyetrenko</a>, <a href=""http://arxiv.org/find/cs/1/au:+Balch_T/0/1/0/all/0/1"">Tucker Balch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1"">Manuela Veloso</a>";Tom Bamford,Andrea Coletta,Elizabeth Fons,Sriram Gopalakrishnan,Svitlana Vyetrenko,Tucker Balch,Manuela Veloso;Multi-Modal Financial Time-Series Retrieval Through Latent Space Projections.;"Financial firms commonly process and store billions of time-series data, generated continuously and at a high frequency. To support efficient data storage and retrieval, specialized time-series databases and systems have emerged. These databases support indexing and querying of time-series by a constrained Structured Query Language(SQL)-like format to enable queries like ""Stocks with monthly price returns greater than 5%"", and expressed in rigid formats. However, such queries do not capture the intrinsic complexity of high dimensional time-series data, which can often be better described by images or language (e.g., ""A stock in low volatility regime""). Moreover, the required storage, computational time, and retrieval complexity to search in the time-series space are often non-trivial. In this paper, we propose and demonstrate a framework to store multi-modal data for financial time-series in a lower-dimensional latent space using deep encoders, such that the latent space projections capture not only the time series trends but also other desirable information or properties of the financial time-series data (such as price volatility). Moreover, our approach allows user-friendly query interfaces, enabling natural language text or sketches of time-series, for which we have developed intuitive interfaces. We demonstrate the advantages of our method in terms of computational efficiency and accuracy on real historical data as well as synthetic data, and highlight the utility of latent-space projections in the storage and retrieval of financial time-series data with intuitive query modalities."
2023.10.03.14.13.13;03.10.2023;13;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2309.01188;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.01188.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Junting Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1"">Adit Krishnan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sundaram_H/0/1/0/all/0/1"">Hari Sundaram</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"">Yunzhe Li</a>";Junting Wang,Adit Krishnan,Hari Sundaram,Yunzhe Li;Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for Recommendation Systems.;Modern neural collaborative filtering techniques are critical to the success of e-commerce, social media, and content-sharing platforms. However, despite technical advances -- for every new application domain, we need to train an NCF model from scratch. In contrast, pre-trained vision and language models are routinely applied to diverse applications directly (zero-shot) or with limited fine-tuning. Inspired by the impact of pre-trained models, we explore the possibility of pre-trained recommender models that support building recommender systems in new domains, with minimal or no retraining, without the use of any auxiliary user or item information. Zero-shot recommendation without auxiliary information is challenging because we cannot form associations between users and items across datasets when there are no overlapping users or items. Our fundamental insight is that the statistical characteristics of the user-item interaction matrix are universally available across different domains and datasets. Thus, we use the statistical characteristics of the user-item interaction matrix to identify dataset-independent representations for users and items. We show how to learn universal (i.e., supporting zero-shot adaptation without user or item auxiliary information) representations for nodes and edges from the bipartite user-item interaction graph. We learn representations by exploiting the statistical properties of the interaction data, including user and item marginals, and the size and density distributions of their clusters.
2023.10.03.14.13.14;03.10.2023;14;12;Health;Medical, Health Care, Pharmacy et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/A_Systematic_Review_of_Chatbot-Enabled_Chronic_Disease_Management_Interventions_and_mHealth/22815275;;TechRxiv RSS Feed;A Systematic Review of Chatbot-Enabled Chronic Disease Management Interventions and mHealth;Chatbots have gained popularity as a tool for managing chronic diseases, with potential advantages such as increased accessibility, individualized care, and cost-effectiveness. This efficient audit means to assess the momentum proof on the viability of chatbot-empowered persistent infection the board intercessions. Twenty relevant studies were identified through a thorough search of multiple databases and included in this review. Diabetes, high blood pressure, and mental health issues were all included in the studies. Generally speaking, the discoveries propose that chatbot-empowered mediations can be successful in further developing wellbeing results, for example, lessening pulse levels, expanding drug adherence, and working on personal satisfaction. However, additional research is required to address the potential ethical issues associated with the utilization of chatbots in healthcare and to evaluate the long-term viability of these interventions.
2023.10.03.14.13.15;03.10.2023;15;21;Software;Development, Software Engineering et al.;towardsai;;;https://pub.towardsai.net/chat-bigquery-using-english-c9bd4bb1b127?source=rss----98111c9905da---4;;;Chat  BigQuery using English;Vanna.ai, an AI SQL agent that talks to your data warehouse ...
2023.10.02.18.20.01;02.10.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;repec;;http://nep.repec.org/rss/nep-sbm.rss.xml;http://d.repec.org/n?u=RePEc:osf:socarx:p3gyb&r=sbm;;Morande, SwapnilArshi, TahseenGul, KanwalAmini, Mitra;Harnessing the Power of Artificial Intelligence to Forecast Startup Success: An Empirical Evaluation of the SECURE AI Model;This pioneering study employs machine learning to predict startup success, addressing the long-standing challenge of deciphering entrepreneurial outcomes amidst uncertainty. Integrating the multidimensional SECURE framework for holistic opportunity evaluation with AI's pattern recognition prowess, the research puts forth a novel analytics-enabled approach to illuminate success determinants. Rigorously constructed predictive models demonstrate remarkable accuracy in forecasting success likelihood, validated through comprehensive statistical analysis. The findings reveal AI’s immense potential in bringing evidence-based objectivity to the complex process of opportunity assessment. On the theoretical front, the research enriches entrepreneurship literature by bridging the knowledge gap at the intersection of structured evaluation tools and data science. On the practical front, it empowers entrepreneurs with an analytical compass for decision-making and helps investors make prudent funding choices. The study also informs policymakers to optimize conditions for entrepreneurship. Overall, it lays the foundation for a new frontier of AI-enabled, data-driven entrepreneurship research and practice. However, acknowledging AI’s limitations, the synthesis underscores the persistent relevance of human creativity alongside data-backed insights. With high predictive performance and multifaceted implications, the SECURE-AI model represents a significant stride toward an analytics-empowered paradigm in entrepreneurship management.
2023.10.02.18.20.02;02.10.2023;02;00;CrossTopic;Generic, Cross Topic, et al.;microsoft;;;https://www.microsoft.com/en-us/research/blog/announcing-the-deepspeed4science-initiative-enabling-large-scale-scientific-discovery-through-sophisticated-ai-system-technologies/;;;Announcing the DeepSpeed4Science Initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies;The DeepSpeed(opens in new tab) system is an industry leading open-source AI system framework, developed by Microsoft, that enables unprecedented scale and speed for deep learning training and inference on a wide range of AI hardware. ...
2023.10.02.18.20.03;02.10.2023;03;00;CrossTopic;Generic, Cross Topic, et al.;towardsdatascience;;;https://towardsdatascience.com/urban-accessibility-how-to-reach-defibrillators-on-time-c865d9194448?source=rss----7f60cf5620c9---4;;;Urban Accessibility — How to Reach Defibrillators on Time;In this piece, I combine earlier work on urban accessibility or walkability with open-source data on the location of public defibrillator devices. Additionally, I incorporate global population data and Uber’s H3 grid system to estimate the share of the population within reasonable reach to any device within Budapest and Vienna. ...
2023.10.02.18.20.04;02.10.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/building-invoice-extraction-bot-using-langchain-and-llm/;;;Building Invoice Extraction Bot using LangChain and LLM;In this article, we are making an invoice extraction bot with the help of a large language model and LangChain. However, the detailed knowledge of LangChain and LLM is out of scope but below is a short description of LangChain and its components. ...
2023.10.02.18.20.05;02.10.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/10/satellite-image-classification-using-vision-transformers/;;;Satellite Image Classification Using Vision Transformers;In this article, we embark on a journey into satellite image classification, leveraging cutting-edge deep learning models known as Vision Transformers (ViTs). What makes this exploration particularly intriguing is the dataset at our disposal: 5631 satellite images, meticulously sorted into four distinct categories—cloudy, desert, green area, and water. These categories encompass various environmental conditions and scenarios, making our dataset a valuable resource for training and testing our model. ...
2023.10.02.18.20.06;02.10.2023;06;07;Industry;I4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202310.0020/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Development of Mathematical Models for Industrial Processes Using Dynamic Neural Networks;Dynamic neural networks (DNN) are types of artificial neural networks (ANN) that are designed to work with sequential data where context in time is important. In contrast to traditional static neural networks that process data in a fixed order, dynamic neural networks use information about past inputs, which is important if dynamic of a certain process is emphasized. They are widely used in natural language processing, speech recognition and time series prediction. In industrial processes, their use is interesting for the prediction of difficult-to-measure process variables. In an industrial process of isomerization, it is crucial to measure the quality attributes affecting the octane number of gasoline. Process analyzers that are commonly used for this purpose are expensive and subject to failures, therefore, in order to achieve continuous production in case of malfunction, mathematical models for estimating the product quality attributes are imposed as a solution. In this paper, mathematical models were developed using dynamic recurrent neural networks (RNN), i.e., their subtype of a long short-term memory (LSTM) architecture. The results of the developed models were compared with the results of several types of other data-driven models developed for an isomerization process, such as multilayer perceptron (MLP) artificial neural networks, support vector machines (SVM) and dynamic polynomial models. The obtained results are satisfactory, which suggests a good possibility of application.
2023.10.02.18.20.07;02.10.2023;07;08;Supply Chain;Supply Chains, Transportation et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.2181/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Blockchain-enabled Pharmaceutical Supply Chain under Uncertain Demand: Cost Prediction through the Tuning of Evolutionary Supervised Learning;This paper provides a new multi-function Blockchain Technology-enabled Pharmaceutical Supply Chain (BT-enabled PSC) mathematical cost model, including PSC costs, BT costs, and uncertain demand fluctuations. The purpose of this study is to find the most appropriate algorithm(s) with minimum prediction errors to predict the costs of the BT-enabled PSC model. This paper also aims to determine the importance and cost of each component of the multi-function model. To reach these goals, we combined four Supervised Learning algorithms (KNN, DT, SVM, and NB) with two Evolutionary Computation algorithms (HS and PSO) after data generation. Each component of the multi-function model has its own importance, and we applied the Feature Weighting approach to analyse their importance. Next, four performance metrics evaluated the multi-function model, and the Total Ranking Score determined predictive algorithms with high reliability. The results indicate the HS-NB and PSO-NB algorithms perform better than the other six algorithms in predicting the costs of the multi-function model with small errors. The findings also show that the Raw Materials cost has a stronger influence on the model than the other components. This study also introduces the components of the multi-function BT-enabled PSC model.
2023.10.02.18.20.08;02.10.2023;08;13;Customer Relation;Management, Service et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/decoding-customer-care-sentiments-comprehensive-audio-analysis-guide/;;;Decoding Customer Care Sentiments: Comprehensive Audio Analysis Guide;In this comprehensive guide, we will explore the complexities of conducting sentiment analysis on customer care audio recordings, providing a detailed roadmap for implementation. ...
2023.09.30.13.29.01;30.09.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/talk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2?source=rss----7f60cf5620c9---4;;;‘Talk’ to Your SQL Database Using LangChain and Azure OpenAI;Explore the power of natural language processing using LLMs for your database queries ...
2023.09.30.13.29.02;30.09.2023;02;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.16534;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16534.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Seff_A/0/1/0/all/0/1"">Ari Seff</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cera_B/0/1/0/all/0/1"">Brian Cera</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1"">Dian Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ng_M/0/1/0/all/0/1"">Mason Ng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1"">Aurick Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nayakanti_N/0/1/0/all/0/1"">Nigamaa Nayakanti</a>, <a href=""http://arxiv.org/find/cs/1/au:+Refaat_K/0/1/0/all/0/1"">Khaled S. Refaat</a>, <a href=""http://arxiv.org/find/cs/1/au:+Al_Rfou_R/0/1/0/all/0/1"">Rami Al-Rfou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sapp_B/0/1/0/all/0/1"">Benjamin Sapp</a>";Ari Seff,Brian Cera,Dian Chen,Mason Ng,Aurick Zhou,Nigamaa Nayakanti,Khaled S. Refaat,Rami Al-Rfou,Benjamin Sapp;MotionLM: Multi-Agent Motion Forecasting as Language Modeling.;Reliable forecasting of the future behavior of road agents is a critical component to safe planning in autonomous vehicles. Here, we represent continuous trajectories as sequences of discrete motion tokens and cast multi-agent motion prediction as a language modeling task over this domain. Our model, MotionLM, provides several advantages: First, it does not require anchors or explicit latent variable optimization to learn multimodal distributions. Instead, we leverage a single standard language modeling objective, maximizing the average log probability over sequence tokens. Second, our approach bypasses post-hoc interaction heuristics where individual agent trajectory generation is conducted prior to interactive scoring. Instead, MotionLM produces joint distributions over interactive agent futures in a single autoregressive decoding process. In addition, the model's sequential factorization enables temporally causal conditional rollouts. The proposed approach establishes new state-of-the-art performance for multi-agent motion prediction on the Waymo Open Motion Dataset, ranking 1st on the interactive challenge leaderboard.
2023.09.30.13.29.03;30.09.2023;03;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.16292;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16292.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1"">Licheng Wen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1"">Daocheng Fu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"">Xin Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1"">Xinyu Cai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1"">Tao Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cai_P/0/1/0/all/0/1"">Pinlong Cai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dou_M/0/1/0/all/0/1"">Min Dou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1"">Botian Shi</a>, <a href=""http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1"">Liang He</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1"">Yu Qiao</a>";Licheng Wen,Daocheng Fu,Xin Li,Xinyu Cai,Tao Ma,Pinlong Cai,Min Dou,Botian Shi,Liang He,Yu Qiao;DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models.;Recent advancements in autonomous driving have relied on data-driven approaches, which are widely adopted but face challenges including dataset bias, overfitting, and uninterpretability. Drawing inspiration from the knowledge-driven nature of human driving, we explore the question of how to instill similar capabilities into autonomous driving systems and summarize a paradigm that integrates an interactive environment, a driver agent, as well as a memory component to address this question. Leveraging large language models with emergent abilities, we propose the DiLu framework, which combines a Reasoning and a Reflection module to enable the system to perform decision-making based on common-sense knowledge and evolve continuously. Extensive experiments prove DiLu's capability to accumulate experience and demonstrate a significant advantage in generalization ability over reinforcement learning-based methods. Moreover, DiLu is able to directly acquire experiences from real-world datasets which highlights its potential to be deployed on practical autonomous driving systems. To the best of our knowledge, we are the first to instill knowledge-driven capability into autonomous driving systems from the perspective of how humans drive.
2023.09.30.13.29.04;30.09.2023;04;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.15890;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2309.15890.pdf;" <a href=""http://arxiv.org/find/physics/1/au:+Kartun_Giles_A/0/1/0/all/0/1"">Alexander P. Kartun-Giles</a>, <a href=""http://arxiv.org/find/physics/1/au:+Ameli_N/0/1/0/all/0/1"">Nadia Ameli</a>";Alexander P. Kartun-Giles,Nadia Ameli;An Introduction to Complex Networks in Climate Finance.;In this perspective, we introduce recent research into the structure and function of complex investor networks supporting sustainability efforts. Using the case of solar, wind and hydro energy technologies, this perspective explores the complexity in low-carbon finance markets, defined as markets that direct capital flows towards low-carbon technologies, using network approaches to study their structure and dynamics. Investors are modeled as nodes which form a network or higher-order network connected by edges representing projects in which joint funding or security-related insurance was provided or other investment-related interaction occurred. We review the literature on investor networks generally, particularly in the case of complex networks, and address areas where these ideas were applied in this emerging field. The complex investor dynamics which emerge from the extant funding scenarios are not well understood. These dynamics have the potential to result in interesting non-linear behaviour, growth, and decline, which can be studied, explained and controlled using the tools of network science.
2023.09.30.13.29.05;30.09.2023;05;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2305.04811;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.04811.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Zhang_C/0/1/0/all/0/1"">Cheng Zhang</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Sjarif_N/0/1/0/all/0/1"">Nilam Nur Amir Sjarif</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Ibrahim_R/0/1/0/all/0/1"">Roslina Ibrahim</a>";Cheng Zhang,Nilam Nur Amir Sjarif,Roslina Ibrahim;Deep learning models for price forecasting of financial time series: A review of recent advancements: 2020-2022.;Accurately predicting the prices of financial time series is essential and challenging for the financial sector. Owing to recent advancements in deep learning techniques, deep learning models are gradually replacing traditional statistical and machine learning models as the first choice for price forecasting tasks. This shift in model selection has led to a notable rise in research related to applying deep learning models to price forecasting, resulting in a rapid accumulation of new knowledge. Therefore, we conducted a literature review of relevant studies over the past three years with a view to aiding researchers and practitioners in the field. This review delves deeply into deep learning-based forecasting models, presenting information on model architectures, practical applications, and their respective advantages and disadvantages. In particular, detailed information is provided on advanced models for price forecasting, such as Transformers, generative adversarial networks (GANs), graph neural networks (GNNs), and deep quantum neural networks (DQNNs). The present contribution also includes potential directions for future research, such as examining the effectiveness of deep learning models with complex structures for price forecasting, extending from point prediction to interval prediction using deep learning models, scrutinising the reliability and validity of decomposition ensembles, and exploring the influence of data volume on model performance.
2023.09.30.13.29.06;30.09.2023;06;05;Legal;Legal, Law et al.;arxiv;2309.16289;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16289.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1"">Zhiwei Fei</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1"">Xiaoyu Shen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1"">Dawei Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1"">Fengzhe Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1"">Zhuo Han</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"">Songyang Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1"">Kai Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1"">Zongwen Shen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1"">Jidong Ge</a>";Zhiwei Fei,Xiaoyu Shen,Dawei Zhu,Fengzhe Zhou,Zhuo Han,Songyang Zhang,Kai Chen,Zongwen Shen,Jidong Ge;LawBench: Benchmarking Legal Knowledge of Large Language Models.;"Large language models (LLMs) have demonstrated strong capabilities in various aspects. However, when applying them to the highly specialized, safe-critical legal domain, it is unclear how much legal knowledge they possess and whether they can reliably perform legal-related tasks. To address this gap, we propose a comprehensive evaluation benchmark LawBench. LawBench has been meticulously crafted to have precise assessment of the LLMs' legal capabilities from three cognitive levels: (1) Legal knowledge memorization: whether LLMs can memorize needed legal concepts, articles and facts; (2) Legal knowledge understanding: whether LLMs can comprehend entities, events and relationships within legal text; (3) Legal knowledge applying: whether LLMs can properly utilize their legal knowledge and make necessary reasoning steps to solve realistic legal tasks. LawBench contains 20 diverse tasks covering 5 task types: single-label classification (SLC), multi-label classification (MLC), regression, extraction and generation. We perform extensive evaluations of 51 LLMs on LawBench, including 20 multilingual LLMs, 22 Chinese-oriented LLMs and 9 legal specific LLMs. The results show that GPT-4 remains the best-performing LLM in the legal domain, surpassing the others by a significant margin. While fine-tuning LLMs on legal specific text brings certain improvements, we are still a long way from obtaining usable and reliable LLMs in legal tasks. All data, model predictions and evaluation code are released in https://github.com/open-compass/LawBench/. We hope this benchmark provides in-depth understanding of the LLMs' domain-specified capabilities and speed up the development of LLMs in the legal domain."
2023.09.30.13.29.07;30.09.2023;07;07;Industry;I4.0, Production et al.;arxiv;2309.16571;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16571.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Karimzadeh_M/0/1/0/all/0/1"">Mohammad Karimzadeh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vakanski_A/0/1/0/all/0/1"">Aleksandar Vakanski</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1"">Fei Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"">Xinchang Zhang</a>";Mohammad Karimzadeh,Aleksandar Vakanski,Fei Xu,Xinchang Zhang;Review of Machine Learning Methods for Additive Manufacturing of Functionally Graded Materials.;Additive manufacturing has revolutionized the manufacturing of complex parts by enabling direct material joining and offers several advantages such as cost-effective manufacturing of complex parts, reducing manufacturing waste, and opening new possibilities for manufacturing automation. One group of materials for which additive manufacturing holds great potential for enhancing component performance and properties is Functionally Graded Materials (FGMs). FGMs are advanced composite materials that exhibit smoothly varying properties making them desirable for applications in aerospace, automobile, biomedical, and defense industries. Such composition differs from traditional composite materials, since the location-dependent composition changes gradually in FGMs, leading to enhanced properties. Recently, machine learning techniques have emerged as a promising means for fabrication of FGMs through optimizing processing parameters, improving product quality, and detecting manufacturing defects. This paper first provides a brief literature review of works related to FGM fabrication, followed by reviewing works on employing machine learning in additive manufacturing, Afterward, we provide an overview of published works in the literature related to the application of machine learning methods in Directed Energy Deposition and for fabrication of FGMs.
2023.09.30.13.29.08;30.09.2023;08;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.16639;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16639.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1"">Ruolan Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1"">Chun Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1"">Xiaole Pan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Yujia Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1"">Ningning Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1"">Yue Fu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yuhan Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1"">Zhi Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1"">Li Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_Q/0/1/0/all/0/1"">Qiaolei Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"">Xuhai Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1"">Yuanchun Shi</a>";Ruolan Wu,Chun Yu,Xiaole Pan,Yujia Liu,Ningning Zhang,Yue Fu,Yuhan Wang,Zhi Zheng,Li Chen,Qiaolei Jiang,Xuhai Xu,Yuanchun Shi;MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention.;Problematic smartphone use negatively affects physical and mental health. Despite the wide range of prior research, existing persuasive techniques are not flexible enough to provide dynamic persuasion content based on users' physical contexts and mental states. We first conduct a Wizard-of-Oz study (N=12) and an interview study (N=10) to summarize the mental states behind problematic smartphone use: boredom, stress, and inertia. This informs our design of four persuasion strategies: understanding, comforting, evoking, and scaffolding habits. We leverage large language models (LLMs) to enable the automatic and dynamic generation of effective persuasion content. We develop MindShift, a novel LLM-powered problematic smartphone use intervention technique. MindShift takes users' in-the-moment physical contexts, mental states, app usage behaviors, users' goals & habits as input, and generates high-quality and flexible persuasive content with appropriate persuasion strategies. We conduct a 5-week field experiment (N=25) to compare MindShift with baseline techniques. The results show that MindShift significantly improves intervention acceptance rates by 17.8-22.5% and reduces smartphone use frequency by 12.1-14.4%. Moreover, users have a significant drop in smartphone addiction scale scores and a rise in self-efficacy. Our study sheds light on the potential of leveraging LLMs for context-aware persuasion in other behavior change domains.
2023.09.30.13.29.09;30.09.2023;09;20;Information;Knowledge, Understanding, Information etc.;towardsai;;;https://pub.towardsai.net/interact-with-your-pdfs-using-python-5ce8e734ad20?source=rss----98111c9905da---4;;;Interact With Your PDFs Using Python;In this article, let’s discuss ways to integrate AskYourPDF.com’s API into a Python program that would allow you to ‘chat’ with any PDF document on your computer. We will also build a simple interface using TKinter that would enable this chat to take place in a more user-friendly way. ...
2023.09.30.13.29.10;30.09.2023;10;20;Information;Knowledge, Understanding, Information etc.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/how-to-develop-a-multi-file-chatbot/;;;How to Develop A Multi-File Chatbot?;Prepare for an exciting journey as we plunge into the intricacies of the code and functionalities that bring the Multi-File Chatbot to life. Get ready to unlock the full potential of your data with the power of Generative AI at your fingertips! ...
2023.09.30.13.29.11;30.09.2023;11;21;Software;Development, Software Engineering et al.;arxiv;2309.16134;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16134.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1"">Qing Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1"">Zhenyu Wan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1"">Zhenchang Xing</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1"">Changjing Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"">Jieshan Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"">Xiwei Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1"">Qinghua Lu</a>";Qing Huang,Zhenyu Wan,Zhenchang Xing,Changjing Wang,Jieshan Chen,Xiwei Xu,Qinghua Lu;Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain.;API recommendation methods have evolved from literal and semantic keyword matching to query expansion and query clarification. The latest query clarification method is knowledge graph (KG)-based, but limitations include out-of-vocabulary (OOV) failures and rigid question templates. To address these limitations, we propose a novel knowledge-guided query clarification approach for API recommendation that leverages a large language model (LLM) guided by KG. We utilize the LLM as a neural knowledge base to overcome OOV failures, generating fluent and appropriate clarification questions and options. We also leverage the structured API knowledge and entity relationships stored in the KG to filter out noise, and transfer the optimal clarification path from KG to the LLM, increasing the efficiency of the clarification process. Our approach is designed as an AI chain that consists of five steps, each handled by a separate LLM call, to improve accuracy, efficiency, and fluency for query clarification in API recommendation. We verify the usefulness of each unit in our AI chain, which all received high scores close to a perfect 5. When compared to the baselines, our approach shows a significant improvement in MRR, with a maximum increase of 63.9% higher when the query statement is covered in KG and 37.2% when it is not. Ablation experiments reveal that the guidance of knowledge in the KG and the knowledge-guided pathfinding strategy are crucial for our approach's performance, resulting in a 19.0% and 22.2% increase in MAP, respectively. Our approach demonstrates a way to bridge the gap between KG and LLM, effectively compensating for the strengths and weaknesses of both.
2023.09.30.13.29.12;30.09.2023;12;21;Software;Development, Software Engineering et al.;arxiv;2309.16120;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.16120.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1"">Zhao Tian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"">Junjie Chen</a>";Zhao Tian,Junjie Chen;Test-Case-Driven Programming Understanding in Large Language Models for Better Code Generation.;Code generation is to automatically generate source code conforming to a given programming specification, which has received extensive attention especially with the development of large language models (LLMs). Due to the inherent difficulty of code generation, the code generated by LLMs may be also not aligned with the specification. To improve the perfor mance of LLMs in code generation, some Chain of Thought (CoT) techniques have been proposed to guide LLMs for programming understanding before code generation. However, they are still hard to figure out complicated programming logic according to the (concise) specification, leadingto unsatisfactory code generation performance. In this work, we propose the first test-case-driven CoT technique, called TCoT, to further enhance the ability of LLMs in code generation. It understands the programming specification from the novel perspective of test cases, which is aligned with human practice by using examples to understand complicated problems. Due to the existence of the expected output specified in a test case, TCoT can instantly check the correctness of the programming understanding and then refine it to be as correct as possible before code generation. In this way, it is more likely to generate correct code. Our evaluation on 6 datasets and 14 baselines demonstrates the effectiveness of TCoT. For example, TCoT improves ChatGPT by 13.93%~69.44% in terms of Pass@1 (measuring the ratio of programming problems for which the generated code passes all test cases), and outperforms the existing CoT technique with the improvement of 12.14%~53.72% in terms of Pass@1.
2023.09.29.14.33.01;29.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;arxiv;2309.15723;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15723.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1"">Haotian Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yun Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1"">Huamin Qu</a>";Haotian Li,Yun Wang,Huamin Qu;Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration.;Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.
2023.09.29.14.33.02;29.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.15649;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15649.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1"">Chao-Han Huck Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1"">Yile Gu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Yi-Chieh Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1"">Shalini Ghosh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bulyko_I/0/1/0/all/0/1"">Ivan Bulyko</a>, <a href=""http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1"">Andreas Stolcke</a>";Chao-Han Huck Yang,Yile Gu,Yi-Chieh Liu,Shalini Ghosh,Ivan Bulyko,Andreas Stolcke;Generative Speech Recognition Error Correction with Large Language Models.;We explore the ability of large language models (LLMs) to act as ASR post-processors that perform rescoring and error correction. Our focus is on instruction prompting to let LLMs perform these task without fine-tuning, for which we evaluate different prompting schemes, both zero- and few-shot in-context learning, and a novel task-activating prompting (TAP) method that combines instruction and demonstration. Using a pre-trained first-pass system and rescoring output on two out-of-domain tasks (ATIS and WSJ), we show that rescoring only by in-context learning with frozen LLMs achieves results that are competitive with rescoring by domain-tuned LMs. By combining prompting techniques with fine-tuning we achieve error rates below the N-best oracle level, showcasing the generalization power of the LLMs.
2023.09.29.14.33.03;29.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.15337;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15337.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Laban_P/0/1/0/all/0/1"">Philippe Laban</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vig_J/0/1/0/all/0/1"">Jesse Vig</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hearst_M/0/1/0/all/0/1"">Marti A. Hearst</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1"">Caiming Xiong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1"">Chien-Sheng Wu</a>";Philippe Laban,Jesse Vig,Marti A. Hearst,Caiming Xiong,Chien-Sheng Wu;Beyond the Chat: Executable and Verifiable Text-Editing with LLMs.;Conversational interfaces powered by Large Language Models (LLMs) have recently become a popular way to obtain feedback during document editing. However, standard chat-based conversational interfaces do not support transparency and verifiability of the editing changes that they suggest. To give the author more agency when editing with an LLM, we present InkSync, an editing interface that suggests executable edits directly within the document being edited. Because LLMs are known to introduce factual errors, Inksync also supports a 3-stage approach to mitigate this risk: Warn authors when a suggested edit introduces new information, help authors Verify the new information's accuracy through external search, and allow an auditor to perform an a-posteriori verification by Auditing the document via a trace of all auto-generated content. Two usability studies confirm the effectiveness of InkSync's components when compared to standard LLM-based chat interfaces, leading to more accurate, more efficient editing, and improved user experience.
2023.09.29.14.33.04;29.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.15358;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15358.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Taher_M/0/1/0/all/0/1"">Mohammad Reza Hosseinzadeh Taher</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gotway_M/0/1/0/all/0/1"">Michael B. Gotway</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1"">Jianming Liang</a>";Mohammad Reza Hosseinzadeh Taher,Michael B. Gotway,Jianming Liang;Towards Foundation Models Learned from Anatomy in Medical Imaging via Self-Supervision.;"Human anatomy is the foundation of medical imaging and boasts one striking characteristic: its hierarchy in nature, exhibiting two intrinsic properties: (1) locality: each anatomical structure is morphologically distinct from the others; and (2) compositionality: each anatomical structure is an integrated part of a larger whole. We envision a foundation model for medical imaging that is consciously and purposefully developed upon this foundation to gain the capability of ""understanding"" human anatomy and to possess the fundamental properties of medical imaging. As our first step in realizing this vision towards foundation models in medical imaging, we devise a novel self-supervised learning (SSL) strategy that exploits the hierarchical nature of human anatomy. Our extensive experiments demonstrate that the SSL pretrained model, derived from our training strategy, not only outperforms state-of-the-art (SOTA) fully/self-supervised baselines but also enhances annotation efficiency, offering potential few-shot segmentation capabilities with performance improvements ranging from 9% to 30% for segmentation tasks compared to SSL baselines. This performance is attributed to the significance of anatomy comprehension via our learning strategy, which encapsulates the intrinsic attributes of anatomical structures-locality and compositionality-within the embedding space, yet overlooked in existing SSL methods. All code and pretrained models are available at https://github.com/JLiangLab/Eden."
2023.09.29.14.33.05;29.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.15461;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15461.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"">June M. Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1"">Donghao Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1"">He Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ren_T/0/1/0/all/0/1"">Tianhe Ren</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liao_Z/0/1/0/all/0/1"">Zeyi Liao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"">Jiamin Wu</a>";June M. Liu,Donghao Li,He Cao,Tianhe Ren,Zeyi Liao,Jiamin Wu;ChatCounselor: A Large Language Models for Mental Health Support.;This paper presents ChatCounselor, a large language model (LLM) solution designed to provide mental health support. Unlike generic chatbots, ChatCounselor is distinguished by its foundation in real conversations between consulting clients and professional psychologists, enabling it to possess specialized knowledge and counseling skills in the field of psychology. The training dataset, Psych8k, was constructed from 260 in-depth interviews, each spanning an hour. To assess the quality of counseling responses, the counseling Bench was devised. Leveraging GPT-4 and meticulously crafted prompts based on seven metrics of psychological counseling assessment, the model underwent evaluation using a set of real-world counseling questions. Impressively, ChatCounselor surpasses existing open-source models in the counseling Bench and approaches the performance level of ChatGPT, showcasing the remarkable enhancement in model capability attained through high-quality domain-specific data.
2023.09.29.14.33.06;29.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/conversations-as-directed-graphs-with-lang-chain-46d70e1a846c?source=rss----7f60cf5620c9---4;;;Conversations as Directed Graphs with LangChain;Building a chatbot designed to understand key information about new prospective customers. ...
2023.09.29.14.33.07;29.09.2023;07;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.2027/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Fault Recovery Methods for a Converged System Comprised of Power Grids, Transportation Networks and Information Networks;Recently, the triple-network convergence system (TNCS) has emerged from the deep integration of the power grid, transportation network, and information network. Fault recovery research in the TNCS is important since this system's complexity and interactivity can expand the faults scale and increase faults impact. Currently, fault recovery focuses primarily on single power grids and cyber-physical systems, but there are certain shortcomings, such as ignoring uncertainties including generator start-up failures and the occurrence of new faults during recovery, energy supply-demand imbalances leading to system security issues and communication delay caused by network attacks. In this study, we propose a recovery method based on the improved TD3 algorithm, factoring in shortcomings of the existing research. Specifically, we establish a TNCS model to analyze interaction mechanisms and design a state matrix to represent the uncertainty changes in the TNCS, a negative reward to reflect the impact of unit start-up failures, a special reward to reflect the impact of communication delay and an improved Actor network update mechanism. Experimental results show that our method obtains the optimal recovery decisions, maximizes restoration benefit in power grid failure scenarios and demonstrates a strong resilience against communication delay caused by DoS attacks.
2023.09.29.14.33.08;29.09.2023;08;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.15727;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15727.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Meer_A/0/1/0/all/0/1"">Arjen A van der Meer</a>, <a href=""http://arxiv.org/find/eess/1/au:+Bhandia_R/0/1/0/all/0/1"">Rishabh Bhandia</a>, <a href=""http://arxiv.org/find/eess/1/au:+Widl_E/0/1/0/all/0/1"">Edmund Widl</a>, <a href=""http://arxiv.org/find/eess/1/au:+Heussen_K/0/1/0/all/0/1"">Kai Heussen</a>, <a href=""http://arxiv.org/find/eess/1/au:+Steinbrink_C/0/1/0/all/0/1"">Cornelius Steinbrink</a>, <a href=""http://arxiv.org/find/eess/1/au:+Chodura_P/0/1/0/all/0/1"">Przemyslaw Chodura</a>, <a href=""http://arxiv.org/find/eess/1/au:+Strasser_T/0/1/0/all/0/1"">Thomas I. Strasser</a>, <a href=""http://arxiv.org/find/eess/1/au:+Palensky_P/0/1/0/all/0/1"">Peter Palensky</a>";Arjen A van der Meer,Rishabh Bhandia,Edmund Widl,Kai Heussen,Cornelius Steinbrink,Przemyslaw Chodura,Thomas I. Strasser,Peter Palensky;Towards Scalable FMI-based Co-simulation of Wind Energy Systems Using PowerFactory.;"Due to the increased deployment of renewable energy sources and intelligent components the electric power system will exhibit a large degree of heterogeneity, which requires inclusive and multi-disciplinary system assessment. The concept of co-simulation is a very attractive option to achieve this; each domain-specific subsystem can be addressed via its own specialized simulation tool. The applicability, however, depends on aspects like standardised interfaces, automated case creation, initialisation, and the scalability of the co-simulation itself. This work deals with the inclusion of the Functional Mock-up Interface for co-simulation into the DIgSILENT PowerFactory simulator, and tests its accuracy, implementation, and scalability for the grid connection study of a wind power plant. The coupling between the RMS mode of PowerFactory and MATLAB/Simulink in a standardised manner is shown. This approach allows a straightforward inclusion of black-boxed modelling, is easily scalable in size, quantity, and component type."
2023.09.29.14.33.09;29.09.2023;09;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.15140;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15140.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1"">Sen Yan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1"">Maqsood Hussain Shah</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Ji Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1"">Noel O&#x27;Connor</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1"">Mingming Liu</a>";Sen Yan,Maqsood Hussain Shah,Ji Li,Noel O'Connor,Mingming Liu;A Review on AI Algorithms for Energy Management in E-Mobility Services.;E-mobility, or electric mobility, has emerged as a pivotal solution to address pressing environmental and sustainability concerns in the transportation sector. The depletion of fossil fuels, escalating greenhouse gas emissions, and the imperative to combat climate change underscore the significance of transitioning to electric vehicles (EVs). This paper seeks to explore the potential of artificial intelligence (AI) in addressing various challenges related to effective energy management in e-mobility systems (EMS). These challenges encompass critical factors such as range anxiety, charge rate optimization, and the longevity of energy storage in EVs. By analyzing existing literature, we delve into the role that AI can play in tackling these challenges and enabling efficient energy management in EMS. Our objectives are twofold: to provide an overview of the current state-of-the-art in this research domain and propose effective avenues for future investigations. Through this analysis, we aim to contribute to the advancement of sustainable and efficient e-mobility solutions, shaping a greener and more sustainable future for transportation.
2023.09.29.14.33.10;29.09.2023;10;02;Energy;Electricity, Smart Grid et al.;towardsdatascience;;;https://towardsdatascience.com/energy-supply-and-demand-optimisation-mathematical-modelling-using-gurobi-python-8a8b1cb9559a?source=rss----7f60cf5620c9---4;;;Energy supply and demand optimisation: mathematical modelling using Gurobi Python;Efficient energy allocation through mathematical optimisation ...
2023.09.29.14.33.11;29.09.2023;11;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.15284;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15284.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Long_K/0/1/0/all/0/1"">Keke Long</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1"">Haotian Shi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sheng_Z/0/1/0/all/0/1"">Zihao Sheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"">Xiaopeng Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1"">Sikai Chen</a>";Keke Long,Haotian Shi,Zihao Sheng,Xiaopeng Li,Sikai Chen;A Physics Enhanced Residual Learning (PERL) Framework for Traffic State Prediction.;In vehicle trajectory prediction, physics models and data-driven models are two predominant methodologies. However, each approach presents its own set of challenges: physics models fall short in predictability, while data-driven models lack interpretability. Addressing these identified shortcomings, this paper proposes a novel framework, the Physics-Enhanced Residual Learning (PERL) model. PERL integrates the strengths of physics-based and data-driven methods for traffic state prediction. PERL contains a physics model and a residual learning model. Its prediction is the sum of the physics model result and a predicted residual as a correction to it. It preserves the interpretability inherent to physics-based models and has reduced data requirements compared to data-driven methods. Experiments were conducted using a real-world vehicle trajectory dataset. We proposed a PERL model, with the Intelligent Driver Model (IDM) as its physics car-following model and Long Short-Term Memory (LSTM) as its residual learning model. We compare this PERL model with the physics car-following model, data-driven model, and other physics-informed neural network (PINN) models. The result reveals that PERL achieves better prediction with a small dataset, compared to the physics model, data-driven model, and PINN model. Second, the PERL model showed faster convergence during training, offering comparable performance with fewer training samples than the data-driven model and PINN model. Sensitivity analysis also proves comparable performance of PERL using another residual learning model and a physics car-following model.
2023.09.29.14.33.12;29.09.2023;12;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.15269;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15269.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Braouezec_Y/0/1/0/all/0/1"">Yann Braouezec</a>, <a href=""http://arxiv.org/find/econ/1/au:+Cagnol_J/0/1/0/all/0/1"">John Cagnol</a>";Yann Braouezec,John Cagnol;Theoretical Foundations of Community Rating by a Private Monopolist Insurer: Framework, Regulation, and Numerical Analysis.;Community rating is a policy that mandates uniform premium regardless of the risk factors. In this paper, our focus narrows to the single contract interpretation wherein we establish a theoretical framework for community rating using Stiglitz's (1977) monopoly model in which there is a continuum of agents. We exhibit profitability conditions and show that, under mild regularity conditions, the optimal premium is unique and satisfies the inverse elasticity rule. Our numerical analysis, using realistic parameter values, reveals that under regulation, a 10% increase in indemnity is possible with minimal impact on other variables.
2023.09.29.14.33.13;29.09.2023;13;07;Industry;I4.0, Production et al.;arxiv;2309.15517;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15517.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ho_K/0/1/0/all/0/1"">Kuo-Hao Ho</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jheng_R/0/1/0/all/0/1"">Ruei-Yu Jheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"">Ji-Han Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chiang_F/0/1/0/all/0/1"">Fan Chiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"">Yen-Chi Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1"">Yuan-Yu Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_I/0/1/0/all/0/1"">I-Chen Wu</a>";Kuo-Hao Ho,Ruei-Yu Jheng,Ji-Han Wu,Fan Chiang,Yen-Chi Chen,Yuan-Yu Wu,I-Chen Wu;Residual Scheduling: A New Reinforcement Learning Approach to Solving Job Shop Scheduling Problem.;Job-shop scheduling problem (JSP) is a mathematical optimization problem widely used in industries like manufacturing, and flexible JSP (FJSP) is also a common variant. Since they are NP-hard, it is intractable to find the optimal solution for all cases within reasonable times. Thus, it becomes important to develop efficient heuristics to solve JSP/FJSP. A kind of method of solving scheduling problems is construction heuristics, which constructs scheduling solutions via heuristics. Recently, many methods for construction heuristics leverage deep reinforcement learning (DRL) with graph neural networks (GNN). In this paper, we propose a new approach, named residual scheduling, to solving JSP/FJSP. In this new approach, we remove irrelevant machines and jobs such as those finished, such that the states include the remaining (or relevant) machines and jobs only. Our experiments show that our approach reaches state-of-the-art (SOTA) among all known construction heuristics on most well-known open JSP and FJSP benchmarks. In addition, we also observe that even though our model is trained for scheduling problems of smaller sizes, our method still performs well for scheduling problems of large sizes. Interestingly in our experiments, our approach even reaches zero gap for 49 among 50 JSP instances whose job numbers are more than 150 on 20 machines.
2023.09.29.14.33.14;29.09.2023;14;08;Supply Chain;Supply Chains, Transportation et al.;acm;;http://cacm.acm.org/browse-by-subject/artificial-intelligence.rss;http://cacm.acm.org/news/276813-ai-is-policing-the-package-theft-beat-for-ups;;Communications of the ACM: Artificial Intelligence;AI Is Policing the Package Theft Beat for UPS;UPS and other large logistics companies are rolling out technology to curtail porch piracy.
2023.09.29.14.33.15;29.09.2023;15;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2309.15363;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15363.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1"">Penghang Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1"">Zhiyi Tan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1"">Guanming Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bao_B/0/1/0/all/0/1"">Bing-Kun Bao</a>";Penghang Yu,Zhiyi Tan,Guanming Lu,Bing-Kun Bao;LD4MRec: Simplifying and Powering Diffusion Model for Multimedia Recommendation.;Multimedia recommendation aims to predict users' future behaviors based on historical behavioral data and item's multimodal information. However, noise inherent in behavioral data, arising from unintended user interactions with uninteresting items, detrimentally impacts recommendation performance. Recently, diffusion models have achieved high-quality information generation, in which the reverse process iteratively infers future information based on the corrupted state. It meets the need of predictive tasks under noisy conditions, and inspires exploring their application to predicting user behaviors. Nonetheless, several challenges must be addressed: 1) Classical diffusion models require excessive computation, which does not meet the efficiency requirements of recommendation systems. 2) Existing reverse processes are mainly designed for continuous data, whereas behavioral information is discrete in nature. Therefore, an effective method is needed for the generation of discrete behavioral information. To tackle the aforementioned issues, we propose a Light Diffusion model for Multimedia Recommendation. First, to reduce computational complexity, we simplify the formula of the reverse process, enabling one-step inference instead of multi-step inference. Second, to achieve effective behavioral information generation, we propose a novel Conditional neural Network. It maps the discrete behavior data into a continuous latent space, and generates behaviors with the guidance of collaborative signals and user multimodal preference. Additionally, considering that completely clean behavior data is inaccessible, we introduce a soft behavioral reconstruction constraint during model training, facilitating behavior prediction with noisy data. Empirical studies conducted on three public datasets demonstrate the effectiveness of LD4MRec.
2023.09.29.14.33.16;29.09.2023;16;15;Control;Control, Planning, Processes et al.;arxiv;2306.06531;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.06531.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"">Yongchao Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Arkin_J/0/1/0/all/0/1"">Jacob Arkin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dawson_C/0/1/0/all/0/1"">Charles Dawson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yang Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Roy_N/0/1/0/all/0/1"">Nicholas Roy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1"">Chuchu Fan</a>";Yongchao Chen,Jacob Arkin,Charles Dawson,Yang Zhang,Nicholas Roy,Chuchu Fan;AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers.;For effective human-robot interaction, robots need to understand, plan, and execute complex, long-horizon tasks described by natural language. Recent advances in large language models (LLMs) have shown promise for translating natural language into robot action sequences for complex tasks. However, existing approaches either translate the natural language directly into robot trajectories or factor the inference process by decomposing language into task sub-goals and relying on a motion planner to execute each sub-goal. When complex environmental and temporal constraints are involved, inference over planning tasks must be performed jointly with motion plans using traditional task-and-motion planning (TAMP) algorithms, making factorization into subgoals untenable. Rather than using LLMs to directly plan task sub-goals, we instead perform few-shot translation from natural language task descriptions to an intermediate task representation that can then be consumed by a TAMP algorithm to jointly solve the task and motion plan. To improve translation, we automatically detect and correct both syntactic and semantic errors via autoregressive re-prompting, resulting in significant improvements in task completion. We show that our approach outperforms several methods using LLMs as planners in complex task domains. See our project website https://yongchao98.github.io/MIT-REALM-AutoTAMP/ for prompts, videos, and code.
2023.09.29.14.33.17;29.09.2023;17;16;Human;Human Resource, Personal Assistance et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/New_Techniques_for_Real-Time_Fall_Prediction_and_Development_of_an_Injury_Prevention_System/24123456;;TechRxiv RSS Feed;New Techniques for Real-Time Fall Prediction and Development of an Injury Prevention System;The Fall_Prediction_arXiv_v2.pdf file is the manuscript. This is the exact same manuscript that is currently posted, but with the missing references corrected. If possible please delete the currently posted version and replace with this.
2023.09.28.15.27.01;28.09.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.13963;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.13963.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Yu_W/0/1/0/all/0/1"">Wenyi Yu</a>, <a href=""http://arxiv.org/find/eess/1/au:+Tang_C/0/1/0/all/0/1"">Changli Tang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Sun_G/0/1/0/all/0/1"">Guangzhi Sun</a>, <a href=""http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1"">Xianzhao Chen</a>, <a href=""http://arxiv.org/find/eess/1/au:+Tan_T/0/1/0/all/0/1"">Tian Tan</a>, <a href=""http://arxiv.org/find/eess/1/au:+Li_W/0/1/0/all/0/1"">Wei Li</a>, <a href=""http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1"">Lu Lu</a>, <a href=""http://arxiv.org/find/eess/1/au:+Ma_Z/0/1/0/all/0/1"">Zejun Ma</a>, <a href=""http://arxiv.org/find/eess/1/au:+Zhang_C/0/1/0/all/0/1"">Chao Zhang</a>";Wenyi Yu,Changli Tang,Guangzhi Sun,Xianzhao Chen,Tian Tan,Wei Li,Lu Lu,Zejun Ma,Chao Zhang;Connecting Speech Encoder and Large Language Model for ASR.;The impressive capability and versatility of large language models (LLMs) have aroused increasing attention in automatic speech recognition (ASR), with several pioneering studies attempting to build integrated ASR models by connecting a speech encoder with an LLM. This paper presents a comparative study of three commonly used structures as connectors, including fully connected layers, multi-head cross-attention, and Q-Former. Speech encoders from the Whisper model series as well as LLMs from the Vicuna model series with different model sizes were studied. Experiments were performed on the commonly used LibriSpeech, Common Voice, and GigaSpeech datasets, where the LLMs with Q-Formers demonstrated consistent and considerable word error rate (WER) reductions over LLMs with other connector structures. Q-Former-based LLMs can generalise well to out-of-domain datasets, where 12% relative WER reductions over the Whisper baseline ASR model were achieved on the Eval2000 test set without using any in-domain training data from Switchboard. Moreover, a novel segment-level Q-Former is proposed to enable LLMs to recognise speech segments with a duration exceeding the limitation of the encoders, which results in 17% relative WER reductions over other connector structures on 90-second-long speech data.
2023.09.28.15.27.02;28.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.14992;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14992.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Kanuka_H/0/1/0/all/0/1"">Hideyuki Kanuka</a>, <a href=""http://arxiv.org/find/cs/1/au:+Koreki_G/0/1/0/all/0/1"">Genta Koreki</a>, <a href=""http://arxiv.org/find/cs/1/au:+Soga_R/0/1/0/all/0/1"">Ryo Soga</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nishikawa_K/0/1/0/all/0/1"">Kazu Nishikawa</a>";Hideyuki Kanuka,Genta Koreki,Ryo Soga,Kazu Nishikawa;Exploring ChatGPT Approach to Bidirectional Traceability Problem between Design Models and Code.;This study explores the capabilities of Large Language Models (LLMs), particularly OpenAI's ChatGPT, in addressing the challenges associated with software modeling, explicitly focusing on the bidirectional traceability problem between design models and code. The objective of this study is to demonstrate the proficiency of ChatGPT in understanding and integrating specific requirements into design models and code and its potential to offer solutions to the bidirectional traceability problem through a case study. The findings indicate that ChatGPT is capable of generating design models and code from natural language requirements, thereby bridging the gap between these requirements and software modeling. Despite its limitations in suggesting a specific method to resolve the problem using ChatGPT itself, it exhibited the capacity to provide corrections to be consistent between design models and code. As a result, the study concludes that achieving bidirectional traceability between design models and code is feasible using ChatGPT.
2023.09.28.15.27.03;28.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.15088;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15088.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Pradeep_R/0/1/0/all/0/1"">Ronak Pradeep</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sharifymoghaddam_S/0/1/0/all/0/1"">Sahel Sharifymoghaddam</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1"">Jimmy Lin</a>";Ronak Pradeep,Sahel Sharifymoghaddam,Jimmy Lin;RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models.;Researchers have successfully applied large language models (LLMs) such as ChatGPT to reranking in an information retrieval context, but to date, such work has mostly been built on proprietary models hidden behind opaque API endpoints. This approach yields experimental results that are not reproducible and non-deterministic, threatening the veracity of outcomes that build on such shaky foundations. To address this significant shortcoming, we present RankVicuna, the first fully open-source LLM capable of performing high-quality listwise reranking in a zero-shot setting. Experimental results on the TREC 2019 and 2020 Deep Learning Tracks show that we can achieve effectiveness comparable to zero-shot reranking with GPT-3.5 with a much smaller 7B parameter model, although our effectiveness remains slightly behind reranking with GPT-4. We hope our work provides the foundation for future research on reranking with modern LLMs. All the code necessary to reproduce our results is available at https://github.com/castorini/rank_llm.
2023.09.28.15.27.04;28.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.15091;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15091.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1"">Han Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zala_A/0/1/0/all/0/1"">Abhay Zala</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1"">Jaemin Cho</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1"">Mohit Bansal</a>";Han Lin,Abhay Zala,Jaemin Cho,Mohit Bansal;VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning.;Although recent text-to-video (T2V) generation methods have seen significant advancements, most of these works focus on producing short video clips of a single event with a single background (i.e., single-scene videos). Meanwhile, recent large language models (LLMs) have demonstrated their capability in generating layouts and programs to control downstream visual modules such as image generation models. This raises an important question: can we leverage the knowledge embedded in these LLMs for temporally consistent long video generation? In this paper, we propose VideoDirectorGPT, a novel framework for consistent multi-scene video generation that uses the knowledge of LLMs for video content planning and grounded video generation. Specifically, given a single text prompt, we first ask our video planner LLM (GPT-4) to expand it into a 'video plan', which involves generating the scene descriptions, the entities with their respective layouts, the background for each scene, and consistency groupings of the entities and backgrounds. Next, guided by this output from the video planner, our video generator, Layout2Vid, has explicit control over spatial layouts and can maintain temporal consistency of entities/backgrounds across scenes, while only trained with image-level annotations. Our experiments demonstrate that VideoDirectorGPT framework substantially improves layout and movement control in both single- and multi-scene video generation and can generate multi-scene videos with visual consistency across scenes, while achieving competitive performance with SOTAs in open-domain single-scene T2V generation. We also demonstrate that our framework can dynamically control the strength for layout guidance and can also generate videos with user-provided images. We hope our framework can inspire future work on better integrating the planning ability of LLMs into consistent long video generation.
2023.09.28.15.27.05;28.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.15112;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15112.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1"">Pan Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"">Xiaoyi Dong Bin Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"">Yuhang Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1"">Chao Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ouyang_L/0/1/0/all/0/1"">Linke Ouyang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1"">Zhiyuan Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1"">Shuangrui Ding</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"">Songyang Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Duan_H/0/1/0/all/0/1"">Haodong Duan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1"">Hang Yan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"">Xinyue Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1"">Wei Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Jingwen Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1"">Kai Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1"">Conghui He</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"">Xingcheng Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1"">Yu Qiao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1"">Dahua Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Jiaqi Wang</a>";Pan Zhang,Xiaoyi Dong Bin Wang,Yuhang Cao,Chao Xu,Linke Ouyang,Zhiyuan Zhao,Shuangrui Ding,Songyang Zhang,Haodong Duan,Hang Yan,Xinyue Zhang,Wei Li,Jingwen Li,Kai Chen,Conghui He,Xingcheng Zhang,Yu Qiao,Dahua Lin,Jiaqi Wang;InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition.;We propose InternLM-XComposer, a vision-language large model that enables advanced image-text comprehension and composition. The innovative nature of our model is highlighted by three appealing properties: 1) Interleaved Text-Image Composition: InternLM-XComposer can effortlessly generate coherent and contextual articles that seamlessly integrate images, providing a more engaging and immersive reading experience. Simply provide a title, and our system will generate the corresponding manuscript. It can intelligently identify the areas in the text where images would enhance the content and automatically insert the most appropriate visual candidates. 2) Comprehension with Rich Multilingual Knowledge: The text-image comprehension is empowered by training on extensive multi-modal multilingual concepts with carefully crafted strategies, resulting in a deep understanding of visual content. 3) State-of-the-art Performance: Our model consistently achieves state-of-the-art results across various mainstream benchmarks for vision-language foundational models, including MME Benchmark, MMBench, MMBench-CN, Seed-Bench, and CCBench (Chinese Cultural Benchmark). Collectively, InternLM-XComposer seamlessly blends advanced text-image comprehension and composition, revolutionizing vision-language interaction and offering new insights and opportunities. The InternLM-XComposer models with 7B parameters are publicly available at https://github.com/InternLM/InternLM-XComposer.
2023.09.28.15.27.06;28.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.14482;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14482.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1"">Xiao Han</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1"">Shuhan Yuan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Trabelsi_M/0/1/0/all/0/1"">Mohamed Trabelsi</a>";Xiao Han,Shuhan Yuan,Mohamed Trabelsi;LogGPT: Log Anomaly Detection via GPT.;Detecting system anomalies based on log data is important for ensuring the security and reliability of computer systems. Recently, deep learning models have been widely used for log anomaly detection. The core idea is to model the log sequences as natural language and adopt deep sequential models, such as LSTM or Transformer, to encode the normal patterns in log sequences via language modeling. However, there is a gap between language modeling and anomaly detection as the objective of training a sequential model via a language modeling loss is not directly related to anomaly detection. To fill up the gap, we propose LogGPT, a novel framework that employs GPT for log anomaly detection. LogGPT is first trained to predict the next log entry based on the preceding sequence. To further enhance the performance of LogGPT, we propose a novel reinforcement learning strategy to finetune the model specifically for the log anomaly detection task. The experimental results on three datasets show that LogGPT significantly outperforms existing state-of-the-art approaches.
2023.09.28.15.27.07;28.09.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/simulating-conversations-with-chatgpt-fd7f34aebb0c?source=rss----98111c9905da---4;;;Simulating Conversations with ChatGPT;In which we find out about the hopes and dreams of a large language model ...
2023.09.28.15.27.08;28.09.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/mapping-with-gpt-4s-advanced-data-analysis-tool-a-comprehensive-example-a2db2042e617?source=rss----98111c9905da---4;;;Mapping With GPT-4's Advanced Data Analysis Tool: A Comprehensive Example;Using GPT-4 to generate beautiful on-the-fly charts and maps ...
2023.09.28.15.27.09;28.09.2023;09;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1904/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Managing the Power Supply Energy Efficiency by Means of Higher Voltage and Interharmonics;The paper proposes an innovative solution for managing and ensuring high energy efficiency of power supply systems at high non-linear loads. This is realized by maintaining optimal value of reliability indicators and high quality of power supply. The validation is carried out using analyzes and tests of quality of electromagnetic compatibility (EMC) for increased number of powered frequency converters. It has been proven that the effective use and reduction of energy consumption can be achieved thanks to the unique technological features of the employed electrical devices. This enables a normal operation of the system with decreased power and adequate control of energy processes. The problem of predicting power losses under changing conditions in a decentralized electrical network has been solved based on the theory of electromagnetic compatibility. The influence of the mains mode parameters and the indices of instantaneous distortion of current and voltage waveforms caused by the operation of converters on the resonance phenomena in power supply systems were investigated. Recommendations were developed for the selection of proper parameters of compensators for 6-10 kV and 0.4-0.66 kV circuits based on the analysis of the optimization problem when minimizing active power losses. Results of our findings may aid parties involved in designing and maintaining power networks in various applications, such as mines, etc.
2023.09.28.15.27.10;28.09.2023;10;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.14608;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14608.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1"">Yuanzheng Li</a>, <a href=""http://arxiv.org/find/eess/1/au:+Long_X/0/1/0/all/0/1"">Xinxin Long</a>, <a href=""http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1"">Yang Li</a>, <a href=""http://arxiv.org/find/eess/1/au:+Ding_Y/0/1/0/all/0/1"">Yizhou Ding</a>, <a href=""http://arxiv.org/find/eess/1/au:+Yang_T/0/1/0/all/0/1"">Tao Yang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Zeng_Z/0/1/0/all/0/1"">Zhigang Zeng</a>";Yuanzheng Li,Xinxin Long,Yang Li,Yizhou Ding,Tao Yang,Zhigang Zeng;A Demand-Supply Cooperative Responding Strategy in Power System with High Renewable Energy Penetration.;Industrial demand response (IDR) plays an important role in promoting the utilization of renewable energy (RE) in power systems. However, it will lead to power adjustments on the supply side, which is also a non-negligible factor in affecting RE utilization. To comprehensively analyze this impact while enhancing RE utilization, this paper proposes a power demand-supply cooperative response (PDSCR) strategy based on both day-ahead and intraday time scales. The day-ahead PDSCR determines a long-term scheme for responding to the predictable trends in RE supply. However, this long-term scheme may not be suitable when uncertain RE fluctuations occur on an intraday basis. Regarding intraday PDSCR, we formulate a profit-driven cooperation approach to address the issue of RE fluctuations. In this context, unreasonable profit distributions on the demand-supply side would lead to the conflict of interests and diminish the effectiveness of cooperative responses. To mitigate this issue, we derive multi-individual profit distribution marginal solutions (MIPDMSs) based on satisfactory profit distributions, which can also maximize cooperative profits. Case studies are conducted on an modified IEEE 24-bus system and an actual power system in China. The results verify the effectiveness of the proposed strategy for enhancing RE utilization, via optimizing the coordination of IDR flexibility with generation resources.
2023.09.28.15.27.11;28.09.2023;11;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.14880;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14880.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zaffar_Z/0/1/0/all/0/1"">Zaffar Zaffar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sohrab_F/0/1/0/all/0/1"">Fahad Sohrab</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kanniainen_J/0/1/0/all/0/1"">Juho Kanniainen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1"">Moncef Gabbouj</a>";Zaffar Zaffar,Fahad Sohrab,Juho Kanniainen,Moncef Gabbouj;Credit Card Fraud Detection with Subspace Learning-based One-Class Classification.;"In an increasingly digitalized commerce landscape, the proliferation of credit card fraud and the evolution of sophisticated fraudulent techniques have led to substantial financial losses. Automating credit card fraud detection is a viable way to accelerate detection, reducing response times and minimizing potential financial losses. However, addressing this challenge is complicated by the highly imbalanced nature of the datasets, where genuine transactions vastly outnumber fraudulent ones. Furthermore, the high number of dimensions within the feature set gives rise to the ``curse of dimensionality"". In this paper, we investigate subspace learning-based approaches centered on One-Class Classification (OCC) algorithms, which excel in handling imbalanced data distributions and possess the capability to anticipate and counter the transactions carried out by yet-to-be-invented fraud techniques. The study highlights the potential of subspace learning-based OCC algorithms by investigating the limitations of current fraud detection strategies and the specific challenges of credit card fraud detection. These algorithms integrate subspace learning into the data description; hence, the models transform the data into a lower-dimensional subspace optimized for OCC. Through rigorous experimentation and analysis, the study validated that the proposed approach helps tackle the curse of dimensionality and the imbalanced nature of credit card data for automatic fraud detection to mitigate financial losses caused by fraudulent activities."
2023.09.28.15.27.12;28.09.2023;12;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.14349;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14349.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Feng_B/0/1/0/all/0/1"">Bojing Feng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1"">Xi Cheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1"">Dan Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zeyu Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1"">Wenfang Xue</a>";Bojing Feng,Xi Cheng,Dan Li,Zeyu Liu,Wenfang Xue;Corporate Credit Rating: A Survey.;Corporate credit rating (CCR) plays a very important role in the process of contemporary economic and social development. How to use credit rating methods for enterprises has always been a problem worthy of discussion. Through reading and studying the relevant literature at home and abroad, this paper makes a systematic survey of CCR. This paper combs the context of the development of CCR methods from the three levels: statistical models, machine learning models and neural network models, summarizes the common databases of CCR, and deeply compares the advantages and disadvantages of the models. Finally, this paper summarizes the problems existing in the current research and prospects the future of CCR. Compared with the existing review of CCR, this paper expounds and analyzes the progress of neural network model in this field in recent years.
2023.09.28.15.27.13;28.09.2023;13;05;Legal;Legal, Law et al.;arxiv;2309.15016;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15016.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1"">Huihui Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ashley_K/0/1/0/all/0/1"">Kevin Ashley</a>";Huihui Xu,Kevin Ashley;Question-Answering Approach to Evaluate Legal Summaries.;Traditional evaluation metrics like ROUGE compare lexical overlap between the reference and generated summaries without taking argumentative structure into account, which is important for legal summaries. In this paper, we propose a novel legal summarization evaluation framework that utilizes GPT-4 to generate a set of question-answer pairs that cover main points and information in the reference summary. GPT-4 is then used to generate answers based on the generated summary for the questions from the reference summary. Finally, GPT-4 grades the answers from the reference summary and the generated summary. We examined the correlation between GPT-4 grading with human grading. The results suggest that this question-answering approach with GPT-4 can be a useful tool for gauging the quality of the summary.
2023.09.28.15.27.14;28.09.2023;14;05;Legal;Legal, Law et al.;arxiv;2309.14735;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14735.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Nigam_S/0/1/0/all/0/1"">Shubham Kumar Nigam</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1"">Shubham Kumar Mishra</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1"">Ayush Kumar Mishra</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shallum_N/0/1/0/all/0/1"">Noel Shallum</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1"">Arnab Bhattacharya</a>";Shubham Kumar Nigam,Shubham Kumar Mishra,Ayush Kumar Mishra,Noel Shallum,Arnab Bhattacharya;Comparative Analysis of Artificial Intelligence for Indian Legal Question Answering (AILQA) Using Different Retrieval and QA Models.;Legal question-answering (QA) systems have the potential to revolutionize the way legal professionals interact with case law documents. This paper conducts a comparative analysis of existing artificial intelligence models for their utility in answering legal questions within the Indian legal system, specifically focusing on Indian Legal Question Answering (AILQA) and our study investigates the efficacy of different retrieval and QA algorithms currently available. Utilizing the OpenAI GPT model as a benchmark, along with query prompts, our investigation shows that existing AILQA systems can automatically interpret natural language queries from users and generate highly accurate responses. This research is particularly focused on applications within the Indian criminal justice domain, which has its own set of challenges due to its complexity and resource constraints. In order to rigorously assess the performance of these models, empirical evaluations are complemented by feedback from practicing legal professionals, thereby offering a multifaceted view on the capabilities and limitations of AI in the context of Indian legal question-answering.
2023.09.28.15.27.15;28.09.2023;15;06;Public Services;Public Services;towardsai;;;https://pub.towardsai.net/smart-control-of-traffic-lights-using-ai-f88827a508d4?source=rss----98111c9905da---4;;;Smart Control of Traffic Lights using AI;Our proposed system takes an image from the CCTV cameras at traffic junctions as input for real-time traffic density calculation using image processing and object detection. This system can be broken down into 3 modules: Vehicle Detection module, Signal Switching Algorithm, and Simulation module. ...
2023.09.28.15.27.16;28.09.2023;16;08;Supply Chain;Supply Chains, Transportation et al.;arxiv;2309.14557;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14557.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ashraf_M/0/1/0/all/0/1"">Mahmoud Ashraf</a>, <a href=""http://arxiv.org/find/cs/1/au:+Eltawil_A/0/1/0/all/0/1"">Amr Eltawil</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ali_I/0/1/0/all/0/1"">Islam Ali</a>";Mahmoud Ashraf,Amr Eltawil,Islam Ali;Disruption Detection for a Cognitive Digital Supply Chain Twin Using Hybrid Deep Learning.;Purpose: Recent disruptive events, such as COVID-19 and Russia-Ukraine conflict, had a significant impact of global supply chains. Digital supply chain twins have been proposed in order to provide decision makers with an effective and efficient tool to mitigate disruption impact. Methods: This paper introduces a hybrid deep learning approach for disruption detection within a cognitive digital supply chain twin framework to enhance supply chain resilience. The proposed disruption detection module utilises a deep autoencoder neural network combined with a one-class support vector machine algorithm. In addition, long-short term memory neural network models are developed to identify the disrupted echelon and predict time-to-recovery from the disruption effect. Results: The obtained information from the proposed approach will help decision-makers and supply chain practitioners make appropriate decisions aiming at minimizing negative impact of disruptive events based on real-time disruption detection data. The results demonstrate the trade-off between disruption detection model sensitivity, encountered delay in disruption detection, and false alarms. This approach has seldom been used in recent literature addressing this issue.
2023.09.28.15.27.17;28.09.2023;17;09;Commerce;Commerce, Trading, Sales, Retail et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/customized-marketing-copywriting-using-llms-for-e-commerce/;;;Customized Marketing Copywriting Using LLMS for E-commerce;From enhancing customer interactions and personalizing product recommendations to streamlining customer support and enabling advanced natural language processing in search. The article will also shed light on the benefits, challenges, and ethical considerations associated with deploying LLMs in the e-commerce ecosystem. ...
2023.09.28.15.27.18;28.09.2023;18;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.14530;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14530.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Muley_A/0/1/0/all/0/1"">Apoorva Muley</a>, <a href=""http://arxiv.org/find/cs/1/au:+Muzumdar_P/0/1/0/all/0/1"">Prathamesh Muzumdar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kurian_G/0/1/0/all/0/1"">George Kurian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Basyal_G/0/1/0/all/0/1"">Ganga Prasad Basyal</a>";Apoorva Muley,Prathamesh Muzumdar,George Kurian,Ganga Prasad Basyal;Risk of AI in Healthcare: A Comprehensive Literature Review and Study Framework.;This study conducts a thorough examination of the research stream focusing on AI risks in healthcare, aiming to explore the distinct genres within this domain. A selection criterion was employed to carefully analyze 39 articles to identify three primary genres of AI risks prevalent in healthcare: clinical data risks, technical risks, and socio-ethical risks. Selection criteria was based on journal ranking and impact factor. The research seeks to provide a valuable resource for future healthcare researchers, furnishing them with a comprehensive understanding of the complex challenges posed by AI implementation in healthcare settings. By categorizing and elucidating these genres, the study aims to facilitate the development of empirical qualitative and quantitative research, fostering evidence-based approaches to address AI-related risks in healthcare effectively. This endeavor contributes to building a robust knowledge base that can inform the formulation of risk mitigation strategies, ensuring safe and efficient integration of AI technologies in healthcare practices. Thus, it is important to study AI risks in healthcare to build better and efficient AI systems and mitigate risks.
2023.09.28.15.27.19;28.09.2023;19;16;Human;Human Resource, Personal Assistance et al.;arxiv;2210.01535;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2210.01535.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Stephany_F/0/1/0/all/0/1"">Fabian Stephany</a>, <a href=""http://arxiv.org/find/econ/1/au:+Teutloff_O/0/1/0/all/0/1"">Ole Teutloff</a>";Fabian Stephany,Ole Teutloff;What is the Price of a Skill? The Value of Complementarity.;The global workforce is urged to constantly reskill, as technological change favours particular new skills while making others redundant. But which skills are a good investment for workers and firms? As skills are seldomly applied in isolation, we propose that complementarity strongly determines a skill's economic value. For 962 skills, we demonstrate that their value is strongly determined by complementarity - that is, how many different skills, ideally of high value, a competency can be combined with. We show that the value of a skill is relative, as it depends on the skill background of the worker. For most skills, their value is highest when used in combination with skills of a different type. We put our model to the test with a set of skills related to Artificial Intelligence (AI). We find that AI skills are particularly valuable - increasing worker wages by 21% on average - because of their strong complementarities and their rising demand in recent years. The model and metrics of our work can inform the policy and practice of digital re-skilling to reduce labour market mismatches. In cooperation with data and education providers, researchers and policy makers should consider using this blueprint to provide learners with personalised skill recommendations that complement their existing capacities and fit their occupational background.
2023.09.28.15.27.20;28.09.2023;20;20;Information;Knowledge, Understanding, Information etc.;arxiv;2309.14488;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14488.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bevilacqua_M/0/1/0/all/0/1"">Marialena Bevilacqua</a>, <a href=""http://arxiv.org/find/cs/1/au:+Oketch_K/0/1/0/all/0/1"">Kezia Oketch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1"">Ruiyang Qin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Stamey_W/0/1/0/all/0/1"">Will Stamey</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"">Xinyuan Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1"">Yi Gan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1"">Kai Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Abbasi_A/0/1/0/all/0/1"">Ahmed Abbasi</a>";Marialena Bevilacqua,Kezia Oketch,Ruiyang Qin,Will Stamey,Xinyuan Zhang,Yi Gan,Kai Yang,Ahmed Abbasi;When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs.;The use of machine learning (ML) models to assess and score textual data has become increasingly pervasive in an array of contexts including natural language processing, information retrieval, search and recommendation, and credibility assessment of online content. A significant disruption at the intersection of ML and text are text-generating large-language models such as generative pre-trained transformers (GPTs). We empirically assess the differences in how ML-based scoring models trained on human content assess the quality of content generated by humans versus GPTs. To do so, we propose an analysis framework that encompasses essay scoring ML-models, human and ML-generated essays, and a statistical model that parsimoniously considers the impact of type of respondent, prompt genre, and the ML model used for assessment model. A rich testbed is utilized that encompasses 18,460 human-generated and GPT-based essays. Results of our benchmark analysis reveal that transformer pretrained language models (PLMs) more accurately score human essay quality as compared to CNN/RNN and feature-based ML methods. Interestingly, we find that the transformer PLMs tend to score GPT-generated text 10-15\% higher on average, relative to human-authored documents. Conversely, traditional deep learning and feature-based ML models score human text considerably higher. Further analysis reveals that although the transformer PLMs are exclusively fine-tuned on human text, they more prominently attend to certain tokens appearing only in GPT-generated text, possibly due to familiarity/overlap in pre-training. Our framework and results have implications for text classification settings where automated scoring of text is likely to be disrupted by generative AI.
2023.09.28.15.27.21;28.09.2023;21;99;Other;Others;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1930/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Data Mining and Fusion Framework for In-Home Monitoring Applications;Sensor fusion algorithms and models have been widely used in recent times. Although research evidence has informed the use of sensor fusion models in diverse applications, there is room for improvement, especially in home-based health monitoring applications which require less supervision and technical knowledge of users. The present work compares data mining-based fusion software packages such as RapidMiner Studio, Anaconda, Weka, and Orange, and proposes a data fusion framework suitable for in-home applications. 574 privacy-friendly (binary) images and 1,722 datasets gleaned from thermal and Radar sensing solutions respectively, were fused using the software packages on instances of homogeneous and heterogeneous data aggregation. Experimental results indicated that the proposed fusion framework achieved an average Classification Accuracy of 84.7% and 95.7% on homogeneous and heterogeneous datasets respectively, with the help of data mining and machine learning models such as Naïve Bayes, Decision Tree, Neural Network, Random Forest, Stochastic Gradient Descent, Support Vector Machine, K-Nearest Neighbours and CN2 induction. Further evaluation of the sensor data fusion framework based on cross validation of features indicated average values of 94.4% for Classification Accuracy, 95.7% Precision and 96.4% for Recall.
2023.09.28.15.27.22;28.09.2023;22;99;Other;Others;arxiv;2309.14540;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14540.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Dwekat_T/0/1/0/all/0/1"">Tasnim M. Dwekat</a>, <a href=""http://arxiv.org/find/cs/1/au:+Almsre_A/0/1/0/all/0/1"">Ayda A. Almsre</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ashqar_H/0/1/0/all/0/1"">Huthaifa I. Ashqar</a>";Tasnim M. Dwekat,Ayda A. Almsre,Huthaifa I. Ashqar;Effect of roundabout design on the behavior of road users: A case study of roundabouts with application of Unsupervised Machine Learning.;This research aims to evaluate the performance of the rotors and study the behavior of the human driver in interacting with the rotors. In recent years, rotors have been increasingly used between countries due to their safety, capacity, and environmental advantages, and because they provide safe and fluid flows of vehicles for transit and integration. It turns out that roundabouts can significantly reduce speed at twisting intersections, entry speed and the resulting effect on speed depends on the rating of road users. In our research, (bus, car, truck) drivers were given special attention and their behavior was categorized into (conservative, normal, aggressive). Anticipating and recognizing driver behavior is an important challenge. Therefore, the aim of this research is to study the effect of roundabouts on these classifiers and to develop a method for predicting the behavior of road users at roundabout intersections. Safety is primarily due to two inherent features of the rotor. First, by comparing the data collected and processed in order to classify and evaluate drivers' behavior, and comparing the speeds of the drivers (bus, car and truck), the speed of motorists at crossing the roundabout was more fit than that of buses and trucks. We looked because the car is smaller and all parts of the rotor are visible to it. So drivers coming from all directions have to slow down, giving them more time to react and mitigating the consequences in the event of an accident. Second, with fewer conflicting flows (and points of conflict), drivers only need to look to their left (in right-hand traffic) for other vehicles, making their job of crossing the roundabout easier as there is less need to split attention between different directions.
2023.09.28.15.27.23;28.09.2023;23;99;Other;Others;arxiv;2309.15097;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.15097.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Despotovic_M/0/1/0/all/0/1"">Miroslav Despotovic</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"">Zedong Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Stumpe_E/0/1/0/all/0/1"">Eric Stumpe</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zeppelzauer_M/0/1/0/all/0/1"">Matthias Zeppelzauer</a>";Miroslav Despotovic,Zedong Zhang,Eric Stumpe,Matthias Zeppelzauer;Case Study: Ensemble Decision-Based Annotation of Unconstrained Real Estate Images.;We describe a proof-of-concept for annotating real estate images using simple iterative rule-based semi-supervised learning. In this study, we have gained important insights into the content characteristics and uniqueness of individual image classes as well as essential requirements for a practical implementation.
2023.09.28.15.27.24;28.09.2023;24;99;Other;Others;arxiv;2309.14807;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.14807.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yeung_C/0/1/0/all/0/1"">Calvin Yeung</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bunker_R/0/1/0/all/0/1"">Rory Bunker</a>, <a href=""http://arxiv.org/find/cs/1/au:+Umemoto_R/0/1/0/all/0/1"">Rikuhei Umemoto</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fujii_K/0/1/0/all/0/1"">Keisuke Fujii</a>";Calvin Yeung,Rory Bunker,Rikuhei Umemoto,Keisuke Fujii;Evaluating Soccer Match Prediction Models: A Deep Learning Approach and Feature Optimization for Gradient-Boosted Trees.;Machine learning models have become increasingly popular for predicting the results of soccer matches, however, the lack of publicly-available benchmark datasets has made model evaluation challenging. The 2023 Soccer Prediction Challenge required the prediction of match results first in terms of the exact goals scored by each team, and second, in terms of the probabilities for a win, draw, and loss. The original training set of matches and features, which was provided for the competition, was augmented with additional matches that were played between 4 April and 13 April 2023, representing the period after which the training set ended, but prior to the first matches that were to be predicted (upon which the performance was evaluated). A CatBoost model was employed using pi-ratings as the features, which were initially identified as the optimal choice for calculating the win/draw/loss probabilities. Notably, deep learning models have frequently been disregarded in this particular task. Therefore, in this study, we aimed to assess the performance of a deep learning model and determine the optimal feature set for a gradient-boosted tree model. The model was trained using the most recent five years of data, and three training and validation sets were used in a hyperparameter grid search. The results from the validation sets show that our model had strong performance and stability compared to previously published models from the 2017 Soccer Prediction Challenge for win/draw/loss prediction.
2023.09.28.15.27.25;28.09.2023;25;99;Other;Others;towardsai;;;https://pub.towardsai.net/using-ai-to-analyze-detect-children-3497f72aaff6?source=rss----98111c9905da---4;;;Use AI to Analyze Videos;How Image Classification and Face Detection can help detect subjects in a video ...
2023.09.27.13.48.01;27.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/the-rise-of-ai-powered-text-messaging-in-business/;;;The Rise of AI-Powered Text Messaging in Business;In recent years, the integration of Artificial Intelligence (AI), specifically Natural Language Processing (NLP) and Machine Learning (ML), has fundamentally transformed the landscape of text-based communication in businesses. This article delves into the technical aspects of AI-powered text messaging, exploring the foundational concepts, applications, benefits, challenges, and the future of this technology. ...
2023.09.27.13.48.02;27.09.2023;02;00;CrossTopic;Generic, Cross Topic, et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/10-use-cases-of-ai-in-space/;;;10 Use Cases of AI in Space;Let’s explore the top 10 fascinating use cases where AI harmoniously combines with space research, offering new horizons and allowing us to better understand the mysteries of the cosmos. ...
2023.09.27.13.48.03;27.09.2023;03;00;CrossTopic;Generic, Cross Topic, et al.;towardsdatascience;;;https://towardsdatascience.com/building-a-smart-travel-itinerary-suggester-with-langchain-google-maps-api-and-gradio-part-3-90dc7be627fb?source=rss----7f60cf5620c9---4;;;Building a Smart Travel Itinerary Suggester with LangChain, Google Maps API, and Gradio (Part 3);Learn how to build an application that might inspire your next road trip ...
2023.09.27.13.48.04;27.09.2023;04;00;CrossTopic;Generic, Cross Topic, et al.;towardsdatascience;;;https://towardsdatascience.com/building-a-smart-travel-itinerary-suggester-with-langchain-google-maps-api-and-gradio-part-2-86e9d2bcae5?source=rss----7f60cf5620c9---4;;;Building a Smart Travel Itinerary Suggester with LangChain, Google Maps API, and Gradio (Part 2);Learn how to build an application that might inspire your next road trip ...
2023.09.27.13.48.05;27.09.2023;05;00;CrossTopic;Generic, Cross Topic, et al.;towardsdatascience;;;https://towardsdatascience.com/building-a-smart-travel-itinerary-suggester-with-langchain-google-maps-api-and-gradio-part-1-4175ff480b74?source=rss----7f60cf5620c9---4;;;Building a Smart Travel Itinerary Suggester with LangChain, Google Maps API, and Gradio (Part 1);Learn how to build an application that might inspire your next road trip ...
2023.09.27.13.48.06;27.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.13233;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.13233.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Davidson_S/0/1/0/all/0/1"">Sam Davidson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Romeo_S/0/1/0/all/0/1"">Salvatore Romeo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shu_R/0/1/0/all/0/1"">Raphael Shu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gung_J/0/1/0/all/0/1"">James Gung</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1"">Arshit Gupta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mansour_S/0/1/0/all/0/1"">Saab Mansour</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yi Zhang</a>";Sam Davidson,Salvatore Romeo,Raphael Shu,James Gung,Arshit Gupta,Saab Mansour,Yi Zhang;User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue.;"One of the major impediments to the development of new task-oriented dialogue (TOD) systems is the need for human evaluation at multiple stages and iterations of the development process. In an effort to move toward automated evaluation of TOD, we propose a novel user simulator built using recently developed large pretrained language models (LLMs). In order to increase the linguistic diversity of our system relative to the related previous work, we do not fine-tune the LLMs used by our system on existing TOD datasets; rather we use in-context learning to prompt the LLMs to generate robust and linguistically diverse output with the goal of simulating the behavior of human interlocutors. Unlike previous work, which sought to maximize goal success rate (GSR) as the primary metric of simulator performance, our goal is a system which achieves a GSR similar to that observed in human interactions with TOD systems. Using this approach, our current simulator is effectively able to interact with several TOD systems, especially on single-intent conversational goals, while generating lexically and syntactically diverse output relative to previous simulators that rely upon fine-tuned models. Finally, we collect a Human2Bot dataset of humans interacting with the same TOD systems with which we experimented in order to better quantify these achievements."
2023.09.27.13.48.07;27.09.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.13063;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.13063.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shah_C/0/1/0/all/0/1"">Chirag Shah</a>, <a href=""http://arxiv.org/find/cs/1/au:+White_R/0/1/0/all/0/1"">Ryen W. White</a>, <a href=""http://arxiv.org/find/cs/1/au:+Andersen_R/0/1/0/all/0/1"">Reid Andersen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Buscher_G/0/1/0/all/0/1"">Georg Buscher</a>, <a href=""http://arxiv.org/find/cs/1/au:+Counts_S/0/1/0/all/0/1"">Scott Counts</a>, <a href=""http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1"">Sarkar Snigdha Sarathi Das</a>, <a href=""http://arxiv.org/find/cs/1/au:+Montazer_A/0/1/0/all/0/1"">Ali Montazer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Manivannan_S/0/1/0/all/0/1"">Sathish Manivannan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Neville_J/0/1/0/all/0/1"">Jennifer Neville</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ni_X/0/1/0/all/0/1"">Xiaochuan Ni</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rangan_N/0/1/0/all/0/1"">Nagu Rangan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Safavi_T/0/1/0/all/0/1"">Tara Safavi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Suri_S/0/1/0/all/0/1"">Siddharth Suri</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wan_M/0/1/0/all/0/1"">Mengting Wan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"">Leijie Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1"">Longqi Yang</a>";Chirag Shah,Ryen W. White,Reid Andersen,Georg Buscher,Scott Counts,Sarkar Snigdha Sarathi Das,Ali Montazer,Sathish Manivannan,Jennifer Neville,Xiaochuan Ni,Nagu Rangan,Tara Safavi,Siddharth Suri,Mengting Wan,Leijie Wang,Longqi Yang;Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies.;Log data can reveal valuable information about how users interact with web search services, what they want, and how satisfied they are. However, analyzing user intents in log data is not easy, especially for new forms of web search such as AI-driven chat. To understand user intents from log data, we need a way to label them with meaningful categories that capture their diversity and dynamics. Existing methods rely on manual or ML-based labeling, which are either expensive or inflexible for large and changing datasets. We propose a novel solution using large language models (LLMs), which can generate rich and relevant concepts, descriptions, and examples for user intents. However, using LLMs to generate a user intent taxonomy and apply it to do log analysis can be problematic for two main reasons: such a taxonomy is not externally validated, and there may be an undesirable feedback loop. To overcome these issues, we propose a new methodology with human experts and assessors to verify the quality of the LLM-generated taxonomy. We also present an end-to-end pipeline that uses an LLM with human-in-the-loop to produce, refine, and use labels for user intent analysis in log data. Our method offers a scalable and adaptable way to analyze user intents in web-scale log data with minimal human effort. We demonstrate its effectiveness by uncovering new insights into user intents from search and chat logs from Bing.
2023.09.27.13.48.08;27.09.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.13064;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.13064.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Yang_Y/0/1/0/all/0/1"">Yi Yang</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Tang_Y/0/1/0/all/0/1"">Yixuan Tang</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Tam_K/0/1/0/all/0/1"">Kar Yan Tam</a>";Yi Yang,Yixuan Tang,Kar Yan Tam;InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning.;We present a new financial domain large language model, InvestLM, tuned on LLaMA-65B (Touvron et al., 2023), using a carefully curated instruction dataset related to financial investment. Inspired by less-is-more-for-alignment (Zhou et al., 2023), we manually curate a small yet diverse instruction dataset, covering a wide range of financial related topics, from Chartered Financial Analyst (CFA) exam questions to SEC filings to Stackexchange quantitative finance discussions. InvestLM shows strong capabilities in understanding financial text and provides helpful responses to investment related questions. Financial experts, including hedge fund managers and research analysts, rate InvestLM's response as comparable to those of state-of-the-art commercial models (GPT-3.5, GPT-4 and Claude-2). Zero-shot evaluation on a set of financial NLP benchmarks demonstrates strong generalizability. From a research perspective, this work suggests that a high-quality domain specific LLM can be tuned using a small set of carefully curated instructions on a well-trained foundation model, which is consistent with the Superficial Alignment Hypothesis (Zhou et al., 2023). From a practical perspective, this work develops a state-of-the-art financial domain LLM with superior capability in understanding financial texts and providing helpful investment advice, potentially enhancing the work efficiency of financial professionals. We release the model parameters to the research community.
2023.09.27.13.48.09;27.09.2023;09;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.13193;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.13193.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1"">Ye Jin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1"">Xiaoxi Shen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1"">Huiling Peng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1"">Xiaoan Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1"">Jingli Qin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Jiayang Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1"">Jintao Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1"">Peizhong Gao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1"">Guyue Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gong_J/0/1/0/all/0/1"">Jiangtao Gong</a>";Ye Jin,Xiaoxi Shen,Huiling Peng,Xiaoan Liu,Jingli Qin,Jiayang Li,Jintao Xie,Peizhong Gao,Guyue Zhou,Jiangtao Gong;SurrealDriver: Designing Generative Driver Agent Simulation Framework in Urban Contexts based on Large Language Model.;Simulation plays a critical role in the research and development of autonomous driving and intelligent transportation systems. However, the current simulation platforms exhibit limitations in the realism and diversity of agent behaviors, which impede the transfer of simulation outcomes to the real world. In this paper, we propose a generative driver agent simulation framework based on large language models (LLMs), capable of perceiving complex traffic scenarios and providing realistic driving maneuvers. Notably, we conducted interviews with 24 drivers and used their detailed descriptions of driving behavior as chain-of-thought prompts to develop a `coach agent' module, which can evaluate and assist driver agents in accumulating driving experience and developing human-like driving styles. Through practical simulation experiments and user experiments, we validate the feasibility of this framework in generating reliable driver agents and analyze the roles of each module. The results show that the framework with full architect decreased the collision rate by 81.04% and increased the human-likeness by 50%. Our research proposes the first urban context driver agent simulation framework based on LLMs and provides valuable insights into the future of agent simulation for complex tasks.
2023.09.27.13.48.10;27.09.2023;10;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/mastering-sentiment-analysis-through-generative-ai/;;;Mastering Sentiment Analysis through Generative AI;Sentiment analysis has revolutionized the way companies understand and respond to customer feedback. Customer sentiment analysis analyzes customer feedback, such as product reviews, chat transcripts, emails, and call center interactions, to categorize customers into happy, neutral, or unhappy. This categorization helps companies tailor their responses and strategies to enhance customer satisfaction. In this article, we’ll explore the fusion of sentiment analysis and Generative AI, shedding light on their transformative role in enhancing the capabilities of both fields. ...
2023.09.27.13.48.11;27.09.2023;11;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/chat-assistant-for-pdfs-and-articles-without-openai-key/;;;Build Powerful Chat Assistant for PDFs and Articles Without OpenAI Key;The world of Natural Language Processing is expanding tremendously, especially with the birth of large language models, which have revolutionized this field and made it accessible to everyone. In this article, we will explore and implement some NLP techniques to create a powerful chat assistant that can respond to your questions based on a given article (or PDF) using open-source libraries, all without requiring an OpenAI API key. ...
2023.09.27.13.48.12;27.09.2023;12;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/crafting-complex-sql-queries-with-generative-ai-assistance/;;;Crafting Complex SQL Queries with Generative AI Assistance;The launch of ChatGPT marked an unprecedented moment in the history of AI. With their incredible capabilities, ChatGPT and many other generative AI tools have the potential to change dramatically the way we work. Writing SQL is one task already changing in data science following the AI revolution. We will provide an illustrative example of using natural language to connect and interact with an SQL database. You will be using Python’s open-source package Vanna. The link to the Notebook is here. Master the art of crafting intricate SQL queries with Generative AI. Learn how to streamline database interactions using natural language prompts in this insightful guide. ...
2023.09.27.13.48.13;27.09.2023;13;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/chatgpt-real-world-applications-f6090fd2a395?source=rss----98111c9905da---4;;;ChatGPT Real-World Applications;Case Studies Of ChatGPT In Various Industries ...
2023.09.27.13.48.14;27.09.2023;14;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2008.11852;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2008.11852.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"">Hao Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1"">Xiaolin Tang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1"">Teng Liu</a>";Hao Chen,Xiaolin Tang,Teng Liu;Decision-making for Autonomous Vehicles on Highway: Deep Reinforcement Learning with Continuous Action Horizon.;Decision-making strategy for autonomous vehicles de-scribes a sequence of driving maneuvers to achieve a certain navigational mission. This paper utilizes the deep reinforcement learning (DRL) method to address the continuous-horizon decision-making problem on the highway. First, the vehicle kinematics and driving scenario on the freeway are introduced. The running objective of the ego automated vehicle is to execute an efficient and smooth policy without collision. Then, the particular algorithm named proximal policy optimization (PPO)-enhanced DRL is illustrated. To overcome the challenges in tardy training efficiency and sample inefficiency, this applied algorithm could realize high learning efficiency and excellent control performance. Finally, the PPO-DRL-based decision-making strategy is estimated from multiple perspectives, including the optimality, learning efficiency, and adaptability. Its potential for online application is discussed by applying it to similar driving scenarios.
2023.09.27.13.48.15;27.09.2023;15;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2206.02014;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2206.02014.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Troxler_A/0/1/0/all/0/1"">Andreas Troxler</a> (AT Analytics), <a href=""http://arxiv.org/find/cs/1/au:+Schelldorfer_J/0/1/0/all/0/1"">J&#xfc;rg Schelldorfer</a> (Swiss Re)";"<a href=""http://arxiv.org/find/cs/1/au:+Troxler_A/0/1/0/all/0/1"">Andreas Troxler</a> (AT Analytics), <a href=""http://arxiv.org/find/cs/1/au:+Schelldorfer_J/0/1/0/all/0/1"">J&#xfc;rg Schelldorfer</a> (Swiss Re)";Actuarial Applications of Natural Language Processing Using Transformers: Case Studies for Using Text Features in an Actuarial Context.;This tutorial demonstrates workflows to incorporate text data into actuarial classification and regression tasks. The main focus is on methods employing transformer-based models. A dataset of car accident descriptions with an average length of 400 words, available in English and German, and a dataset with short property insurance claims descriptions are used to demonstrate these techniques. The case studies tackle challenges related to a multi-lingual setting and long input sequences. They also show ways to interpret model output, to assess and improve model performance, by fine-tuning the models to the domain of application or to a specific prediction task. Finally, the tutorial provides practical approaches to handle classification tasks in situations with no or only few labeled data, including but not limited to ChatGPT. The results achieved by using the language-understanding skills of off-the-shelf natural language processing (NLP) models with only minimal pre-processing and fine-tuning clearly demonstrate the power of transfer learning for practical applications.
2023.09.27.13.48.16;27.09.2023;16;04;Finance;Finance, DeFi, Insurance, Banking et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/application-of-data-science-in-the-world-of-fintech/;;;Application of Data Science in the World of FinTech;In this article, we delve into the pivotal role data science plays in shaping the world of finance. From the fundamental significance of credit scoring to the intricacies of data governance and the transformative power of customer segmentation, this exploration highlights how data science empowers financial institutions to make data-driven decisions. ...
2023.09.27.13.48.17;27.09.2023;17;05;Legal;Legal, Law et al.;arxiv;2309.13051;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.13051.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hemmat_Z/0/1/0/all/0/1"">Zahra Hemmat</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mehraeen_M/0/1/0/all/0/1"">Mohammad Mehraeen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fattahi_R/0/1/0/all/0/1"">Rahmatolloah Fattahi</a>";Zahra Hemmat,Mohammad Mehraeen,Rahmatolloah Fattahi;A Contextual Topic Modeling and Content Analysis of Iranian laws and Regulations.;A constitution is the highest legal document of a country and serves as a guide for the establishment of other laws. The constitution defines the political principles, structure, hierarchy, position, and limits of the political power of a country's government. It determines and guarantees the rights of citizens. This study aimed at topic modeling of Iranian laws. As part of this research, 11760 laws were collected from the Dotic website. Then, topic modeling was conducted on the title and content of the regularizations using LDA. Data analysis with topic modeling led to the identification of 10 topics including Economic, Customs, Housing and Urban Development, Agriculture, Insurance, Legal and judicial, Cultural, Information Technology, Political, and Government. The largest topic, Economic, accounts for 29% of regulations, while the smallest are Political and Government, accounting for 2%. This research utilizes a topic modeling method in exploring law texts and identifying trends in regularizations from 2016-2023. In this study, it was found that regularizations constitute a significant percentage of law, most of which are related to economics and customs. Cultural regularizations have increased in 2023. It can be concluded any law enacted each year can reflect society's conditions and legislators' top concerns.
2023.09.27.13.48.18;27.09.2023;18;06;Public Services;Public Services;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Utilizing_Blockchain_Technology_for_Enhanced_Governance_A_Comprehensive_Analysis_of_Potential_Applications_and_Innovations_in_the_Governmental_Sector_of_the_EU/24173400;;TechRxiv RSS Feed;Utilizing Blockchain Technology for Enhanced Governance: A Comprehensive Analysis of Potential Applications and Innovations in the Governmental Sector of the EU;This research delineates the transformative potential of blockchain technology within the realm of European governments. By conducting a meticulous analysis of existing literature and case studies, the study seeks to identify and evaluate the opportunities and challenges associated with implementing blockchain technology in governmental operations across Europe. The methodology involves a comprehensive review of peer-reviewed articles, white papers, and governmental reports, aiming to construct a nuanced perspective on the current state of blockchain applications in European governmental structures. Key findings indicate that blockchain technology can significantly enhance transparency, efficiency, and security in governmental processes within the European context, albeit with certain challenges and barriers to implementation. This study serves as a pivotal reference point, fostering a deeper understanding of the intricate dynamics of blockchain technology in the European governmental sphere and paving the way for future research and policy developments.
2023.09.27.13.48.19;27.09.2023;19;07;Industry;I4.0, Production et al.;arxiv;2309.13310;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.13310.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hasib_A/0/1/0/all/0/1"">Abdullah Al Hasib</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1"">Ashikur Rahman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Khabir_M/0/1/0/all/0/1"">Mahpara Khabir</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shawon_M/0/1/0/all/0/1"">Md. Tanvir Rouf Shawon</a>";Abdullah Al Hasib,Ashikur Rahman,Mahpara Khabir,Md. Tanvir Rouf Shawon;An Interpretable Systematic Review of Machine Learning Models for Predictive Maintenance of Aircraft Engine.;This paper presents an interpretable review of various machine learning and deep learning models to predict the maintenance of aircraft engine to avoid any kind of disaster. One of the advantages of the strategy is that it can work with modest datasets. In this study, sensor data is utilized to predict aircraft engine failure within a predetermined number of cycles using LSTM, Bi-LSTM, RNN, Bi-RNN GRU, Random Forest, KNN, Naive Bayes, and Gradient Boosting. We explain how deep learning and machine learning can be used to generate predictions in predictive maintenance using a straightforward scenario with just one data source. We applied lime to the models to help us understand why machine learning models did not perform well than deep learning models. An extensive analysis of the model's behavior is presented for several test data to understand the black box scenario of the models. A lucrative accuracy of 97.8%, 97.14%, and 96.42% are achieved by GRU, Bi-LSTM, and LSTM respectively which denotes the capability of the models to predict maintenance at an early stage.
2023.09.27.13.48.20;27.09.2023;20;13;Customer Relation;Management, Service et al.;towardsdatascience;;;https://towardsdatascience.com/mastering-customer-segmentation-with-llm-3d9008235f41?source=rss----7f60cf5620c9---4;;;Mastering Customer Segmentation with LLM;Unlock advanced customer segmentation techniques using LLMs, and improve your clustering models with advanced techniques ...
2023.09.27.13.48.21;27.09.2023;21;16;Human;Human Resource, Personal Assistance et al.;arxiv;2309.13060;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.13060.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Baillifard_A/0/1/0/all/0/1"">Ambroise Baillifard</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gabella_M/0/1/0/all/0/1"">Maxime Gabella</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lavenex_P/0/1/0/all/0/1"">Pamela Banta Lavenex</a>, <a href=""http://arxiv.org/find/cs/1/au:+Martarelli_C/0/1/0/all/0/1"">Corinna S. Martarelli</a>";Ambroise Baillifard,Maxime Gabella,Pamela Banta Lavenex,Corinna S. Martarelli;Implementing Learning Principles with a Personal AI Tutor: A Case Study.;Effective learning strategies based on principles like personalization, retrieval practice, and spaced repetition are often challenging to implement due to practical constraints. Here we explore the integration of AI tutors to complement learning programs in accordance with learning sciences. A semester-long study was conducted at UniDistance Suisse, where an AI tutor app was provided to psychology students taking a neuroscience course (N=51). After automatically generating microlearning questions from existing course materials using GPT-3, the AI tutor developed a dynamic neural-network model of each student's grasp of key concepts. This enabled the implementation of distributed retrieval practice, personalized to each student's individual level and abilities. The results indicate that students who actively engaged with the AI tutor achieved significantly higher grades. Moreover, active engagement led to an average improvement of up to 15 percentile points compared to a parallel course without AI tutor. Additionally, the grasp strongly correlated with the exam grade, thus validating the relevance of neural-network predictions. This research demonstrates the ability of personal AI tutors to model human learning processes and effectively enhance academic performance. By integrating AI tutors into their programs, educators can offer students personalized learning experiences grounded in the principles of learning sciences, thereby addressing the challenges associated with implementing effective learning strategies. These findings contribute to the growing body of knowledge on the transformative potential of AI in education.
2023.09.27.13.48.22;27.09.2023;22;16;Human;Human Resource, Personal Assistance et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/mlops-employee-attrition-rate-prediction-using-zenml-and-streamlit/;;;Employee Attrition Rate Prediction Using ZenML and Streamlit;Are u working as an HR ? struggling to predict whether the employees in your team will continue working or they’re consider leaving the organisation, No worries ! you don’t wanna be a astrologer to predict this, by using the power of Data Science, we can predict it accurately. Let us begin our wonderful journey of employee Attrition rate with a simple, yet powerful MLOps tool, called ZenML and streamlit. Let’s start our journey. ...
2023.09.27.13.48.23;27.09.2023;23;21;Software;Development, Software Engineering et al.;turingpost;;;https://www.turingpost.com/p/10-code-assistants;;;10 AI Code Companions;Models and Tools
2023.09.26.10.27.01;26.09.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:bde:wpaper:2321&r=pay;;Andres Alonso-RobiscoJose Manuel Carbo;Analysis of CBDC Narrative OF Central Banks using Large Language Models;Central banks are increasingly using verbal communication for policymaking, focusing not only on traditional monetary policy, but also on a broad set of topics. One such topic is central bank digital currency (CBDC), which is attracting attention from the international community. The complex nature of this project means that it must be carefully designed to avoid unintended consequences, such as financial instability. We propose the use of different Natural Language Processing (NLP) techniques to better understand central banks’ stance towards CBDC, analyzing a set of central bank discourses from 2016 to 2022. We do this using traditional techniques, such as dictionary-based methods, and two large language models (LLMs), namely Bert and ChatGPT, concluding that LLMs better reflect the stance identified by human experts. In particular, we observe that ChatGPT exhibits a higher degree of alignment because it can capture subtler information than BERT. Our study suggests that LLMs are an effective tool to improve sentiment measurements for policy-specific texts, though they are not infallible and may be subject to new risks, like higher sensitivity to the length of texts, and prompt engineering.
2023.09.26.10.27.02;26.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.09357;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.09357.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1"">Ziqi Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"">Xuhai Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yao_B/0/1/0/all/0/1"">Bingsheng Yao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"">Shao Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rogers_E/0/1/0/all/0/1"">Ethan Rogers</a>, <a href=""http://arxiv.org/find/cs/1/au:+Intille_S/0/1/0/all/0/1"">Stephen Intille</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shara_N/0/1/0/all/0/1"">Nawar Shara</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1"">Guodong Gordon Gao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"">Dakuo Wang</a>";Ziqi Yang,Xuhai Xu,Bingsheng Yao,Shao Zhang,Ethan Rogers,Stephen Intille,Nawar Shara,Guodong Gordon Gao,Dakuo Wang;Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model.;Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered VA interface for effective information collection. (2) For health providers, we built an LLM-based dashboard to summarize and present important health information based on older adults' conversations with the VA. We further conducted two user studies with older adults and providers to evaluate the usability of the system. The results showed that Talk2Care could facilitate the communication process, enrich the health information collected from older adults, and considerably save providers' efforts and time. We envision our work as an initial exploration of LLMs' capability in the intersection of healthcare and interpersonal communication.
2023.09.26.10.27.03;26.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.12938;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12938.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wadhwa_N/0/1/0/all/0/1"">Nalin Wadhwa</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pradhan_J/0/1/0/all/0/1"">Jui Pradhan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sonwane_A/0/1/0/all/0/1"">Atharv Sonwane</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sahu_S/0/1/0/all/0/1"">Surya Prakash Sahu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Natarajan_N/0/1/0/all/0/1"">Nagarajan Natarajan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kanade_A/0/1/0/all/0/1"">Aditya Kanade</a>, <a href=""http://arxiv.org/find/cs/1/au:+Parthasarathy_S/0/1/0/all/0/1"">Suresh Parthasarathy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rajamani_S/0/1/0/all/0/1"">Sriram Rajamani</a>";Nalin Wadhwa,Jui Pradhan,Atharv Sonwane,Surya Prakash Sahu,Nagarajan Natarajan,Aditya Kanade,Suresh Parthasarathy,Sriram Rajamani;Frustrated with Code Quality Issues? LLMs can Help!.;As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the use of (instruction-following) large language models (LLMs) to assist developers in revising code to resolve code quality issues. We present a tool, CORE (short for COde REvisions), architected using a pair of LLMs organized as a duo comprised of a proposer and a ranker. Providers of static analysis tools recommend ways to mitigate the tool warnings and developers follow them to revise their code. The \emph{proposer LLM} of CORE takes the same set of recommendations and applies them to generate candidate code revisions. The candidates which pass the static quality checks are retained. However, the LLM may introduce subtle, unintended functionality changes which may go un-detected by the static analysis. The \emph{ranker LLM} evaluates the changes made by the proposer using a rubric that closely follows the acceptance criteria that a developer would enforce. CORE uses the scores assigned by the ranker LLM to rank the candidate revisions before presenting them to the developer. CORE could revise 59.2% Python files (across 52 quality checks) so that they pass scrutiny by both a tool and a human reviewer. The ranker LLM is able to reduce false positives by 25.8% in these cases. CORE produced revisions that passed the static analysis tool in 76.8% Java files (across 10 quality checks) comparable to 78.3% of a specialized program repair tool, with significantly much less engineering efforts.
2023.09.26.10.27.04;26.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.12941;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12941.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"">Zezhong Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1"">Yuxin Deng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1"">Wenjie Du</a>";Zezhong Chen,Yuxin Deng,Wenjie Du;Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models.;Assurance cases can be used to argue for the safety of products in safety engineering. In safety-critical areas, the construction of assurance cases is indispensable. Trustworthiness Derivation Trees (TDTs) enhance assurance cases by incorporating formal methods, rendering it possible for automatic reasoning about assurance cases. We present Trustworthiness Derivation Tree Analyzer (Trusta), a desktop application designed to automatically construct and verify TDTs. The tool has a built-in Prolog interpreter in its backend, and is supported by the constraint solvers Z3 and MONA. Therefore, it can solve constraints about logical formulas involving arithmetic, sets, Horn clauses etc. Trusta also utilizes large language models to make the creation and evaluation of assurance cases more convenient. It allows for interactive human examination and modification. We evaluated top language models like ChatGPT-3.5, ChatGPT-4, and PaLM 2 for generating assurance cases. Our tests showed a 50%-80% similarity between machine-generated and human-created cases. In addition, Trusta can extract formal constraints from text in natural languages, facilitating an easier interpretation and validation process. This extraction is subject to human review and correction, blending the best of automated efficiency with human insight. To our knowledge, this marks the first integration of large language models in automatic creating and reasoning about assurance cases, bringing a novel approach to a traditional challenge. Through several industrial case studies, Trusta has proven to quickly find some subtle issues that are typically missed in manual inspection, demonstrating its practical value in enhancing the assurance case development process.
2023.09.26.10.27.05;26.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.12881;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12881.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1"">Shutong Feng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1"">Guangzhi Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lubis_N/0/1/0/all/0/1"">Nurul Lubis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1"">Chao Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gasic_M/0/1/0/all/0/1"">Milica Ga&#x161;i&#x107;</a>";"Shutong Feng,Guangzhi Sun,Nurul Lubis,Chao Zhang,Milica Ga&#x161;i&#x107;";Affect Recognition in Conversations Using Large Language Models.;Affect recognition, encompassing emotions, moods, and feelings, plays a pivotal role in human communication. In the realm of conversational artificial intelligence (AI), the ability to discern and respond to human affective cues is a critical factor for creating engaging and empathetic interactions. This study delves into the capacity of large language models (LLMs) to recognise human affect in conversations, with a focus on both open-domain chit-chat dialogues and task-oriented dialogues. Leveraging three diverse datasets, namely IEMOCAP, EmoWOZ, and DAIC-WOZ, covering a spectrum of dialogues from casual conversations to clinical interviews, we evaluated and compared LLMs' performance in affect recognition. Our investigation explores the zero-shot and few-shot capabilities of LLMs through in-context learning (ICL) as well as their model capacities through task-specific fine-tuning. Additionally, this study takes into account the potential impact of automatic speech recognition (ASR) errors on LLM predictions. With this work, we aim to shed light on the extent to which LLMs can replicate human-like affect recognition capabilities in conversations.
2023.09.26.10.27.06;26.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.12555;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12555.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shin_D/0/1/0/all/0/1"">Donghoon Shin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hsieh_G/0/1/0/all/0/1"">Gary Hsieh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1"">Young-Ho Kim</a>";Donghoon Shin,Gary Hsieh,Young-Ho Kim;PlanFitting: Tailoring Personalized Exercise Plans with Large Language Models.;A personally tailored exercise regimen is crucial to ensuring sufficient physical activities, yet challenging to create as people have complex schedules and considerations and the creation of plans often requires iterations with experts. We present PlanFitting, a conversational AI that assists in personalized exercise planning. Leveraging generative capabilities of large language models, PlanFitting enables users to describe various constraints and queries in natural language, thereby facilitating the creation and refinement of their weekly exercise plan to suit their specific circumstances while staying grounded in foundational principles. Through a user study where participants (N=18) generated a personalized exercise plan using PlanFitting and expert planners (N=3) evaluated these plans, we identified the potential of PlanFitting in generating personalized, actionable, and evidence-based exercise plans. We discuss future design opportunities for AI assistants in creating plans that better comply with exercise principles and accommodate personal constraints.
2023.09.26.10.27.07;26.09.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.12626;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12626.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wong_S/0/1/0/all/0/1"">Saika Wong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1"">Chunmo Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1"">Xing Su</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1"">Yinqiu Tang</a>";Saika Wong,Chunmo Zheng,Xing Su,Yinqiu Tang;Construction contract risk identification based on knowledge-augmented language model.;Contract review is an essential step in construction projects to prevent potential losses. However, the current methods for reviewing construction contracts lack effectiveness and reliability, leading to time-consuming and error-prone processes. While large language models (LLMs) have shown promise in revolutionizing natural language processing (NLP) tasks, they struggle with domain-specific knowledge and addressing specialized issues. This paper presents a novel approach that leverages LLMs with construction contract knowledge to emulate the process of contract review by human experts. Our tuning-free approach incorporates construction contract domain knowledge to enhance language models for identifying construction contract risks. The use of a natural language when building the domain knowledge base facilitates practical implementation. We evaluated our method on real construction contracts and achieved solid performance. Additionally, we investigated how large language models employ logical thinking during the task and provide insights and recommendations for future research.
2023.09.26.10.27.08;26.09.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/discovering-insights-into-customers-with-chatgpt-7086f93c4bc?source=rss----98111c9905da---4;;;Finding Insights into Customers with ChatGPT;Businesses need to know their customer's interests, needs and purchase history in order to personalize their marketing services and sales efforts to the specific needs of individuals. When working with customer data, we need to divide a company’s customers into groups where customers within each group share common characteristics (e.g., personality, interests, purchase history). This process makes it easier to personalize your marketing, service, and sales efforts to the specific needs of individuals within each group. In this article, we will use ChatGPT to analyze customer invoice data, use a machine learning model to segment customer data into groups, and discover insights about each customer group. ...
2023.09.26.10.27.09;26.09.2023;09;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/the-ai-boom-practical-guide-to-generative-ai-for-small-businesses-f7f3641b4388?source=rss----98111c9905da---4;;;The AI Boom: Practical Guide to Generative AI for Small Businesses;In this blog post, we delve into the heart of this transformative AI advancement, focusing on Generative AI. We’ll explore the fundamentals, its historical context, and the recent surge in its capabilities. Additionally, we’ll explain how small businesses can use Generative AI effectively, clearing up any misunderstandings and showing you how to get your hands on these advanced tools. By the end, we are hoping you’ll be in a better position to navigate the AI landscape and position your small business for success in this era of change. ...
2023.09.26.10.27.10;26.09.2023;10;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/customer-surveys-and-feedback-analysis-with-large-language-models/;;;Enhancing Customer Surveys Feedback Analysis with Large Language Models;This article introduces the fusion of AI and customer feedback analysis, exploring how technologies like Natural Language Processing (NLP) and machine learning extract actionable insights. We uncover AI’s transformative potential in enhancing customer satisfaction and driving business triumph. Join us on this enlightening journey as we explore the synergy between AI and optimizing customer experiences. ...
2023.09.26.10.27.11;26.09.2023;11;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1596/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Exploring Machine Learning Techniques to Maximize Efficiency in Construction Industry Electrical and Electronics Engineering Projects;The construction enterprise is a essential zone that contributes considerably to the worldwide financial system. but it faces numerous challenges, together with inefficiency in electric and electronics engineering tasks. This inefficiency results in delays, expanded charges, and decreased productivity. Device learning strategies have the capacity to deal with those challenges through optimizing the making plans and execution of electrical and electronics engineering tasks within the construction industry. This study paper targets to discover using machines gaining knowledge of strategies to maximise efficiency in electrical and electronics engineering projects inside the production industry. Mainly, the paper will be conscious of developing and imposing gadget mastering algorithms to optimize project scheduling, fabric procurement, and system utilization. The paper will even look at the ability of using predictive analytics to identify and mitigate dangers related to electric and electronics engineering tasks. The study could be based on a combination of literature review and empirical analysis. The literature evaluation will provide a top-level view of the demanding situations going through the development industry and the capability advantages of the usage of system getting to know strategies to deal with those challenges. The empirical evaluation will involve the improvement and testing of device mastering models on real-world information from electrical and electronics engineering initiatives inside the construction industry. The predicted results of this research are the development of a fixed of sensible recommendations for the use of machine gaining knowledge of strategies to optimize electric and electronics engineering projects within the construction industry. These suggestions will be beneficial for venture managers, engineers, and other stakeholders within the creation enterprise who're inquisitive about maximizing performance and decreasing charges of their tasks. Ordinary, this studies paper aims to contribute to the continued efforts to enhance the efficiency and productiveness of the development enterprise via exploring the ability of system studying techniques to optimize electrical and electronics engineering tasks.
2023.09.26.10.27.12;26.09.2023;12;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.12781;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12781.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1"">Liming Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mak_S/0/1/0/all/0/1"">Stephen Mak</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schoepf_S/0/1/0/all/0/1"">Stefan Schoepf</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ostroumov_M/0/1/0/all/0/1"">Michael Ostroumov</a>, <a href=""http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1"">Alexandra Brintrup</a>";Liming Xu,Stephen Mak,Stefan Schoepf,Michael Ostroumov,Alexandra Brintrup;AgentChat: Multi-Agent Collaborative Logistics for Carbon Reduction.;Heavy Good Vehicles (HGVs) are the second largest source of greenhouse gas emissions in transportation, after cars and taxis. However, HGVs are inefficiently utilised, with more than one-third of their weight capacity not being used during travel. We, thus, in this paper address collaborative logistics, an effective pathway to enhance HGVs' utilisation and reduce carbon emissions. We investigate a multi-agent system approach to facilitate collaborative logistics, particularly carrier collaboration. We propose a simple yet effective multi-agent collaborative logistics (MACL) framework, representing key stakeholders as intelligent agents. Furthermore, we utilise the MACL framework in conjunction with a proposed system architecture to create an integrated collaborative logistics testbed. This testbed, consisting of a physical system and its digital replica, is a tailored cyber-physical system or digital twin for collaborative logistics. Through a demonstration, we show the utility of the testbed for studying collaborative logistics.
2023.09.26.10.27.13;26.09.2023;13;04;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2308.10309&r=pay;;Lennart AnteFriedrich-Philipp WazinskiAman Saggu;Digital Real Estate in the Metaverse: An Empirical Analysis of Retail Investor Motivations;This paper investigates retail investor motivations for digital real estate ownership in the crypto-metaverse. Utilizing a detailed financial behavior survey of metaverse landowners' intrinsic and extrinsic motivations, we apply principal components analysis to uncover four distinct motivational groups: (1) Aesthetics and Identity, (2) Social and Community, (3) Speculation and Investment, and (4) Innovation and Technology. Our findings reveal that age, education, investment knowledge, risk-taking, and impulsivity significantly influence investor group membership. This research provides valuable insights to investors and developers, underscoring the potential of a platform to attract retail investors with speculative intentions, engagement longevity, and passive or active trading characteristics, contingent on unique crypto-metaverse attributes.
2023.09.26.10.27.14;26.09.2023;14;05;Legal;Legal, Law et al.;arxiv;2309.05074;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.05074.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"">Linyu Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1"">Sihan Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Yang Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1"">Ya Gao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1"">Xiangrui Cai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"">Jiarun Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1"">Wenli Song</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zheli Liu</a>";Linyu Li,Sihan Xu,Yang Liu,Ya Gao,Xiangrui Cai,Jiarun Wu,Wenli Song,Zheli Liu;LiSum: Open Source Software License Summarization with Multi-Task Learning.;Open source software (OSS) licenses regulate the conditions under which users can reuse, modify, and distribute the software legally. However, there exist various OSS licenses in the community, written in a formal language, which are typically long and complicated to understand. In this paper, we conducted a 661-participants online survey to investigate the perspectives and practices of developers towards OSS licenses. The user study revealed an indeed need for an automated tool to facilitate license understanding. Motivated by the user study and the fast growth of licenses in the community, we propose the first study towards automated license summarization. Specifically, we released the first high quality text summarization dataset and designed two tasks, i.e., license text summarization (LTS), aiming at generating a relatively short summary for an arbitrary license, and license term classification (LTC), focusing on the attitude inference towards a predefined set of key license terms (e.g., Distribute). Aiming at the two tasks, we present LiSum, a multi-task learning method to help developers overcome the obstacles of understanding OSS licenses. Comprehensive experiments demonstrated that the proposed jointly training objective boosted the performance on both tasks, surpassing state-of-the-art baselines with gains of at least 5 points w.r.t. F1 scores of four summarization metrics and achieving 95.13% micro average F1 score for classification simultaneously. We released all the datasets, the replication package, and the questionnaires for the community.
2023.09.26.10.27.15;26.09.2023;15;08;Supply Chain;Supply Chains, Transportation et al.;arxiv;2309.12365;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12365.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Tong_C/0/1/0/all/0/1"">Chunan Tong</a>";Chunan Tong;An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking System.;In the context of evolving supply chain management, the significance of efficient inventory management has grown substantially for businesses. However, conventional manual and experience-based approaches often struggle to meet the complexities of modern market demands. This research introduces an intelligent inventory management system to address challenges related to inaccurate data, delayed monitoring, and overreliance on subjective experience in forecasting. The proposed system integrates bar code and distributed flutter application technologies for intelligent perception, alongside comprehensive big data analytics to enable data-driven decision-making. Through meticulous analysis, system design, critical technology exploration, and simulation validation, the effectiveness of the proposed system is successfully demonstrated. The intelligent system facilitates second-level monitoring, high-frequency checks, and artificial intelligence-driven forecasting, consequently enhancing the automation, precision, and intelligence of inventory management. This system contributes to cost reduction and optimized inventory sizes through accurate predictions and informed decisions, ultimately achieving a mutually beneficial scenario. The outcomes of this research offer
2023.09.26.10.27.16;26.09.2023;16;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2309.12645;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12645.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1"">Kesen Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1"">Shuchang Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1"">Qingpeng Cai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1"">Xiangyu Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Ziru Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1"">Dong Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1"">Peng Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1"">Kun Gai</a>";Kesen Zhao,Shuchang Liu,Qingpeng Cai,Xiangyu Zhao,Ziru Liu,Dong Zheng,Peng Jiang,Kun Gai;KuaiSim: A Comprehensive Simulator for Recommender Systems.;Reinforcement Learning (RL)-based recommender systems (RSs) have garnered considerable attention due to their ability to learn optimal recommendation policies and maximize long-term user rewards. However, deploying RL models directly in online environments and generating authentic data through A/B tests can pose challenges and require substantial resources. Simulators offer an alternative approach by providing training and evaluation environments for RS models, reducing reliance on real-world data. Existing simulators have shown promising results but also have limitations such as simplified user feedback, lacking consistency with real-world data, the challenge of simulator evaluation, and difficulties in migration and expansion across RSs. To address these challenges, we propose KuaiSim, a comprehensive user environment that provides user feedback with multi-behavior and cross-session responses. The resulting simulator can support three levels of recommendation problems: the request level list-wise recommendation task, the whole-session level sequential recommendation task, and the cross-session level retention optimization task. For each task, KuaiSim also provides evaluation protocols and baseline recommendation algorithms that further serve as benchmarks for future research. We also restructure existing competitive simulators on the KuaiRand Dataset and compare them against KuaiSim to future assess their performance and behavioral differences. Furthermore, to showcase KuaiSim's flexibility in accommodating different datasets, we demonstrate its versatility and robustness when deploying it on the ML-1m dataset.
2023.09.26.10.27.17;26.09.2023;17;16;Human;Human Resource, Personal Assistance et al.;repec;;http://nep.repec.org/rss/nep-tid.rss.xml;http://d.repec.org/n?u=RePEc:ilo:ilowps:995324892702676&r=tid;;Gmyrek, Pawel,Berg, Janine,Bescond, David,;Generative AI and jobs a global analysis of potential effects on job quantity and quality;This study assesses the potential global exposure of occupations to Generative AI, particularly GPT-4. It predicts that the overwhelming effect of the technology will be to augment occupations, rather than to automate them. The greatest impact is likely to be in high and upper-middle income countries due to a higher share of employment in clerical occupations. As clerical jobs are an important source of female employment, the effects are highly gendered. Insights from this study underline the need for proactive policies that focus on job quality, ensure fair transitions, and that are based on dialogue and adequate regulation.
2023.09.26.10.27.18;26.09.2023;18;16;Human;Human Resource, Personal Assistance et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1698/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Evaluating the Sustainable Human Resource Management in Manufacturing Firms Using Single-Valued Neutrosophic Distance Measure-Based RANCOM-AROMAN Model;Along with the economic growth, the companies must contribute to social progress and promote environmental sustainability in equal harmony. Sustainable human resource management (SHRM) strategies make it possible to attain the economic, social and environmental goals of a firm. In this regard, a survey method is discussed using the literature review and online questionnaire to identify the main factors/indicators during the SHRM evaluation of manufacturing firms in India. Uncertainty is commonly occurred in the assessment of SHRM factors. As a generalized version of fuzzy sets, single-valued neutrosophic set (SVNS) has been demonstrated as a valuable tool to illustrate the indeterminate, inconsistent and uncertain data of realistic decision-making problems. Considering the idea of SVNSs, this study develops a hybrid multi-criteria group decision-making (MCGDM) approach for assessing the SHRM of manufacturing firms under uncertainty settings. For this purpose, an SVN-alternative ranking order method accounting for two-step normalization (AROMAN) is proposed based on VIFI-score function-based decision experts’ (DEs’) weighting tool and integrated criteria weight-determining model to solve the MCGDM problems with fully unknown DEs and criteria weights. In this regard, we develop new SVN-distance measure to compute the degree of difference between SVNSs. Some examples are presented to demonstrate the efficacy of developed measure over the existing ones. In addition, new criteria weight-determination model is presented with the integration of objective weights through IVIF-distance measure-based model and subjective weights through ranking comparison (RANCOM) tool on SVNSs. The proposed ranking method is applied to an empirical study of SHRM assessment for manufacturing firms in India, which shows its applicability and feasibility. In this study, the evaluation criteria are characterized into social, environmental and economic aspects with DE’s opinions. Comparative and sensitivity analyses are made to show the strength and steadiness of presented approach. This study provides an innovative MCGDM analysis framework, which makes a significant contribution to the SHRM assessment problem under indeterminate, inconsistent and uncertain setting.
2023.09.26.10.27.19;26.09.2023;19;16;Human;Human Resource, Personal Assistance et al.;arxiv;2309.12320;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12320.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Cassidy_D/0/1/0/all/0/1"">Dara Cassidy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Borgne_Y/0/1/0/all/0/1"">Yann-A&#xeb;l Le Borgne</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bellas_F/0/1/0/all/0/1"">Francisco Bellas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vuorikari_R/0/1/0/all/0/1"">Riina Vuorikari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rondin_E/0/1/0/all/0/1"">Elise Rondin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1"">Madhumalti Sharma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Niewint_Gori_J/0/1/0/all/0/1"">Jessica Niewint-Gori</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gropler_J/0/1/0/all/0/1"">Johanna Gr&#xf6;pler</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gilleran_A/0/1/0/all/0/1"">Anne Gilleran</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kralj_L/0/1/0/all/0/1"">Lidija Kralj</a>";Dara Cassidy,Yann-Aël Le Borgne,Francisco Bellas,Riina Vuorikari,Elise Rondin,Madhumalti Sharma,Jessica Niewint-Gori,Johanna Gröpler,Anne Gilleran,Lidija Kralj;Use Scenarios & Practical Examples of AI Use in Education.;This report presents a set of use scenarios based on existing resources that teachers can use as inspiration to create their own, with the aim of introducing artificial intelligence (AI) at different pre-university levels, and with different goals. The Artificial Intelligence Education field (AIEd) is very active, with new resources and tools arising continuously. Those included in this document have already been tested with students and selected by experts in the field, but they must be taken just as practical examples to guide and inspire teachers creativity.
2023.09.26.10.27.20;26.09.2023;20;16;Human;Human Resource, Personal Assistance et al.;arxiv;2309.12332;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12332.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Mello_R/0/1/0/all/0/1"">Rafael Ferreira Mello</a>, <a href=""http://arxiv.org/find/cs/1/au:+Freitas_E/0/1/0/all/0/1"">Elyda Freitas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pereira_F/0/1/0/all/0/1"">Filipe Dwan Pereira</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cabral_L/0/1/0/all/0/1"">Luciano Cabral</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tedesco_P/0/1/0/all/0/1"">Patricia Tedesco</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ramalho_G/0/1/0/all/0/1"">Geber Ramalho</a>";Rafael Ferreira Mello,Elyda Freitas,Filipe Dwan Pereira,Luciano Cabral,Patricia Tedesco,Geber Ramalho;Education in the age of Generative AI: Context and Recent Developments.;With the emergence of generative artificial intelligence, an increasing number of individuals and organizations have begun exploring its potential to enhance productivity and improve product quality across various sectors. The field of education is no exception. However, it is vital to notice that artificial intelligence adoption in education dates back to the 1960s. In light of this historical context, this white paper serves as the inaugural piece in a four-part series that elucidates the role of AI in education. The series delves into topics such as its potential, successful applications, limitations, ethical considerations, and future trends. This initial article provides a comprehensive overview of the field, highlighting the recent developments within the generative artificial intelligence sphere.
2023.09.26.10.27.21;26.09.2023;21;20;Information;Knowledge, Understanding, Information etc.;arxiv;2305.16052;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.16052.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Tsoy_N/0/1/0/all/0/1"">Nikita Tsoy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Konstantinov_N/0/1/0/all/0/1"">Nikola Konstantinov</a>";Nikita Tsoy,Nikola Konstantinov;Strategic Data Sharing between Competitors.;Collaborative learning techniques have significantly advanced in recent years, enabling private model training across multiple organizations. Despite this opportunity, firms face a dilemma when considering data sharing with competitors -- while collaboration can improve a company's machine learning model, it may also benefit competitors and hence reduce profits. In this work, we introduce a general framework for analyzing this data-sharing trade-off. The framework consists of three components, representing the firms' production decisions, the effect of additional data on model quality, and the data-sharing negotiation process, respectively. We then study an instantiation of the framework, based on a conventional market model from economic theory, to identify key factors that affect collaboration incentives. Our findings indicate a profound impact of market conditions on the data-sharing incentives. In particular, we find that reduced competition, in terms of the similarities between the firms' products, and harder learning tasks foster collaboration.
2023.09.26.10.27.22;26.09.2023;22;21;Software;Development, Software Engineering et al.;arxiv;2309.12732;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12732.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Moussiades_L/0/1/0/all/0/1"">Lefteris Moussiades</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zografos_G/0/1/0/all/0/1"">George Zografos</a>";Lefteris Moussiades,George Zografos;OpenAi's GPT4 as coding assistant.;Lately, Large Language Models have been widely used in code generation. GPT4 is considered the most potent Large Language Model from Openai. In this paper, we examine GPT3.5 and GPT4 as coding assistants. More specifically, we have constructed appropriate tests to check whether the two systems can a) answer typical questions that can arise during the code development, b) produce reliable code, and c) contribute to code debugging. The test results are impressive. The performance of GPT4 is outstanding and signals an increase in the productivity of programmers and the reorganization of software development procedures based on these new tools.
2023.09.26.10.27.23;26.09.2023;23;21;Software;Development, Software Engineering et al.;arxiv;2309.12813;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12813.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Eniser_H/0/1/0/all/0/1"">Hasan Ferit Eniser</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wustholz_V/0/1/0/all/0/1"">Valentin W&#xfc;stholz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Christakis_M/0/1/0/all/0/1"">Maria Christakis</a>";Hasan Ferit Eniser,Valentin Wüstholz,Maria Christakis;Automatically Testing Functional Properties of Code Translation Models.;"Large language models are becoming increasingly practical for translating code across programming languages, a process known as $transpiling$. Even though automated transpilation significantly boosts developer productivity, a key concern is whether the generated code is correct. Existing work initially used manually crafted test suites to test the translations of a small corpus of programs; these test suites were later automated. In contrast, we devise the first approach for automated, functional, property-based testing of code translation models. Our general, user-provided specifications about the transpiled code capture a range of properties, from purely syntactic to purely semantic ones. As shown by our experiments, this approach is very effective in detecting property violations in popular code translation models, and therefore, in evaluating model quality with respect to given properties. We also go a step further and explore the usage scenario where a user simply aims to obtain a correct translation of some code with respect to certain properties without necessarily being concerned about the overall quality of the model. To this purpose, we develop the first property-guided search procedure for code translation models, where a model is repeatedly queried with slightly different parameters to produce alternative and potentially more correct translations. Our results show that this search procedure helps to obtain significantly better code translations."
2023.09.26.10.27.24;26.09.2023;24;21;Software;Development, Software Engineering et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/ai-in-web-development/;;;Top 10 Ways to Use AI in Web Development;Web development integrates creative thinking and building techniques for building and maintaining websites. To create a successful website, you need to have an assortment of coding, web design, and software engineering skills. AI is transforming web development in many different ways. Websites may now customize their data and layout in real-time according to user actions and choices, providing a high level of personalization. ...
2023.09.23.20.17.01;23.09.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.11506;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11506.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lobo_E/0/1/0/all/0/1"">Elita Lobo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hassanzadeh_O/0/1/0/all/0/1"">Oktie Hassanzadeh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pham_N/0/1/0/all/0/1"">Nhan Pham</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1"">Nandana Mihindukulasooriya</a>, <a href=""http://arxiv.org/find/cs/1/au:+Subramanian_D/0/1/0/all/0/1"">Dharmashankar Subramanian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Samulowitz_H/0/1/0/all/0/1"">Horst Samulowitz</a>";Elita Lobo,Oktie Hassanzadeh,Nhan Pham,Nandana Mihindukulasooriya,Dharmashankar Subramanian,Horst Samulowitz;Matching Table Metadata with Business Glossaries Using Large Language Models.;Enterprises often own large collections of structured data in the form of large databases or an enterprise data lake. Such data collections come with limited metadata and strict access policies that could limit access to the data contents and, therefore, limit the application of classic retrieval and analysis solutions. As a result, there is a need for solutions that can effectively utilize the available metadata. In this paper, we study the problem of matching table metadata to a business glossary containing data labels and descriptions. The resulting matching enables the use of an available or curated business glossary for retrieval and analysis without or before requesting access to the data contents. One solution to this problem is to use manually-defined rules or similarity measures on column names and glossary descriptions (or their vector embeddings) to find the closest match. However, such approaches need to be tuned through manual labeling and cannot handle many business glossaries that contain a combination of simple as well as complex and long descriptions. In this work, we leverage the power of large language models (LLMs) to design generic matching methods that do not require manual tuning and can identify complex relations between column names and glossaries. We propose methods that utilize LLMs in two ways: a) by generating additional context for column names that can aid with matching b) by using LLMs to directly infer if there is a relation between column names and glossary descriptions. Our preliminary experimental results show the effectiveness of our proposed methods.
2023.09.23.20.17.02;23.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.11805;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11805.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ghosh_P/0/1/0/all/0/1"">Preetam Ghosh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sadaphal_V/0/1/0/all/0/1"">Vaishali Sadaphal</a>";Preetam Ghosh,Vaishali Sadaphal;JobRecoGPT -- Explainable job recommendations using LLMs.;In today's rapidly evolving job market, finding the right opportunity can be a daunting challenge. With advancements in the field of AI, computers can now recommend suitable jobs to candidates. However, the task of recommending jobs is not same as recommending movies to viewers. Apart from must-have criteria, like skills and experience, there are many subtle aspects to a job which can decide if it is a good fit or not for a given candidate. Traditional approaches can capture the quantifiable aspects of jobs and candidates, but a substantial portion of the data that is present in unstructured form in the job descriptions and resumes is lost in the process of conversion to structured format. As of late, Large Language Models (LLMs) have taken over the AI field by storm with extraordinary performance in fields where text-based data is available. Inspired by the superior performance of LLMs, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form. To this end, we compare performance of four different approaches for job recommendations namely, (i) Content based deterministic, (ii) LLM guided, (iii) LLM unguided, and (iv) Hybrid. In this study, we present advantages and limitations of each method and evaluate their performance in terms of time requirements.
2023.09.23.20.17.03;23.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.12276;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12276.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Torre_F/0/1/0/all/0/1"">Fernanda De La Torre</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1"">Cathy Mengying Fang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1"">Han Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Banburski_Fahey_A/0/1/0/all/0/1"">Andrzej Banburski-Fahey</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fernandez_J/0/1/0/all/0/1"">Judith Amores Fernandez</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lanier_J/0/1/0/all/0/1"">Jaron Lanier</a>";Fernanda De La Torre,Cathy Mengying Fang,Han Huang,Andrzej Banburski-Fahey,Judith Amores Fernandez,Jaron Lanier;LLMR: Real-time Prompting of Interactive Worlds using Large Language Models.;We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.
2023.09.23.20.17.04;23.09.2023;04;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.11504;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2309.11504.pdf;" <a href=""http://arxiv.org/find/stat/1/au:+Hajri_A/0/1/0/all/0/1"">Alaeddine Hajri</a>, <a href=""http://arxiv.org/find/stat/1/au:+Garay_Martinez_R/0/1/0/all/0/1"">Roberto Garay-Martinez</a>, <a href=""http://arxiv.org/find/stat/1/au:+Macarulla_A/0/1/0/all/0/1"">Ana Maria Macarulla</a>, <a href=""http://arxiv.org/find/stat/1/au:+Sassi_M/0/1/0/all/0/1"">Mohamed Amin Ben Sassi</a>";Alaeddine Hajri,Roberto Garay-Martinez,Ana Maria Macarulla,Mohamed Amin Ben Sassi;Data-Driven Model For Heat Load Prediction In Buildings Connected To District Heating Networks.;In this study we investigate the heat load patterns in one building using multi-step forecasting model. We combine the Autoregressive models that use multiple eXogenous variables (ARX) with Seasonally adaptable Time of Week and Climate dependent models (S-TOW-C) (to correct model inaccuracies), to obtain a robust and accurate regression model that we called S-TOW-C-ARX used in time series forecasting. Based on the experiment results, it has been shown that the proposed model is suitable for short term heat load forecasting. The best forecasting performance is achieved in winter term where the prediction values are from 4 to 20 % away from the targets, which are commonly seen as very good values.
2023.09.23.20.17.05;23.09.2023;05;04;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2308.02820&r=big;;Xianhua PengChenyin GongXue Dong He;Reinforcement Learning for Financial Index Tracking;We propose the first discrete-time infinite-horizon dynamic formulation of the financial index tracking problem under both return-based tracking error and value-based tracking error. The formulation overcomes the limitations of existing models by incorporating the intertemporal dynamics of market information variables not limited to prices, allowing exact calculation of transaction costs, accounting for the tradeoff between overall tracking error and transaction costs, allowing effective use of data in a long time period, etc. The formulation also allows novel decision variables of cash injection or withdraw. We propose to solve the portfolio rebalancing equation using a Banach fixed point iteration, which allows to accurately calculate the transaction costs specified as nonlinear functions of trading volumes in practice. We propose an extension of deep reinforcement learning (RL) method to solve the dynamic formulation. Our RL method resolves the issue of data limitation resulting from the availability of a single sample path of financial data by a novel training scheme. A comprehensive empirical study based on a 17-year-long testing set demonstrates that the proposed method outperforms a benchmark method in terms of tracking accuracy and has the potential for earning extra profit through cash withdraw strategy.
2023.09.23.20.17.06;23.09.2023;06;05;Legal;Legal, Law et al.;arxiv;2309.12132;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.12132.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1"">Chunmo Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wong_S/0/1/0/all/0/1"">Saika Wong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1"">Xing Su</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1"">Yinqiu Tang</a>";Chunmo Zheng,Saika Wong,Xing Su,Yinqiu Tang;A knowledge representation approach for construction contract knowledge modeling.;The emergence of large language models (LLMs) presents an unprecedented opportunity to automate construction contract management, reducing human errors and saving significant time and costs. However, LLMs may produce convincing yet inaccurate and misleading content due to a lack of domain expertise. To address this issue, expert-driven contract knowledge can be represented in a structured manner to constrain the automatic contract management process. This paper introduces the Nested Contract Knowledge Graph (NCKG), a knowledge representation approach that captures the complexity of contract knowledge using a nested structure. It includes a nested knowledge representation framework, a NCKG ontology built on the framework, and an implementation method. Furthermore, we present the LLM-assisted contract review pipeline enhanced with external knowledge in NCKG. Our pipeline achieves a promising performance in contract risk reviewing, shedding light on the combination of LLM and KG towards more reliable and interpretable contract management.
2023.09.23.20.17.07;23.09.2023;07;07;Industry;I4.0, Production et al.;arxiv;2309.11509;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11509.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"">Xia Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1"">Ruiji Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Saluz_U/0/1/0/all/0/1"">Ueli Saluz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schiavon_S/0/1/0/all/0/1"">Stefano Schiavon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Geyer_P/0/1/0/all/0/1"">Philipp Geyer</a>";Xia Chen,Ruiji Sun,Ueli Saluz,Stefano Schiavon,Philipp Geyer;Using causal inference to avoid fallouts in data-driven parametric analysis: a case study in the architecture, engineering, and construction industry.;"The decision-making process in real-world implementations has been affected by a growing reliance on data-driven models. We investigated the synergetic pattern between the data-driven methods, empirical domain knowledge, and first-principles simulations. We showed the potential risk of biased results when using data-driven models without causal analysis. Using a case study assessing the implication of several design solutions on the energy consumption of a building, we proved the necessity of causal analysis during the data-driven modeling process. We concluded that: (a) Data-driven models' accuracy assessment or domain knowledge screening may not rule out biased and spurious results; (b) Data-driven models' feature selection should involve careful consideration of causal relationships, especially colliders; (c) Causal analysis results can be used as an aid to first-principles simulation design and parameter checking to avoid cognitive biases. We proved the benefits of causal analysis when applied to data-driven models in building engineering."
2023.09.23.20.17.08;23.09.2023;08;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2309.12122;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2309.12122.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Shota_I/0/1/0/all/0/1"">Ichihashi Shota</a>, <a href=""http://arxiv.org/find/econ/1/au:+Alex_S/0/1/0/all/0/1"">Smolin Alex</a>";Ichihashi Shota,Smolin Alex;Buyer-Optimal Algorithmic Consumption.;We analyze a bilateral trade model in which the buyer's value for the product and the seller's costs are uncertain, the seller chooses the product price, and the product is recommended by an algorithm based on its value and price. We characterize an algorithm that maximizes the buyer's expected payoff and show that the optimal algorithm underrecommends the product at high prices and overrecommends at low prices. Higher algorithm precision increases the maximal equilibrium price and may increase prices across all of the seller's costs, whereas informing the seller about the buyer's value results in a mean-preserving spread of equilibrium prices and a mean-preserving contraction of the buyer's payoff.
2023.09.23.20.17.09;23.09.2023;09;16;Human;Human Resource, Personal Assistance et al.;arxiv;2309.11599;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11599.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Kadoma_K/0/1/0/all/0/1"">Kowe Kadoma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Quere_M/0/1/0/all/0/1"">Marianne Aubin Le Quere</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1"">Jenny Fu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Munsch_C/0/1/0/all/0/1"">Christin Munsch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Metaxa_D/0/1/0/all/0/1"">Danae Metaxa</a>, <a href=""http://arxiv.org/find/cs/1/au:+Naaman_M/0/1/0/all/0/1"">Mor Naaman</a>";Kowe Kadoma,Marianne Aubin Le Quere,Jenny Fu,Christin Munsch,Danae Metaxa,Mor Naaman;The Role of Inclusion, Control, and Ownership in Workplace AI-Mediated Communication.;Large language models (LLMs) can exhibit social biases. Given LLMs' increasing integration into workplace software, these biases may impact workers' well-being and may disproportionately impact minoritized communities. This short paper investigates how co-writing with an LLM impacts three measures related to user's well-being: feelings of inclusion, control, and ownership over their work. In an online experiment, participants wrote hypothetical job promotion requests to their boss and using either hesitant or self-assured auto-complete suggestions from an LLM. Afterward, participants reported their feelings of inclusion, control, and ownership. We found that the style of the AI model did not impact perceived inclusion. Furthermore, individuals with higher perceived inclusion also perceived greater agency and ownership, an effect more strongly impacting participants of minoritized genders. Lastly, feelings of inclusion can mitigate a loss of control and agency when accepting more AI suggestions. Future work should explore feelings of inclusion in AI-written communication.
2023.09.23.20.17.10;23.09.2023;10;99;Other;Others;arxiv;2309.11941;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11941.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Vigne_R/0/1/0/all/0/1"">Ralph Vigne</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mangler_J/0/1/0/all/0/1"">Juergen Mangler</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schikuta_E/0/1/0/all/0/1"">Erich Schikuta</a>";Ralph Vigne,Juergen Mangler,Erich Schikuta;A Digital Marketplace Combining WS-Agreement, Service Negotiation Protocols and Heterogeneous Services.;With the ever increasing importance of web services and the Cloud as a reliable commodity to provide business value as well as consolidate IT infrastructure, electronic contracts have become very important. WS-Agreement has itself established as a well accepted container format for describing such contracts. However, the semantic interpretation of the terms contained in these contracts, as well as the process of agreeing to contracts when multiple options have to be considered (negotiation), are still pretty much dealt with on a case by case basis. In this paper we address the issues of diverging contracts and varying contract negotiation protocols by introducing the concept of a contract aware marketplace, which abstracts from the heterogeneous offers of different services providers. This allows for the automated consumption of services solely based on preferences, instead of additional restrictions such as understanding of contract terms and/or negotiation protocols. We also contribute an evaluation of several existing negotiation concepts/protocols. We think that reducing the complexity for automated contract negotiation and thus service consumption is a key for the success of future service and Cloud infrastructures.
2023.09.22.16.10.01;22.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;towardsdatascience;;;https://towardsdatascience.com/can-chatgpt-solve-knapsack-problems-1a9a388c4caf?source=rss----7f60cf5620c9---4;;;Can ChatGPT solve knapsack problems?;Ever since the emergence of ChatGPT, I’ve been thinking about how ChatGPT would influence the world of optimization and Operations Research (OR). There has been news about ChatGPT passing high school and undergraduate level math exams, which piques my interest in exploring how well it can do on solving OR problems. In this article, I will use a classic OR problem — 0/1 knapsack problem to run some tests. ...
2023.09.22.16.10.02;22.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.11436;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11436.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhan_Z/0/1/0/all/0/1"">Zhuosheng Zhan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1"">Aston Zhang</a>";Zhuosheng Zhan,Aston Zhang;You Only Look at Screens: Multimodal Chain-of-Action Agents.;Autonomous user interface (UI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To align with the input-output requirement of LLMs, existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions. Consequently, those approaches often grapple with inference inefficiency and error propagation risks. To mitigate the challenges, we introduce Auto-UI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs. Moreover, we propose a chain-of-action technique -- leveraging a series of intermediate previous action histories and future action plans -- to help the agent decide what action to execute. We evaluate our approach on a new device-control benchmark AITW with 30K unique instructions, spanning multi-step tasks such as application operation, web searching, and web shopping. Experimental results show that Auto-UI achieves state-of-the-art performance with an action type prediction accuracy of 90% and an overall action success rate of 74%. Code is publicly available at https://github.com/cooelf/Auto-UI.
2023.09.22.16.10.03;22.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.11456;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11456.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ghaffarzadegan_N/0/1/0/all/0/1"">Navid Ghaffarzadegan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Majumdar_A/0/1/0/all/0/1"">Aritra Majumdar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Williams_R/0/1/0/all/0/1"">Ross Williams</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hosseinichimeh_N/0/1/0/all/0/1"">Niyousha Hosseinichimeh</a>";Navid Ghaffarzadegan,Aritra Majumdar,Ross Williams,Niyousha Hosseinichimeh;Generative Agent-Based Modeling: Unveiling Social System Dynamics through Coupling Mechanistic Models with Generative Artificial Intelligence.;We discuss the emerging new opportunity for building feedback-rich computational models of social systems using generative artificial intelligence. Referred to as Generative Agent-Based Models (GABMs), such individual-level models utilize large language models such as ChatGPT to represent human decision-making in social settings. We provide a GABM case in which human behavior can be incorporated in simulation models by coupling a mechanistic model of human interactions with a pre-trained large language model. This is achieved by introducing a simple GABM of social norm diffusion in an organization. For educational purposes, the model is intentionally kept simple. We examine a wide range of scenarios and the sensitivity of the results to several changes in the prompt. We hope the article and the model serve as a guide for building useful diffusion models that include realistic human reasoning and decision-making.
2023.09.22.16.10.04;22.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.11231;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11231.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Berrezueta_Guzman_J/0/1/0/all/0/1"">Jonnathan Berrezueta-Guzman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Malache_Silva_L/0/1/0/all/0/1"">Laura Malache-Silva</a>, <a href=""http://arxiv.org/find/cs/1/au:+Krusche_S/0/1/0/all/0/1"">Stephan Krusche</a>";Jonnathan Berrezueta-Guzman,Laura Malache-Silva,Stephan Krusche;ChatGPT-4 as a Tool for Reviewing Academic Books in Spanish.;This study evaluates the potential of ChatGPT-4, an artificial intelligence language model developed by OpenAI, as an editing tool for Spanish literary and academic books. The need for efficient and accessible reviewing and editing processes in the publishing industry has driven the search for automated solutions. ChatGPT-4, being one of the most advanced language models, offers notable capabilities in text comprehension and generation. In this study, the features and capabilities of ChatGPT-4 are analyzed in terms of grammatical correction, stylistic coherence, and linguistic enrichment of texts in Spanish. Tests were conducted with 100 literary and academic texts, where the edits made by ChatGPT-4 were compared to those made by expert human reviewers and editors. The results show that while ChatGPT-4 is capable of making grammatical and orthographic corrections with high accuracy and in a very short time, it still faces challenges in areas such as context sensitivity, bibliometric analysis, deep contextual understanding, and interaction with visual content like graphs and tables. However, it is observed that collaboration between ChatGPT-4 and human reviewers and editors can be a promising strategy for improving efficiency without compromising quality. Furthermore, the authors consider that ChatGPT-4 represents a valuable tool in the editing process, but its use should be complementary to the work of human editors to ensure high-caliber editing in Spanish literary and academic books.
2023.09.22.16.10.05;22.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.11295;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11295.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shoham_O/0/1/0/all/0/1"">Ofir Ben Shoham</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rappoport_N/0/1/0/all/0/1"">Nadav Rappoport</a>";Ofir Ben Shoham,Nadav Rappoport;CPLLM: Clinical Prediction with Large Language Models.;We present Clinical Prediction with Large Language Models (CPLLM), a method that involves fine-tuning a pre-trained Large Language Model (LLM) for clinical disease prediction. We utilized quantization and fine-tuned the LLM using prompts, with the task of predicting whether patients will be diagnosed with a target disease during their next visit or in the subsequent diagnosis, leveraging their historical diagnosis records. We compared our results versus various baselines, including Logistic Regression, RETAIN, and Med-BERT, which is the current state-of-the-art model for disease prediction using structured EHR data. Our experiments have shown that CPLLM surpasses all the tested models in terms of both PR-AUC and ROC-AUC metrics, displaying noteworthy enhancements compared to the baseline models.
2023.09.22.16.10.06;22.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.11359;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11359.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1"">Jingkai Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1"">Qiang Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1"">Yiqun Duan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1"">Xiaoyang Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1"">Chong Cheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1"">Renjing Xu</a>";Jingkai Sun,Qiang Zhang,Yiqun Duan,Xiaoyang Jiang,Chong Cheng,Renjing Xu;Prompt, Plan, Perform: LLM-based Humanoid Control via Quantized Imitation Learning.;In recent years, reinforcement learning and imitation learning have shown great potential for controlling humanoid robots' motion. However, these methods typically create simulation environments and rewards for specific tasks, resulting in the requirements of multiple policies and limited capabilities for tackling complex and unknown tasks. To overcome these issues, we present a novel approach that combines adversarial imitation learning with large language models (LLMs). This innovative method enables the agent to learn reusable skills with a single policy and solve zero-shot tasks under the guidance of LLMs. In particular, we utilize the LLM as a strategic planner for applying previously learned skills to novel tasks through the comprehension of task-specific prompts. This empowers the robot to perform the specified actions in a sequence. To improve our model, we incorporate codebook-based vector quantization, allowing the agent to generate suitable actions in response to unseen textual commands from LLMs. Furthermore, we design general reward functions that consider the distinct motion features of humanoid robots, ensuring the agent imitates the motion data while maintaining goal orientation without additional guiding direction approaches or policies. To the best of our knowledge, this is the first framework that controls humanoid robots using a single learning policy network and LLM as a planner. Extensive experiments demonstrate that our method exhibits efficient and adaptive ability in complicated motion tasks.
2023.09.22.16.10.07;22.09.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.11385;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11385.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Cifarelli_D/0/1/0/all/0/1"">Davide Cifarelli</a>, <a href=""http://arxiv.org/find/cs/1/au:+Boiardi_L/0/1/0/all/0/1"">Leonardo Boiardi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Puppo_A/0/1/0/all/0/1"">Alessandro Puppo</a>";Davide Cifarelli,Leonardo Boiardi,Alessandro Puppo;Safurai 001: New Qualitative Approach for Code LLM Evaluation.;This paper presents Safurai-001, a new Large Language Model (LLM) with significant potential in the domain of coding assistance. Driven by recent advancements in coding LLMs, Safurai-001 competes in performance with the latest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al., 2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more conversational interaction. By capitalizing on the progress in data engineering (including latest techniques of data transformation and prompt engineering) and instruction tuning, this new model promises to stand toe-to-toe with recent closed and open source developments. Recognizing the need for an efficacious evaluation metric for coding LLMs, this paper also introduces GPT4-based MultiParameters, an evaluation benchmark that harnesses varied parameters to present a comprehensive insight into the models functioning and performance. Our assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and WizardCoder by 18.78% in the Code Readability parameter and more.
2023.09.22.16.10.08;22.09.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/how-i-use-chatgpt-as-an-llm-engineer-to-create-projects-fast-fb201f976b1b?source=rss----98111c9905da---4;;;How I Use ChatGPT as an LLM Engineer to Create Projects Fast;So let’s build a full-stack project with ReactJS and Flask relying entirely on clear prompts and ChatGPT’s responses! ...
2023.09.22.16.10.09;22.09.2023;09;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.11039;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11039.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"">Shiying Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Jun Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1"">Long Shi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1"">Ming Ding</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1"">Dinh C. Nguyen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1"">Wuzheng Tan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Weng_J/0/1/0/all/0/1"">Jian Weng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1"">Zhu Han</a>";Shiying Zhang,Jun Li,Long Shi,Ming Ding,Dinh C. Nguyen,Wuzheng Tan,Jian Weng,Zhu Han;Federated Learning in Intelligent Transportation Systems: Recent Applications and Open Problems.;Intelligent transportation systems (ITSs) have been fueled by the rapid development of communication technologies, sensor technologies, and the Internet of Things (IoT). Nonetheless, due to the dynamic characteristics of the vehicle networks, it is rather challenging to make timely and accurate decisions of vehicle behaviors. Moreover, in the presence of mobile wireless communications, the privacy and security of vehicle information are at constant risk. In this context, a new paradigm is urgently needed for various applications in dynamic vehicle environments. As a distributed machine learning technology, federated learning (FL) has received extensive attention due to its outstanding privacy protection properties and easy scalability. We conduct a comprehensive survey of the latest developments in FL for ITS. Specifically, we initially research the prevalent challenges in ITS and elucidate the motivations for applying FL from various perspectives. Subsequently, we review existing deployments of FL in ITS across various scenarios, and discuss specific potential issues in object recognition, traffic management, and service providing scenarios. Furthermore, we conduct a further analysis of the new challenges introduced by FL deployment and the inherent limitations that FL alone cannot fully address, including uneven data distribution, limited storage and computing power, and potential privacy and security concerns. We then examine the existing collaborative technologies that can help mitigate these challenges. Lastly, we discuss the open challenges that remain to be addressed in applying FL in ITS and propose several future research directions.
2023.09.22.16.10.10;22.09.2023;10;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.11400;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11400.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Bilokon_P/0/1/0/all/0/1"">Paul Bilokon</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Qiu_Y/0/1/0/all/0/1"">Yitao Qiu</a>";Paul Bilokon,Yitao Qiu;Transformers versus LSTMs for electronic trading.;With the rapid development of artificial intelligence, long short term memory (LSTM), one kind of recurrent neural network (RNN), has been widely applied in time series prediction. Like RNN, Transformer is designed to handle the sequential data. As Transformer achieved great success in Natural Language Processing (NLP), researchers got interested in Transformer's performance on time series prediction, and plenty of Transformer-based solutions on long time series forecasting have come out recently. However, when it comes to financial time series prediction, LSTM is still a dominant architecture. Therefore, the question this study wants to answer is: whether the Transformer-based model can be applied in financial time series prediction and beat LSTM. To answer this question, various LSTM-based and Transformer-based models are compared on multiple financial prediction tasks based on high-frequency limit order book data. A new LSTM-based model called DLSTM is built and new architecture for the Transformer-based model is designed to adapt for financial prediction. The experiment result reflects that the Transformer-based model only has the limited advantage in absolute price sequence prediction. The LSTM-based models show better and more robust performance on difference sequence prediction, such as price difference and price movement.
2023.09.22.16.10.11;22.09.2023;11;05;Legal;Legal, Law et al.;arxiv;2309.11325;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11325.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1"">Shengbin Yue</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1"">Wei Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Siyuan Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1"">Bingxuan Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1"">Chenchen Shen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1"">Shujun Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1"">Yuxuan Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1"">Yao Xiao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1"">Song Yun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1"">Wei Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1"">Xuanjing Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1"">Zhongyu Wei</a>";Shengbin Yue,Wei Chen,Siyuan Wang,Bingxuan Li,Chenchen Shen,Shujun Liu,Yuxuan Zhou,Yao Xiao,Song Yun,Wei Lin,Xuanjing Huang,Zhongyu Wei;DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal Services.;We propose DISC-LawLLM, an intelligent legal system utilizing large language models (LLMs) to provide a wide range of legal services. We adopt legal syllogism prompting strategies to construct supervised fine-tuning datasets in the Chinese Judicial domain and fine-tune LLMs with legal reasoning capability. We augment LLMs with a retrieval module to enhance models' ability to access and utilize external legal knowledge. A comprehensive legal benchmark, DISC-Law-Eval, is presented to evaluate intelligent legal systems from both objective and subjective dimensions. Quantitative and qualitative results on DISC-Law-Eval demonstrate the effectiveness of our system in serving various users across diverse legal scenarios. The detailed resources are available at https://github.com/FudanDISC/DISC-LawLLM.
2023.09.22.16.10.12;22.09.2023;12;07;Industry;I4.0, Production et al.;arxiv;2309.11267;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11267.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Forest_F/0/1/0/all/0/1"">Florent Forest</a>, <a href=""http://arxiv.org/find/cs/1/au:+Porta_H/0/1/0/all/0/1"">Hugo Porta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tuia_D/0/1/0/all/0/1"">Devis Tuia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fink_O/0/1/0/all/0/1"">Olga Fink</a>";Florent Forest,Hugo Porta,Devis Tuia,Olga Fink;From Classification to Segmentation with Explainable AI: A Study on Crack Detection and Growth Monitoring.;Monitoring surface cracks in infrastructure is crucial for structural health monitoring. Automatic visual inspection offers an effective solution, especially in hard-to-reach areas. Machine learning approaches have proven their effectiveness but typically require large annotated datasets for supervised training. Once a crack is detected, monitoring its severity often demands precise segmentation of the damage. However, pixel-level annotation of images for segmentation is labor-intensive. To mitigate this cost, one can leverage explainable artificial intelligence (XAI) to derive segmentations from the explanations of a classifier, requiring only weak image-level supervision. This paper proposes applying this methodology to segment and monitor surface cracks. We evaluate the performance of various XAI methods and examine how this approach facilitates severity quantification and growth monitoring. Results reveal that while the resulting segmentation masks may exhibit lower quality than those produced by supervised methods, they remain meaningful and enable severity monitoring, thus reducing substantial labeling costs.
2023.09.22.16.10.13;22.09.2023;13;08;Supply Chain;Supply Chains, Transportation et al.;repec;;http://nep.repec.org/rss/nep-cfn.rss.xml;http://d.repec.org/n?u=RePEc:hal:journl:hal-03373718&r=cfn;;Franck MorauxD.A. PhanThi Le Hoa Vo;Financing and Cost Sharing for a Supply Chain Under CSR - Sensitive Demand;Downstream firms nowadays adopt either financing or cost sharing (CS) mechanisms to enhance the corporate social responsibility (CSR) performance of their suppliers. In this paper, we are interested in combining these two mechanisms in a supply chain. We consider a supply chain where the demand is CSR-dependent and where a large retailer shares the costs of CSR activities undertaken by a SME supplier. We investigate how the retailer's choice of two financing mechanisms, namely Bank Financing (BF) and Reverse Factoring (RF), can influence the various operational decisions of both parties and the performance of the supply chain. Our findings demonstrate that no matter which financing mechanism is applied (BF or RF), CS leads to higher CSR effort and higher profits for all supply chain members. Moreover, a CS contract affects the financing preferences of both the retailer and the supplier. Managerially, a CS contract combined with an appropriate financing mechanism help to improve the CSR performance and the profitability of a supply chain. © 2021, IFIP International Federation for Information Processing.
2023.09.22.16.10.14;22.09.2023;14;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2006.04313;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2006.04313.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Torrico_A/0/1/0/all/0/1"">Alfredo Torrico</a>, <a href=""http://arxiv.org/find/cs/1/au:+Carvalho_M/0/1/0/all/0/1"">Margarida Carvalho</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lodi_A/0/1/0/all/0/1"">Andrea Lodi</a>";Alfredo Torrico,Margarida Carvalho,Andrea Lodi;Multi-agent Assortment Optimization in Sequential Matching Markets.;In this work, we study the multi-agent assortment optimization problem in the two-sided sequential matching model introduced by Ashlagi et al. (2022). The setting is the following: we (the platform) offer a menu of suppliers to each customer. Then, every customer selects, simultaneously and independently, to match with a supplier or to remain unmatched. Each supplier observes the subset of customers that selected them, and choose either to match a customer or to leave the system. Therefore, a match takes place if both a customer and a supplier sequentially select each other. Each agent's behavior is probabilistic and determined by a discrete choice model. Our goal is to choose an assortment family that maximizes the expected revenue of the matching. Given the hardness of the problem, we show a $1-1/e$-approximation factor for the heterogeneous setting where customers follow general choice models and suppliers follow a general choice model whose demand function is monotone and submodular. Our approach is flexible enough to allow for different assortment constraints and for a revenue objective function. Furthermore, we design an algorithm that beats the $1-1/e$ barrier and, in fact, is asymptotically optimal when suppliers follow the classic multinomial-logit choice model and are sufficiently selective. We finally provide other results and further insights. Notably, in the unconstrained setting where customers and suppliers follow multinomial-logit models, we design a simple and efficient approximation algorithm that appropriately randomizes over a family of nested-assortments. Also, we analyze various aspects of the matching market model that lead to several operational insights, such as the fact that matching platforms can benefit from allowing the more selective agents to initiate the matchmaking process.
2023.09.22.16.10.15;22.09.2023;15;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.10895;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10895.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Mehandru_N/0/1/0/all/0/1"">Nikita Mehandru</a>, <a href=""http://arxiv.org/find/cs/1/au:+Miao_B/0/1/0/all/0/1"">Brenda Y. Miao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Almaraz_E/0/1/0/all/0/1"">Eduardo Rodriguez Almaraz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sushil_M/0/1/0/all/0/1"">Madhumita Sushil</a>, <a href=""http://arxiv.org/find/cs/1/au:+Butte_A/0/1/0/all/0/1"">Atul J. Butte</a>, <a href=""http://arxiv.org/find/cs/1/au:+Alaa_A/0/1/0/all/0/1"">Ahmed Alaa</a>";Nikita Mehandru,Brenda Y. Miao,Eduardo Rodriguez Almaraz,Madhumita Sushil,Atul J. Butte,Ahmed Alaa;Large Language Models as Agents in the Clinic.;"Recent developments in large language models (LLMs) have unlocked new opportunities for healthcare, from information synthesis to clinical decision support. These new LLMs are not just capable of modeling language, but can also act as intelligent ""agents"" that interact with stakeholders in open-ended conversations and even influence clinical decision-making. Rather than relying on benchmarks that measure a model's ability to process clinical data or answer standardized test questions, LLM agents should be assessed for their performance on real-world clinical tasks. These new evaluation frameworks, which we call ""Artificial-intelligence Structured Clinical Examinations"" (""AI-SCI""), can draw from comparable technologies where machines operate with varying degrees of self-governance, such as self-driving cars. High-fidelity simulations may also be used to evaluate interactions between users and LLMs within a clinical workflow, or to model the dynamic interactions of multiple LLMs. Developing these robust, real-world clinical evaluations will be crucial towards deploying LLM agents into healthcare."
2023.09.22.16.10.16;22.09.2023;16;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.10980;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10980.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shaik_T/0/1/0/all/0/1"">Thanveer Shaik</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tao_X/0/1/0/all/0/1"">Xiaohui Tao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1"">Haoran Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"">Lin Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yong_J/0/1/0/all/0/1"">Jianming Yong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1"">Hong-Ning Dai</a>";Thanveer Shaik,Xiaohui Tao,Haoran Xie,Lin Li,Jianming Yong,Hong-Ning Dai;AI-Driven Patient Monitoring with Multi-Agent Deep Reinforcement Learning.;Effective patient monitoring is vital for timely interventions and improved healthcare outcomes. Traditional monitoring systems often struggle to handle complex, dynamic environments with fluctuating vital signs, leading to delays in identifying critical conditions. To address this challenge, we propose a novel AI-driven patient monitoring framework using multi-agent deep reinforcement learning (DRL). Our approach deploys multiple learning agents, each dedicated to monitoring a specific physiological feature, such as heart rate, respiration, and temperature. These agents interact with a generic healthcare monitoring environment, learn the patients' behavior patterns, and make informed decisions to alert the corresponding Medical Emergency Teams (METs) based on the level of emergency estimated. In this study, we evaluate the performance of the proposed multi-agent DRL framework using real-world physiological and motion data from two datasets: PPG-DaLiA and WESAD. We compare the results with several baseline models, including Q-Learning, PPO, Actor-Critic, Double DQN, and DDPG, as well as monitoring frameworks like WISEML and CA-MAQL. Our experiments demonstrate that the proposed DRL approach outperforms all other baseline models, achieving more accurate monitoring of patient's vital signs. Furthermore, we conduct hyperparameter optimization to fine-tune the learning process of each agent. By optimizing hyperparameters, we enhance the learning rate and discount factor, thereby improving the agents' overall performance in monitoring patient health status. Our AI-driven patient monitoring system offers several advantages over traditional methods, including the ability to handle complex and uncertain environments, adapt to varying patient conditions, and make real-time decisions without external supervision.
2023.09.22.16.10.17;22.09.2023;17;17;AgriCulture;Agriculture et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/vision-transformers-in-agriculture-harvesting-innovation/;;;Vision Transformers in Agriculture | Harvesting Innovation;Agriculture has always been a cornerstone of human civilization, providing sustenance and livelihoods for billions worldwide. As technology advances, we find new and innovative ways to enhance agricultural practices. One such advancement is using Vision Transformers (ViTs) to classify leaf diseases in crops. In this blog, we’ll explore how vision transformers in agriculture revolutionize by offering an efficient and accurate solution for identifying and mitigating crop diseases. ...
2023.09.22.16.10.18;22.09.2023;18;20;Information;Knowledge, Understanding, Information etc.;arxiv;2309.11419;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.11419.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1"">Tengchao Lv</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1"">Yupan Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"">Jingye Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1"">Lei Cui</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1"">Shuming Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1"">Yaoyao Chang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1"">Shaohan Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1"">Wenhui Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1"">Li Dong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1"">Weiyao Luo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1"">Shaoxiang Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1"">Guoxin Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1"">Cha Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1"">Furu Wei</a>";Tengchao Lv,Yupan Huang,Jingye Chen,Lei Cui,Shuming Ma,Yaoyao Chang,Shaohan Huang,Wenhui Wang,Li Dong,Weiyao Luo,Shaoxiang Wu,Guoxin Wang,Cha Zhang,Furu Wei;Kosmos-2.5: A Multimodal Literate Model.;We present Kosmos-2.5, a multimodal literate model for machine reading of text-intensive images. Pre-trained on large-scale text-intensive images, Kosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1) generating spatially-aware text blocks, where each block of text is assigned its spatial coordinates within the image, and (2) producing structured text output that captures styles and structures into the markdown format. This unified multimodal literate capability is achieved through a shared Transformer architecture, task-specific prompts, and flexible text representations. We evaluate Kosmos-2.5 on end-to-end document-level text recognition and image-to-markdown text generation. Furthermore, the model can be readily adapted for any text-intensive image understanding task with different prompts through supervised fine-tuning, making it a general-purpose tool for real-world applications involving text-rich images. This work also paves the way for the future scaling of multimodal large language models.
2023.09.22.16.10.19;22.09.2023;19;20;Information;Knowledge, Understanding, Information etc.;arxiv;2309.10952;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10952.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Perot_V/0/1/0/all/0/1"">Vincent Perot</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kang_K/0/1/0/all/0/1"">Kai Kang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Luisier_F/0/1/0/all/0/1"">Florian Luisier</a>, <a href=""http://arxiv.org/find/cs/1/au:+Su_G/0/1/0/all/0/1"">Guolong Su</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1"">Xiaoyu Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Boppana_R/0/1/0/all/0/1"">Ramya Sree Boppana</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"">Zilong Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1"">Jiaqi Mu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1"">Hao Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hua_N/0/1/0/all/0/1"">Nan Hua</a>";Vincent Perot,Kai Kang,Florian Luisier,Guolong Su,Xiaoyu Sun,Ramya Sree Boppana,Zilong Wang,Jiaqi Mu,Hao Zhang,Nan Hua;LMDX: Language Model-based Document Information Extraction and Localization.;Large Language Models (LLM) have revolutionized Natural Language Processing (NLP), improving state-of-the-art on many existing tasks and exhibiting emergent capabilities. However, LLMs have not yet been successfully applied on semi-structured document information extraction, which is at the core of many document processing workflows and consists of extracting key entities from a visually rich document (VRD) given a predefined target schema. The main obstacles to LLM adoption in that task have been the absence of layout encoding within LLMs, critical for a high quality extraction, and the lack of a grounding mechanism ensuring the answer is not hallucinated. In this paper, we introduce Language Model-based Document Information Extraction and Localization (LMDX), a methodology to adapt arbitrary LLMs for document information extraction. LMDX can do extraction of singular, repeated, and hierarchical entities, both with and without training data, while providing grounding guarantees and localizing the entities within the document. In particular, we apply LMDX to the PaLM 2-S LLM and evaluate it on VRDU and CORD benchmarks, setting a new state-of-the-art and showing how LMDX enables the creation of high quality, data-efficient parsers.
2023.09.22.16.10.20;22.09.2023;20;20;Information;Knowledge, Understanding, Information etc.;towardsdatascience;;;https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517?source=rss----7f60cf5620c9---4;;;Extracting text from PDF files with Python: A comprehensive guide;A complete process to extract textual information from tables, images, and plain text from a PDF file. ...
2023.09.22.16.10.21;22.09.2023;21;20;Information;Knowledge, Understanding, Information etc.;towardsdatascience;;;https://towardsdatascience.com/generative-ai-on-research-papers-using-nougat-model-38aa37a354f6?source=rss----7f60cf5620c9---4;;;Generative AI on Research Papers Using Nougat Model;Recent advances in large language models (LLMs) like GPT-4 have shown impressive capabilities in generating coherent text. However, parsing and understanding research papers accurately remains an extremely challenging task for AI. Research papers contain complex formatting, math equations, tables, figures, and domain-specific language. The density of information is very high and important semantics are encoded in the formatting. In this article, I will demonstrate how a new model called Nougat from Meta can help parse research papers accurately. We then combine it with an LLM pipeline that extracts and summarizes all the tables in the paper. The potential here is immense. There is a lot of data/information locked up in research papers and books that have not been parsed correctly. Accurate parsing enables their use in many different applications including LLM retraining. ...
2023.09.22.16.10.22;22.09.2023;22;20;Information;Knowledge, Understanding, Information etc.;theintercept;;;https://theintercept.com/2023/09/20/pentagon-ai-budget-gamechanger/;;;Pentagon’s Budget is so Bloated That it Needs an AI Program to Navigate it;Codenamed GAMECHANGER, an AI program helps the military make sense of its own 'byzantine' and 'tedious' bureaucracy. Shortly after its release, GAMECHANGER was already used by over 6,000 Defense Department users conducting over 100,000 queries, according to the Defense Intelligence Agency. Described as a natural language processing application - a broad term in computer science generally referring the use of machine learning to allow computers to interpret human speech and writing - GAMECHANGER is just one of a vast suite of AI programs bankrolled by the Pentagon in recent months. The Pentagon is currently funding 686 such AI projects, according to the National Academy of Sciences, a nonprofit that frequently conducts research into the government. The figure does not include the Department of Defense's classified efforts. Before it was formally released, GAMECHANGER was granted an award by the Office of Personnel Management, the federal government's human resources agency for civil servants.
2023.09.21.13.03.01;21.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:usg:econwp:2023:07&r=big;;Fengler, MatthiasPhan, Minh Tri;A Topic Model for 10-K Management Disclosures;We investigate the topics discussed in the Management's Discussion and Analysis (MD&A) section of 10-K filings from January 1994 to December 2018. In our modeling approach, we elicit the MD&A topics by clustering words around a set of anchor words that broadly define a potential topic. From the topics, we extract two hidden loading series from the MD&As - a measure of topic prevalence and a measure of topic sentiment. The results are three-fold. First, the topics we find are intelligible and distinctive but are potentially multi-modal, which may explain why classical topic models applied to 10-K filings often lack interpretability. Second, topic prevalence and sentiment tend to follow trends which, by and large, can be rationalized historically. Third, sentiment affects topics heterogeneously, i.e., in topic-specific ways. Adding to the extant document-level techniques, our study demonstrates the potential benefits of using a nuanced topic-level approach to analyze the MD&A.
2023.09.21.13.03.02;21.09.2023;02;00;CrossTopic;Generic, Cross Topic, et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/data-engineering-project/;;;Top 20 Data Engineering Project Ideas [With Source Code];Data engineering plays a pivotal role in the vast data ecosystem by collecting, transforming, and delivering data essential for analytics, reporting, and machine learning. Aspiring data engineers often seek real-world projects to gain hands-on experience and showcase their expertise. This article presents the top 20 data engineering project ideas with their source code. Whether you’re a beginner, an intermediate-level engineer, or an advanced practitioner, these projects offer an excellent opportunity to sharpen your data engineering skills. ...
2023.09.21.13.03.03;21.09.2023;03;00;CrossTopic;Generic, Cross Topic, et al.;kdnuggets;;;https://www.kdnuggets.com/10-chatgpt-projects-cheat-sheet?utm_source=rss&utm_medium=rss&utm_campaign=10-chatgpt-projects-cheat-sheet;;;10 ChatGPT Projects Cheat Sheet;ChatGPT is rapidly changing the game for artificial intelligence capabilities. KDnuggets' latest cheat sheet provides a helpful guide to 10 exciting hands-on projects that demonstrate how to leverage ChatGPT for a variety of data science workflows. From building AI assistants and web applications to generating PowerPoint presentations, the projects outlined offer practical examples across machine learning, natural language processing, and full stack development. ...
2023.09.21.13.03.04;21.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2306.02552;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.02552.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"">Lei Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"">Jingsen Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1"">Hao Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1"">Zhiyuan Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1"">Jiakai Tang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"">Zeyu Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"">Xu Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1"">Yankai Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1"">Ruihua Song</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1"">Wayne Xin Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1"">Jun Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1"">Zhicheng Dou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Jun Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1"">Ji-Rong Wen</a>";Lei Wang,Jingsen Zhang,Hao Yang,Zhiyuan Chen,Jiakai Tang,Zeyu Zhang,Xu Chen,Yankai Lin,Ruihua Song,Wayne Xin Zhao,Jun Xu,Zhicheng Dou,Jun Wang,Ji-Rong Wen;When Large Language Model based Agent Meets User Behavior Analysis: A Novel User Simulation Paradigm.;User behavior analysis is crucial in human-centered AI applications. In this field, the collection of sufficient and high-quality user behavior data has always been a fundamental yet challenging problem. An intuitive idea to address this problem is automatically simulating the user behaviors. However, due to the subjective and complex nature of human cognitive processes, reliably simulating the user behavior is difficult. Recently, large language models (LLM) have obtained remarkable successes, showing great potential to achieve human-like intelligence. We argue that these models present significant opportunities for reliable user simulation, and have the potential to revolutionize traditional study paradigms in user behavior analysis. In this paper, we take recommender system as an example to explore the potential of using LLM for user simulation. Specifically, we regard each user as an LLM-based autonomous agent, and let different agents freely communicate, behave and evolve in a virtual simulator called RecAgent. For comprehensively simulation, we not only consider the behaviors within the recommender system (\emph{e.g.}, item browsing and clicking), but also accounts for external influential factors, such as, friend chatting and social advertisement. Our simulator contains at most 1000 agents, and each agent is composed of a profiling module, a memory module and an action module, enabling it to behave consistently, reasonably and reliably. In addition, to more flexibly operate our simulator, we also design two global functions including real-human playing and system intervention. To evaluate the effectiveness of our simulator, we conduct extensive experiments from both agent and system perspectives. In order to advance this direction, we have released our project at {https://github.com/RUC-GSAI/YuLan-Rec}.
2023.09.21.13.03.05;21.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.09506;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.09506.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1"">Zecheng Tang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1"">Chenfei Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Juntao Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1"">Nan Duan</a>";Zecheng Tang,Chenfei Wu,Juntao Li,Nan Duan;LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models.;"Graphic layout generation, a growing research field, plays a significant role in user engagement and information perception. Existing methods primarily treat layout generation as a numerical optimization task, focusing on quantitative aspects while overlooking the semantic information of layout, such as the relationship between each layout element. In this paper, we propose LayoutNUWA, the first model that treats layout generation as a code generation task to enhance semantic information and harness the hidden layout expertise of large language models~(LLMs). More concretely, we develop a Code Instruct Tuning (CIT) approach comprising three interconnected modules: 1) the Code Initialization (CI) module quantifies the numerical conditions and initializes them as HTML code with strategically placed masks; 2) the Code Completion (CC) module employs the formatting knowledge of LLMs to fill in the masked portions within the HTML code; 3) the Code Rendering (CR) module transforms the completed code into the final layout output, ensuring a highly interpretable and transparent layout generation procedure that directly maps code to a visualized layout. We attain significant state-of-the-art performance (even over 50\% improvements) on multiple datasets, showcasing the strong capabilities of LayoutNUWA. Our code is available at https://github.com/ProjectNUWA/LayoutNUWA."
2023.09.21.13.03.06;21.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.09708;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.09708.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1"">Nan Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kang_B/0/1/0/all/0/1"">Bo Kang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bie_T/0/1/0/all/0/1"">Tijl De Bie</a>";Nan Li,Bo Kang,Tijl De Bie;LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models.;Automated occupation extraction and standardization from free-text job postings and resumes are crucial for applications like job recommendation and labor market policy formation. This paper introduces LLM4Jobs, a novel unsupervised methodology that taps into the capabilities of large language models (LLMs) for occupation coding. LLM4Jobs uniquely harnesses both the natural language understanding and generation capacities of LLMs. Evaluated on rigorous experimentation on synthetic and real-world datasets, we demonstrate that LLM4Jobs consistently surpasses unsupervised state-of-the-art benchmarks, demonstrating its versatility across diverse datasets and granularities. As a side result of our work, we present both synthetic and real-world datasets, which may be instrumental for subsequent research in this domain. Overall, this investigation highlights the promise of contemporary LLMs for the intricate task of occupation extraction and standardization, laying the foundation for a robust and adaptable framework relevant to both research and industrial contexts.
2023.09.21.13.03.07;21.09.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.10561;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10561.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lakatos_R/0/1/0/all/0/1"">Robert Lakatos</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pollner_P/0/1/0/all/0/1"">Peter Pollner</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hajdu_A/0/1/0/all/0/1"">Andras Hajdu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Joo_T/0/1/0/all/0/1"">Tamas Joo</a>";Robert Lakatos,Peter Pollner,Andras Hajdu,Tamas Joo;A multimodal deep learning architecture for smoking detection with a small data approach.;Introduction: Covert tobacco advertisements often raise regulatory measures. This paper presents that artificial intelligence, particularly deep learning, has great potential for detecting hidden advertising and allows unbiased, reproducible, and fair quantification of tobacco-related media content. Methods: We propose an integrated text and image processing model based on deep learning, generative methods, and human reinforcement, which can detect smoking cases in both textual and visual formats, even with little available training data. Results: Our model can achieve 74\% accuracy for images and 98\% for text. Furthermore, our system integrates the possibility of expert intervention in the form of human reinforcement. Conclusions: Using the pre-trained multimodal, image, and text processing models available through deep learning makes it possible to detect smoking in different media even with few training data.
2023.09.21.13.03.08;21.09.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.10621;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10621.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Thomas_P/0/1/0/all/0/1"">Paul Thomas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Spielman_S/0/1/0/all/0/1"">Seth Spielman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Craswell_N/0/1/0/all/0/1"">Nick Craswell</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mitra_B/0/1/0/all/0/1"">Bhaskar Mitra</a>";Paul Thomas,Seth Spielman,Nick Craswell,Bhaskar Mitra;Large language models can accurately predict searcher preferences.;Relevance labels, which indicate whether a search result is valuable to a searcher, are key to evaluating and optimising search systems. The best way to capture the true preferences of users is to ask them for their careful feedback on which results would be useful, but this approach does not scale to produce a large number of labels. Getting relevance labels at scale is usually done with third-party labellers, who judge on behalf of the user, but there is a risk of low-quality data if the labeller doesn't understand user needs. To improve quality, one standard approach is to study real users through interviews, user studies and direct feedback, find areas where labels are systematically disagreeing with users, then educate labellers about user needs through judging guidelines, training and monitoring. This paper introduces an alternate approach for improving label quality. It takes careful feedback from real users, which by definition is the highest-quality first-party gold data that can be derived, and develops an large language model prompt that agrees with that data. We present ideas and observations from deploying language models for large-scale relevance labelling at Bing, and illustrate with data from TREC. We have found large language models can be effective, with accuracy as good as human labellers and similar capability to pick the hardest queries, best runs, and best groups. Systematic changes to the prompts make a difference in accuracy, but so too do simple paraphrases. To measure agreement with real searchers needs high-quality ``gold'' labels, but with these we find that models produce better labels than third-party workers, for a fraction of the cost, and these labels let us train notably better rankers.
2023.09.21.13.03.09;21.09.2023;09;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.10238;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10238.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1"">Chenhao Tang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zhengliang Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1"">Chong Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1"">Zihao Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"">Yiwei Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1"">Wei Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1"">Dajiang Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1"">Quanzheng Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"">Xiang Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1"">Tianming Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1"">Lei Fan</a>";Chenhao Tang,Zhengliang Liu,Chong Ma,Zihao Wu,Yiwei Li,Wei Liu,Dajiang Zhu,Quanzheng Li,Xiang Li,Tianming Liu,Lei Fan;PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models.;Privacy policies serve as the primary conduit through which online service providers inform users about their data collection and usage procedures. However, in a bid to be comprehensive and mitigate legal risks, these policy documents are often quite verbose. In practical use, users tend to click the Agree button directly rather than reading them carefully. This practice exposes users to risks of privacy leakage and legal issues. Recently, the advent of Large Language Models (LLM) such as ChatGPT and GPT-4 has opened new possibilities for text analysis, especially for lengthy documents like privacy policies. In this study, we investigate a privacy policy text analysis framework PolicyGPT based on the LLM. This framework was tested using two datasets. The first dataset comprises of privacy policies from 115 websites, which were meticulously annotated by legal experts, categorizing each segment into one of 10 classes. The second dataset consists of privacy policies from 304 popular mobile applications, with each sentence manually annotated and classified into one of another 10 categories. Under zero-shot learning conditions, PolicyGPT demonstrated robust performance. For the first dataset, it achieved an accuracy rate of 97%, while for the second dataset, it attained an 87% accuracy rate, surpassing that of the baseline machine learning and neural network models.
2023.09.21.13.03.10;21.09.2023;10;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.10020;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10020.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"">Chunyuan Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1"">Zhe Gan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1"">Zhengyuan Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1"">Jianwei Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"">Linjie Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1"">Lijuan Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1"">Jianfeng Gao</a>";Chunyuan Li,Zhe Gan,Zhengyuan Yang,Jianwei Yang,Linjie Li,Lijuan Wang,Jianfeng Gao;Multimodal Foundation Models: From Specialists to General-Purpose Assistants.;This paper presents a comprehensive survey of the taxonomy and evolution of multimodal foundation models that demonstrate vision and vision-language capabilities, focusing on the transition from specialist models to general-purpose assistants. The research landscape encompasses five core topics, categorized into two classes. (i) We start with a survey of well-established research areas: multimodal foundation models pre-trained for specific purposes, including two topics -- methods of learning vision backbones for visual understanding and text-to-image generation. (ii) Then, we present recent advances in exploratory, open research areas: multimodal foundation models that aim to play the role of general-purpose assistants, including three topics -- unified vision models inspired by large language models (LLMs), end-to-end training of multimodal LLMs, and chaining multimodal tools with LLMs. The target audiences of the paper are researchers, graduate students, and professionals in computer vision and vision-language multimodal communities who are eager to learn the basics and recent advances in multimodal foundation models.
2023.09.21.13.03.11;21.09.2023;11;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.10187;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10187.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Villalba_A/0/1/0/all/0/1"">Alejandro Cuevas Villalba</a>, <a href=""http://arxiv.org/find/cs/1/au:+Brown_E/0/1/0/all/0/1"">Eva M. Brown</a>, <a href=""http://arxiv.org/find/cs/1/au:+Scurrell_J/0/1/0/all/0/1"">Jennifer V. Scurrell</a>, <a href=""http://arxiv.org/find/cs/1/au:+Entenmann_J/0/1/0/all/0/1"">Jason Entenmann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Daepp_M/0/1/0/all/0/1"">Madeleine I. G. Daepp</a>";Alejandro Cuevas Villalba,Eva M. Brown,Jennifer V. Scurrell,Jason Entenmann,Madeleine I. G. Daepp;Automated Interviewer or Augmented Survey? Collecting Social Data with Large Language Models.;"Qualitative methods like interviews produce richer data in comparison with quantitative surveys, but are difficult to scale. Switching from web-based questionnaires to interactive chatbots offers a compromise, improving user engagement and response quality. Uptake remains limited, however, because of differences in users' expectations versus the capabilities of natural language processing methods. In this study, we evaluate the potential of large language models (LLMs) to support an information elicitation chatbot that narrows this ""gulf of expectations"" (Luger & Sellen 2016). We conduct a user study in which participants (N = 399) were randomly assigned to interact with a rule-based chatbot versus one of two LLM-augmented chatbots. We observe limited evidence of differences in user engagement or response richness between conditions. However, the addition of LLM-based dynamic probing skills produces significant improvements in both quantitative and qualitative measures of user experience, consistent with a narrowing of the expectations gulf."
2023.09.21.13.03.12;21.09.2023;12;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/balancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a?source=rss----7f60cf5620c9---4;;;Balancing Innovation With Safety & Privacy in the Era of Large Language Models (LLM);The AI era has ushered in Large Language Models (aka LLMs) to the technological forefront, which has been much of the talk in 2023, and is likely to remain as such for many years to come. LLMs are the AI models that are the power house behind things like ChatGPT. These AI models, fueled by vast amounts of data and computational prowess, have unlocked remarkable capabilities, from human-like text generating to assisting with natural language understanding (NLU) tasks. They have quickly become the foundation upon which countless applications and software services are being built, or at least being augmented with. However, as with any groundbreaking innovations, the rise of LLMs brings forth a critical question — “How do we balance this pursuit of technological advancement with the imperative of safety and privacy?”. This is not a mere philosophical question, but a challenge that requires proactive and thoughtful action. ...
2023.09.21.13.03.13;21.09.2023;13;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1476/v1;;Preprints.org - The Multidisciplinary Preprint Platform;A Data Envelopment Analysis to Benchmark Hotel Energy Consumption in an Urban Locality;The benchmarking of hotel energy use comprehensively identifies the controllable and uncontrollable factors affecting energy performance, including building characteristics, management strategies, operations, and maintenance systems. Other factors include climatic conditions, floor areas, operating hours, occupancy rates, and guest populations. A benchmarking study on energy consumption patterns in significant hotels (each with less than 100 rooms and an average staff strength of 40 employees), situated in the university town of Nsukka (longitude 70 23' E, latitude 60 52' N), Nigeria, was performed using the data envelopment analysis (DEA) methodology. DEA, a linear programming technique that measures the relative performances of units, was chosen as a benchmarking methodology due to its ability to handle multiple inputs and outputs. Following a correlation test, energy use intensity, diesel consumption, and the number of employees were selected as the analysis inputs, while the occupancy rate was chosen as the output variable. Data on these variables spanning 12 months were collected using questionnaires, interviews, site visits, and oral conversations with hotel managers to ensure validity. Grid-supplied electricity accounted for most of the hotels' energy needs, followed by diesel used in generators. More than 70% of the electricity use was for HVAC. From the DEA, Hotel 3 (DMU H3) had a technical efficiency score of 1, whereas adjustments were recommended for improving the efficiency scores of the other hotels, which were deemed inefficient. DMU H7 had the lowest efficiency score (0.474) and the highest identified savings for electricity and diesel. The analysis also revealed that occupancy rates were generally low in the months of June and July, coinciding with the high rainfall season with its accompanying decline in outdoor activities. Consistent with this, electricity consumption was highest in the Christmas and Easter holiday months of December, January, and April following increased travel-related activities.
2023.09.21.13.03.14;21.09.2023;14;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.10141;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10141.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Krishnakumar_S/0/1/0/all/0/1"">Sriharini Krishnakumar</a>, <a href=""http://arxiv.org/find/eess/1/au:+Partin_Vaisband_D/0/1/0/all/0/1"">Dr.Inna Partin-Vaisband</a>";Sriharini Krishnakumar,Dr.Inna Partin-Vaisband;Vertical Power Delivery for Emerging Packaging and Integration Platforms -- Power Conversion and Distribution.;Efficient delivery of current from PCB to point-of-load (POL) is a primary concern in modern high-power high-density integrated systems. Traditionally, a 48 V power signal is converted to the low, POL voltage at the board and/or package level. As interconnect has become the dominant power loss component, minimizing voltage drop across the laterally routed portions of the board-to-die interconnect (referred to as horizontal interconnect) is a promising approach to enhance the efficiency of the power delivery system. Delivering lower current vertically, at a higher voltage should therefore be considered. High-power conversion near POL, however, results in higher switching and inductor losses, exhibiting an undesired power efficiency tradeoff. To address this problem, four vertical power delivery architectures are proposed in this paper, considering state-of-the-art power converter topologies, integration levels, and voltage conversion schemes. Embedding Silicon (Si) and Gallium Nitride (GaN) power devices and inductors on top of and/or within the interposer is investigated. Integrating GaN power devices on a dedicated power die is also discussed. Various multi-stage 48V-to-1V power conversion schemes are examined and state-of-the-art power conversion circuits are reviewed. Power delivery characteristics with these architectures are determined for a high power (1 kW) high-current density (2 A/mm$^2$) system.
2023.09.21.13.03.15;21.09.2023;15;05;Legal;Legal, Law et al.;arxiv;2309.10563;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10563.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Prasad_N/0/1/0/all/0/1"">Nishchal Prasad</a>, <a href=""http://arxiv.org/find/cs/1/au:+Boughanem_M/0/1/0/all/0/1"">Mohand Boughanem</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dkaki_T/0/1/0/all/0/1"">Taoufik Dkaki</a>";Nishchal Prasad,Mohand Boughanem,Taoufik Dkaki;A Hierarchical Neural Framework for Classification and its Explanation in Large Unstructured Legal Documents.;"Automatic legal judgment prediction and its explanation suffer from the problem of long case documents exceeding tens of thousands of words, in general, and having a non-uniform structure. Predicting judgments from such documents and extracting their explanation becomes a challenging task, more so on documents with no structural annotation. We define this problem as ""scarce annotated legal documents"" and explore their lack of structural information and their long lengths with a deep learning-based classification framework which we call MESc; ""Multi-stage Encoder-based Supervised with-clustering""; for judgment prediction. Specifically, we divide a document into parts to extract their embeddings from the last four layers of a custom fine-tuned Large Language Model, and try to approximate their structure through unsupervised clustering. Which we use in another set of transformer encoder layers to learn the inter-chunk representations. We explore the adaptability of LLMs with multi-billion parameters (GPT-Neo, and GPT-J) to legal texts and their intra-domain(legal) transfer learning capacity. Alongside this, we compare their performance with MESc and the impact of combining embeddings from their last layers. For such hierarchical models, we also propose an explanation extraction algorithm named ORSE; Occlusion sensitivity-based Relevant Sentence Extractor;"
2023.09.21.13.03.16;21.09.2023;16;07;Industry;I4.0, Production et al.;arxiv;2309.10132;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10132.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1"">Jonghan Lim</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pfeiffer_L/0/1/0/all/0/1"">Leander Pfeiffer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ocker_F/0/1/0/all/0/1"">Felix Ocker</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vogel_Heuser_B/0/1/0/all/0/1"">Birgit Vogel-Heuser</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kovalenko_I/0/1/0/all/0/1"">Ilya Kovalenko</a>";Jonghan Lim,Leander Pfeiffer,Felix Ocker,Birgit Vogel-Heuser,Ilya Kovalenko;Ontology-Based Feedback to Improve Runtime Control for Multi-Agent Manufacturing Systems.;Improving the overall equipment effectiveness (OEE) of machines on the shop floor is crucial to ensure the productivity and efficiency of manufacturing systems. To achieve the goal of increased OEE, there is a need to develop flexible runtime control strategies for the system. Decentralized strategies, such as multi-agent systems, have proven effective in improving system flexibility. However, runtime multi-agent control of complex manufacturing systems can be challenging as the agents require extensive communication and computational efforts to coordinate agent activities. One way to improve communication speed and cooperation capabilities between system agents is by providing a common language between these agents to represent knowledge about system behavior. The integration of ontology into multi-agent systems in manufacturing provides agents with the capability to continuously update and refine their knowledge in a global context. This paper contributes to the design of an ontology for multi-agent systems in manufacturing, introducing an extendable knowledge base and a methodology for continuously updating the production data by agents during runtime. To demonstrate the effectiveness of the proposed framework, a case study is conducted in a simulated environment, which shows improvements in OEE during runtime.
2023.09.21.13.03.17;21.09.2023;17;08;Supply Chain;Supply Chains, Transportation et al.;technologyreview;;;https://www.technologyreview.com/2023/09/20/1079519/moving-data-through-the-supply-chain-with-unprecedented-speed/;;;Moving data through the supply chain with unprecedented speed;Product information is a powerful commodity in today’s digital economy. Making it accessible can let consumers know if an item contains allergens, help retailers respond swiftly to product recalls, and enable suppliers to track real-time inventory levels. But data can become siloed and inaccessible if organizations fail to make it easy to connect with. This means shifting away from legacy processes and using a “phygital” approach, which brings together data from physical objects and connected digital sources. “The phygital creates a link between the actual physical good and its digital representation, which can unlock vast volumes of information for consumers—data they haven’t been able to access in the past because it has been tied up in proprietary systems,” says Carrie Wilkie, senior vice president at GS1 US, a member of GS1, a global not-for-profit supply chain standards organization. ...
2023.09.21.13.03.18;21.09.2023;18;12;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1342/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Artificial Intelligence and Medicine: Advances and Challenges;Artificial Intelligence (AI) has emerged as a disruptive technology in various areas, and medicine is no exception. In the last decade, there has been rapid progress in the application of AI in healthcare, from diagnosing and prognosticating diseases to improving operational efficiency in hospitals. This literature review explores the advances of artificial intelligence in the field of medicine, discusses its benefits, and discusses the ethical and regulatory challenges that need to be addressed to maximize its potential.
2023.09.21.13.03.19;21.09.2023;19;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2205.04766;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2205.04766.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Patricio_C/0/1/0/all/0/1"">Cristiano Patr&#xed;cio</a>, <a href=""http://arxiv.org/find/eess/1/au:+Neves_J/0/1/0/all/0/1"">Jo&#xe3;o C. Neves</a>, <a href=""http://arxiv.org/find/eess/1/au:+Teixeira_L/0/1/0/all/0/1"">Lu&#xed;s F. Teixeira</a>";Cristiano Patrício,João C. Neves,Luís F. Teixeira;Explainable Deep Learning Methods in Medical Image Classification: A Survey.;The remarkable success of deep learning has prompted interest in its application to medical imaging diagnosis. Even though state-of-the-art deep learning models have achieved human-level accuracy on the classification of different types of medical data, these models are hardly adopted in clinical workflows, mainly due to their lack of interpretability. The black-box-ness of deep learning models has raised the need for devising strategies to explain the decision process of these models, leading to the creation of the topic of eXplainable Artificial Intelligence (XAI). In this context, we provide a thorough survey of XAI applied to medical imaging diagnosis, including visual, textual, example-based and concept-based explanation methods. Moreover, this work reviews the existing medical imaging datasets and the existing metrics for evaluating the quality of the explanations. In addition, we include a performance comparison among a set of report generation-based methods. Finally, the major challenges in applying XAI to medical imaging and the future research directions on the topic are also discussed.
2023.09.21.13.03.20;21.09.2023;20;15;Control;Control, Planning, Processes et al.;arxiv;2309.10062;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10062.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Kannan_S/0/1/0/all/0/1"">Shyam Sundar Kannan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Venkatesh_V/0/1/0/all/0/1"">Vishnunandan L. N. Venkatesh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Min_B/0/1/0/all/0/1"">Byung-Cheol Min</a>";Shyam Sundar Kannan,Vishnunandan L. N. Venkatesh,Byung-Cheol Min;SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models.;In this work, we introduce SMART-LLM, an innovative framework designed for embodied multi-robot task planning. SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models (LLMs), harnesses the power of LLMs to convert high-level task instructions provided as input into a multi-robot task plan. It accomplishes this by executing a series of stages, including task decomposition, coalition formation, and task allocation, all guided by programmatic LLM prompts within the few-shot prompting paradigm. We create a benchmark dataset designed for validating the multi-robot task planning problem, encompassing four distinct categories of high-level instructions that vary in task complexity. Our evaluation experiments span both simulation and real-world scenarios, demonstrating that the proposed model can achieve promising results for generating multi-robot task plans. The experimental videos, code, and datasets from the work can be found at https://sites.google.com/view/smart-llm/.
2023.09.21.13.03.21;21.09.2023;21;20;Information;Knowledge, Understanding, Information etc.;arxiv;2309.10094;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.10094.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1"">Chenglong Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Thompson_J/0/1/0/all/0/1"">John Thompson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1"">Bongshin Lee</a>";Chenglong Wang,John Thompson,Bongshin Lee;Data Formulator: AI-powered Concept-driven Visualization Authoring.;With most modern visualization tools, authors need to transform their data into tidy formats to create visualizations they want. Because this requires experience with programming or separate data processing tools, data transformation remains a barrier in visualization authoring. To address this challenge, we present a new visualization paradigm, concept binding, that separates high-level visualization intents and low-level data transformation steps, leveraging an AI agent. We realize this paradigm in Data Formulator, an interactive visualization authoring tool. With Data Formulator, authors first define data concepts they plan to visualize using natural languages or examples, and then bind them to visual channels. Data Formulator then dispatches its AI-agent to automatically transform the input data to surface these concepts and generate desired visualizations. When presenting the results (transformed table and output visualizations) from the AI agent, Data Formulator provides feedback to help authors inspect and understand them. A user study with 10 participants shows that participants could learn and use Data Formulator to create visualizations that involve challenging data transformations, and presents interesting future research directions.
2023.09.20.13.41.01;20.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/unlocking-langchain-flan-t5-xxl-a-guide-to-efficient-document-querying/;;;Unlocking LangChain & Flan-T5 XXL | A Guide to Efficient Document Querying;A specific category of artificial intelligence models known as large language models (LLMs) is designed to understand and generate human-like text. The term “large” is often quantified by the number of parameters they possess. For example, OpenAI’s GPT-3 model has 175 billion parameters. Use it for a variety of tasks, like translating text, answering questions, writing essays, summarizing text. Despite the abundance of resources demonstrating the capabilities of LLMs and providing guidance on setting up chat applications with them, there are few endeavors that thoroughly examine their suitability for real-life business scenarios. In this article, you will learn how to create document querying system using LangChain & Flan-T5 XXL leveraging in building large-language based applications. ...
2023.09.20.13.41.02;20.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/how-to-use-langchains-chains-and-gpt-models-to-generate-endless-content-ideas-a-step-by-step-bce29a71b907?source=rss----98111c9905da---4;;;How to Use LangChain’s Chains and GPT Models to Generate Endless Content Ideas: A Step-by-step…;ChatGPT is powerful, but it has a huge limitation — it’s just a single model. Luckily, in March 2023, Open AI released API for its most powerful models, such as GPT-4 or GPT-3.5. And that was the real game-changer. Since then, opportunities are endless. You can now take several models and combine them however you want. Think of it as your own team of GPTs. And that’s where LangChain’s Chains come in. ...
2023.09.20.13.41.03;20.09.2023;03;04;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:qed:wpaper:1509&r=pay;;Jonathan ChiuThorsten V. KoepplHanna YuShengxing Zhang;Understanding the DeFi Network Through the Lens of a Production-Network Model;Decentralized Finance (DeFi) is composed of a variety of heterogeneous sectors that are interconnected through an input-output network of its tokens. We use a panel data set to empricially document the evolution of the DeFi network across its different sectors. We then employ a standard, theoretical production-network model to measure the value added and service outputs of different DeFi sectors which is fundamentally different from the commonly used metric of Total Value Locked (TVL). Our calibrated model is then used to study DeFi token prices and to predict the equilibrium effects of increasing network interconnectedness.
2023.09.20.13.41.04;20.09.2023;04;09;Commerce;Commerce, Trading, Sales, Retail et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/chatgpt-for-marketing/;;;15 Ways to Use ChatGPT for Marketing;Marketing is a very dynamic sector where one really struggles to stay ahead of the curve. There is a compelling urge and a need to compete or beat business rivals to attain success. Maintaining success is as crucial as attaining it. ChatGPT can be your ticket to success, a gift of technology in today’s fast-paced, ever-evolving digital landscape. It can effectively guide you to craft attractive content that can help automate customers and engage them, bringing conversions and brand success. An AI-powered tool like ChatGPT offers endless chances to nurture your business. Let us unveil 15 interesting ways to use ChatGPT for marketing. ...
2023.09.20.13.41.05;20.09.2023;05;12;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1272/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Evaluating ChatGPT Efficacy in Navigating the Spanish Medical Residency Entrance Examination (MIR): A New Horizon for AI in Clinical Medicine;"The rapid progress in artificial intelligence, machine learning, and natural language processing has led to the emergence of increasingly sophisticated large language models (LLMs) enabling their use in healthcare. The study assesses the performance of two LLMs: the GPT-3.5 and GPT-4 models in passing the medical examination for access to medical specialist training in Spain MIR. Our objectives included gauging the model's overall performance, analyzing discrepancies across different medical specialties, discerning between theoretical and practical questions, estimating error proportions, and assessing the hypothetical severity of errors committed by a physician. We studied the 2022 Spanish MIR examination after excluding those questions requiring image evaluations or having acknowledged errors. The remaining 182 questions were presented to the LLM ChatGPT4 and GPT-3.5 in Spanish and English. Logistic regression models analyzed the relationships between question length and question sequence d performance. GPT-4 outperformed GPT -3.5, scoring 86.81% in Spanish (p<0.001). English translations had a slightly enhanced performance. Among medical specialties, GPT-4 achieved a 100% correct response rate in several areas, with specialties like Pharmacology, ICU, and Infectious Diseases showing lower performance. The error analysis revealed that while a 13.2% error rate existed, gravest categories like ""error requiring intervention to sustain life"" and ""error resulting in death"" had a 0% rate. Conclusions: GPT-4 performs robustly on the Spanish MIR examination, varying its capability to discriminate knoweldge across specialties. While the model's high success rate is commendable, understanding the error severity is critical, especially when considering AI's potential role in real-world medical practice and its implication on patient safety."
2023.09.20.13.41.06;20.09.2023;06;12;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.0867/v2;;Preprints.org - The Multidisciplinary Preprint Platform;A Sustainable Digital Transformation in Healthcare and Well-Being: An Overview, Integration, Design and Security Challenges, Blockchain Technology, Applications, and Future Research Directions;"Good health and well-being is one of the essential SDGs that ensure healthy lives and promote well-being for all ages and further entails providing substantial medical services to the public at low cost and with minimal adverse effects on the environment. Information and communication technologies (ICTs) have taken on an increasingly important function as significant facilitators of healthcare reform, with the goals of enhancing access to health services, the quality of treatment provided, and the overall productivity of the healthcare system. However, the integration of ever-increasing ICT technologies into the healthcare systems, also referred to as digital transformation, is not a straightforward process, but it comes with different types of challenges from integration level to application design level and security level. Although several studies have been proposed to address the integration of ICT technologies into healthcare systems, there is still a need for a comprehensive research study on the integration and design challenges, security and privacy challenges, application areas, and possible positive and negative impacts. Therefore, this paper contributes as the research literature study covering an important SDG, ""Good health and well-being,"" and its digital transformation, along with summarising our research findings in a detailed and taxonomical way. To start with, firstly, we present a detailed comparison of existing studies on healthcare and well-being, mainly focusing on integrating ICT technologies in healthcare in terms of sustainable aspects, security and privacy challenges, design and integration challenges, E-health-related applications, and future directions. We also present an overview and the need for digital transformation in healthcare, discuss its significant components, highlight E-health's importance and benefits, explore its integration and design challenges, and categorise the security and privacy challenges. Next, we present an in-depth discussion on the role of Blockchain technology as today's leading technology in E-health, discussing Blockchain technology and its characteristics, highlighting its benefits, and describing the possible types of Blockchain-based E-health use cases. Furthermore, we discuss the positive and negative impact of ICT integration along with identifying open issues and challenges of integrating ICT technologies into the healthcare systems and discuss future research directions, which provide the strength for researchers to address the issues in future solutions."
2023.09.20.13.41.07;20.09.2023;07;12;Health;Medical, Health Care, Pharmacy et al.;towardsdatascience;;;https://towardsdatascience.com/a-foundation-model-for-medical-ai-7b97e3ab3893?source=rss----7f60cf5620c9---4;;;A Foundation Model for Medical AI;In this blog post, I describe PLIP (Pathology Language and Image Pre-Training) as one of the first foundation models for pathology. PLIP is a vision-language model that can be used to embed images and text in the same vector space, thus allowing multi-modal applications. PLIP is derived from the original CLIP model proposed by OpenAI in 2021 and has been recently published in Nature Medicine ...
2023.09.20.13.41.08;20.09.2023;08;18;Sustainability;Sustainability, Efficiency et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1321/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Physical Assets Life Cycle Evaluation Models – A Comparative Analysis Aiming the Sustainability;Having as objective to reach a circular economy, it is important to maximize the Physical Asset’s Life Cycle. The evaluation of Physical Assets Life Cycle may have several approaches which may provide different results. These differences may not be very significant, but must be taken into consideration, because they have consequences in the manager decision. This permits to have a wider time interval to decide when to withdrawal the Physical Asset or to renewal it, and or if this ought to continue functioning because the profits are higher than the expenses, what allows to diminish waste and increase sustainability. These are some aspects that are discussed in this paper, which presents several models to evaluate the Physical Assets Life Cycle, considering the market value, devaluations methods and a more generalized way of Fisher’s Equation, which can include the Risk tax, among others. The results are discussed supported in data for simulation, which are used for each Econometric Model aiming to evaluate the differences among them. In all Models they are considered not only the expenses, namely of Investment and Functioning, but also the Profits, which permit to evaluate the Physical Asset Life Cycle in a holistic way. The models are very versatile, allowing to evaluate quantitatively the changing in the maintenance policies, the energy prices variations, the risk evaluation, the variation of profits according to the real market, and so on. The results demonstrated the robustness of the approach described and that maximize the Physical Assets Life Cycle allowing to minimize the consumption of world resources and, by consequence, it contributes for a more sustainable world.
2023.09.20.13.41.09;20.09.2023;09;20;Information;Knowledge, Understanding, Information etc.;arxiv;2309.08754;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08754.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Babalou_S/0/1/0/all/0/1"">Samira Babalou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Samuel_S/0/1/0/all/0/1"">Sheeba Samuel</a>, <a href=""http://arxiv.org/find/cs/1/au:+Konig_Ries_B/0/1/0/all/0/1"">Birgitta K&#xf6;nig-Ries</a>";Samira Babalou,Sheeba Samuel,Birgitta König-Ries;Reproducible Domain-Specific Knowledge Graphs in the Life Sciences: a Systematic Literature Review.;Knowledge graphs (KGs) are widely used for representing and organizing structured knowledge in diverse domains. However, the creation and upkeep of KGs pose substantial challenges. Developing a KG demands extensive expertise in data modeling, ontology design, and data curation. Furthermore, KGs are dynamic, requiring continuous updates and quality control to ensure accuracy and relevance. These intricacies contribute to the considerable effort required for their development and maintenance. One critical dimension of KGs that warrants attention is reproducibility. The ability to replicate and validate KGs is fundamental for ensuring the trustworthiness and sustainability of the knowledge they represent. Reproducible KGs not only support open science by allowing others to build upon existing knowledge but also enhance transparency and reliability in disseminating information. Despite the growing number of domain-specific KGs, a comprehensive analysis concerning their reproducibility has been lacking. This paper addresses this gap by offering a general overview of domain-specific KGs and comparing them based on various reproducibility criteria. Our study over 19 different domains shows only eight out of 250 domain-specific KGs (3.2%) provide publicly available source code. Among these, only one system could successfully pass our reproducibility assessment (14.3%). These findings highlight the challenges and gaps in achieving reproducibility across domain-specific KGs. Our finding that only 0.4% of published domain-specific KGs are reproducible shows a clear need for further research and a shift in cultural practices.
2023.09.20.13.41.10;20.09.2023;10;99;Other;Others;arxiv;2309.08788;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08788.pdf;" <a href=""http://arxiv.org/find/cond-mat/1/au:+Luu_R/0/1/0/all/0/1"">Rachel K. Luu</a>, <a href=""http://arxiv.org/find/cond-mat/1/au:+Buehler_M/0/1/0/all/0/1"">Markus J. Buehler</a>";Rachel K. Luu,Markus J. Buehler;BioinspiredLLM: Conversational Large Language Model for the Mechanics of Biological and Bio-inspired Materials.;"The study of biological materials and bio-inspired materials science is well established; however, surprisingly little knowledge has been systematically translated to engineering solutions. To accelerate discovery and guide insights, an open-source autoregressive transformer large language model, BioinspiredLLM, is reported. The model was finetuned with a corpus of over a thousand peer-reviewed articles in the field of structural biological and bio-inspired materials and can be prompted to actively and interactively recall information, assist with research tasks, and function as an engine for creativity. The model has proven by example that it is not only able to accurately recall information about biological materials when queried but also formulate biomaterials questions and answers that can evaluate its own performance. BioinspiredLLM also has been shown to develop sound hypotheses regarding biological materials design and remarkably so for materials that have never been explicitly studied before. Lastly, the model showed impressive promise in collaborating with other generative artificial intelligence models in a workflow that can reshape the traditional materials design process. This collaborative generative artificial intelligence method can stimulate and enhance bio-inspired materials design workflows. Biological materials is at a critical intersection of multiple scientific fields and models like BioinspiredLLM help to connect knowledge domains."
2023.09.19.12.06.01;19.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;repec;;http://nep.repec.org/rss/nep-cse.rss.xml;http://d.repec.org/n?u=RePEc:frz:wpmmos:wp2023_01.rdf&r=cse;;Damiano Cesa BianchiMarco BellucciGiacomo ManettiLuca Bagnoli;NFTs and business model innovations;Nonfungible tokens (NFTs) use blockchain technology to certify the ownership of digital assets. This study aims to understand the opportunities and limits of NFTs in the innovation of business models (BMs) across various sectors, including auction houses, museums, ticketing companies, and online art exchanges. Specifically, we are interested in understanding the role of NFTs in enabling the decentralization and digitalization of BMs owing to new products, services or processes. By adopting a conceptual approach based on the BM framework proposed by Osterwalder and Pigneur, this study uses a qualitative methodology based on multiple case studies to discuss the unique cases of Christie's, OpenSea, Uffizi Gallery, and Ticketmaster. Our findings suggest that despite the opportunities presented by NFTs in terms of revenue streams, customer interface, digital authentication, and decentralization, many limitations remain, including regulatory uncertainty and ethical and environmental concerns.
2023.09.19.12.06.02;19.09.2023;02;00;CrossTopic;Generic, Cross Topic, et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/documents-with-langchain-and-deep-lake/;;;Ask your Documents with Langchain and Deep Lake!;A new method called Retrieval Augmented Generation (RAG) seems promising. Using RAG to query an LLM with your private knowledge base. It helps these models get better by adding extra information from their data sources. This makes them more innovative and helps reduce their mistakes when they don’t have enough information. RAG works by enhancing prompts with proprietary data, ultimately enhancing the knowledge of these large language models while simultaneously reducing the occurrence of hallucinations. ...
2023.09.19.12.06.03;19.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/document-topic-extraction-with-large-language-models-llm-and-the-latent-dirichlet-allocation-e4697e4dae87?source=rss----7f60cf5620c9---4;;;Document Topic Extraction with Large Language Models (LLM) and the Latent Dirichlet Allocation…;I was developing a web application for chatting with PDF files, capable of processing large documents, above 1000 pages. But before starting a conversation with the document, I wanted the application to give the user a brief summary of the main topics, so it would be easier to start the interaction. ...
2023.09.19.12.06.04;19.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/llmops-production-prompt-engineering-patterns-with-hamilton-5c3a20178ad2?source=rss----7f60cf5620c9---4;;;LLMOps: Production prompt engineering patterns with Hamilton;What you send to your large language model (LLM) is quite important. Small variations and changes can have large impacts on outputs, so as your product evolves, the need to evolve your prompts will too. LLMs are also constantly being developed and released, and so as LLMs change, your prompts will also need to change. Therefore it’s important to set up an iteration pattern to operationalize how you “deploy” your prompts so you and your team can move efficiently, but also ensure that production issues are minimized, if not avoided. In this post, we’ll guide you through the best practices of managing prompts with Hamilton, an open source micro-orchestration framework, making analogies to MLOps patterns, and discussing trade-offs along the way. The high level takeaways of this post are still applicable even if you don’t use Hamilton. ...
2023.09.19.12.06.05;19.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;kdnuggets;;;https://www.kdnuggets.com/meet-metagpt-the-chatgptpowered-ai-assistant-that-turns-text-into-web-apps?utm_source=rss&utm_medium=rss&utm_campaign=meet-metagpt-the-chatgpt-powered-ai-assistant-that-turns-text-into-web-apps;;;Meet MetaGPT: The ChatGPT-Powered AI Assistant That Turns Text Into Web Apps;MetaGPT by Pico allows users to build any kind of app they envision using the power of natural language. All you need to do is type in a text prompt, and MetaGPT automatically turns your input into a functional web application. The tool uses GPT-4 under the hood, which gives it the ability to understand nuanced prompts and craft the underlying logic for the web app. And although the current capabilities of MetaGPT may seem impressive, this is just the tip of the iceberg of what lies ahead in the field of generative AI. As we continue to refine AI models, the functionalities that no-code platforms can offer will expand, democratizing the tech development landscape. ...
2023.09.19.12.06.06;19.09.2023;06;04;Finance;Finance, DeFi, Insurance, Banking et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1147/v1;;Preprints.org - The Multidisciplinary Preprint Platform;The Impact Of Sustainability Reporting On Financial Performance: Evidence From Turkish FBT And TCL Sectors;This study investigated the impact of sustainability reporting on financial performance, with a focus on companies in the Turkish food, beverage and tobacco and textile, wearing apparel and leather sectors. The sustainability reports of 48 companies listed on the Istanbul Stock Exchange for 2022 were studied, and the quality of sustainability practices was determined by using a general index (Sustainability Reporting Disclosure Quality Index (SRDQI)) and three partial indices (Environmental Disclosure Quality Index, Social Disclosure Quality Index, and Corporate Governance Disclosure Quality Index (CGDQI)). To analyze the relationships between financial performance and sustainability practices two types of regression models were developed, based on which eight models were directly examined. The results indicate the complete absence of a statistically significant impact of SRDQI on all financial performance measures used. Among the partial indices, only CGDQI has a significant positive effect on the Assets Turnover Ratio. An analysis of the influence of control variables shows a multidirectional dependence of individual financial performance measures on the size of companies, their age, industry affiliation, as well as on the structure of capital used. Finally, this study provides directions for improving the institutional environment of sustainability reporting for Turkish companies.
2023.09.19.12.06.07;19.09.2023;07;08;Supply Chain;Supply Chains, Transportation et al.;towardsdatascience;;;https://towardsdatascience.com/getting-started-with-ai-ml-to-build-intelligent-supply-chains-76829f492ef8?source=rss----7f60cf5620c9---4;;;Getting Started with AI/ML to Build Intelligent Supply Chains;Supply chain optimization is a vast area of research. There is a plethora of use cases within supply chains that would benefit from the application of AI/ML technology. Oftentimes, organizations struggle with where and how to start in this space. Supply chain executives are typically looking for areas where to invest the time and effort of their teams (which are already stretched) to derive the most value from these approaches. In this article, we explore a small but diverse set of use cases that can serve as a starting point for a supply chain organization’s foray into AI/ML. Supply chain leaders can expect to gain a high degree of cost and efficiency improvements from these applications. We divide supply chain management into five components: Plan, Source, Make, Deliver, Reverse Logistics and outline uses cases of Demand Sensing, Supplier Segmentation, Equipment Failure Prediction, Delivery Time Prediction, Customer Returns Forecast that map to the five components. Applying the criteria of economic value, tractability, results explainability, insights actionability, and application sustainability, qualitatively across the use cases, we also assess the overall benefit of implementing each use case. ...
2023.09.19.12.06.08;19.09.2023;08;09;Commerce;Commerce, Trading, Sales, Retail et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/ai-for-customer-service/;;;AI for Customer Service | Top 10 Use Cases;Customer queries are endless for any company. With the rise of different problems or to gain familiarity with the offerings, every company strives to lower the response time and pace up the resolution process. The more efficient system in such a scenario is generative AI-based compared to traditional ones of humans. Generative AI is capable of generating novel data compared to conventional AI systems. It utilizes the Large Language Models (LLMs) and deep learning techniques to interpret the natural conversational responses. More advancements and research are currently in progress to easily understand the complex inquiries, with a fraction of it visible through the current chatbot-based customer queries. ...
2023.09.19.12.06.09;19.09.2023;09;16;Human;Human Resource, Personal Assistance et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/09/how-to-clear-gmail-inbox-with-ai/;;;How to Clear Gmail Inbox with AI? ;Are you tired of wading through a sea of emails in your Gmail inbox? Do you find yourself drowning in newsletters, promotions, and spam? Well, you’re not alone. Email overload is a common struggle in our digital age. And thanks to AI, there is now a perfect solution to overflowing mail. Read on to learn how to clear Gmail inbox with AI! ...
2023.09.19.12.06.10;19.09.2023;10;16;Human;Human Resource, Personal Assistance et al.;gartner;;;https://www.gartner.com/en/human-resources/topics/artificial-intelligence-in-hr;;;AI in HR: How AI Is Transforming the Future of HR;76% of HR leaders believe that if their organization does not adopt and implement AI solutions, such as generative AI, in the next 12 to 24 months, they will be lagging in organizational success compared to those that do. CHROs must take a structured approach, using this three-step framework, to assess technology trends to be able to make an effective decision on whether to adopt new AI solutions into HR. ...
2023.09.18.17.57.01;18.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1106/v1;;Preprints.org - The Multidisciplinary Preprint Platform; Research on Safety Risk Transfer in Subway Construction Based on Text Mining and Complex Networks ;"Subway construction is often in a complex natural and human-machine operating environment, and that complicated setting leads to subway construction more prone to safety accidents, which can cause substantial casualties and monetary losses. Thus, it is necessary to investigate the safety risks of subway construction. The existing literature on the identification and assessment of subway construction safety risks(SCSR) is susceptible to the influence of subjective factors. Moreover, although existing studies have explored the interrelationships between different risks, these studies usually analyze the interrelationships of single risks, lack the study of risk chain transfer relationships, and fail to find out the key path of risk transfer. Therefore, this paper innovatively combines text mining, association rules and complex networks to deep mine subway construction safety incident reports and explore risk transfer process. Firstly, it uses text mining technology to identify subway construction safety risk; Then, association rules are introduced to explore the causal relationships among safety risk; Finally, the key safety risk and important transfer paths of subway construction safety accidents (SCSA) are obtained based on the complex network model. Research results show that (a) improper safety management, unimplemented safety subject responsibilities, violation of operation rules, non-perfect safety responsibilities system and insufficient safety education and training are the key safety risk in SCSA; (b) two shorter key risk transfer paths in the subway construction safety network can be obtained: insufficient safety education and training→lower safety awareness→violation of operation rules→safety accidents; insufficient safety checks or hidden trouble investigations→violation of operation rules→safety accidents; (c) in the process of risk transfer, the risk can be controlled by controlling the key nodes or cutting off the transfer path. The results of the study provide new ideas and methods for SCSR identification and influence element mining, which help safety managers propose accurate subway construction safety risk control measures."
2023.09.18.17.57.02;18.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.08491;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08491.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1"">Bohui Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Reklos_I/0/1/0/all/0/1"">Ioannis Reklos</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1"">Nitisha Jain</a>, <a href=""http://arxiv.org/find/cs/1/au:+Penuela_A/0/1/0/all/0/1"">Albert Mero&#xf1;o Pe&#xf1;uela</a>, <a href=""http://arxiv.org/find/cs/1/au:+Simperl_E/0/1/0/all/0/1"">Elena Simperl</a>";Bohui Zhang,Ioannis Reklos,Nitisha Jain,Albert Meroño Peñuela,Elena Simperl;Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata.;In this work, we explore the use of Large Language Models (LLMs) for knowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge. For this task, given subject and relation pairs sourced from Wikidata, we utilize pre-trained LLMs to produce the relevant objects in string format and link them to their respective Wikidata QIDs. We developed a pipeline using LLMs for Knowledge Engineering (LLMKE), combining knowledge probing and Wikidata entity mapping. The method achieved a macro-averaged F1-score of 0.701 across the properties, with the scores varying from 1.00 to 0.328. These results demonstrate that the knowledge of LLMs varies significantly depending on the domain and that further experimentation is required to determine the circumstances under which LLMs can be used for automatic Knowledge Base (e.g., Wikidata) completion and correction. The investigation of the results also suggests the promising contribution of LLMs in collaborative knowledge engineering. LLMKE won Track 2 of the challenge. The implementation is available at https://github.com/bohuizhang/LLMKE.
2023.09.18.17.57.03;18.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.08181;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08181.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Stewart_M/0/1/0/all/0/1"">Michael Stewart</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hodkiewicz_M/0/1/0/all/0/1"">Melinda Hodkiewicz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1"">Sirui Li</a>";Michael Stewart,Melinda Hodkiewicz,Sirui Li;Large Language Models for Failure Mode Classification: An Investigation.;In this paper we present the first investigation into the effectiveness of Large Language Models (LLMs) for Failure Mode Classification (FMC). FMC, the task of automatically labelling an observation with a corresponding failure mode code, is a critical task in the maintenance domain as it reduces the need for reliability engineers to spend their time manually analysing work orders. We detail our approach to prompt engineering to enable an LLM to predict the failure mode of a given observation using a restricted code list. We demonstrate that the performance of a GPT-3.5 model (F1=0.80) fine-tuned on annotated data is a significant improvement over a currently available text classification model (F1=0.60) trained on the same annotated data set. The fine-tuned model also outperforms the out-of-the box GPT-3.5 (F1=0.46). This investigation reinforces the need for high quality fine-tuning data sets for domain-specific tasks using LLMs.
2023.09.18.17.57.04;18.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.08112;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08112.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"">Yulin Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1"">Ning Ding</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1"">Hai-Tao Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zhiyuan Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1"">Maosong Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1"">Bowen Zhou</a>";Yulin Chen,Ning Ding,Hai-Tao Zheng,Zhiyuan Liu,Maosong Sun,Bowen Zhou;Empowering Private Tutoring by Chaining Large Language Models.;Artificial intelligence has been applied in various aspects of online education to facilitate teaching and learning. However, few approaches has been made toward a complete AI-powered tutoring system. In this work, we explore the development of a full-fledged intelligent tutoring system powered by state-of-the-art large language models (LLMs), covering automatic course planning and adjusting, tailored instruction, and flexible quiz evaluation. To make the system robust to prolonged interaction and cater to individualized education, the system is decomposed into three inter-connected core processes-interaction, reflection, and reaction. Each process is implemented by chaining LLM-powered tools along with dynamically updated memory modules. Tools are LLMs prompted to execute one specific task at a time, while memories are data storage that gets updated during education process. Statistical results from learning logs demonstrate the effectiveness and mechanism of each tool usage. Subjective feedback from human users reveal the usability of each function, and comparison with ablation systems further testify the benefits of the designed processes in long-term interaction.
2023.09.18.17.57.05;18.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.07938;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.07938.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Mudgal_P/0/1/0/all/0/1"">Priyanka Mudgal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wouhaybi_R/0/1/0/all/0/1"">Rita Wouhaybi</a>";Priyanka Mudgal,Rita Wouhaybi;An Assessment of ChatGPT on Log Data.;Recent development of large language models (LLMs), such as ChatGPT has been widely applied to a wide range of software engineering tasks. Many papers have reported their analysis on the potential advantages and limitations of ChatGPT for writing code, summarization, text generation, etc. However, the analysis of the current state of ChatGPT for log processing has received little attention. Logs generated by large-scale software systems are complex and hard to understand. Despite their complexity, they provide crucial information for subject matter experts to understand the system status and diagnose problems of the systems. In this paper, we investigate the current capabilities of ChatGPT to perform several interesting tasks on log data, while also trying to identify its main shortcomings. Our findings show that the performance of the current version of ChatGPT for log processing is limited, with a lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role of LLMs in the log processing discipline and possible next steps to improve the current capabilities of ChatGPT and the future LLMs in this area. We believe our work can contribute to future academic research to address the identified issues.
2023.09.18.17.57.06;18.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;kdnuggets;;;https://www.kdnuggets.com/meet-metagpt-the-chatgptpowered-ai-assistant-that-turns-text-into-web-apps?utm_source=rss&utm_medium=rss&utm_campaign=meet-metagpt-the-chatgpt-powered-ai-assistant-that-turns-text-into-web-apps;;;Meet MetaGPT: The ChatGPT-Powered AI Assistant That Turns Text Into Web Apps;MetaGPT by Pico allows users to build any kind of app they envision using the power of natural language. All you need to do is type in a text prompt, and MetaGPT automatically turns your input into a functional web application. The tool uses GPT-4 under the hood, which gives it the ability to understand nuanced prompts and craft the underlying logic for the web app. And although the current capabilities of MetaGPT may seem impressive, this is just the tip of the iceberg of what lies ahead in the field of generative AI. As we continue to refine AI models, the functionalities that no-code platforms can offer will expand, democratizing the tech development landscape. We are paving the way to a future where anyone can bring their app ideas to life without hefty investments or having to spend years learning programming languages. ...
2023.09.18.17.57.07;18.09.2023;07;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.08284;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08284.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Reif_V/0/1/0/all/0/1"">Valerie Reif</a>, <a href=""http://arxiv.org/find/cs/1/au:+Strasser_T/0/1/0/all/0/1"">Thomas I. Strasser</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jimeno_J/0/1/0/all/0/1"">Joseba Jimeno</a>, <a href=""http://arxiv.org/find/cs/1/au:+Farre_M/0/1/0/all/0/1"">Marjolaine Farre</a>, <a href=""http://arxiv.org/find/cs/1/au:+Genest_O/0/1/0/all/0/1"">Oliver Genest</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gyrard_A/0/1/0/all/0/1"">Am&#xe9;lie Gyrard</a>, <a href=""http://arxiv.org/find/cs/1/au:+McGranaghan_M/0/1/0/all/0/1"">Mark McGranaghan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lipari_G/0/1/0/all/0/1"">Gianluca Lipari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schutz_J/0/1/0/all/0/1"">Johann Sch&#xfc;tz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Uslar_M/0/1/0/all/0/1"">Mathias Uslar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vogel_S/0/1/0/all/0/1"">Sebastian Vogel</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bytyqi_A/0/1/0/all/0/1"">Arsim Bytyqi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dornmair_R/0/1/0/all/0/1"">Rita Dornmair</a>, <a href=""http://arxiv.org/find/cs/1/au:+Corusa_A/0/1/0/all/0/1"">Andreas Corusa</a>, <a href=""http://arxiv.org/find/cs/1/au:+Roy_G/0/1/0/all/0/1"">Gaurav Roy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ponci_F/0/1/0/all/0/1"">Ferdinanda Ponci</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dognini_A/0/1/0/all/0/1"">Alberto Dognini</a>, <a href=""http://arxiv.org/find/cs/1/au:+Monti_A/0/1/0/all/0/1"">Antonello Monti</a>";Valerie Reif,Thomas I. Strasser,Joseba Jimeno,Marjolaine Farre,Oliver Genest,Amélie Gyrard,Mark McGranaghan,Gianluca Lipari,Johann Schütz,Mathias Uslar,Sebastian Vogel,Arsim Bytyqi,Rita Dornmair,Andreas Corusa,Gaurav Roy,Ferdinanda Ponci,Alberto Dognini,Antonello Monti;Towards an Interoperability Roadmap for the Energy Transition.;Smart grid interoperability is the means to achieve the twin green and digital transition but re-mains heterogeneous and fragmented to date. This work presents the first ideas and corner-stones of an Interoperability Roadmap for the Energy Transition that is being developed by the Horizon Europe int:net project. This roadmap builds on four cornerstones that address open interoperability issues. These are a knowledge base to address the lack of convergence among existing initiatives, a maturity model and a network of testing and certification facilities to ad-dress the lack of practical tools for the industry, and a governance process to address the gap between standards-related approaches of Standards Development Organisations and Research and Innovation projects. A community of practice will be set up to ensure the continuity of the ongoing activities related to smart grid interoperability. To outlive the duration of the int:net project, the aim is to formalise the community of practice as a legal entity.
2023.09.18.17.57.08;18.09.2023;08;05;Legal;Legal, Law et al.;arxiv;2309.08173;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08173.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yue_L/0/1/0/all/0/1"">Linan Yue</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1"">Qi Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1"">Yichao Du</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1"">Weibo Gao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Ye Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yao_F/0/1/0/all/0/1"">Fangzhou Yao</a>";Linan Yue,Qi Liu,Yichao Du,Weibo Gao,Ye Liu,Fangzhou Yao;FedJudge: Federated Legal Large Language Model.;Large Language Models (LLMs) have gained prominence in the field of Legal Intelligence, offering potential applications in assisting legal professionals and laymen. However, the centralized training of these Legal LLMs raises data privacy concerns, as legal data is distributed among various institutions containing sensitive individual information. This paper addresses this challenge by exploring the integration of Legal LLMs with Federated Learning (FL) methodologies. By employing FL, Legal LLMs can be fine-tuned locally on devices or clients, and their parameters are aggregated and distributed on a central server, ensuring data privacy without directly sharing raw data. However, computation and communication overheads hinder the full fine-tuning of LLMs under the FL setting. Moreover, the distribution shift of legal data reduces the effectiveness of FL methods. To this end, in this paper, we propose the first Federated Legal Large Language Model (FedJudge) framework, which fine-tunes Legal LLMs efficiently and effectively. Specifically, FedJudge utilizes parameter-efficient fine-tuning methods to update only a few additional parameters during the FL training. Besides, we explore the continual learning methods to preserve the global model's important parameters when training local clients to mitigate the problem of data shifts. Extensive experimental results on three real-world datasets clearly validate the effectiveness of FedJudge. Code is released at https://github.com/yuelinan/FedJudge.
2023.09.18.17.57.09;18.09.2023;09;06;Public Services;Public Services;arxiv;2309.08266;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08266.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ghezzi_R/0/1/0/all/0/1"">Reetta Ghezzi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kolehmainen_T/0/1/0/all/0/1"">Taija Kolehmainen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Setala_M/0/1/0/all/0/1"">Manu Set&#xe4;l&#xe4;</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mikkonen_T/0/1/0/all/0/1"">Tommi Mikkonen</a>";Reetta Ghezzi,Taija Kolehmainen,Manu Setälä,Tommi Mikkonen;Enterprise Architecture as an Enabler for a Government Business Ecosystem: Experiences from Finland.;Public sector procurement units in the field of ICT suffer from siloed, application-specific architectures, where each system operates in isolation from others. As a consequence, similar or even identical data is maintained in several different databases hosted by different organizations. Such problems are caused by the lack of standard guidelines and practices that would result in interoperable systems instead of overlapping ones. In the Finnish public sector, enterprise architecture (EA) is a mandatory requirement so that an ecosystem can be formed to overcome the above problems. However, the adoption rates are low, and the focus is often on technology rather than processes and practices. This study investigates the use of EA and its potential in Finnish procurement units through semi-structured interviews. Five procurement units and four vendors participated in the study, and altogether 12 interviews took place.
2023.09.18.17.57.10;18.09.2023;10;09;Commerce;Commerce, Trading, Sales, Retail et al.;repec;;http://nep.repec.org/rss/nep-com.rss.xml;http://d.repec.org/n?u=RePEc:cpl:wpaper:2301&r=com;;Matthew T. ColeMichael McCullough;California Beer Price Posting: An exploratory analysis of pricing along the supply chain;Using newly released public data on beer prices in the state of California, we construct a large dataset (approximately 2 million observations) that includes beer price and packaging configurations. We merge this dataset with brewery attributes and county demographics to explore pricing differentials across California, the USâ€™s largest brewing state. We provide evidence of potential pricing-to-market conducted by macro breweries across the three-tier distribution system where craft breweries do not. In addition, we describe package attributes that exhibit price differentials across brewery types. We make the cleaned data available to the public and provide avenues for future research that may addressed with this new data.
2023.09.18.17.57.11;18.09.2023;11;09;Commerce;Commerce, Trading, Sales, Retail et al.;towardsai;;;https://pub.towardsai.net/the-llm-advantage-transforming-ecommerce-search-6d398e1e9cf2;;;The LLM Advantage: Transforming E-commerce Search;In this post, we shall explore some of these ideas and possible implementation approaches, along with code samples with vertex.ai. Here are a few such cases where LLMs could catalyze product discovery and hence increase customer engagement in an e-commerce product - Producing comprehensive product summaries with LLM's generative ability to capture a broader context for the product. Leveraging the power of generalization and reasoning ability of LLMs to overlap the contexts — both query and products for better product discovery driven by shared understanding. Harnessing the power of code /query generation ability of the LLMs to produce backend queries to cater to the advanced search filters and segments from the generic expressions given by the user in natural language form. Employing the conversational interface for stateful product discovery instead of discrete search queries alongside filters and paginated scrolls. The chat interface goes a long way in harnessing deep contextual signals expressed by the user over multi-level interactions, which only strengthens the context over time. LLM's innate ability in chat-context propagation and reasoning the impending user action aligns perfectly with the concept of conversational discovery!
2023.09.18.17.57.12;18.09.2023;12;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.08008;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08008.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sivarajkumar_S/0/1/0/all/0/1"">Sonish Sivarajkumar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kelley_M/0/1/0/all/0/1"">Mark Kelley</a>, <a href=""http://arxiv.org/find/cs/1/au:+Samolyk_Mazzanti_A/0/1/0/all/0/1"">Alyssa Samolyk-Mazzanti</a>, <a href=""http://arxiv.org/find/cs/1/au:+Visweswaran_S/0/1/0/all/0/1"">Shyam Visweswaran</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yanshan Wang</a>";Sonish Sivarajkumar,Mark Kelley,Alyssa Samolyk-Mazzanti,Shyam Visweswaran,Yanshan Wang;An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing.;Large language models (LLMs) have shown remarkable capabilities in Natural Language Processing (NLP), especially in domains where labeled data is scarce or expensive, such as clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches. In this paper, we present a comprehensive and systematic experimental study on prompt engineering for five clinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence Extraction, Coreference Resolution, Medication Status Extraction, and Medication Attribute Extraction. We assessed the prompts proposed in recent literature, including simple prefix, simple cloze, chain of thought, and anticipatory prompts, and introduced two new types of prompts, namely heuristic prompting and ensemble prompting. We evaluated the performance of these prompts on three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted zero-shot prompting with few-shot prompting, and provide novel insights and guidelines for prompt engineering for LLMs in clinical NLP. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative AI, and we hope that it will inspire and inform future research in this area.
2023.09.18.17.57.13;18.09.2023;13;15;Control;Control, Planning, Processes et al.;arxiv;2309.08587;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08587.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ajay_A/0/1/0/all/0/1"">Anurag Ajay</a>, <a href=""http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1"">Seungwook Han</a>, <a href=""http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1"">Yilun Du</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1"">Shaung Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1"">Abhi Gupta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1"">Tommi Jaakkola</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1"">Josh Tenenbaum</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1"">Leslie Kaelbling</a>, <a href=""http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1"">Akash Srivastava</a>, <a href=""http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1"">Pulkit Agrawal</a>";Anurag Ajay,Seungwook Han,Yilun Du,Shaung Li,Abhi Gupta,Tommi Jaakkola,Josh Tenenbaum,Leslie Kaelbling,Akash Srivastava,Pulkit Agrawal;Compositional Foundation Models for Hierarchical Planning.;To make effective decisions in novel environments with long-horizon goals, it is crucial to engage in hierarchical reasoning across spatial and temporal scales. This entails planning abstract subgoal sequences, visually reasoning about the underlying plans, and executing actions in accordance with the devised plan through visual-motor control. We propose Compositional Foundation Models for Hierarchical Planning (HiP), a foundation model which leverages multiple expert foundation model trained on language, vision and action data individually jointly together to solve long-horizon tasks. We use a large language model to construct symbolic plans that are grounded in the environment through a large video diffusion model. Generated video plans are then grounded to visual-motor control, through an inverse dynamics model that infers actions from generated videos. To enable effective reasoning within this hierarchy, we enforce consistency between the models via iterative refinement. We illustrate the efficacy and adaptability of our approach in three different long-horizon table-top manipulation tasks.
2023.09.18.17.57.14;18.09.2023;14;16;Human;Human Resource, Personal Assistance et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1164/v1;;Preprints.org - The Multidisciplinary Preprint Platform;The Well-Being of Employees as a Derivative of the Concept of Sustainable Production—the Effects of Implementation from the Perspective of Enterprises Producing Parts and Subassemblies of Technical Means of Agricultural Transport;"The main purpose of the work is to indicate the effects of the implementation of the concept of sustainable production from the perspective of the well-being of employees. The diagnosis was made among manufacturers operating in the sector of agricultural technical means of transport (production of parts and subassemblies). Achieving the main goal required the formulation and implementation of partial goals, which the authors included: (C1) analysis of the concept of sustainable production from the perspective of employees' well-being (theoretical plane); (C2) compiling a research model in the form of an evaluation sheet being the result of a literature query and an expert study (theoretical and design layer); attention was paid to the articulation of categories relevant to the content and scope of research; (C3) verification of the research model (indication of the effects of the implementation of the concept of sustainable production (the perspective of employee well-being) by the surveyed enterprises)."
2023.09.18.17.57.15;18.09.2023;15;16;Human;Human Resource, Personal Assistance et al.;arxiv;2309.08333;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.08333.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Gahar_R/0/1/0/all/0/1"">Rania Mkhinini Gahar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hidri_A/0/1/0/all/0/1"">Adel Hidri</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hidri_M/0/1/0/all/0/1"">Minyar Sassi Hidri</a>";Rania Mkhinini Gahar,Adel Hidri,Minyar Sassi Hidri;Let's Predict Who Will Move to a New Job.;Any company's human resources department faces the challenge of predicting whether an applicant will search for a new job or stay with the company. In this paper, we discuss how machine learning (ML) is used to predict who will move to a new job. First, the data is pre-processed into a suitable format for ML models. To deal with categorical features, data encoding is applied and several MLA (ML Algorithms) are performed including Random Forest (RF), Logistic Regression (LR), Decision Tree (DT), and eXtreme Gradient Boosting (XGBoost). To improve the performance of ML models, the synthetic minority oversampling technique (SMOTE) is used to retain them. Models are assessed using decision support metrics such as precision, recall, F1-Score, and accuracy.
2023.09.18.17.57.16;18.09.2023;16;16;Human;Human Resource, Personal Assistance et al.;gartner;;;https://www.gartner.com/en/human-resources/topics/artificial-intelligence-in-hr;;;AI in HR: How AI Is Transforming the Future of HR;Advancements in generative AI have renewed focus on applying AI in the HR function 81% of HR leaders have explored or implemented artificial intelligence (AI) solutions to improve process efficiency within their organizations. CHROs must stay ahead by understanding the value of AI solutions and use cases, while planning for the effects AI will have on their HR function and the entire workforce. ...
2023.09.18.17.57.17;18.09.2023;17;17;AgriCulture;Agriculture et al.;arxiv;2112.03816;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2112.03816.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Cerrato_S/0/1/0/all/0/1"">Simone Cerrato</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mazzia_V/0/1/0/all/0/1"">Vittorio Mazzia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Salvetti_F/0/1/0/all/0/1"">Francesco Salvetti</a>, <a href=""http://arxiv.org/find/cs/1/au:+Martini_M/0/1/0/all/0/1"">Mauro Martini</a>, <a href=""http://arxiv.org/find/cs/1/au:+Angarano_S/0/1/0/all/0/1"">Simone Angarano</a>, <a href=""http://arxiv.org/find/cs/1/au:+Navone_A/0/1/0/all/0/1"">Alessandro Navone</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1"">Marcello Chiaberge</a>";Simone Cerrato,Vittorio Mazzia,Francesco Salvetti,Mauro Martini,Simone Angarano,Alessandro Navone,Marcello Chiaberge;A Deep Learning Driven Algorithmic Pipeline for Autonomous Navigation in Row-Based Crops.;Expensive sensors and inefficient algorithmic pipelines significantly affect the overall cost of autonomous machines. However, affordable robotic solutions are essential to practical usage, and their financial impact constitutes a fundamental requirement to employ service robotics in most fields of application. Among all, researchers in the precision agriculture domain strive to devise robust and cost-effective autonomous platforms in order to provide genuinely large-scale competitive solutions. In this article, we present a complete algorithmic pipeline for row-based crops autonomous navigation, specifically designed to cope with low-range sensors and seasonal variations. Firstly, we build on a robust data-driven methodology to generate a viable path for the autonomous machine, covering the full extension of the crop with only the occupancy grid map information of the field. Moreover, our solution leverages on latest advancement of deep learning optimization techniques and synthetic generation of data to provide an affordable solution that efficiently tackles the well-known Global Navigation Satellite System unreliability and degradation due to vegetation growing inside rows. Extensive experimentation and simulations against computer-generated environments and real-world crops demonstrated the robustness and intrinsic generalizability of our methodology that opens the possibility of highly affordable and fully autonomous machines.
2023.09.18.17.57.18;18.09.2023;18;18;Sustainability;Sustainability, Efficiency et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1113/v1;;Preprints.org - The Multidisciplinary Preprint Platform;A Solution for Sustainable City Using Multi-Criteria Decision-Making to achieve Sustainable Developmental Goals for Industry 4.0;Due to a shortage of funding and other market challenges, Small and Medium-sized Enterprises (SMEs) have a tough time adopting new technologies. Numerous technological obstacles nega-tively impact the long-term commercial achievement of SMEs. The deployment of Industry 4.0 might resolve several technological challenges. A sustainable city is a difficult structure whose economical, societal, and ecological components interact and compete with one another. There is a dearth of actual methodologies for measuring interaction. The objective of Industry 4.0 is to obtain a better degree of performance effectiveness and profitability, and greater automation. Conse-quently, the purpose of the research is to determine the influence of Industry 4.0 in fostering economic efficiency in small and medium enterprises' sustainability. A Sustainable City using Multi-Criteria Decision Making (SC-MCDM) system is designed in this research to test and achieve sustainable developmental goals. This paper then gives a technique for calculating the interaction between various standards, such as static interactions and dynamical pattern resemblance, as well as the weight variables of every indication generated by the connection. Furthermore, the ap-plication of the suggested technique is proved by assessing the sustainable development goals of twelve Chinese cities within the Triple Bottom Line (TBL) paradigm. From a geographic-temporal viewpoint, spatial variations in city sustainability reveal regional inequalities in sustainability. Indicator scores suggest that the lack of research spending, falling financing in stationary assets, shortage of financial development, and inadequate shared transit are the most significant limiting factors for most communities. Furthermore, the growth of tertiary industries, the improvement of energy performance, the expansion of green areas, and the reduction of pollution emissions are the key driving forces for enhancing sustainability. Compared to other methodologies, Multi-Criteria Decision Making (MCDM) considers the interplay between conditions, which is an excellent way to assess the sustainability of a city. The experimental findings show the impact of MCDM and sustainability to achieve sustainable development goals.
2023.09.16.13.05.01;16.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;arxiv;2309.07682;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.07682.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"">Chuang Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1"">Hengchang Hu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yan Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1"">Min-Yen Kan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1"">Haizhou Li</a>";Chuang Li,Hengchang Hu,Yan Zhang,Min-Yen Kan,Haizhou Li;A Conversation is Worth A Thousand Recommendations: A Survey of Holistic Conversational Recommender Systems.;"Conversational recommender systems (CRS) generate recommendations through an interactive process. However, not all CRS approaches use human conversations as their source of interaction data; the majority of prior CRS work simulates interactions by exchanging entity-level information. As a result, claims of prior CRS work do not generalise to real-world settings where conversations take unexpected turns, or where conversational and intent understanding is not perfect. To tackle this challenge, the research community has started to examine holistic CRS, which are trained using conversational data collected from real-world scenarios. Despite their emergence, such holistic approaches are under-explored. We present a comprehensive survey of holistic CRS methods by summarizing the literature in a structured manner. Our survey recognises holistic CRS approaches as having three components: 1) a backbone language model, the optional use of 2) external knowledge, and/or 3) external guidance. We also give a detailed analysis of CRS datasets and evaluation methods in real application scenarios. We offer our insight as to the current challenges of holistic CRS and possible future trends."
2023.09.16.13.05.02;16.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.07755;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.07755.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Abburi_H/0/1/0/all/0/1"">Harika Abburi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Suesserman_M/0/1/0/all/0/1"">Michael Suesserman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pudota_N/0/1/0/all/0/1"">Nirmala Pudota</a>, <a href=""http://arxiv.org/find/cs/1/au:+Veeramani_B/0/1/0/all/0/1"">Balaji Veeramani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bowen_E/0/1/0/all/0/1"">Edward Bowen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1"">Sanmitra Bhattacharya</a>";Harika Abburi,Michael Suesserman,Nirmala Pudota,Balaji Veeramani,Edward Bowen,Sanmitra Bhattacharya;Generative AI Text Classification using Ensemble LLM Approaches.;Large Language Models (LLMs) have shown impressive performance across a variety of Artificial Intelligence (AI) and natural language processing tasks, such as content creation, report generation, etc. However, unregulated malign application of these models can create undesirable consequences such as generation of fake news, plagiarism, etc. As a result, accurate detection of AI-generated language can be crucial in responsible usage of LLMs. In this work, we explore 1) whether a certain body of text is AI generated or written by human, and 2) attribution of a specific language model in generating a body of text. Texts in both English and Spanish are considered. The datasets used in this study are provided as part of the Automated Text Identification (AuTexTification) shared task. For each of the research objectives stated above, we propose an ensemble neural model that generates probabilities from different pre-trained LLMs which are used as features to a Traditional Machine Learning (TML) classifier following it. For the first task of distinguishing between AI and human generated text, our model ranked in fifth and thirteenth place (with macro $F1$ scores of 0.733 and 0.649) for English and Spanish texts, respectively. For the second task on model attribution, our model ranked in first place with macro $F1$ scores of 0.625 and 0.653 for English and Spanish texts, respectively.
2023.09.16.13.05.03;16.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.07382;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.07382.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1"">Yunshu Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Iso_H/0/1/0/all/0/1"">Hayate Iso</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pezeshkpour_P/0/1/0/all/0/1"">Pouya Pezeshkpour</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bhutani_N/0/1/0/all/0/1"">Nikita Bhutani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hruschka_E/0/1/0/all/0/1"">Estevam Hruschka</a>";Yunshu Wu,Hayate Iso,Pouya Pezeshkpour,Nikita Bhutani,Estevam Hruschka;Less is More for Long Document Summary Evaluation by LLMs.;Large Language Models (LLMs) have shown promising performance in summary evaluation tasks, yet they face challenges such as high computational costs and the Lost-in-the-Middle problem where important information in the middle of long documents is often overlooked. To address these issues, this paper introduces a novel approach, Extract-then-Evaluate, which involves extracting key sentences from a long source document and then evaluating the summary by prompting LLMs. The results reveal that the proposed method not only significantly reduces evaluation costs but also exhibits a higher correlation with human evaluations. Furthermore, we provide practical recommendations for optimal document length and sentence extraction methods, contributing to the development of cost-effective yet more accurate methods for LLM-based text generation evaluation.
2023.09.16.13.05.04;16.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/document-topic-extraction-with-large-language-models-llm-and-the-latent-dirichlet-allocation-e4697e4dae87;;;Document Topic Extraction with Large Language Models (LLM) and the Latent Dirichlet Allocation (LDA) Algorithm;I was developing a web application for chatting with PDF files, capable of processing large documents, above 1000 pages. But before starting a conversation with the document, I wanted the application to give the user a brief summary of the main topics, so it would be easier to start the interaction. One way to do it is by summarizing the document using LangChain, as showed in its documentation. The problem, however, is the high computational cost and, by extension, the monetary cost. A thousand-page document contains roughly 250 000 words and each word needs to be fed into the LLM. Even more, the results must be further processed, as with the map-reduce method. A conservative estimate on the cost using gpt-3.5 Turbo with 4k context is above 1$ per document, just for the summary. Even when using free resources, such as the Unofficial HuggingChat API, the sheer number of required API calls would be an abuse. So, I needed a different approach.
2023.09.16.13.05.05;16.09.2023;05;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.07629;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.07629.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Smith_P/0/1/0/all/0/1"">Paul Smith</a>, <a href=""http://arxiv.org/find/cs/1/au:+Piatkowska_E/0/1/0/all/0/1"">Eva Piatkowska</a>, <a href=""http://arxiv.org/find/cs/1/au:+Widl_E/0/1/0/all/0/1"">Edmund Widl</a>, <a href=""http://arxiv.org/find/cs/1/au:+Andren_F/0/1/0/all/0/1"">Filip Pr&#xf6;stl Andr&#xe9;n</a>, <a href=""http://arxiv.org/find/cs/1/au:+Strasser_T/0/1/0/all/0/1"">Thomas I. Strasser</a>";Paul Smith,Eva Piatkowska,Edmund Widl,Filip Pröstl Andrén,Thomas I. Strasser;Towards a Systematic Approach for Smart Grid Hazard Analysis and Experiment Specification.;"The transition to the smart grid introduces complexity to the design and operation of electric power systems. This complexity has the potential to result in safety-related losses that are caused, for example, by unforeseen interactions between systems and cyber-attacks. Consequently, it is important to identify potential losses and their root causes, ideally during system design. This is non-trivial and requires a systematic approach. Furthermore, due to complexity, it may not possible to reason about the circumstances that could lead to a loss; in this case, experiments are required. In this work, we present how two complementary deductive approaches can be usefully integrated to address these concerns: Systems Theoretic Process Analysis (STPA) is a systems approach to identifying safety-related hazard scenarios; and the ERIGrid Holistic Test Description (HTD) provides a structured approach to refine and document experiments. The intention of combining these approaches is to enable a systematic approach to hazard analysis whose findings can be experimentally tested. We demonstrate the use of this approach with a reactive power voltage control case study for a low voltage distribution network."
2023.09.16.13.05.06;16.09.2023;06;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.07708;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.07708.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1"">Haochong Xia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1"">Shuo Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"">Xinrun Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1"">Bo An</a>";Haochong Xia,Shuo Sun,Xinrun Wang,Bo An;Market-GAN: Adding Control to Financial Market Data Generation with Semantic Context.;"Financial simulators play an important role in enhancing forecasting accuracy, managing risks, and fostering strategic financial decision-making. Despite the development of financial market simulation methodologies, existing frameworks often struggle with adapting to specialized simulation context. We pinpoint the challenges as i) current financial datasets do not contain context labels; ii) current techniques are not designed to generate financial data with context as control, which demands greater precision compared to other modalities; iii) the inherent difficulties in generating context-aligned, high-fidelity data given the non-stationary, noisy nature of financial data. To address these challenges, our contributions are: i) we proposed the Contextual Market Dataset with market dynamics, stock ticker, and history state as context, leveraging a market dynamics modeling method that combines linear regression and Dynamic Time Warping clustering to extract market dynamics; ii) we present Market-GAN, a novel architecture incorporating a Generative Adversarial Networks (GAN) for the controllable generation with context, an autoencoder for learning low-dimension features, and supervisors for knowledge transfer; iii) we introduce a two-stage training scheme to ensure that Market-GAN captures the intrinsic market distribution with multiple objectives. In the pertaining stage, with the use of the autoencoder and supervisors, we prepare the generator with a better initialization for the adversarial training stage. We propose a set of holistic evaluation metrics that consider alignment, fidelity, data usability on downstream tasks, and market facts. We evaluate Market-GAN with the Dow Jones Industrial Average data from 2000 to 2023 and showcase superior performance in comparison to 4 state-of-the-art time-series generative models."
2023.09.16.13.05.07;16.09.2023;07;11;Communication;Language, Machine Translation, Audio, Vision et al.;arxiv;2307.04408;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.04408.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1"">Jiali Zeng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1"">Fandong Meng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1"">Yongjing Yin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1"">Jie Zhou</a>";Jiali Zeng,Fandong Meng,Yongjing Yin,Jie Zhou;TIM: Teaching Large Language Models to Translate with Comparison.;Open-sourced large language models (LLMs) have demonstrated remarkable efficacy in various tasks with instruction tuning. However, these models can sometimes struggle with tasks that require more specialized knowledge such as translation. One possible reason for such deficiency is that instruction tuning aims to generate fluent and coherent text that continues from a given instruction without being constrained by any task-specific requirements. Moreover, it can be more challenging for tuning smaller LLMs with lower-quality training data. To address this issue, we propose a novel framework using examples in comparison to teach LLMs to learn translation. Our approach involves presenting the model with examples of correct and incorrect translations and using a preference loss to guide the model's learning. We evaluate our method on WMT2022 test sets and show that it outperforms existing methods. Our findings offer a new perspective on fine-tuning LLMs for translation tasks and provide a promising solution for generating high-quality translations. Please refer to Github for more details: https://github.com/lemon0830/TIM.
2023.09.16.13.05.08;16.09.2023;08;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.07430;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.07430.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Veen_D/0/1/0/all/0/1"">Dave Van Veen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Uden_C/0/1/0/all/0/1"">Cara Van Uden</a>, <a href=""http://arxiv.org/find/cs/1/au:+Blankemeier_L/0/1/0/all/0/1"">Louis Blankemeier</a>, <a href=""http://arxiv.org/find/cs/1/au:+Delbrouck_J/0/1/0/all/0/1"">Jean-Benoit Delbrouck</a>, <a href=""http://arxiv.org/find/cs/1/au:+Aali_A/0/1/0/all/0/1"">Asad Aali</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bluethgen_C/0/1/0/all/0/1"">Christian Bluethgen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pareek_A/0/1/0/all/0/1"">Anuj Pareek</a>, <a href=""http://arxiv.org/find/cs/1/au:+Polacin_M/0/1/0/all/0/1"">Malgorzata Polacin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Collins_W/0/1/0/all/0/1"">William Collins</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ahuja_N/0/1/0/all/0/1"">Neera Ahuja</a>, <a href=""http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1"">Curtis P. Langlotz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hom_J/0/1/0/all/0/1"">Jason Hom</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gatidis_S/0/1/0/all/0/1"">Sergios Gatidis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pauly_J/0/1/0/all/0/1"">John Pauly</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chaudhari_A/0/1/0/all/0/1"">Akshay S. Chaudhari</a>";Dave Van Veen,Cara Van Uden,Louis Blankemeier,Jean-Benoit Delbrouck,Asad Aali,Christian Bluethgen,Anuj Pareek,Malgorzata Polacin,William Collins,Neera Ahuja,Curtis P. Langlotz,Jason Hom,Sergios Gatidis,John Pauly,Akshay S. Chaudhari;Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts.;Sifting through vast textual data and summarizing key information imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown immense promise in natural language processing (NLP) tasks, their efficacy across diverse clinical summarization tasks has not yet been rigorously examined. In this work, we employ domain adaptation methods on eight LLMs, spanning six datasets and four distinct summarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue. Our thorough quantitative assessment reveals trade-offs between models and adaptation methods in addition to instances where recent advances in LLMs may not lead to improved results. Further, in a clinical reader study with six physicians, we depict that summaries from the best adapted LLM are preferable to human summaries in terms of completeness and correctness. Our ensuing qualitative analysis delineates mutual challenges faced by both LLMs and human experts. Lastly, we correlate traditional quantitative NLP metrics with reader study scores to enhance our understanding of how these metrics align with physician preferences. Our research marks the first evidence of LLMs outperforming human experts in clinical text summarization across multiple tasks. This implies that integrating LLMs into clinical workflows could alleviate documentation burden, empowering clinicians to focus more on personalized patient care and other irreplaceable human aspects of medicine.
2023.09.16.13.05.09;16.09.2023;09;16;Human;Human Resource, Personal Assistance et al.;towardsdatascience;;;https://towardsdatascience.com/your-own-personal-chatgpt-cb0512091e3f;;;Your Own Personal ChatGPT;I was excited when I got an email from OpenAI announcing the ability to fine-tune ChatGPT. The update came in response to the requests from developers and businesses looking to customize the model to better cater to their specific requirements. By leveraging this fine-tuning, it's now possible to improve steerability, achieve more consistent output formatting, and establish a desired custom tone. Another noteworthy aspect is that users can send shorter prompts without any notable dip in performance. Here's what OpenAI says on their development blog. This update gives developers the ability to customize models that perform better for their use cases and run these custom models at scale. Early tests have shown a fine-tuned version of GPT-3.5 Turbo can match, or even outperform, base GPT-4-level capabilities on certain narrow tasks. As with all our APIs, data sent in and out of the fine-tuning API is owned by the customer and is not used by OpenAI, or any other organization, to train other models. In this article, I'll demonstrate how I used text from my Medium articles as training and test data to convert plain text into Markdown format automatically. Before I describe the experiment, I'll give you a little background on ChatGPT.
2023.09.15.13.34.01;15.09.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.07026;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.07026.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1"">Yafeng Gu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1"">Yiheng Shen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"">Xiang Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1"">Shaoyu Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1"">Yiling Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1"">Zhixiang Cao</a>";Yafeng Gu,Yiheng Shen,Xiang Chen,Shaoyu Yang,Yiling Huang,Zhixiang Cao;APICom: Automatic API Completion via Prompt Learning and Adversarial Training-based Data Augmentation.;Based on developer needs and usage scenarios, API (Application Programming Interface) recommendation is the process of assisting developers in finding the required API among numerous candidate APIs. Previous studies mainly modeled API recommendation as the recommendation task, which can recommend multiple candidate APIs for the given query, and developers may not yet be able to find what they need. Motivated by the neural machine translation research domain, we can model this problem as the generation task, which aims to directly generate the required API for the developer query. After our preliminary investigation, we find the performance of this intuitive approach is not promising. The reason is that there exists an error when generating the prefixes of the API. However, developers may know certain API prefix information during actual development in most cases. Therefore, we model this problem as the automatic completion task and propose a novel approach APICom based on prompt learning, which can generate API related to the query according to the prompts (i.e., API prefix information). Moreover, the effectiveness of APICom highly depends on the quality of the training dataset. In this study, we further design a novel gradient-based adversarial training method {\atpart} for data augmentation, which can improve the normalized stability when generating adversarial examples. To evaluate the effectiveness of APICom, we consider a corpus of 33k developer queries and corresponding APIs. Compared with the state-of-the-art baselines, our experimental results show that APICom can outperform all baselines by at least 40.02\%, 13.20\%, and 16.31\% in terms of the performance measures EM@1, MRR, and MAP. Finally, our ablation studies confirm the effectiveness of our component setting (such as our designed adversarial training method, our used pre-trained model, and prompt learning) in APICom.
2023.09.15.13.34.02;15.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.07062;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.07062.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Cummins_C/0/1/0/all/0/1"">Chris Cummins</a>, <a href=""http://arxiv.org/find/cs/1/au:+Seeker_V/0/1/0/all/0/1"">Volker Seeker</a>, <a href=""http://arxiv.org/find/cs/1/au:+Grubisic_D/0/1/0/all/0/1"">Dejan Grubisic</a>, <a href=""http://arxiv.org/find/cs/1/au:+Elhoushi_M/0/1/0/all/0/1"">Mostafa Elhoushi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1"">Youwei Liang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Roziere_B/0/1/0/all/0/1"">Baptiste Roziere</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gehring_J/0/1/0/all/0/1"">Jonas Gehring</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gloeckle_F/0/1/0/all/0/1"">Fabian Gloeckle</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hazelwood_K/0/1/0/all/0/1"">Kim Hazelwood</a>, <a href=""http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1"">Gabriel Synnaeve</a>, <a href=""http://arxiv.org/find/cs/1/au:+Leather_H/0/1/0/all/0/1"">Hugh Leather</a>";Chris Cummins,Volker Seeker,Dejan Grubisic,Mostafa Elhoushi,Youwei Liang,Baptiste Roziere,Jonas Gehring,Fabian Gloeckle,Kim Hazelwood,Gabriel Synnaeve,Hugh Leather;Large Language Models for Compiler Optimization.;We explore the novel application of Large Language Models to code optimization. We present a 7B-parameter transformer model trained from scratch to optimize LLVM assembly for code size. The model takes as input unoptimized assembly and outputs a list of compiler options to best optimize the program. Crucially, during training, we ask the model to predict the instruction counts before and after optimization, and the optimized code itself. These auxiliary learning tasks significantly improve the optimization performance of the model and improve the model's depth of understanding. We evaluate on a large suite of test programs. Our approach achieves a 3.0% improvement in reducing instruction counts over the compiler, outperforming two state-of-the-art baselines that require thousands of compilations. Furthermore, the model shows surprisingly strong code reasoning abilities, generating compilable code 91% of the time and perfectly emulating the output of the compiler 70% of the time.
2023.09.15.13.34.03;15.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.06719;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06719.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"">Siyao Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1"">Daocheng Fu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"">Zhao Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1"">Bin Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cai_P/0/1/0/all/0/1"">Pinlong Cai</a>";Siyao Zhang,Daocheng Fu,Zhao Zhang,Bin Yu,Pinlong Cai;TrafficGPT: Viewing, Processing and Interacting with Traffic Foundation Models.;"With the promotion of chatgpt to the public, Large language models indeed showcase remarkable common sense, reasoning, and planning skills, frequently providing insightful guidance. These capabilities hold significant promise for their application in urban traffic management and control. However, LLMs struggle with addressing traffic issues, especially processing numerical data and interacting with simulations, limiting their potential in solving traffic-related challenges. In parallel, specialized traffic foundation models exist but are typically designed for specific tasks with limited input-output interactions. Combining these models with LLMs presents an opportunity to enhance their capacity for tackling complex traffic-related problems and providing insightful suggestions. To bridge this gap, we present TrafficGPT, a fusion of ChatGPT and traffic foundation models. This integration yields the following key enhancements: 1) empowering ChatGPT with the capacity to view, analyze, process traffic data, and provide insightful decision support for urban transportation system management; 2) facilitating the intelligent deconstruction of broad and complex tasks and sequential utilization of traffic foundation models for their gradual completion; 3) aiding human decision-making in traffic control through natural language dialogues; and 4) enabling interactive feedback and solicitation of revised outcomes. By seamlessly intertwining large language model and traffic expertise, TrafficGPT not only advances traffic management but also offers a novel approach to leveraging AI capabilities in this domain. The TrafficGPT demo can be found in https://github.com/lijlansg/TrafficGPT.git."
2023.09.15.13.34.04;15.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.06490;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06490.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Finch_S/0/1/0/all/0/1"">Sarah E. Finch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Paek_E/0/1/0/all/0/1"">Ellie S. Paek</a>, <a href=""http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1"">Jinho D. Choi</a>";Sarah E. Finch,Ellie S. Paek,Jinho D. Choi;Leveraging Large Language Models for Automated Dialogue Analysis.;Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses. However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance. Nevertheless, ChatGPT shows promising potential and often outperforms specialized detection models. We conclude with an in-depth examination of the prevalent shortcomings of ChatGPT, offering guidance for future research to enhance LLM capabilities.
2023.09.15.13.34.05;15.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.06503;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06503.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Tekumalla_R/0/1/0/all/0/1"">Ramya Tekumalla</a>, <a href=""http://arxiv.org/find/cs/1/au:+Banda_J/0/1/0/all/0/1"">Juan M. Banda</a>";Ramya Tekumalla,Juan M. Banda;Leveraging Large Language Models and Weak Supervision for Social Media data annotation: an evaluation using COVID-19 self-reported vaccination tweets.;The COVID-19 pandemic has presented significant challenges to the healthcare industry and society as a whole. With the rapid development of COVID-19 vaccines, social media platforms have become a popular medium for discussions on vaccine-related topics. Identifying vaccine-related tweets and analyzing them can provide valuable insights for public health research-ers and policymakers. However, manual annotation of a large number of tweets is time-consuming and expensive. In this study, we evaluate the usage of Large Language Models, in this case GPT-4 (March 23 version), and weak supervision, to identify COVID-19 vaccine-related tweets, with the purpose of comparing performance against human annotators. We leveraged a manu-ally curated gold-standard dataset and used GPT-4 to provide labels without any additional fine-tuning or instructing, in a single-shot mode (no additional prompting).
2023.09.15.13.34.06;15.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.06551;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06551.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Spinellis_D/0/1/0/all/0/1"">Diomidis Spinellis</a>";Diomidis Spinellis;Commands as AI Conversations.;"Developers and data scientists often struggle to write command-line inputs, even though graphical interfaces or tools like ChatGPT can assist. The solution? ""ai-cli,"" an open-source system inspired by GitHub Copilot that converts natural language prompts into executable commands for various Linux command-line tools. By tapping into OpenAI's API, which allows interaction through JSON HTTP requests, ""ai-cli"" transforms user queries into actionable command-line instructions. However, integrating AI assistance across multiple command-line tools, especially in open source settings, can be complex. Historically, operating systems could mediate, but individual tool functionality and the lack of a unified approach have made centralized integration challenging. The ""ai-cli"" tool, by bridging this gap through dynamic loading and linking with each program's Readline library API, makes command-line interfaces smarter and more user-friendly, opening avenues for further enhancement and cross-platform applicability."
2023.09.15.13.34.07;15.09.2023;07;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0948/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Environmental Impact on RF and PLC for Advanced Metering Infrastructure in Smart Grids;In the Neighborhood Area Network (NAN), the Advanced Metering Infrastructure (AMI) enables a bidirectional connection between the Smart Meter (SM) and the Data Concentrator (DC). Sensors, such as smart meter node or Radio Frequency transceiver, play a crucial role in collecting and transmitting data from meters to central unit for advanced monitoring, management, and analysis of energy consumption. Wired and wireless communication technologies can be used to implement the AMI-NAN. This paper delves into a novel approach for optimizing the choice of communication medium, Radio Frequency (RF) or Power-Line Communication (PLC), between the SM and DC in the context of AMI-NAN. The authors methodically select the specific technologies, RF and NB-PLC (Narrow Band Power-Line Communication), and meticulously characterize their attributes. Then, a comparative analysis spanning rural, urban, and industrial settings is conducted to evaluate the proposed method. The overall reliability performance of the AMI-NAN system requires a Packet Error Rate (PER) lower than 10%. To this end, a comprehensive methodology is introduced to assess and enhance the reliability of NB-PLC and RF for AMI-NAN applications. Simulation results demonstrate that wireless communication is the optimal choice for the rural scenario, especially for Signal to Noise Ratio (SNR) lower than 25 dB. However, in urban environments characterized by higher SNR values and moderately dense networks, NB-PLC gains prominence. In denser networks, it outperforms wireless communication, exhibiting a remarkable 10 dB gain for a bit error rate (BER) of 10-3. Moreover, in industrial zones characterized by intricate network topologies and non-linear loads, the powerline channel emerges as the optimal choice for data transmission, affording a gain surpassing 20 dB.
2023.09.15.13.34.08;15.09.2023;08;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202306.1890/v2;;Preprints.org - The Multidisciplinary Preprint Platform;Modeling Social Equity in Energy Consumption Using Digital Twins;This research examines the impact of social equity on energy consumption. We constructed a digital twin for residential energy consumption by enriching the synthetic population with real-world surveys and feeding them with other environmental and appliance data to the energy modeling framework. We analyzed household hourly energy consumption data from Albemarle County and Charlottesville City in Virginia, USA, for the year 2019. We used clustering analysis to identify patterns in social equity and energy consumption. The results demonstrated the impact of different residential attributes on energy poverty. Statistical analyses, including ANOVA and Chi-Squared tests, were conducted to test for significant differences between racial groups in quantitative and categorical variables. The study found that race is significant in determining the location and quality of housing. People of color often live in areas with higher pollution and less access to green spaces. Additionally, income levels and the age of the house are influential factors in determining energy efficiency. Future work should focus on collecting and analyzing data at the country level and using qualitative data collection methods to gain a more comprehensive understanding of social equity issues concerning energy consumption. Overall, this study provides valuable insights into the relationship between different residential attributes and energy consumption, which can inform policy development to promote more equitable and sustainable communities.
2023.09.15.13.34.09;15.09.2023;09;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.06793;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06793.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1"">Yun Bai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Camal_S/0/1/0/all/0/1"">Simon Camal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Michiorri_A/0/1/0/all/0/1"">Andrea Michiorri</a>";Yun Bai,Simon Camal,Andrea Michiorri;Electricity Demand Forecasting through Natural Language Processing with Long Short-Term Memory Networks.;Electricity demand forecasting is a well established research field. Usually this task is performed considering historical loads, weather forecasts, calendar information and known major events. Recently attention has been given on the possible use of new sources of information from textual news in order to improve the performance of these predictions. This paper proposes a Long and Short-Term Memory (LSTM) network incorporating textual news features that successfully predicts the deterministic and probabilistic tasks of the UK national electricity demand. The study finds that public sentiment and word vector representations related to transport and geopolitics have time-continuity effects on electricity demand. The experimental results show that the LSTM with textual features improves by more than 3% compared to the pure LSTM benchmark and by close to 10% over the official benchmark. Furthermore, the proposed model effectively reduces forecasting uncertainty by narrowing the confidence interval and bringing the forecast distribution closer to the truth.
2023.09.15.13.34.10;15.09.2023;10;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.06502;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2309.06502.pdf;" <a href=""http://arxiv.org/find/math/1/au:+Habiba_U/0/1/0/all/0/1"">Ummey Habiba</a>, <a href=""http://arxiv.org/find/math/1/au:+Quddoos_A/0/1/0/all/0/1"">Abdul Quddoos</a>, <a href=""http://arxiv.org/find/math/1/au:+Masihuddin/0/1/0/all/0/1"">Masihuddin</a>";Ummey Habiba,Abdul Quddoos,Masihuddin;On Solving Fixed Charge Transportation Problems Having Interval Valued Parameters.;In this article, we propose a new method for solving the interval fixed charge transportation problem (IFCTP), wherein the parameters (associated cost, fixed cost, supply, and demand) are represented by interval numbers. First, an equivalent bi-objective fixed charge transportation problem (FCTP) is derived from the given IFCTP, and then the equivalent crisp problem is solved using a fuzzy programming technique. To demonstrate the solution procedure, two existing numerical examples (Safi and Razmjoo {\cite{bakp1}}) are coded and solved in LINGO 19.0. We establish the effectiveness of our proposed method through a comparison of the results achieved with those of two pre-existing methods.
2023.09.15.13.34.11;15.09.2023;11;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2308.14131;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.14131.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1"">Jingyang Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1"">Mingyu Xiao</a>";Jingyang Zhao,Mingyu Xiao;Improved Approximation Algorithms for Multidepot Capacitated Vehicle Routing.;The Multidepot Capacitated Vehicle Routing Problem (MCVRP) is a well-known variant of the classic Capacitated Vehicle Routing Problem (CVRP), where we need to route capacitated vehicles located in multiple depots to serve customers' demand such that each vehicle must return to the depot it starts, and the total traveling distance is minimized. There are three variants of MCVRP according to the property of the demand: unit-demand, splittable and unsplittable. We study approximation algorithms for $k$-MCVRP in metric graphs where $k$ is the capacity of each vehicle, and all three versions are APX-hard for any constant $k\geq 3$. Previously, Li and Simchi-Levi proposed a $(2\alpha+1-\alpha/k)$-approximation algorithm for splittable and unit-demand $k$-MCVRP and a $(2\alpha+2-2\alpha/k)$-approximation algorithm for unsplittable $k$-MCVRP, where $\alpha=3/2-10^{-36}$ is the current best approximation ratio for metric TSP. Harks et al. further improved the ratio to 4 for the unsplittable case. We give a $(4-1/1500)$-approximation algorithm for unit-demand and splittable $k$-MCVRP, and a $(4-1/50000)$-approximation algorithm for unsplittable $k$-MCVRP. Furthermore, we give a $(3+\ln2-\max\{\Theta(1/\sqrt{k}),1/9000\})$-approximation algorithm for splittable and unit-demand $k$-MCVRP, and a $(3+\ln2-\Theta(1/\sqrt{k}))$-approximation algorithm for unsplittable $k$-MCVRP under the assumption that the capacity $k$ is a fixed constant. Our results are based on recent progress in approximating CVRP.
2023.09.15.13.34.12;15.09.2023;12;11;Communication;Language, Machine Translation, Audio, Vision et al.;arxiv;2309.06706;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06706.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1"">Minghan Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1"">Jinming Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1"">Thuy-Trang Vu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shiri_F/0/1/0/all/0/1"">Fatemeh Shiri</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1"">Ehsan Shareghi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1"">Gholamreza Haffari</a>";Minghan Wang,Jinming Zhao,Thuy-Trang Vu,Fatemeh Shiri,Ehsan Shareghi,Gholamreza Haffari;Simultaneous Machine Translation with Large Language Models.;Large language models (LLM) have demonstrated their abilities to solve various natural language processing tasks through dialogue-based interactions. For instance, research indicates that LLMs can achieve competitive performance in offline machine translation tasks for high-resource languages. However, applying LLMs to simultaneous machine translation (SimulMT) poses many challenges, including issues related to the training-inference mismatch arising from different decoding patterns. In this paper, we explore the feasibility of utilizing LLMs for SimulMT. Building upon conventional approaches, we introduce a simple yet effective mixture policy that enables LLMs to engage in SimulMT without requiring additional training. Furthermore, after Supervised Fine-Tuning (SFT) on a mixture of full and prefix sentences, the model exhibits significant performance improvements. Our experiments, conducted with Llama2-7B-chat on nine language pairs from the MUST-C dataset, demonstrate that LLM can achieve translation quality and latency comparable to dedicated SimulMT models.
2023.09.15.13.34.13;15.09.2023;13;18;Sustainability;Sustainability, Efficiency et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.1047/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Identification and Reduction of Product Carbon Footprints: Case Studies from the Austrian Automotive Supplier Industry;Greenhouse gas (GHG) emissions from human activities have climbed significantly above pre-pandemic levels and reached record highs that unequivocally accelerate global warming. Industry has a significant impact on climate change, emitting at least 21 % of global GHGs and making little overall progress toward its reduction until now. Reducing industry’s emissions requires coordinated action along the value chains in order to promote mitigation options, such as energy and material efficiency, circular material flows, and transformative changes within production processes. The authors analyzed the GHG emissions generated during the manufacturing of three different products of automotive suppliers located in Austria. Despite previous efforts toward an environmentally compatible fabrication, additional and significant reduction potentials were identified. These measures for product carbon footprint (PCF) reduction included the sourcing of low-carbon materials (which are already available on the market), more extensive use of renewable energy, and changes towards more resource efficient manufacturing processes and machinery. Depending on the materials used, the PCF can be reduced by up to 80 %. The findings serve to prepare for future PCF reporting regulations and illustrate reduction potentials to achieve future market advantages, especially when PCFs become an awarding criterion.
2023.09.14.09.45.01;14.09.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.05557;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.05557.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Miao_Y/0/1/0/all/0/1"">Yukai Miao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1"">Yu Bai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1"">Li Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1"">Dan Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1"">Haifeng Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"">Xizheng Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1"">Ziqiu Luo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1"">Dapeng Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"">Xiuting Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1"">Qi Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiang_C/0/1/0/all/0/1"">Chao Xiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"">Xinchi Li</a>";Yukai Miao,Yu Bai,Li Chen,Dan Li,Haifeng Sun,Xizheng Wang,Ziqiu Luo,Dapeng Sun,Xiuting Xu,Qi Zhang,Chao Xiang,Xinchi Li;An Empirical Study of NetOps Capability of Pre-Trained Large Language Models.;Large language models (LLMs) can respond to human language queries and have shown powerful potential applications in network operations (NetOps). Thanks to the large amount of commonsense knowledge inherent, LLMs achieve much better inference accuracy than traditional models and emerge with strong abilities in generalization, reasoning, and code generation. These abilities may have a crucial boost to automated and intelligent NetOps. However, it remains under-explored how well LLMs perform in various NetOps tasks. In this work, we make a systematic assessment of the capabilities, strengths, and limitations of selected LLMs in the field of NetOps. The evaluation is conducted on a collection of 5,732 questions about NetOps, encompassing 26 publicly available general-domain LLMs, including ChatGPT, LLaMA, Falcon, etc. We also finetune some of these LLMs with our collected NetOps corpus and evaluate the resulting models. The evaluation method follows the widely adopted benchmarks for general-domain LLMs, combined with Chain-of-Thought Prompts and Retrieval-Augmented Generation. The results show that only GPT-4 achieves high accuracy equivalent to passing the NetOps certification exam for humans, while all the other LLMs have much lower accuracy. However, some open models like LLaMA 2 still demonstrate significant potential. Furthermore, we evaluate the impact of factors such as model parameters, prompt engineering, instruction fine-tuning etc. This work shall be treated as the initial effort to systematic evaluation of LLMs in NetOps, and a more rigorous study is required for production use. The evaluation code and dataset will be released to benefit future research.
2023.09.14.09.45.02;14.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.00900;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00900.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Kampik_T/0/1/0/all/0/1"">Timotheus Kampik</a>, <a href=""http://arxiv.org/find/cs/1/au:+Warmuth_C/0/1/0/all/0/1"">Christian Warmuth</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rebmann_A/0/1/0/all/0/1"">Adrian Rebmann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Agam_R/0/1/0/all/0/1"">Ron Agam</a>, <a href=""http://arxiv.org/find/cs/1/au:+Egger_L/0/1/0/all/0/1"">Lukas N.P. Egger</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gerber_A/0/1/0/all/0/1"">Andreas Gerber</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1"">Johannes Hoffart</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kolk_J/0/1/0/all/0/1"">Jonas Kolk</a>, <a href=""http://arxiv.org/find/cs/1/au:+Herzig_P/0/1/0/all/0/1"">Philipp Herzig</a>, <a href=""http://arxiv.org/find/cs/1/au:+Decker_G/0/1/0/all/0/1"">Gero Decker</a>, <a href=""http://arxiv.org/find/cs/1/au:+Aa_H/0/1/0/all/0/1"">Han van der Aa</a>, <a href=""http://arxiv.org/find/cs/1/au:+Polyvyanyy_A/0/1/0/all/0/1"">Artem Polyvyanyy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rinderle_Ma_S/0/1/0/all/0/1"">Stefanie Rinderle-Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Weber_I/0/1/0/all/0/1"">Ingo Weber</a>, <a href=""http://arxiv.org/find/cs/1/au:+Weidlich_M/0/1/0/all/0/1"">Matthias Weidlich</a>";Timotheus Kampik,Christian Warmuth,Adrian Rebmann,Ron Agam,Lukas N.P. Egger,Andreas Gerber,Johannes Hoffart,Jonas Kolk,Philipp Herzig,Gero Decker,Han van der Aa,Artem Polyvyanyy,Stefanie Rinderle-Ma,Ingo Weber,Matthias Weidlich;Large Process Models: Business Process Management in the Age of Generative AI.;The continued success of Large Language Models (LLMs) and other generative artificial intelligence approaches highlights the advantages that large information corpora can have over rigidly defined symbolic models, but also serves as a proof-point of the challenges that purely statistics-based approaches have in terms of safety and trustworthiness. As a framework for contextualizing the potential, as well as the limitations of LLMs and other foundation model-based technologies, we propose the concept of a Large Process Model (LPM) that combines the correlation power of LLMs with the analytical precision and reliability of knowledge-based systems and automated reasoning approaches. LPMs are envisioned to directly utilize the wealth of process management experience that experts have accumulated, as well as process performance data of organizations with diverse characteristics, e.g., regarding size, region, or industry. In this vision, the proposed LPM would allow organizations to receive context-specific (tailored) process and other business models, analytical deep-dives, and improvement recommendations. As such, they would allow to substantially decrease the time and effort required for business transformation, while also allowing for deeper, more impactful, and more actionable insights than previously possible. We argue that implementing an LPM is feasible, but also highlight limitations and research challenges that need to be solved to implement particular aspects of the LPM vision.
2023.09.14.09.45.03;14.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.06358;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06358.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1"">Arijit Ghosh Chowdhury</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1"">Aman Chadha</a>";Arijit Ghosh Chowdhury,Aman Chadha;Generative Data Augmentation using LLMs improves Distributional Robustness in Question Answering.;"Robustness in Natural Language Processing continues to be a pertinent issue, where state of the art models under-perform under naturally shifted distributions. In the context of Question Answering, work on domain adaptation methods continues to be a growing body of research. However, very little attention has been given to the notion of domain generalization under natural distribution shifts, where the target domain is unknown. With drastic improvements in the quality and access to generative models, we answer the question: How do generated datasets influence the performance of QA models under natural distribution shifts? We perform experiments on 4 different datasets under varying amounts of distribution shift, and analyze how ""in-the-wild"" generation can help achieve domain generalization. We take a two-step generation approach, generating both contexts and QA pairs to augment existing datasets. Through our experiments, we demonstrate how augmenting reading comprehension datasets with generated data leads to better robustness towards natural distribution shifts."
2023.09.14.09.45.04;14.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.06363;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06363.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1"">Tianhui Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bollegala_D/0/1/0/all/0/1"">Danushka Bollegala</a>, <a href=""http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1"">Bei Peng</a>";Tianhui Zhang,Danushka Bollegala,Bei Peng;Learning to Predict Concept Ordering for Common Sense Generation.;Prior work has shown that the ordering in which concepts are shown to a commonsense generator plays an important role, affecting the quality of the generated sentence. However, it remains a challenge to determine the optimal ordering of a given set of concepts such that a natural sentence covering all the concepts could be generated from a pretrained generator. To understand the relationship between the ordering of the input concepts and the quality of the generated sentences, we conduct a systematic study considering multiple language models (LMs) and concept ordering strategies. We find that BART-large model consistently outperforms all other LMs considered in this study when fine-tuned using the ordering of concepts as they appear in CommonGen training data as measured using multiple evaluation metrics. Moreover, the larger GPT3-based large language models (LLMs) variants do not necessarily outperform much smaller LMs on this task, even when fine-tuned on task-specific training data. Interestingly, human annotators significantly reorder input concept sets when manually writing sentences covering those concepts, and this ordering provides the best sentence generations independently of the LM used for the generation, outperforming a probabilistic concept ordering baseline
2023.09.14.09.45.05;14.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.06424;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06424.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Roy_P/0/1/0/all/0/1"">Palash R. Roy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Alam_A/0/1/0/all/0/1"">Ajmain I. Alam</a>, <a href=""http://arxiv.org/find/cs/1/au:+Al_omari_F/0/1/0/all/0/1"">Farouq Al-omari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1"">Banani Roy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Roy_C/0/1/0/all/0/1"">Chanchal K. Roy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schneider_K/0/1/0/all/0/1"">Kevin A. Schneider</a>";Palash R. Roy,Ajmain I. Alam,Farouq Al-omari,Banani Roy,Chanchal K. Roy,Kevin A. Schneider;Unveiling the potential of large language models in generating semantic and cross-language clones.;Semantic and Cross-language code clone generation may be useful for code reuse, code comprehension, refactoring and benchmarking. OpenAI's GPT model has potential in such clone generation as GPT is used for text generation. When developers copy/paste codes from Stack Overflow (SO) or within a system, there might be inconsistent changes leading to unexpected behaviours. Similarly, if someone possesses a code snippet in a particular programming language but seeks equivalent functionality in a different language, a semantic cross-language code clone generation approach could provide valuable assistance.In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.We have comprised a diverse set of code fragments and assessed GPT-3s performance in generating code variants.Through extensive experimentation and analysis, where 9 judges spent 158 hours to validate, we investigate the model's ability to produce accurate and semantically correct variants. Our findings shed light on GPT-3's strengths in code generation, offering insights into the potential applications and challenges of using advanced language models in software development. Our quantitative analysis yields compelling results. In the realm of semantic clones, GPT-3 attains an impressive accuracy of 62.14% and 0.55 BLEU score, achieved through few-shot prompt engineering. Furthermore, the model shines in transcending linguistic confines, boasting an exceptional 91.25% accuracy in generating cross-language clones
2023.09.14.09.45.06;14.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.05833;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.05833.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1"">Dylan Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"">Xuchao Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bansal_C/0/1/0/all/0/1"">Chetan Bansal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Las_Casas_P/0/1/0/all/0/1"">Pedro Las-Casas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fonseca_R/0/1/0/all/0/1"">Rodrigo Fonseca</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rajmohan_S/0/1/0/all/0/1"">Saravan Rajmohan</a>";Dylan Zhang,Xuchao Zhang,Chetan Bansal,Pedro Las-Casas,Rodrigo Fonseca,Saravan Rajmohan;PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis.;In recent years, the transition to cloud-based platforms in the IT sector has emphasized the significance of cloud incident root cause analysis to ensure service reliability and maintain customer trust. Central to this process is the efficient determination of root causes, a task made challenging due to the complex nature of contemporary cloud infrastructures. Despite the proliferation of AI-driven tools for root cause identification, their applicability remains limited by the inconsistent quality of their outputs. This paper introduces a method for enhancing confidence estimation in root cause analysis tools by prompting retrieval-augmented large language models (LLMs). This approach operates in two phases. Initially, the model evaluates its confidence based on historical incident data, considering its assessment of the evidence strength. Subsequently, the model reviews the root cause generated by the predictor. An optimization step then combines these evaluations to determine the final confidence assignment. Experimental results illustrate that our method enables the model to articulate its confidence effectively, providing a more calibrated score. We address research questions evaluating the ability of our method to produce calibrated confidence scores using LLMs, the impact of domain-specific retrieved examples on confidence estimates, and its potential generalizability across various root cause analysis models. Through this, we aim to bridge the confidence estimation gap, aiding on-call engineers in decision-making and bolstering the efficiency of cloud incident management.
2023.09.14.09.45.07;14.09.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.05898;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.05898.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lore_N/0/1/0/all/0/1"">Nunzio Lor&#xe8;</a>, <a href=""http://arxiv.org/find/cs/1/au:+Heydari_B/0/1/0/all/0/1"">Babak Heydari</a>";Nunzio Lorè,Babak Heydari;Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing.;This paper investigates the strategic decision-making capabilities of three Large Language Models (LLMs): GPT-3.5, GPT-4, and LLaMa-2, within the framework of game theory. Utilizing four canonical two-player games -- Prisoner's Dilemma, Stag Hunt, Snowdrift, and Prisoner's Delight -- we explore how these models navigate social dilemmas, situations where players can either cooperate for a collective benefit or defect for individual gain. Crucially, we extend our analysis to examine the role of contextual framing, such as diplomatic relations or casual friendships, in shaping the models' decisions. Our findings reveal a complex landscape: while GPT-3.5 is highly sensitive to contextual framing, it shows limited ability to engage in abstract strategic reasoning. Both GPT-4 and LLaMa-2 adjust their strategies based on game structure and context, but LLaMa-2 exhibits a more nuanced understanding of the games' underlying mechanics. These results highlight the current limitations and varied proficiencies of LLMs in strategic decision-making, cautioning against their unqualified use in tasks requiring complex strategic reasoning.
2023.09.14.09.45.08;14.09.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.05920;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.05920.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Nikolakopoulos_A/0/1/0/all/0/1"">Athanasios N. Nikolakopoulos</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kaul_S/0/1/0/all/0/1"">Swati Kaul</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gade_S/0/1/0/all/0/1"">Siva Karthik Gade</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dubrov_B/0/1/0/all/0/1"">Bella Dubrov</a>, <a href=""http://arxiv.org/find/cs/1/au:+Batur_U/0/1/0/all/0/1"">Umit Batur</a>, <a href=""http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1"">Suleiman Ali Khan</a>";Athanasios N. Nikolakopoulos,Swati Kaul,Siva Karthik Gade,Bella Dubrov,Umit Batur,Suleiman Ali Khan;SAGE: Structured Attribute Value Generation for Billion-Scale Product Catalogs.;"We introduce SAGE; a Generative LLM for inferring attribute values for products across world-wide e-Commerce catalogs. We introduce a novel formulation of the attribute-value prediction problem as a Seq2Seq summarization task, across languages, product types and target attributes. Our novel modeling approach lifts the restriction of predicting attribute values within a pre-specified set of choices, as well as, the requirement that the sought attribute values need to be explicitly mentioned in the text. SAGE can infer attribute values even when such values are mentioned implicitly using periphrastic language, or not-at-all-as is the case for common-sense defaults. Additionally, SAGE is capable of predicting whether an attribute is inapplicable for the product at hand, or non-obtainable from the available information. SAGE is the first method able to tackle all aspects of the attribute-value-prediction task as they arise in practical settings in e-Commerce catalogs. A comprehensive set of experiments demonstrates the effectiveness of the proposed approach, as well as, its superiority against state-of-the-art competing alternatives. Moreover, our experiments highlight SAGE's ability to tackle the task of predicting attribute values in zero-shot setting; thereby, opening up opportunities for significantly reducing the overall number of labeled examples required for training."
2023.09.14.09.45.09;14.09.2023;09;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.06082;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06082.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1"">Milan Jain</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1"">Xueqing Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1"">Sohom Datta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Somani_A/0/1/0/all/0/1"">Abhishek Somani</a>";Milan Jain,Xueqing Sun,Sohom Datta,Abhishek Somani;A Machine Learning Framework to Deconstruct the Primary Drivers for Electricity Market Price Events.;"Power grids are moving towards 100% renewable energy source bulk power grids, and the overall dynamics of power system operations and electricity markets are changing. The electricity markets are not only dispatching resources economically but also taking into account various controllable actions like renewable curtailment, transmission congestion mitigation, and energy storage optimization to ensure grid reliability. As a result, price formations in electricity markets have become quite complex. Traditional root cause analysis and statistical approaches are rendered inapplicable to analyze and infer the main drivers behind price formation in the modern grid and markets with variable renewable energy (VRE). In this paper, we propose a machine learning-based analysis framework to deconstruct the primary drivers for price spike events in modern electricity markets with high renewable energy. The outcomes can be utilized for various critical aspects of market design, renewable dispatch and curtailment, operations, and cyber-security applications. The framework can be applied to any ISO or market data; however, in this paper, it is applied to open-source publicly available datasets from California Independent System Operator (CAISO) and ISO New England (ISO-NE)."
2023.09.14.09.45.10;14.09.2023;10;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2309.06299;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.06299.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Bihler_M/0/1/0/all/0/1"">Miranda Bihler</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nelson_H/0/1/0/all/0/1"">Hala Nelson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Okey_E/0/1/0/all/0/1"">Erin Okey</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rivas_N/0/1/0/all/0/1"">Noe Reyes Rivas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Webb_J/0/1/0/all/0/1"">John Webb</a>, <a href=""http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1"">Anna White</a>";Miranda Bihler,Hala Nelson,Erin Okey,Noe Reyes Rivas,John Webb,Anna White;Modeling Supply and Demand in Public Transportation Systems.;The Harrisonburg Department of Public Transportation (HDPT) aims to leverage their data to improve the efficiency and effectiveness of their operations. We construct two supply and demand models that help the department identify gaps in their service. The models take many variables into account, including the way that the HDPT reports to the federal government and the areas with the most vulnerable populations in Harrisonburg City. We employ data analysis and machine learning techniques to make our predictions.
2023.09.14.09.45.11;14.09.2023;11;07;Industry;I4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0899/v1;;Preprints.org - The Multidisciplinary Preprint Platform;A Methodological Approach for Digital Twin Implementation in Waste Management: Improvement of Production and Service Systems;"The escalating environmental challenges that stem from urban residential waste in densely populated areas have become increasingly prominent in recent times. As a result, the waste management sector has experienced significant growth nationwide. However, due to the predominantly manual nature of these processes, their effectiveness falls short of meeting the current demand. Addressing these issues requires process enhancement. In this context, Industry 4.0, particularly the concept of Digital Twins, emerges as a potential avenue for refining processes. To tackle both current and future industry challenges, it is imperative to create a comprehensive methodology capable of generating effective solutions within the waste management sector. This paper provides an explanation of digital twins, outlines the methodological framework comprising an architectural structure and layered model, and details a series of sequential methodical stages for implementing digital twins based on the specific scope determined by the end-user. A noteworthy aspect is the transformative potential of digital twins in enhancing efficiency and precision within waste management practices. By providing a virtual real-time representation of the waste management system, digital twins empower simulations and experimentation to fine-tune processes. Furthermore, they facilitate informed decision-making by offering a detailed visualization of the complete system, simplifying the identification of challenges and opportunities for improvement. that this article derives from the presentation titled ""Digital Twin application methodology for the improvement of production and service systems. Application to waste management processes"" at the ""Sustainable Smart Cities and Territories International Conference"" held in the city of Manizales, Colombia, from 21st to 23rd June 2023."
2023.09.14.09.45.12;14.09.2023;12;15;Control;Control, Planning, Processes et al.;arxiv;2309.05952;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.05952.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Miyaoka_Y/0/1/0/all/0/1"">Yuya Miyaoka</a>, <a href=""http://arxiv.org/find/cs/1/au:+Inoue_M/0/1/0/all/0/1"">Masaki Inoue</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nii_T/0/1/0/all/0/1"">Tomotaka Nii</a>";Yuya Miyaoka,Masaki Inoue,Tomotaka Nii;ChatMPC: Natural Language based MPC Personalization.;We address the personalization of control systems, which is an attempt to adjust inherent safety and other essential control performance based on each user's personal preferences. A typical approach to personalization requires a substantial amount of user feedback and data collection, which may result in a burden on users. Moreover, it might be challenging to collect data in real-time. To overcome this drawback, we propose a natural language-based personalization, which places a comparatively lighter burden on users and enables the personalization system to collect data in real-time. In particular, we consider model predictive control (MPC) and introduce an approach that updates the control specification using chat within the MPC framework, namely ChatMPC. In the numerical experiment, we simulated an autonomous robot equipped with ChatMPC. The result shows that the specification in robot control is updated by providing natural language-based chats, which generate different behaviors.
2023.09.13.21.20.01;13.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0737/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Building a Digital Transformation Maturity Evaluation Model for Construction Enterprises Based on AHP-DEMATEL;With the continuous development of digital transformation and upgrading of Chinese construction enterprises, it is becoming increasingly important to measure their digital level, find the problems in the enterprise transformation process, and identify the key factors of enterprise digital capacity enhancement. This paper constructs a construction enterprise digital transformation maturity evaluation model from six first-level indicators and 20 second-level indicators, including digital strategy, digital business application, digital technology capability, data capability, digital organization capability, and change management. Digital maturity is divided into five levels: business management, process operation, intelligent construction, intelligent scene application, and industrial ecological collaboration. A detailed process of digital maturity evaluation based on the method of Analytic Hierarchy Process (AHP)-Decision Testing and Evaluation Laboratory (DEMATEL) is then developed. A questionnaire survey of 25 experts is used to weight the various parameters in the model, which is then demonstrated with an example construction enterprise. The model comprehensively reflects digital levels under the background of the digital economy. Its application will help understand the advantages and disadvantages enterprises face in their digital transformation to enable targeted measures to improve their digital transformation capabilities and efficiency, enhance their core competitiveness of enterprises, and promote the development of digital transformation in the construction industry.
2023.09.13.21.20.02;13.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.04716;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.04716.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Xiang_Q/0/1/0/all/0/1"">Qiao Xiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1"">Yuling Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1"">Mingjun Fang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1"">Bang Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1"">Siyong Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wen_R/0/1/0/all/0/1"">Ridi Wen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Le_F/0/1/0/all/0/1"">Franck Le</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1"">Linghe Kong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shu_J/0/1/0/all/0/1"">Jiwu Shu</a>";Qiao Xiang,Yuling Lin,Mingjun Fang,Bang Huang,Siyong Huang,Ridi Wen,Franck Le,Linghe Kong,Jiwu Shu;Toward Reproducing Network Research Results Using Large Language Models.;"Reproducing research results in the networking community is important for both academia and industry. The current best practice typically resorts to three approaches: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; and (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report the experiment's observations and lessons and discuss future open research questions of this proposal. This work raises no ethical issue."
2023.09.13.21.20.03;13.09.2023;03;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0699/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Research on Energy Harvesting Mechanism and Low Power Technology in Wireless Sensor Networks;Wireless sensor networks (WSN) are widely used in various fields such as military, industrial and transportation for real-time monitoring, sensing and data collection of different environments or objects. However, the development of WSN is hindered by several limitations, including energy, storage space, computing power and data transmission rate. Among these, the availability of power energy plays a crucial role as it directly determines the lifespan of WSN. To extend the life cycle of WSN, two key approaches are power supply improvement and energy conservation. Therefor, we proposed an energy harvesting system and a low energy consumption mechanism for WSN. Firstly, we delved into the energy harvesting technology of WSN, explored the utilization of solar energy and mechanical vibration energy to ensure a continuous and dependable power supply to the sensor nodes, and analyzed the voltage output characteristics of bistable piezoelectric cantilever. Secondly, we proposed a neighbor discovery mechanism that utilizes a separation beacon, is based on reply to ACK, and can facilitate the identification of neighboring nodes. This mechanism operates at a certain duty cycle ratio, significantly reduces idle listening time and results in substantial energy savings. In comparison to the Disco and U-connect protocols, our proposed mechanism achieves a remarkable reduction of 66.67% and 75% in the worst discovery delay, respectively. Furthermore, we introduced a data fusion mechanism based on integer wavelet transform. This mechanism effectively eliminates data redundancy caused by spatio-temporal correlation, results in a data compression rate of 5.42. Additionally, it significantly reduces energy consumption associated with data transmission by the nodes.
2023.09.13.21.20.04;13.09.2023;04;02;Energy;Electricity, Smart Grid et al.;arxiv;2108.00925;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2108.00925.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Haberle_V/0/1/0/all/0/1"">Verena H&#xe4;berle</a>, <a href=""http://arxiv.org/find/eess/1/au:+Fisher_M/0/1/0/all/0/1"">Michael W. Fisher</a>, <a href=""http://arxiv.org/find/eess/1/au:+Prieto_Araujo_E/0/1/0/all/0/1"">Eduardo Prieto-Araujo</a>, <a href=""http://arxiv.org/find/eess/1/au:+Dorfler_F/0/1/0/all/0/1"">Florian D&#xf6;rfler</a>";Verena Häberle,Michael W. Fisher,Eduardo Prieto-Araujo,Florian Dörfler;Control Design of Dynamic Virtual Power Plants: An Adaptive Divide-and-Conquer Approach.;In this paper, we present a novel control approach for dynamic virtual power plants (DVPPs). In particular, we consider a group of heterogeneous distributed energy resources (DERs) which collectively provide desired dynamic ancillary services such as fast frequency and voltage control. Our control approach relies on an adaptive divide-and-conquer strategy: first, we disaggregate the desired frequency and voltage control specifications of the aggregate DVPP via adaptive dynamic participation matrices (ADPMs) to obtain the desired local behavior for each device. Second, we design local linear parameter-varying (LPV) $\mathcal{H}_\infty$ controllers to optimally match this local behaviors. In the process, the control design also incorporates the physical and engineered limits of each DVPP device. Furthermore, our adaptive control design can properly respond to fluctuating device capacities, and thus include weather-driven DERs into the DVPP setup. Finally, we demonstrate the effectiveness of our control strategy in a case study based on the IEEE nine-bus system.
2023.09.13.21.20.05;13.09.2023;05;02;Energy;Electricity, Smart Grid et al.;schweitzer-online;;;https://www.schweitzer-online.de/buch/Abdel-Basset/Multi-Criteria-Decision-Making-for-Renewable-Energy/9780443133787/A67229518/;;;Multi-Criteria Decision-Making for Renewable Energy;Multi-Criteria Decision-Making for Renewable Energy: Methods, Applications, and Challenges brings together the latest fuzzy and soft computing methods, models, and algorithms as applied to the field of renewable energy and supported by specific application examples and case studies. The book begins by approaching renewable energy sources, challenges and factors that affect their development, as well as green renewable energy sites and the utilization of fuzzy multi-criteria decision-making (MCDM) techniques in these broad contexts, as well as utilization in addressing the various environmental, economic, and social barriers to ensuring the sustainability of energy resources. Detailed chapters focus on the application of multi-criteria decision-making methods for planning, modeling and prioritization in specific areas of renewable energy, including solar energy, wind farms, solar-powered hydrogen production plants, biofuel production, energy storage, hydropower, and marine energy. Finally, future opportunities and research directions are explored.
2023.09.13.21.20.06;13.09.2023;06;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0811/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Demographic Analysis of Active Travel Users in Urban Context;Active transportation, such as walking, cycling, and micro-mobility modes, has received a lot of attention in recent years due to its potential benefits to urban residents, such as less traffic, better air quality, more opportunities to get exercise, and an overall higher quality of life. In this study, we used Classification and Regression Trees (CART) to compare and contrast three mobility options: shared micro-mobility, individual micro-mobility, and walking. We surveyed 219 people living in Budapest, Hungary, to learn more about their travel habits and investigate the demographic elements that influence people's mode choice, such as age, gender, ownership of micro-mobility modes, education, job, and income. Results showed that ownership of personal micro-mobility modes, and age as important predictors of active travel mode choice. Males seem to prioritize cost and weather conditions when choosing shared micromobility modes, while females value safety and weather conditions. Our findings can guide policy decisions and urban planning initiatives by identifying the most significant predictors of mode choice and evaluating the possible benefits and drawbacks of each mode.
2023.09.13.21.20.07;13.09.2023;07;04;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2307.11845&r=big;;Christopher GerlingStefan Lessmann;Multimodal Document Analytics for Banking Process Automation;In response to growing FinTech competition and the need for improved operational efficiency, this research focuses on understanding the potential of advanced document analytics, particularly using multimodal models, in banking processes. We perform a comprehensive analysis of the diverse banking document landscape, highlighting the opportunities for efficiency gains through automation and advanced analytics techniques in the customer business. Building on the rapidly evolving field of natural language processing (NLP), we illustrate the potential of models such as LayoutXLM, a cross-lingual, multimodal, pre-trained model, for analyzing diverse documents in the banking sector. This model performs a text token classification on German company register extracts with an overall F1 score performance of around 80\%. Our empirical evidence confirms the critical role of layout information in improving model performance and further underscores the benefits of integrating image information. Interestingly, our study shows that over 75% F1 score can be achieved with only 30% of the training data, demonstrating the efficiency of LayoutXLM. Through addressing state-of-the-art document analysis frameworks, our study aims to enhance process efficiency and demonstrate the real-world applicability and benefits of multimodal models within banking.
2023.09.13.21.20.08;13.09.2023;08;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2209.11914;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2209.11914.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Mamaysky_H/0/1/0/all/0/1"">Harry Mamaysky</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Shen_Y/0/1/0/all/0/1"">Yiwen Shen</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Wu_H/0/1/0/all/0/1"">Hongyu Wu</a>";Harry Mamaysky,Yiwen Shen,Hongyu Wu;Credit Information in Earnings Calls.;We develop a novel technique to extract credit-relevant information from the text of quarterly earnings calls. This information is not spanned by fundamental or market variables and forecasts future credit spread changes. One reason for such forecastability is that our text-based measure predicts future credit spread risk and firm profitability. More firm- and call-level complexity increase the forecasting power of our measure for spread changes. Out-of-sample portfolio tests show the information in our measure is valuable for investors. Both results suggest that investors do not fully internalize the credit-relevant information contained in earnings calls.
2023.09.13.21.20.09;13.09.2023;09;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.05560;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2309.05560.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Glasserman_P/0/1/0/all/0/1"">Paul Glasserman</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Mamaysky_H/0/1/0/all/0/1"">Harry Mamaysky</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Qin_J/0/1/0/all/0/1"">Jimmy Qin</a>";Paul Glasserman,Harry Mamaysky,Jimmy Qin;New News is Bad News.;An increase in the novelty of news predicts negative stock market returns and negative macroeconomic outcomes over the next year. We quantify news novelty - changes in the distribution of news text - through an entropy measure, calculated using a recurrent neural network applied to a large news corpus. Entropy is a better out-of-sample predictor of market returns than a collection of standard measures. Cross-sectional entropy exposure carries a negative risk premium, suggesting that assets that positively covary with entropy hedge the aggregate risk associated with shifting news language. Entropy risk cannot be explained by existing long-short factors.
2023.09.13.21.20.10;13.09.2023;10;09;Commerce;Commerce, Trading, Sales, Retail et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0843/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Possibilities of Sale Forecasting of Textile Products with a Short Life Cycle;Almost 115 million tons of fibers of which almost 90 million tons of chemical fibers were produced in the world in 2021, which are mainly used for the production of clothing and footwear. 30% of textile and apparel products are never sold, which means an extreme waste production. This article points out the possibilities of forecasting the sales of clothing in the case of one relatively large online store. Inadequate stocks of textile products in the company lead to loss and the need to sell products at a discount, which is undesirable for the company. The study in this article points to the calculation of the sales forecast for 2019 for the selected textile products, finding the analogy of the followed product sale. Sales for the years 2017 and 2018 serve as input data. The problem with textile products is that they have a short life cycle, i.e. the length of the life cycle is approximately half a year, and a high seasonality is also presented there. Therefore, the seasonal indices and Holt-Winters methods (multiplication and additional approaches) were used for products forecasting. Ultimately, this model could contribute to reducing the loss of unsold goods and thus reduce the waste of resources and increase the use of goods in other similar companies.
2023.09.13.21.20.11;13.09.2023;11;09;Commerce;Commerce, Trading, Sales, Retail et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0696/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Predict the Shopping Trip (Online and Offline) Using a Combination of a Gray Wolf Optimization Algorithm (GWO) and a Deep Convolutional Neural Network: A Case Study of Tehran, Iran;Online and offline shopping trip have different impacts on various aspects of urban life, such as e-commerce, transportation systems, and sustainability. Therefore, it is important to evaluate the factors that influence their choices. We use a hybrid machine learning model that combines a gray wolf optimization algorithm and a deep convolutional neural network to estimate shopping trip based on a survey of 1,000 active e-commerce users who made successful orders in both online and offline services in the last 20 days of 2021 in areas 2 and 5 of Tehran. The gray wolf optimization algorithm performs feature selection and hyperparameter tuning for the deep convolutional neural network, which is a powerful deep learning model for image recognition and classification. The results show that our model achieves an accuracy of 97.81% with an MSE of 0.325 by selecting seven out of ten features. The most important features are delivery cost, delivery time, product price, car ownership. In addition, comparing the performance of the proposed method with other methods showed that the proposed algorithm with an accuracy of 97.81%, the accuracies of the single deep learning model, MLP neural network, decision tree, and KNN models were 95.63%, 90.0%, 86.49%, and 80.16%, respectively.
2023.09.13.21.20.12;13.09.2023;12;12;Health;Medical, Health Care, Pharmacy et al.;repec;;http://nep.repec.org/rss/nep-dcm.rss.xml;http://d.repec.org/n?u=RePEc:nbr:nberwo:31524&r=dcm;;Karen MulliganDrishti BaidJason N. DoctorCharles E. PhelpsDarius N. Lakdawalla;Risk Preferences Over Health: Empirical Estimates and Implications for Healthcare Decision-Making;Recent research has documented a link between consumer risk preferences over health and the willingness to pay (WTP) for medical technologies. However, the absence of empirical health risk preference estimates so far limits the implementation of this generalized risk-adjusted cost-effectiveness (GRACE) theory, which addresses several limitations of traditional cost-effectiveness analysis (CEA). To address this gap, we elicit from a nationally representative U.S. sample individual risk preference parameters over health-related quality of life (HRQoL) that shed light on health risk attitudes and enable GRACE valuation of medical technology. We find individuals exhibit risk-seeking preferences at low levels of health, switch to risk-averse preferences at health equal to 0.485 (measured on a zero to one scale), and become most risk-averse when their health is perfect (coefficient of relative risk aversion = 4.36). The risk preference estimates imply an empirical premium for disease severity: each unit of health is worth three times more to patients with serious health conditions (health equals 0.5) than those who are perfectly healthy. They also imply that traditional CEA overvalues treatments for the mildest diseases by more than a factor of two. Use of traditional CEA both overstimulates mild disease treatment innovation and underprovides severe disease treatment innovation.
2023.09.13.21.20.13;13.09.2023;13;16;Human;Human Resource, Personal Assistance et al.;datasciencecentral;;;https://www.datasciencecentral.com/dsc-webinar-series-influence-data-driven-decisions-based-on-your-communication-style/;;;Influence Data-Driven Decisions Based On Your Communication Style;Those in data-driven roles often struggle to facilitate effective communication with non-technical stakeholders and persuade them to make business decisions using insights. Data storytelling is a critical skill that helps data scientists and analysts give key decision-makers the ability to make data-driven decisions. Using augmented analytics and business intelligence to influence others not only makes others' lives easier but helps you make an impact with your work. Break down different communication styles, how they show up in the workplace, and how each can use augmented analytics and business intelligence to easily share insights. No matter how you prefer to communicate, you'll gain tips and tricks on how to best share information that you can act on in your daily role.
2023.09.11.17.02.01;11.09.2023;01;02;Energy;Electricity, Smart Grid et al.;repec;;http://nep.repec.org/rss/nep-com.rss.xml;http://d.repec.org/n?u=RePEc:hhs:lunewp:2023_008&r=com;;Ganhammar, Kajsa;Bidding Behaviour in Interdependent Markets for Electricity and Green Certificates;Market-based climate policies have received increased attention, making it important to understand how such politically created markets affect competition in the electricity market. This paper focuses on the green certificate policy which financially supports producers of renewably sourced electricity by means of tradable certificates, and develops a simple duopoly model that incorporates both the electricity and the green certificate markets in an auction-based setting. The results suggest that, in case the subsidised technology has a higher expected marginal cost than the conventional technology, the policy can improve competition and efficiency in the electricity market. Conversely, if producers are ex-ante symmetric in their marginal costs, the advantage the policy creates enables the subsidised producer to bid higher at given cost as the probability of winning the electricity auction increases. This is harmful for competition and results in high consumer prices of electricity.
2023.09.11.17.02.02;11.09.2023;02;02;Energy;Electricity, Smart Grid et al.;arxiv;2306.10617;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.10617.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chevalier_S/0/1/0/all/0/1"">Samuel Chevalier</a>, <a href=""http://arxiv.org/find/cs/1/au:+Murzakhanov_I/0/1/0/all/0/1"">Ilgiz Murzakhanov</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chatzivasileiadis_S/0/1/0/all/0/1"">Spyros Chatzivasileiadis</a>";Samuel Chevalier,Ilgiz Murzakhanov,Spyros Chatzivasileiadis;GPU-Accelerated Verification of Machine Learning Models for Power Systems.;"Computational tools for rigorously verifying the performance of large-scale machine learning (ML) models have progressed significantly in recent years. The most successful solvers employ highly specialized, GPU-accelerated branch and bound routines. Such tools are crucial for the successful deployment of machine learning applications in safety-critical systems, such as power systems. Despite their successes, however, barriers prevent out-of-the-box application of these routines to power system problems. This paper addresses this issue in two key ways. First, for the first time to our knowledge, we enable the simultaneous verification of multiple verification problems (e.g., checking for the violation of all line flow constraints simultaneously and not by solving individual verification problems). For that, we introduce an exact transformation that converts the ""worst-case"" violation across a set of potential violations to a series of ReLU-based layers that augment the original neural network. This allows verifiers to interpret them directly. Second, power system ML models often must be verified to satisfy power flow constraints. We propose a dualization procedure which encodes linear equality and inequality constraints directly into the verification problem; and in a manner which is mathematically consistent with the specialized verification tools. To demonstrate these innovations, we verify problems associated with data-driven security constrained DC-OPF solvers. We build and test our first set of innovations using the $\alpha,\beta$-CROWN solver, and we benchmark against Gurobi 10.0. Our contributions achieve a speedup that can exceed 100x and allow higher degrees of verification flexibility."
2023.09.11.17.02.03;11.09.2023;03;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.04296;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.04296.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Prabowo_A/0/1/0/all/0/1"">Arian Prabowo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1"">Kaixuan Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1"">Hao Xue</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sethuvenkatraman_S/0/1/0/all/0/1"">Subbu Sethuvenkatraman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1"">Flora D. Salim</a>";Arian Prabowo,Kaixuan Chen,Hao Xue,Subbu Sethuvenkatraman,Flora D. Salim;Navigating Out-of-Distribution Electricity Load Forecasting during COVID-19: A Continual Learning Approach Leveraging Human Mobility.;In traditional deep learning algorithms, one of the key assumptions is that the data distribution remains constant during both training and deployment. However, this assumption becomes problematic when faced with Out-of-Distribution periods, such as the COVID-19 lockdowns, where the data distribution significantly deviates from what the model has seen during training. This paper employs a two-fold strategy: utilizing continual learning techniques to update models with new data and harnessing human mobility data collected from privacy-preserving pedestrian counters located outside buildings. In contrast to online learning, which suffers from 'catastrophic forgetting' as newly acquired knowledge often erases prior information, continual learning offers a holistic approach by preserving past insights while integrating new data. This research applies FSNet, a powerful continual learning algorithm, to real-world data from 13 building complexes in Melbourne, Australia, a city which had the second longest total lockdown duration globally during the pandemic. Results underscore the crucial role of continual learning in accurate energy forecasting, particularly during Out-of-Distribution periods. Secondary data such as mobility and temperature provided ancillary support to the primary forecasting model. More importantly, while traditional methods struggled to adapt during lockdowns, models featuring at least online learning demonstrated resilience, with lockdown periods posing fewer challenges once armed with adaptive learning techniques. This study contributes valuable methodologies and insights to the ongoing effort to improve energy load forecasting during future Out-of-Distribution periods.
2023.09.11.17.02.04;11.09.2023;04;02;Energy;Electricity, Smart Grid et al.;arxiv;2309.04361;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.04361.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Boyd_J/0/1/0/all/0/1"">Jonathan D. Boyd</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tyler_J/0/1/0/all/0/1"">Joshua H. Tyler</a>, <a href=""http://arxiv.org/find/cs/1/au:+Murphy_A/0/1/0/all/0/1"">Anthony M. Murphy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Reising_D/0/1/0/all/0/1"">Donald R. Reising</a>";Jonathan D. Boyd,Joshua H. Tyler,Anthony M. Murphy,Donald R. Reising;Learning from Power Signals: An Automated Approach to Electrical Disturbance Identification Within a Power Transmission System.;As power quality becomes a higher priority in the electric utility industry, the amount of disturbance event data continues to grow. Utilities do not have the required personnel to analyze each event by hand. This work presents an automated approach for analyzing power quality events recorded by digital fault recorders and power quality monitors operating within a power transmission system. The automated approach leverages rule-based analytics to examine the time and frequency domain characteristics of the voltage and current signals. Customizable thresholds are set to categorize each disturbance event. The events analyzed within this work include various faults, motor starting, and incipient instrument transformer failure. Analytics for fourteen different event types have been developed. The analytics were tested on 160 signal files and yielded an accuracy of ninety-nine percent. Continuous, nominal signal data analysis is performed using an approach coined as the cyclic histogram. The cyclic histogram process will be integrated into the digital fault recorders themselves to facilitate the detection of subtle signal variations that are too small to trigger a disturbance event and that can occur over hours or days. In addition to reducing memory requirements by a factor of 320, it is anticipated that cyclic histogram processing will aid in identifying incipient events and identifiers. This project is expected to save engineers time by automating the classification of disturbance events and increase the reliability of the transmission system by providing near real time detection and identification of disturbances as well as prevention of problems before they occur.
2023.09.11.17.02.05;11.09.2023;05;02;Energy;Electricity, Smart Grid et al.;repec;;http://nep.repec.org/rss/nep-for.rss.xml;http://d.repec.org/n?u=RePEc:pra:mprapa:118239&r=for;;Fantazzini, DeanKurbatskii, AlexeyMironenkov, AlexeyLycheva, Maria;Forecasting oil prices with penalized regressions, variance risk premia and Google data;This paper investigates whether augmenting models with the variance risk premium (VRP) and Google search data improves the quality of the forecasts for real oil prices. We considered a time sample of monthly data from 2007 to 2019 that includes several episodes of high volatility in the oil market. Our evidence shows that penalized regressions provided the best forecasting performances across most of the forecasting horizons. Moreover, we found that models using the VRP as an additional predictor performed best for forecasts up to 6-12 months ahead forecasts, while models using Google data as an additional predictor performed better for longer-term forecasts up to 12-24 months ahead. However, we found that the differences in forecasting performances were not statistically different for most models, and only the Principal Component Regression (PCR) and the Partial least squares (PLS) regression were consistently excluded from the set of best forecasting models. These results also held after a set of robustness checks that considered model specifications using a wider set of influential variables, a Hierarchical Vector Auto-Regression model estimated with the LASSO, and a set of forecasting models using a simplified specification for Google Trends data.
2023.09.11.17.02.06;11.09.2023;06;05;Legal;Legal, Law et al.;arxiv;2309.04146;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.04146.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1"">Kyoungyeon Cho</a>, <a href=""http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1"">Seungkum Han</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1"">Wonseok Hwang</a>";Kyoungyeon Cho,Seungkum Han,Wonseok Hwang;NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus.;"The statistical analysis of large scale legal corpus can provide valuable legal insights. For such analysis one needs to (1) select a subset of the corpus using document retrieval tools, (2) structuralize text using information extraction (IE) systems, and (3) visualize the data for the statistical analysis. Each process demands either specialized tools or programming skills whereas no comprehensive unified ""no-code"" tools have been available. Especially for IE, if the target information is not predefined in the ontology of the IE system, one needs to build their own system. Here we provide NESTLE, a no code tool for large-scale statistical analysis of legal corpus. With NESTLE, users can search target documents, extract information, and visualize the structured data all via the chat interface with accompanying auxiliary GUI for the fine-level control. NESTLE consists of three main components: a search engine, an end-to-end IE system, and a Large Language Model (LLM) that glues the whole components together and provides the chat interface. Powered by LLM and the end-to-end IE system, NESTLE can extract any type of information that has not been predefined in the IE system opening up the possibility of unlimited customizable statistical analysis of the corpus without writing a single line of code. The use of the custom end-to-end IE system also enables faster and low-cost IE on large scale corpus. We validate our system on 15 Korean precedent IE tasks and 3 legal text classification tasks from LEXGLUE. The comprehensive experiments reveal NESTLE can achieve GPT-4 comparable performance by training the internal IE module with 4 human-labeled, and 192 LLM-labeled examples. The detailed analysis provides the insight on the trade-off between accuracy, time, and cost in building such system."
2023.09.11.17.02.07;11.09.2023;07;07;Industry;I4.0, Production et al.;arxiv;2309.04001;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.04001.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Reza_M/0/1/0/all/0/1"">Md Kaykobad Reza</a> (1), <a href=""http://arxiv.org/find/cs/1/au:+Prater_Bennette_A/0/1/0/all/0/1"">Ashley Prater-Bennette</a> (2), <a href=""http://arxiv.org/find/cs/1/au:+Asif_M/0/1/0/all/0/1"">M. Salman Asif</a> (1) ((1) University of California, Riverside, (2) Air Force Research Laboratory)";"<a href=""http://arxiv.org/find/cs/1/au:+Reza_M/0/1/0/all/0/1"">Md Kaykobad Reza</a> (1), <a href=""http://arxiv.org/find/cs/1/au:+Prater_Bennette_A/0/1/0/all/0/1"">Ashley Prater-Bennette</a> (2), <a href=""http://arxiv.org/find/cs/1/au:+Asif_M/0/1/0/all/0/1"">M. Salman Asif</a> (1) ((1) University of California, Riverside, (2) Air Force Research Laboratory)";Multimodal Transformer for Material Segmentation.;Leveraging information across diverse modalities is known to enhance performance on multimodal segmentation tasks. However, effectively fusing information from different modalities remains challenging due to the unique characteristics of each modality. In this paper, we propose a novel fusion strategy that can effectively fuse information from different combinations of four different modalities: RGB, Angle of Linear Polarization (AoLP), Degree of Linear Polarization (DoLP) and Near-Infrared (NIR). We also propose a new model named Multi-Modal Segmentation Transformer (MMSFormer) that incorporates the proposed fusion strategy to perform multimodal material segmentation. MMSFormer achieves 52.05% mIoU outperforming the current state-of-the-art on Multimodal Material Segmentation (MCubeS) dataset. For instance, our method provides significant improvement in detecting gravel (+10.4%) and human (+9.1%) classes. Ablation studies show that different modules in the fusion block are crucial for overall model performance. Furthermore, our ablation studies also highlight the capacity of different input modalities to improve performance in the identification of different types of materials. The code and pretrained models will be made available at https://github.com/csiplab/MMSFormer.
2023.09.11.17.02.08;11.09.2023;08;08;Supply Chain;Supply Chains, Transportation et al.;repec;;http://nep.repec.org/rss/nep-tre.rss.xml;http://d.repec.org/n?u=RePEc:hal:journl:hal-04166257&r=tre;;David GuerreroAdolf K Y NgHidekazu Itoh;Logistics and the globalization of the automotive supply chain: A case study on the Parts Consolidation Centres in the Seine Valley Corridor;During the past decades, the geography of the automotive industry has changed considerably. Today (2021) almost half of the production and sales take place in emerging economies compared to about 10% in 2000. Supply chains have been transformed to follow manufacturers towards the emerging economies. While most parts are sourced locally, non-negligible amounts are conveyed in containers from suppliers' plants in the advanced economies. To save transport costs and to ensure the reliability of these pipelines, car manufacturers rely on Parts Consolidation Centres (PCCs), i.e., cross-docking facilities where parts are sorted and packed in containers depending on their final destinations. Through an in-depth case study on the Seine Valley Corridor, this chapter unveils the logistics operations realized at PCCs, creating opportunities for upgrading through innovation and new technologies such as Hybrid and Electric vehicles, but simultaneously underlines the continued prevalence of low value-added logistics operations and the overall instability of demand.
2023.09.11.17.02.09;11.09.2023;09;16;Human Resource;Human Resource et al.;arxiv;2308.14982;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2308.14982.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Kausik_B/0/1/0/all/0/1"">B. N. Kausik</a>";B. N. Kausik;Cognitive Aging and Labor Share.;Labor share, the fraction of economic output accrued as wages, is inexplicably declining in industrialized countries. Whilst numerous prior works attempt to explain the decline via economic factors, our novel approach links the decline to biological factors. Specifically, we propose a theoretical macroeconomic model where labor share reflects a dynamic equilibrium between the workforce automating existing outputs, and consumers demanding new output variants that require human labor. Industrialization leads to an aging population, and while cognitive performance is stable in the working years it drops sharply thereafter. Consequently, the declining cognitive performance of aging consumers reduces the demand for new output variants, leading to a decline in labor share. Our model expresses labor share as an algebraic function of median age, and is validated with surprising accuracy on historical data across industrialized economies via non-linear stochastic regression.
2023.09.10.13.35.01;10.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;arxiv;2309.03213;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03213.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Asiala_L/0/1/0/all/0/1"">Lillian Asiala</a>, <a href=""http://arxiv.org/find/cs/1/au:+McCarthy_J/0/1/0/all/0/1"">James E. McCarthy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1"">Lixiao Huang</a>";Lillian Asiala,James E. McCarthy,Lixiao Huang;Improving the State of the Art for Training Human-AI Teams: Technical Report #3 -- Analysis of Testbed Alternatives.;Sonalysts is working on an initiative to expand our current expertise in teaming to Human-Artificial Intelligence (AI) teams by developing original research in this area. To provide a foundation for that research, Sonalysts is investigating the development of a Synthetic Task Environment (STE). In a previous report, we documented the findings of a recent outreach effort in which we asked military Subject Matter Experts (SMEs) and other researchers in the Human-AI teaming domain to identify the qualities that they most valued in a testbed. A surprising finding from that outreach was that several respondents recommended that our team look into existing human-AI teaming testbeds, rather than creating something new. Based on that recommendation, we conducted a systematic investigation of the associated landscape. In this report, we describe the results of that investigation. Building on the survey results, we developed testbed evaluation criteria, identified potential testbeds, and conducted qualitative and quantitative evaluations of candidate testbeds. The evaluation process led to five candidate testbeds for the research team to consider. In the coming months, we will assess the viability of the various alternatives and begin to execute our program of research.
2023.09.10.13.35.02;10.09.2023;02;00;CrossTopic;Generic, Cross Topic, et al.;arxiv;2309.03212;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03212.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+McCarthy_J/0/1/0/all/0/1"">James E. McCarthy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Asiala_L/0/1/0/all/0/1"">Lillian Asiala</a>, <a href=""http://arxiv.org/find/cs/1/au:+Maryeski_L/0/1/0/all/0/1"">LeeAnn Maryeski</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sillars_D/0/1/0/all/0/1"">Dawn Sillars</a>";James E. McCarthy,Lillian Asiala,LeeAnn Maryeski,Dawn Sillars;Improving the State of the Art for Training Human-AI Teams: Technical Report #2 -- Results of Researcher Knowledge Elicitation Survey.;"A consensus report produced for the Air Force Research Laboratory (AFRL) by the National Academies of Sciences, Engineering, and Mathematics documented a prevalent and increasing desire to support human-Artificial Intelligence (AI) teaming across military service branches. Sonalysts has begun an internal initiative to explore the training of Human-AI teams. The first step in this effort is to develop a Synthetic Task Environment (STE) that is capable of facilitating research on Human-AI teams. Our goal is to create a STE that offers a task environment that could support the breadth of research that stakeholders plan to perform within this domain. As a result, we wanted to sample the priorities of the relevant research community broadly, and the effort documented in this report is our initial attempt to do so. We created a survey that featured two types of questions. The first asked respondents to report their agreement with STE features that we anticipated might be important. The second represented open-ended questions that asked respondents to specify their priorities within several dimensions of the anticipated STE. The research team invited nineteen researchers from academic and Government labs to participate, and 11 were able to complete the survey. The team analyzed their responses to identify themes that emerged and topics that would benefit from further analysis. The most significant finding of the survey was that a number of researchers felt that various open-source STEs that would meet our needs already exist. Researchers also emphasized the need for automated transcription and coding tools to ease the burden of assessing inter-team communications; the importance of robust data capture and export capabilities; and the desirability of extensive flexibility across many aspects of the tool."
2023.09.10.13.35.03;10.09.2023;03;00;CrossTopic;Generic, Cross Topic, et al.;arxiv;2309.03211;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03211.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+McCarthy_J/0/1/0/all/0/1"">James E. McCarthy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Asiala_L/0/1/0/all/0/1"">Lillian Asiala</a>, <a href=""http://arxiv.org/find/cs/1/au:+Maryeski_L/0/1/0/all/0/1"">LeeAnn Maryeski</a>, <a href=""http://arxiv.org/find/cs/1/au:+Warren_N/0/1/0/all/0/1"">Nyla Warren</a>";James E. McCarthy,Lillian Asiala,LeeAnn Maryeski,Nyla Warren;Improving the State of the Art for Training Human-AI Teams: Technical Report #1 -- Results of Subject-Matter Expert Knowledge Elicitation Survey.;"A consensus report produced for the Air Force Research Laboratory by the National Academies of Sciences, Engineering, and Mathematics documented a prevalent and increasing desire to support human-Artificial Intelligence (AI) teaming across military service branches. Sonalysts has begun an internal initiative to explore the training of human-AI teams. The first step in this effort is to develop a Synthetic Task Environment (STE) that is capable of facilitating research on human-AI teams. We decided to use Joint All-Domain Command and Control (JADC2) as a focus point for developing the STE because the volume of sensor inputs and decision options within the JADC2 concept likely requires the use of AI systems to enable timely decisions. Given this focus, we engaged a number of Subject-Matter Experts (SMEs) with Command and Control experience to gain insight into developing a STE that embodied the teaming challenges associated with JADC2. This report documents our initial engagement with those stakeholders. The research team identified thirteen Sonalysts employees with military backgrounds and Command and Control experience, and invited them to participate. Twelve respondents completed the survey. The team then analyzed the responses to identify themes that emerged and topics that would benefit from further analysis. The results indicated that our SMEs were amenable to research using tasks that were analogous to those encountered in military environments, as long as they required teams to process a great deal of incoming data to arrive at complex decisions. The SMEs felt that the testbed should support 'teams of teams"" that represented a matrixed organization, and that it should support a robust array to spoken, text-based, and face-to-face communications."
2023.09.10.13.35.04;10.09.2023;04;00;CrossTopic;Generic, Cross Topic, et al.;arxiv;2309.03392;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03392.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Khor_C/0/1/0/all/0/1"">Chin Khor</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lutz_R/0/1/0/all/0/1"">Robyn Lutz</a>";Chin Khor,Robyn Lutz;Requirements Analysis of Variability Constraints in a Configurable Flight Software System.;Variability constraints are an integral part of the requirements for a configurable system. The constraints specified in the requirements on the legal combinations of options define the space of potential valid configurations for the system-to-be. This paper reports on our experience with the variability-related requirements constraints of a flight software framework used by multiple space missions. A challenge that we saw for practitioners using the current framework, now open-sourced, is that the specifications of its variability-related requirements and constraints are dispersed across several documents, rather than being centralized in the software requirements specification. Such dispersion can contribute to misunderstandings of the side-effects of design choices, increased effort for developers, and bugs during operations. Based on our experience, we propose a new software variability model, similar to a product-line feature model, in the flight software framework. We describe the structured technique by which our model is developed, demonstrate its use, and evaluate it on a key service module of the flight software. Results show that our lightweight modeling technique helped find missing and inconsistent variability-related requirements and constraints. More generally, we suggest that a variability modeling technique such as this can be an efficient way for developers to centralize the specification and improve the analysis of dispersed variability-related requirements and constraints in other configurable systems.
2023.09.10.13.35.05;10.09.2023;05;00;CrossTopic;Generic, Cross Topic, et al.;zoom;;;https://blog.zoom.us/zoom-ai-companion/;;;Meet Zoom AI Companion, your new AI assistant! Unlock the benefits with a paid Zoom account;Preparing for that big meeting. Writing emails. Catching up on a backlog of chat messages. Repetitive tasks like these can take up 62% of your workday, not to mention sap your productivity and hurt your ability to collaborate with your team. But now, you're empowered to do more using Zoom AI Companion. We're excited to introduce you to AI Companion (formerly Zoom IQ), your new generative AI assistant across the Zoom platform. AI Companion empowers individuals by helping them be more productive, connect and collaborate with teammates, and improve their skills.
2023.09.10.13.35.05;10.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2308.06260&r=cmp;;Oleksandr RomankoAkhilesh NarayanRoy H. Kwon;ChatGPT-based Investment Portfolio Selection;"In this paper, we explore potential uses of generative AI models, such as ChatGPT, for investment portfolio selection. Trusting investment advice from Generative Pre-Trained Transformer (GPT) models is a challenge due to model ""hallucinations"", necessitating careful verification and validation of the output. Therefore, we take an alternative approach. We use ChatGPT to obtain a universe of stocks from S&P500 market index that are potentially attractive for investing. Subsequently, we compared various portfolio optimization strategies that utilized this AI-generated trading universe, evaluating those against quantitative portfolio optimization models as well as comparing to some of the popular investment funds. Our findings indicate that ChatGPT is effective in stock selection but may not perform as well in assigning optimal weights to stocks within the portfolio. But when stocks selection by ChatGPT is combined with established portfolio optimization models, we achieve even better results. By blending strengths of AI-generated stock selection with advanced quantitative optimization techniques, we observed the potential for more robust and favorable investment outcomes, suggesting a hybrid approach for more effective and reliable investment decision-making in the future."
2023.09.10.13.35.06;10.09.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:osf:osfxxx:amdqz&r=cmp;;Jsowd, Kyldo;Advances in Deep Learning for Meta-Analysis in AI-Driven Chatbots;This paper explores the recent advances in deep learning techniques for meta-analysis in AI-driven chatbots. Chatbots have become increasingly popular in various domains, offering intelligent conversational interfaces to interact with users. Meta-analysis, as a research methodology, allows for the systematic synthesis and analysis of findings from multiple studies. Deep learning has emerged as a powerful approach within AI, enabling chatbots to understand natural language, generate context-aware responses, and improve their performance over time. This paper reviews the advancements in deep learning techniques specifically applied to meta-analysis in the context of AI-driven chatbots. It examines the utilization of deep neural networks, recurrent neural networks, and attention mechanisms in meta-analysis tasks. The paper also discusses the challenges and future research directions in leveraging deep learning for meta-analysis in AI-driven chatbots.
2023.09.10.13.35.07;10.09.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:osf:osfxxx:s9bza&r=cmp;;Jsowd, Kyldo;Building Intelligent Chatbot Systems using Meta-Analysis and Deep Learning;Chatbot systems have gained significant attention in recent years due to their potential to automate customer interactions and provide personalized assistance. This article presents a novel approach for building intelligent chatbot systems by leveraging the power of meta-analysis and deep learning techniques. In this study, we propose a framework that combines meta-analysis, which synthesizes findings from existing chatbot research, with deep learning algorithms to enhance the performance and intelligence of chatbot systems. We explore the application of deep learning models, such as recurrent neural networks (RNNs) and transformer models, for various chatbot tasks, including natural language understanding, dialogue management, and response generation
2023.09.10.13.35.08;10.09.2023;09;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.03595;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03595.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Biancotti_C/0/1/0/all/0/1"">Claudia Biancotti</a>, <a href=""http://arxiv.org/find/cs/1/au:+Camassa_C/0/1/0/all/0/1"">Carolina Camassa</a>";Claudia Biancotti,Carolina Camassa;Loquacity and Visible Emotion: ChatGPT as a Policy Advisor.;ChatGPT, a software seeking to simulate human conversational abilities, is attracting increasing attention. It is sometimes portrayed as a groundbreaking productivity aid, including for creative work. In this paper, we run an experiment to assess its potential in complex writing tasks. We ask the software to compose a policy brief for the Board of the Bank of Italy. We find that ChatGPT can accelerate workflows by providing well-structured content suggestions, and by producing extensive, linguistically correct text in a matter of seconds. It does, however, require a significant amount of expert supervision, which partially offsets productivity gains. If the app is used naively, output can be incorrect, superficial, or irrelevant. Superficiality is an especially problematic limitation in the context of policy advice intended for high-level audiences.
2023.09.10.13.35.09;10.09.2023;10;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.03613;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03613.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Palma_D/0/1/0/all/0/1"">Dario Di Palma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Biancofiore_G/0/1/0/all/0/1"">Giovanni Maria Biancofiore</a>, <a href=""http://arxiv.org/find/cs/1/au:+Anelli_V/0/1/0/all/0/1"">Vito Walter Anelli</a>, <a href=""http://arxiv.org/find/cs/1/au:+Narducci_F/0/1/0/all/0/1"">Fedelucio Narducci</a>, <a href=""http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1"">Tommaso Di Noia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sciascio_E/0/1/0/all/0/1"">Eugenio Di Sciascio</a>";Dario Di Palma,Giovanni Maria Biancofiore,Vito Walter Anelli,Fedelucio Narducci,Tommaso Di Noia,Eugenio Di Sciascio;Evaluating ChatGPT as a Recommender System: A Rigorous Approach.;Recent popularity surrounds large AI language models due to their impressive natural language capabilities. They contribute significantly to language-related tasks, including prompt-based learning, making them valuable for various specific tasks. This approach unlocks their full potential, enhancing precision and generalization. Research communities are actively exploring their applications, with ChatGPT receiving recognition. Despite extensive research on large language models, their potential in recommendation scenarios still needs to be explored. This study aims to fill this gap by investigating ChatGPT's capabilities as a zero-shot recommender system. Our goals include evaluating its ability to use user preferences for recommendations, reordering existing recommendation lists, leveraging information from similar users, and handling cold-start situations. We assess ChatGPT's performance through comprehensive experiments using three datasets (MovieLens Small, Last.FM, and Facebook Book). We compare ChatGPT's performance against standard recommendation algorithms and other large language models, such as GPT-3.5 and PaLM-2. To measure recommendation effectiveness, we employ widely-used evaluation metrics like Mean Average Precision (MAP), Recall, Precision, F1, normalized Discounted Cumulative Gain (nDCG), Item Coverage, Expected Popularity Complement (EPC), Average Coverage of Long Tail (ACLT), Average Recommendation Popularity (ARP), and Popularity-based Ranking-based Equal Opportunity (PopREO). Through thoroughly exploring ChatGPT's abilities in recommender systems, our study aims to contribute to the growing body of research on the versatility and potential applications of large language models. Our experiment code is available on the GitHub repository: https://github.com/sisinflab/Recommender-ChatGPT
2023.09.10.13.35.10;10.09.2023;11;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.03409;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03409.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1"">Chengrun Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"">Xuezhi Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1"">Yifeng Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1"">Hanxiao Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1"">Quoc V. Le</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1"">Denny Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"">Xinyun Chen</a>";Chengrun Yang,Xuezhi Wang,Yifeng Lu,Hanxiao Liu,Quoc V. Le,Denny Zhou,Xinyun Chen;Large Language Models as Optimizers.;Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.
2023.09.10.13.35.07;10.09.2023;12;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;salesforce;;;https://www.salesforce.com/news/press-releases/2023/05/04/slack-gpt-news/;;;Salesforce Announces Slack GPT, Unlocks Power of Conversational AI for Work;Salesforce announced Slack GPT, a new conversational AI experience natively integrated into Slack that will transform how work gets done. Slack GPT will deliver the ability to use generative AI app integrations, different language models, and the power to tap into secure customer data insights from the Customer 360 and Data Cloud. And, it will work with Einstein GPT to unlock the power of CRM and conversational data to make every organization more productive.
2023.09.10.13.35.11;10.09.2023;13;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2306.07019;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.07019.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1"">Junpeng Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Ziyue Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Zhishuai Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1"">Lei Bai</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1"">Rui Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1"">Chen Zhang</a>";Junpeng Lin,Ziyue Li,Zhishuai Li,Lei Bai,Rui Zhao,Chen Zhang;Dynamic Causal Graph Convolutional Network for Traffic Prediction.;Modeling complex spatiotemporal dependencies in correlated traffic series is essential for traffic prediction. While recent works have shown improved prediction performance by using neural networks to extract spatiotemporal correlations, their effectiveness depends on the quality of the graph structures used to represent the spatial topology of the traffic network. In this work, we propose a novel approach for traffic prediction that embeds time-varying dynamic Bayesian network to capture the fine spatiotemporal topology of traffic data. We then use graph convolutional networks to generate traffic forecasts. To enable our method to efficiently model nonlinear traffic propagation patterns, we develop a deep learning-based module as a hyper-network to generate stepwise dynamic causal graphs. Our experimental results on a real traffic dataset demonstrate the superior prediction performance of the proposed method. The code is available at https://github.com/MonBG/DCGCN.
2023.09.10.13.35.12;10.09.2023;14;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.03303;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03303.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sontakke_N/0/1/0/all/0/1"">Nikhil Sontakke</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rastogi_S/0/1/0/all/0/1"">Shivansh Rastogi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Utekar_S/0/1/0/all/0/1"">Sejal Utekar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sonawane_S/0/1/0/all/0/1"">Shriraj Sonawane</a>";Nikhil Sontakke,Shivansh Rastogi,Sejal Utekar,Shriraj Sonawane;A Novel Approach for Invoice Management using Blockchain.;Electronic invoicing is another area where blockchain technology is being used. Additionally, it has the power to alter how payments are made, invoices are issued, and transactions are validated. Using a blockchain-based invoicing system will enable smooth payments from a customer's digital wallet to a business's digital wallet. Transactions are simple to track and monitor, and the blockchain may be used to retrieve an exchange's full history. Sometimes shopkeepers create fake bills and submit them to the higher tax-paying authorities. To bring transparency to this billing system between customers, shopkeepers, and tax-paying authorities billing system using blockchain is to be implemented using the concept of Blockchain and make the billing system in our country work smoothly. Blockchain technology can revolutionize the invoicing and payment process by providing a secure, transparent and tamper-proof system. A blockchain-based billing system can facilitate smooth payments, allow for easy tracking and monitoring of transactions, and provide a tamper-proof history of all exchanges. The use of blockchain can prevent fraud and increase transparency among customers, shopkeepers, and tax-paying authorities. Furthermore, it can streamline the process by using digital wallets for both customers and businesses, reducing time and resources for traditional invoicing methods. Overall, blockchain technology can bring greater efficiency and trust to the billing system, benefiting all parties involved. It can prevent fraud, increase transparency and streamline the invoicing and payment process. This technology can create a more secure and efficient billing system ultimately benefiting all parties involved.
2023.09.10.13.35.02;10.09.2023;15;04;Finance;Finance, DeFi, Insurance, Banking et al.;intuit;;;https://www.intuit.com/blog/innovative-thinking/introducing-intuit-assist/;;;Introducing Intuit Assist - The Generative AI-Powered Financial Assistant for Small Businesses and Consumers;Embedded across Intuit's platform and products with a common user interface, Intuit Assist will put the power of next-generation AI in the hands of customers. Intuit Assist uses powerful and relevant contextual data sets spanning small business, consumer finance, and tax to deliver personalized financial insights to our 100 million small business and consumer customers. This data, combined with the power of Intuit's AI-driven expert platform and the accelerated investment the company has made in GenAI, will deliver game-changing new experiences. Intuit Assist will intuitively show, guide, help, and do the hard work for users, and connect customers to experts on our Live Platform to provide human assistance when needed.
2023.09.10.13.35.13;10.09.2023;16;06;Public Services;Public Services;arxiv;2309.03231;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03231.pdf;" <a href=""http://arxiv.org/find/quant-ph/1/au:+Shah_S/0/1/0/all/0/1"">Syed Atif Ali Shah</a>, <a href=""http://arxiv.org/find/quant-ph/1/au:+Algeelani_N/0/1/0/all/0/1"">Nasir Algeelani</a>, <a href=""http://arxiv.org/find/quant-ph/1/au:+Al_Sammarraie_N/0/1/0/all/0/1"">Najeeb Al-Sammarraie</a>";Syed Atif Ali Shah,Nasir Algeelani,Najeeb Al-Sammarraie;Quantum-AI empowered Intelligent Surveillance: Advancing Public Safety Through Innovative Contraband Detection.;Surveillance systems have emerged as crucial elements in upholding peace and security in the modern world. Their ubiquity aids in monitoring suspicious activities effectively. However, in densely populated environments, continuous active monitoring becomes impractical, necessitating the development of intelligent surveillance systems. AI integration in the surveillance domain was a big revolution, however, speed issues have prevented its widespread implementation in the field. It has been observed that quantum artificial intelligence has led to a great breakthrough. Quantum artificial intelligence-based surveillance systems have shown to be more accurate as well as capable of performing well in real-time scenarios, which had never been seen before. In this research, a RentinaNet model is integrated with Quantum CNN and termed as Quantum-RetinaNet. By harnessing the Quantum capabilities of QCNN, Quantum-RetinaNet strikes a balance between accuracy and speed. This innovative integration positions it as a game-changer, addressing the challenges of active monitoring in densely populated scenarios. As demand for efficient surveillance solutions continues to grow, Quantum-RetinaNet offers a compelling alternative to existing CNN models, upholding accuracy standards without sacrificing real-time performance. The unique attributes of Quantum-RetinaNet have far-reaching implications for the future of intelligent surveillance. With its enhanced processing speed, it is poised to revolutionize the field, catering to the pressing need for rapid yet precise monitoring. As Quantum-RetinaNet becomes the new standard, it ensures public safety and security while pushing the boundaries of AI in surveillance.
2023.09.10.13.35.14;10.09.2023;17;08;Supply Chain;Supply Chains, Transportation et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1894/v2;;Preprints.org - The Multidisciplinary Preprint Platform;Sustainable Post-COVID-19 Global Supply Chain Management: Conceptual Framework;There are two purposes for this article. The first purpose is to perform a reiew of previous research on global supply chain management (GSCM) principles that can adapt and survive adversity, such as the COVID-19 pandemic. The second purpose is to put forth a conceptual framework for the GSCM that is sustainable in the event of future turbulence similar to that experienced during the COVID-19 pandemic. With regard to the issues raised, the article posits the following questions. Is there, perhaps, a sustainable post-COVID-19 pandemic GSCM? Can the COVID-19 pandemic-related international logistics system (GSC) turbulences be predicted with certainty using these sustainable post-COVID-19 pandemic GSCM concepts? Putting it all together, the paper concludes that, while debatable, sustainable GSCM is feasible and can be accomplished utilizing JIT, supply chain mitigation, and supply chain visibility, as demonstrated by the manufacturing firms referenced in the article.
2023.09.10.13.35.15;10.09.2023;18;09;Commerce;Commerce, Trading, Sales, Retail et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:hal:journl:hal-04153038&r=cmp;;Camilo R. ContrerasPierre Valette-Florence;Brands And Chatbots: An Overview Using Machine Learning;"As artificial intelligence (AI) and machine learning techniques have evolved to improve Natural Language Processing, human language understanding has enabled human-machine communication tools to be increasingly deployed by brands. Conversational agents or chatbots are among the most widely positioned in recent years of technological evolution, with unprecedented social skills. They have become a cornerstone for supporting brands' interactions with consumers in both digital and physical spaces. Due to the chatbots' massive scientific boom and the relevance, they are gaining for brand management, its practitioners and scholars wake a growing interest in understanding the epistemological map on which this topic is embedded. To discover the main cross-cutting issues, the current and emerging research topics pragmatically. This study proposes using Machine Learning techniques in the scientific production body of this fruitful branch of marketing. Our instruments are twofold; first, we applied Latent Dirichlet Allocation (LDA) to identify eight thematic groups. Second, Dynamic Topic Models (DTM) reveals that the current research streams are oriented to technological advancement. In addition, research on chatbots and brand management is also emerging in two possible directions."
2023.09.10.13.35.16;10.09.2023;19;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2309.03645;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03645.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Granada_M/0/1/0/all/0/1"">Mateo Gutierrez Granada</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zilbershtein_D/0/1/0/all/0/1"">Dina Zilbershtein</a>, <a href=""http://arxiv.org/find/cs/1/au:+Odijk_D/0/1/0/all/0/1"">Daan Odijk</a>, <a href=""http://arxiv.org/find/cs/1/au:+Barile_F/0/1/0/all/0/1"">Francesco Barile</a>";Mateo Gutierrez Granada,Dina Zilbershtein,Daan Odijk,Francesco Barile;VideolandGPT: A User Study on a Conversational Recommender System.;This paper investigates how large language models (LLMs) can enhance recommender systems, with a specific focus on Conversational Recommender Systems that leverage user preferences and personalised candidate selections from existing ranking models. We introduce VideolandGPT, a recommender system for a Video-on-Demand (VOD) platform, Videoland, which uses ChatGPT to select from a predetermined set of contents, considering the additional context indicated by users' interactions with a chat interface. We evaluate ranking metrics, user experience, and fairness of recommendations, comparing a personalised and a non-personalised version of the system, in a between-subject user study. Our results indicate that the personalised version outperforms the non-personalised in terms of accuracy and general user satisfaction, while both versions increase the visibility of items which are not in the top of the recommendation lists. However, both versions present inconsistent behavior in terms of fairness, as the system may generate recommendations which are not available on Videoland.
2023.09.10.13.35.17;10.09.2023;20;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.03227;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03227.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jegal_Y/0/1/0/all/0/1"">Yongseung Jegal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1"">Jaewoong Choi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1"">Jiho Lee</a>, <a href=""http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1"">Ki-Su Park</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1"">Seyoung Lee</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1"">Janghyeok Yoon</a>";Yongseung Jegal,Jaewoong Choi,Jiho Lee,Ki-Su Park,Seyoung Lee,Janghyeok Yoon;Learning a Patent-Informed Biomedical Knowledge Graph Reveals Technological Potential of Drug Repositioning Candidates.;Drug repositioning-a promising strategy for discovering new therapeutic uses for existing drugs-has been increasingly explored in the computational science literature using biomedical databases. However, the technological potential of drug repositioning candidates has often been overlooked. This study presents a novel protocol to comprehensively analyse various sources such as pharmaceutical patents and biomedical databases, and identify drug repositioning candidates with both technological potential and scientific evidence. To this end, first, we constructed a scientific biomedical knowledge graph (s-BKG) comprising relationships between drugs, diseases, and genes derived from biomedical databases. Our protocol involves identifying drugs that exhibit limited association with the target disease but are closely located in the s-BKG, as potential drug candidates. We constructed a patent-informed biomedical knowledge graph (p-BKG) by adding pharmaceutical patent information. Finally, we developed a graph embedding protocol to ascertain the structure of the p-BKG, thereby calculating the relevance scores of those candidates with target disease-related patents to evaluate their technological potential. Our case study on Alzheimer's disease demonstrates its efficacy and feasibility, while the quantitative outcomes and systematic methods are expected to bridge the gap between computational discoveries and successful market applications in drug repositioning research.
2023.09.10.13.35.18;10.09.2023;21;99;Other;Others;acm;;http://cacm.acm.org/browse-by-subject/artificial-intelligence.rss;http://cacm.acm.org/careers/276126-meet-generative-ais-super-users-70-of-gen-z-use-genai;;Communications of the ACM: Artificial Intelligence;Meet Generative AI's 'Super Users': 70% of Gen Z Use GenAI ;Salesforce's survey shows that age and employment status are major factors in AI adoption.
2023.09.07.15.19.01;07.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;arxiv;2309.02945;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.02945.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sayara_A/0/1/0/all/0/1"">Anika Sayara</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1"">Benjamin Lee</a>, <a href=""http://arxiv.org/find/cs/1/au:+Quijano_Chavez_C/0/1/0/all/0/1"">Carlos Quijano-Chavez</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sedlmair_M/0/1/0/all/0/1"">Michael Sedlmair</a>";Anika Sayara,Benjamin Lee,Carlos Quijano-Chavez,Michael Sedlmair;Designing Situated Dashboards: Challenges and Opportunities.;Situated Visualization is an emerging field that unites several areas - visualization, augmented reality, human-computer interaction, and internet-of-things, to support human data activities within the ubiquitous world. Likewise, dashboards are broadly used to simplify complex data through multiple views. However, dashboards are only adapted for desktop settings, and requires visual strategies to support situatedness. We propose the concept of AR-based situated dashboards and present design considerations and challenges developed over interviews with experts. These challenges aim to propose directions and opportunities for facilitating the effective designing and authoring of situated dashboards.
2023.09.07.15.19.02;07.09.2023;02;00;CrossTopic;Generic, Cross Topic, et al.;datasciencecentral;;;https://www.datasciencecentral.com/16-most-interesting-ai-applications-across-industries-worldwide/;;;16 most interesting AI applications across industries worldwide;"1. Healthcare
2. eCommerce
3. Banking and finance
4. Transportation and logistics
5. Travel
6. Education
7. Real estate
8. Entertainment and gaming
9. Manufacturing
10. Automotive
11. Automated Driving programs
12. Email Spam Filters
13. Facial Recognition
14. Transaction Authentication
15. Domestic Robots such as Automated vacuums and lawnmowers
16. Advanced Home Security Systems"
2023.09.07.15.19.02;07.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.02884;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.02884.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Manathunga_S/0/1/0/all/0/1"">Supun Manathunga</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hettigoda_I/0/1/0/all/0/1"">Isuru Hettigoda</a>";Supun Manathunga,Isuru Hettigoda;Aligning Large Language Models for Clinical Tasks.;Large Language Models (LLMs) have demonstrated remarkable adaptability, showcasing their capacity to excel in tasks for which they were not explicitly trained. However, despite their impressive natural language processing (NLP) capabilities, effective alignment of LLMs remains a crucial challenge when deploying them for specific clinical applications. The ability to generate responses with factually accurate content and to engage in non-trivial reasoning steps are crucial for the LLMs to be eligible for applications in clinical medicine. Employing a combination of techniques including instruction-tuning and in-prompt strategies like few-shot and chain of thought prompting has significantly enhanced the performance of LLMs. Our proposed alignment strategy for medical question-answering, known as 'expand-guess-refine', offers a parameter and data-efficient solution. A preliminary analysis of this method demonstrated outstanding performance, achieving a score of 70.63% on a subset of questions sourced from the USMLE dataset.
2023.09.07.15.19.03;07.09.2023;04;02;Energy;Electricity, Smart Grid et al.;arxiv;2306.07731;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2306.07731.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Laudage_C/0/1/0/all/0/1"">Christian Laudag&#xe9;</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Aichinger_F/0/1/0/all/0/1"">Florian Aichinger</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Desmettre_S/0/1/0/all/0/1"">Sascha Desmettre</a>";Christian Laudagé,Florian Aichinger,Sascha Desmettre;A Comparative Study of Factor Models for Different Periods of the Electricity Spot Price Market.;Due to major shifts in European energy supply, a structural change can be observed in Austrian electricity spot price data starting from the second quarter of the year 2021 onward. In this work we study the performance of two different factor models for the electricity spot price in three different time periods. To this end, we consider three samples of EEX data for the Austrian base load electricity spot price, one from the pre-crises from 2018 to 2021, the second from the time of the crisis from 2021 to 2023 and the whole data from 2018 to 2023. For each of these samples, we investigate the fit of a classical 3-factor model with a Gaussian base signal and one positive and one negative jump signal and compare it with a 4-factor model to assess the effect of adding a second Gaussian base signal to the model. For the calibration of the models we develop a tailor-made Markov Chain Monte Carlo method based on Gibbs sampling. To evaluate the model adequacy, we provide simulations of the spot price as well as a posterior predictive check for the 3- and the 4-factor model. We find that the 4-factor model outperforms the 3-factor model in times of non-crises. In times of crises, the second Gaussian base signal does not lead to a better fit of the model. To the best of our knowledge, this is the first study regarding stochastic electricity spot price models in this new market environment. Hence, it serves as a solid base for future research.
2023.09.07.15.19.04;07.09.2023;05;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.03079;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.03079.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Gupta_U/0/1/0/all/0/1"">Udit Gupta</a>";Udit Gupta;GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models.;Annual Reports of publicly listed companies contain vital information about their financial health which can help assess the potential impact on Stock price of the firm. These reports are comprehensive in nature, going up to, and sometimes exceeding, 100 pages. Analysing these reports is cumbersome even for a single firm, let alone the whole universe of firms that exist. Over the years, financial experts have become proficient in extracting valuable information from these documents relatively quickly. However, this requires years of practice and experience. This paper aims to simplify the process of assessing Annual Reports of all the firms by leveraging the capabilities of Large Language Models (LLMs). The insights generated by the LLM are compiled in a Quant styled dataset and augmented by historical stock price data. A Machine Learning model is then trained with LLM outputs as features. The walkforward test results show promising outperformance wrt S&P500 returns. This paper intends to provide a framework for future work in this direction. To facilitate this, the code has been released as open source.
2023.09.07.15.19.05;07.09.2023;06;06;Public Services;Public Services;arxiv;2303.05382;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2303.05382.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zheng_O/0/1/0/all/0/1"">Ou Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Abdel_Aty_M/0/1/0/all/0/1"">Mohamed Abdel-Aty</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"">Dongdong Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"">Zijin Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1"">Shengxuan Ding</a>";Ou Zheng,Mohamed Abdel-Aty,Dongdong Wang,Zijin Wang,Shengxuan Ding;ChatGPT is on the Horizon: Could a Large Language Model be Suitable for Intelligent Traffic Safety Research and Applications?.;ChatGPT embarks on a new era of artificial intelligence and will revolutionize the way we approach intelligent traffic safety systems. This paper begins with a brief introduction about the development of large language models (LLMs). Next, we exemplify using ChatGPT to address key traffic safety issues. Furthermore, we discuss the controversies surrounding LLMs, raise critical questions for their deployment, and provide our solutions. Moreover, we propose an idea of multi-modality representation learning for smarter traffic safety decision-making and open more questions for application improvement. We believe that LLM will both shape and potentially facilitate components of traffic safety research.
2023.09.07.15.19.06;07.09.2023;07;07;Industry;I4.0, Production et al.;arxiv;2308.14063;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.14063.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1"">Hejing Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1"">Jian Guan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1"">Qiaoxi Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiao_F/0/1/0/all/0/1"">Feiyang Xiao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Youde Liu</a>";Hejing Zhang,Jian Guan,Qiaoxi Zhu,Feiyang Xiao,Youde Liu;Anomalous Sound Detection Using Self-Attention-Based Frequency Pattern Analysis of Machine Sounds.;Different machines can exhibit diverse frequency patterns in their emitted sound. This feature has been recently explored in anomaly sound detection and reached state-of-the-art performance. However, existing methods rely on the manual or empirical determination of the frequency filter by observing the effective frequency range in the training data, which may be impractical for general application. This paper proposes an anomalous sound detection method using self-attention-based frequency pattern analysis and spectral-temporal information fusion. Our experiments demonstrate that the self-attention module automatically and adaptively analyses the effective frequencies of a machine sound and enhances that information in the spectral feature representation. With spectral-temporal information fusion, the obtained audio feature eventually improves the anomaly detection performance on the DCASE 2020 Challenge Task 2 dataset.
2023.09.07.15.19.07;07.09.2023;08;07;Industry;I4.0, Production et al.;arxiv;2309.02465;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.02465.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jignasu_A/0/1/0/all/0/1"">Anushrut Jignasu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Marshall_K/0/1/0/all/0/1"">Kelly Marshall</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ganapathysubramanian_B/0/1/0/all/0/1"">Baskar Ganapathysubramanian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Balu_A/0/1/0/all/0/1"">Aditya Balu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1"">Chinmay Hegde</a>, <a href=""http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1"">Adarsh Krishnamurthy</a>";Anushrut Jignasu,Kelly Marshall,Baskar Ganapathysubramanian,Aditya Balu,Chinmay Hegde,Adarsh Krishnamurthy;Towards Foundational AI Models for Additive Manufacturing: Language Models for G-Code Debugging, Manipulation, and Comprehension.;3D printing or additive manufacturing is a revolutionary technology that enables the creation of physical objects from digital models. However, the quality and accuracy of 3D printing depend on the correctness and efficiency of the G-code, a low-level numerical control programming language that instructs 3D printers how to move and extrude material. Debugging G-code is a challenging task that requires a syntactic and semantic understanding of the G-code format and the geometry of the part to be printed. In this paper, we present the first extensive evaluation of six state-of-the-art foundational large language models (LLMs) for comprehending and debugging G-code files for 3D printing. We design effective prompts to enable pre-trained LLMs to understand and manipulate G-code and test their performance on various aspects of G-code debugging and manipulation, including detection and correction of common errors and the ability to perform geometric transformations. We analyze their strengths and weaknesses for understanding complete G-code files. We also discuss the implications and limitations of using LLMs for G-code comprehension.
2023.09.07.15.19.08;07.09.2023;09;09;Commerce;Commerce, Trading, Sales, Retail et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0458/v1;;Preprints.org - The Multidisciplinary Preprint Platform;The Future of Electronic Commerce in the IoT Environment;The Internet of Things (IoT) was born from the fusion of virtual and physical space and became the initiator of many scientific fields. Economic sustainability is the key to further development and progress. Today, the need for electronic commerce has become an economic priority in the transition period between Industry 4.0 and Industry 5.0. Unlike mass production in Industry 4.0, customized production in Industry 5.0 should reach its true potential in vertically organized management and decision-making systems. The authors focused their research on e-commerce based on the three-level vertical IoT environment and the edge, fog, and cloud computing. The paper presents hands-on machine learning (ML) algorithms to facilitate the transition from a flat to a vertical e-commerce concept. The authors also propose practical ML algorithms for a few e-commerce types: consumer-consumer relationships and consumer-company-consumer relationships. These algorithms are mainly composed of convolution neural networks (CNN), natural language understanding (NLU) and sequential pattern mining (SPM), reinforcement learning (RL for agent training), algorithms for clicking on the item prediction, consumer behavior learning, etc. All presented concepts, algorithms, and models are described in detail.
2023.09.07.15.19.02;07.09.2023;10;09;Commerce;Commerce, Trading, Sales, Retail et al.;doordash;;;https://about.doordash.com/en-us/news/introducing-ai-and-agent-powered-voice-ordering;;;DoorDash Introduces AI and Agent-Powered Voice Ordering Solution;DoorDash announced its development of voice ordering capabilities incorporating AI, building on its existing model leveraging best-in-class agents, to further support restaurant operations. The cost-efficient innovation will enable select operators the potential to increase their sales by answering all calls and pursuing incremental revenue opportunities, while providing an excellent end-to-end customer experience. 'Customers expect more from restaurateurs, and in return, restaurateurs expect even more technology-forward solutions from us - including support for phone channels to meet customers where they're ordering,' said Rajat Shroff, Head of Product and Design at DoorDash. 'Supporting operators by capturing customer demand through investments in our voice product is one way we're delivering more and enabling our partners to grow their business.'
2023.09.07.15.19.09;07.09.2023;11;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2305.19347;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.19347.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+ElSayed_Z/0/1/0/all/0/1"">Zag ElSayed</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ozer_M/0/1/0/all/0/1"">Murat Ozer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Elsayed_N/0/1/0/all/0/1"">Nelly Elsayed</a>, <a href=""http://arxiv.org/find/cs/1/au:+Abdelgawad_A/0/1/0/all/0/1"">Ahmed Abdelgawad</a>";Zag ElSayed,Murat Ozer,Nelly Elsayed,Ahmed Abdelgawad;Machine Learning Based IoT Adaptive Architecture for Epilepsy Seizure Detection: Anatomy and Analysis.;"A seizure tracking system is crucial for monitoring and evaluating epilepsy treatments. Caretaker seizure diaries are used in epilepsy care today, but clinical seizure monitoring may miss seizures. Monitoring devices that can be worn may be better tolerated and more suitable for long-term ambulatory use. Many techniques and methods are proposed for seizure detection; However, simplicity and affordability are key concepts for daily use while preserving the accuracy of the detection. In this study, we propose a versal, affordable noninvasive based on a simple real-time k-Nearest-Neighbors (kNN) machine learning that can be customized and adapted to individual users in less than four seconds of training time; the system was verified and validated using 500 subjects, with seizure detection data sampled at 178 Hz, the operated with a mean accuracy of (94.5%)."
2023.09.07.15.19.10;07.09.2023;12;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2306.11963;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.11963.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shaik_T/0/1/0/all/0/1"">Thanveer Shaik</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tao_X/0/1/0/all/0/1"">Xiaohui Tao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1"">Lin Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1"">Haoran Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Velasquez_J/0/1/0/all/0/1"">Juan D. Vel&#xe1;squez</a>";Thanveer Shaik,Xiaohui Tao,Lin Li,Haoran Xie,Juan D. Velásquez;A Survey of Multimodal Information Fusion for Smart Healthcare: Mapping the Journey from Data to Wisdom.;Multimodal medical data fusion has emerged as a transformative approach in smart healthcare, enabling a comprehensive understanding of patient health and personalized treatment plans. In this paper, a journey from data to information to knowledge to wisdom (DIKW) is explored through multimodal fusion for smart healthcare. We present a comprehensive review of multimodal medical data fusion focused on the integration of various data modalities. The review explores different approaches such as feature selection, rule-based systems, machine learning, deep learning, and natural language processing, for fusing and analyzing multimodal data. This paper also highlights the challenges associated with multimodal fusion in healthcare. By synthesizing the reviewed frameworks and theories, it proposes a generic framework for multimodal medical data fusion that aligns with the DIKW model. Moreover, it discusses future directions related to the four pillars of healthcare: Predictive, Preventive, Personalized, and Participatory approaches. The components of the comprehensive survey presented in this paper form the foundation for more successful implementation of multimodal fusion in smart healthcare. Our findings can guide researchers and practitioners in leveraging the power of multimodal fusion with the state-of-the-art approaches to revolutionize healthcare and improve patient outcomes.
2023.09.07.15.19.11;07.09.2023;13;18;Sustainability;Sustainability, Efficiency et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0492/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Sustainable Cooperation between Schools, Enterprises, and Government: An Evolutionary Game Theory Analysis;"Promoting close and sustainable cooperation between schools, enterprises, and government has become an important concern in many countries. Based on evolutionary game theory, this paper constructs a tripartite evolutionary game model of schools, enterprises, and government in order to analyze the stability of strategies of the different players. The results show that the main factor that influences the stability of the strategies of schools and enterprises is the reward of positive cooperation from sources other than the government, and the main factor that influences the stability of the strategy of the government is the benefit of positive cooperation strategy under the scenario where schools cooperate with enterprises. Therefore, the government should focus on implementing more effective policies, such as increasing the incentives and penalties, improving the mechanism for managing conflicts, ensuring the fairness of benefits distribution, and clarifying the responsibilities of different departments; schools should focus on providing more practical curricula and programs for students, training high-quality teachers, and perfecting talent cultivation to meet the needs of enterprises; and enterprises should focus on providing job experiences for students and transforming the results of schools’ teaching and theoretical research into practical productivity."
2023.09.07.15.19.12;07.09.2023;14;18;Sustainability;Sustainability, Efficiency et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0523/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Exploring the Interplay of Physical Environment and Organizational Climate in Sustainable Innovation: A Multidimensional Framework;The intricate relationship between physical and social environments within organizations plays a pivotal role in shaping sustainable innovation endeavors. This paper presents a comprehensive analysis of two key dynamics that have garnered substantial scholarly attention for promoting sustainable innovation: the physical environment and the organizational climate. To elucidate the intricate interplay between these dynamics, we propose a novel three-dimensional framework that guides the modeling of the intricate processes through which the physical environment and innovation climate synergistically influence innovation outcomes. Building on this framework, we delve into an in-depth literature review concerning physical environments that exert a significant impact on innovation. Through this review, we identify and elaborate on four pivotal elements of the physical environment: communality, personalization, comfort, and healthiness. Leveraging insights gleaned from this review, we outline two promising avenues for future research in the realm of the physical environment's interaction with the innovation climate. Furthermore, we underscore the critical importance of adopting an interdisciplinary approach that seamlessly integrates insights from both the physical and social domains to comprehensively understand the sustainable innovation landscape.
2023.09.06.16.35.01;06.09.2023;01;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.00638;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00638.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Nagy_P/0/1/0/all/0/1"">Peer Nagy</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Frey_S/0/1/0/all/0/1"">Sascha Frey</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Sapora_S/0/1/0/all/0/1"">Silvia Sapora</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Li_K/0/1/0/all/0/1"">Kang Li</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Calinescu_A/0/1/0/all/0/1"">Anisoara Calinescu</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Zohren_S/0/1/0/all/0/1"">Stefan Zohren</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Foerster_J/0/1/0/all/0/1"">Jakob Foerster</a>";Peer Nagy,Sascha Frey,Silvia Sapora,Kang Li,Anisoara Calinescu,Stefan Zohren,Jakob Foerster;Generative AI for End-to-End Limit Order Book Modelling: A Token-Level Autoregressive Generative Model of Message Flow Using a Deep State Space Network.;Developing a generative model of realistic order flow in financial markets is a challenging open problem, with numerous applications for market participants. Addressing this, we propose the first end-to-end autoregressive generative model that generates tokenized limit order book (LOB) messages. These messages are interpreted by a Jax-LOB simulator, which updates the LOB state. To handle long sequences efficiently, the model employs simplified structured state-space layers to process sequences of order book states and tokenized messages. Using LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message data, converting groups of successive digits to tokens, similar to tokenization in large language models. Out-of-sample results show promising performance in approximating the data distribution, as evidenced by low model perplexity. Furthermore, the mid-price returns calculated from the generated order flow exhibit a significant correlation with the data, indicating impressive conditional forecast performance. Due to the granularity of generated data, and the accuracy of the model, it offers new application areas for future work beyond forecasting, e.g. acting as a world model in high-frequency financial reinforcement learning applications. Overall, our results invite the use and extension of the model in the direction of autoregressive large financial models for the generation of high-frequency financial data and we commit to open-sourcing our code to facilitate future research.
2023.09.06.16.35.02;06.09.2023;02;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.00649;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00649.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Niszczota_P/0/1/0/all/0/1"">Pawe&#x142; Niszczota</a>, <a href=""http://arxiv.org/find/cs/1/au:+Abbas_S/0/1/0/all/0/1"">Sami Abbas</a>";"Pawe&#x142; Niszczota,Sami Abbas";GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice.;We assess the ability of GPT -- a large language model -- to serve as a financial robo-advisor for the masses, by using a financial literacy test. Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial literacy test, respectively, compared to a baseline of 33%. However, ChatGPT based on GPT-4 achieves a near-perfect 99% score, pointing to financial literacy becoming an emergent ability of state-of-the-art models. We use the Judge-Advisor System and a savings dilemma to illustrate how researchers might assess advice-utilization from large language models. We also present a number of directions for future research.
2023.09.06.16.35.03;06.09.2023;03;06;Public Services;Public Services;arxiv;2308.14284;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.14284.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Da_L/0/1/0/all/0/1"">Longchao Da</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1"">Minchiuan Gao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1"">Hao Mei</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1"">Hua Wei</a>";Longchao Da,Minchiuan Gao,Hao Mei,Hua Wei;LLM Powered Sim-to-real Transfer for Traffic Signal Control.;Numerous solutions are proposed for the Traffic Signal Control (TSC) tasks aiming to provide efficient transportation and mitigate congestion waste. In recent, promising results have been attained by Reinforcement Learning (RL) methods through trial and error in simulators, bringing confidence in solving cities' congestion headaches. However, there still exist performance gaps when simulator-trained policies are deployed to the real world. This issue is mainly introduced by the system dynamic difference between the training simulator and the real-world environments. The Large Language Models (LLMs) are trained on mass knowledge and proved to be equipped with astonishing inference abilities. In this work, we leverage LLMs to understand and profile the system dynamics by a prompt-based grounded action transformation. Accepting the cloze prompt template, and then filling in the answer based on accessible context, the pre-trained LLM's inference ability is exploited and applied to understand how weather conditions, traffic states, and road types influence traffic dynamics, being aware of this, the policies' action is taken and grounded based on realistic dynamics, thus help the agent learn a more realistic policy. We conduct experiments using DQN to show the effectiveness of the proposed PromptGAT's ability in mitigating the performance gap from simulation to reality (sim-to-real).
2023.09.06.16.35.04;06.09.2023;04;08;Supply Chain;Supply Chains, Transportation et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Digital_Twins_of_Supply_Chains_A_Systems_Approach/24073527;;TechRxiv RSS Feed;Digital Twins of Supply Chains: A Systems Approach;We tackle the long-standing problem of digitalisation of Supply Chains, focusing on collaboration and sharing of information. By expanding and generalising the notion of Digital Twins, we review, develop, and conceptualise the (emerging) notion of Digital Twins of Supply Chains (DTofSC). Whereas Digital Twins is now an active research area with data available from numerous industry projects, its application to Supply Chains is just emerging as a cross-discipline which, in turn, stems from decades of maturing the notion of Digital Supply Chains. The concept is still imprecise beyond key metaphors (e.g., visibility, traceability, control, etc.), but, as we conceptualise, the overall vision is to create technical and organisational mechanisms enabling any Supply Chain to be monitored and controlled from, e.g., a simple dashboard screen – taking parallels with the Internet. We perform a literature review on the intersections between Digital Supply Chains, Digital Twins, and emerging digital technologies (e.g. Blockchain). From this review, we (1) propose a synthesis systems architecture of DTofSC, (2) identify a key requirement gap (that we term addressability), and (3) to ground our contributions, apply our systems architecture to battery recycling.
2023.09.06.16.35.05;06.09.2023;05;08;Supply Chain;Supply Chains, Transportation et al.;arxiv;2109.03870;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2109.03870.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Botta_V/0/1/0/all/0/1"">Vincenzo Botta</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fusco_L/0/1/0/all/0/1"">Laura Fusco</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mondelli_A/0/1/0/all/0/1"">Attilio Mondelli</a>, <a href=""http://arxiv.org/find/cs/1/au:+Visconti_I/0/1/0/all/0/1"">Ivan Visconti</a>";Vincenzo Botta,Laura Fusco,Attilio Mondelli,Ivan Visconti;Secure Blockchain-Based Supply Chain Management with Verifiable Digital Twins.;A major problem in blockchain-based supply chain management is the potential unreliability of digital twins when considering digital representations of physical goods. Indeed, the use of blockchain technology to trace goods is obviously ineffective if there is no strong correspondence between what is physically exchanged and the digital information that appears in blockchain transactions. In this work, we propose a model for strengthening the supply chain management of physical goods by leveraging blockchain technology along with a digital-twin verification feature. Our model can be instantiated in various scenarios and we have in particular considered the popular case of food traceability. In contrast to other models known in the literature that propose their own ad-hoc properties to assess the robustness of their supply chain management systems, in this work we use the formalism of secure computation, where processes are described through generic and natural ideal functionalities.
2023.09.06.16.35.06;06.09.2023;06;12;Health;Medical, Health Care, Pharmacy et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Healthcare_Internet_of_Things_IoT_A_Survey_of_State-of-the-art_Methods_and_Approaches/24080559;;TechRxiv RSS Feed;Healthcare Internet of Things (IoT): A Survey of State-of-the-art Methods and Approaches;The field of the Internet of Things (IoT) is expanding rapidly and shows the potential to completely transform the healthcare sector. The integration of machine learning algorithms in Internet of Medical Things (IoMT) systems has shown the potential to revolutionize healthcare by enabling efficient, accurate, and privacy-preserving services. However, the limitations of existing IoMT models pose significant challenges that need to be addressed to achieve sustainability in their adoption. Some of these challenges include energy consumption, complex data scheduling, low-latency models, privacy, joint offloading, limited data, and data security. There is a need to explore various novel architectures, develop new training and optimization techniques such as generative adversarial networks and stochastic gradient descent variants, and developed interpretative models to help in the decision-making process. Additionally, designing IoMT models that are suitable for low-resource environments and addressing ethical and fairness issues are crucial to preventing bias and discrimination, particularly in healthcare domains. In general, this paper reviews the current state of the art of IoMT and existing models and suggests various areas for further improvement to address the limitations of IoMT systems and enable the development of more efficient, accurate, and privacy-preserving healthcare services.
2023.09.06.16.35.07;06.09.2023;07;99;Other;Others;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0314/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Smart Textiles: A Review and Bibliometric Mapping;According to ISO/TR 23383, smart textiles reversibly interact with their environment and respond or adapt to changes in the environment. The present review and bibliometric analysis was performed on 5,810 documents (1989–2022) from the Scopus database, using VOSviewer and Bibliometrix/Biblioshiny for science mapping. The results show that the field of smart textiles is highly interdisciplinary and dynamic, with an average growth rate of 22% and exponential growth in the last 10 years. Beeby, S.P., and Torah, R.N. have published the highest number of papers, while Wang, Z.L. has the highest number of citations. The leading journals are Sensors, ACS Applied Materials and Interfaces, and Textile Research Journal, while Advanced Materials has the highest number of citations. China is the country with the most publications and the most extensive cooperative relationships with other countries. Research on smart textiles is largely concerned with new materials and technologies, particularly in relation to electronic textiles. Recent research focuses on energy generation (triboelectric nanogenerators, thermoelectrics, Joule heating), conductive materials (MXenes, liquid metal, silver nanoparticles), sensors (strain sensors, self-powered sensors, gait analysis), specialty products (artificial muscles, soft robotics, EMI shielding), and advanced properties of smart textiles (self-powered, self-cleaning, washable, sustainable smart textiles).
2023.09.05.15.08.01;05.09.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2307.09332&r=big;;Christopher Gerling;Company2Vec -- German Company Embeddings based on Corporate Websites;With Company2Vec, the paper proposes a novel application in representation learning. The model analyzes business activities from unstructured company website data using Word2Vec and dimensionality reduction. Company2Vec maintains semantic language structures and thus creates efficient company embeddings in fine-granular industries. These semantic embeddings can be used for various applications in banking. Direct relations between companies and words allow semantic business analytics (e.g. top-n words for a company). Furthermore, industry prediction is presented as a supervised learning application and evaluation method. The vectorized structure of the embeddings allows measuring companies similarities with the cosine distance. Company2Vec hence offers a more fine-grained comparison of companies than the standard industry labels (NACE). This property is relevant for unsupervised learning tasks, such as clustering. An alternative industry segmentation is shown with k-means clustering on the company embeddings. Finally, this paper proposes three algorithms for (1) firm-centric, (2) industry-centric and (3) portfolio-centric peer-firm identification.
2023.09.05.15.08.02;05.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:zbw:cfswop:713&r=pay;;Brühl, Volker;Generative Artificial Intelligence (GAI): Foundations, use cases and economic potential;"A key technology driving the digital transformation of the economy is artificial intelligence (AI). It has gained a high degree of public attention with the initial release of the chatbot ChatGPT, which demonstrates the potential of generative AI (GAI) as a relatively new segment within AI. It is widely expected that GAI will shape the future of many industries and society in the coming years. This article provides a brief overview of the foundations of generative AI (""GAI"") including machine learning and what distinguishes it from other fields of AI. Furthermore, we look at important players in this emerging market, possible use cases and the expected economic potential as of today. It is apparent that, once again, a few US-based Big Tech firms are about to dominate this emerging technology and that the European tech sector is falling further behind. Finally, we conclude that the recently adopted Digital Markets Act (DMA) and the Digital Service Act (DSA) as well as the upcoming AI Act should be reviewed to ensure that the regulatory framework of European digital markets keeps up with the accelerated development of AI."
2023.09.05.15.08.03;05.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2302.08468;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2302.08468.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ni_A/0/1/0/all/0/1"">Ansong Ni</a>, <a href=""http://arxiv.org/find/cs/1/au:+Iyer_S/0/1/0/all/0/1"">Srini Iyer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1"">Dragomir Radev</a>, <a href=""http://arxiv.org/find/cs/1/au:+Stoyanov_V/0/1/0/all/0/1"">Ves Stoyanov</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1"">Wen-tau Yih</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Sida I. Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1"">Xi Victoria Lin</a>";Ansong Ni,Srini Iyer,Dragomir Radev,Ves Stoyanov,Wen-tau Yih,Sida I. Wang,Xi Victoria Lin;LEVER: Learning to Verify Language-to-Code Generation with Execution.;The advent of large language models trained on code (code LLMs) has led to significant progress in language-to-code generation. State-of-the-art approaches in this area combine LLM decoding with sample pruning and reranking using test cases or heuristics based on the execution results. However, it is challenging to obtain test cases for many real-world language-to-code applications, and heuristics cannot well capture the semantic features of the execution results, such as data type and value range, which often indicates the correctness of the program. In this work, we propose LEVER, a simple approach to improve language-to-code generation by learning to verify the generated programs with their execution results. Specifically, we train verifiers to determine whether a program sampled from the LLMs is correct or not based on the natural language input, the program itself and its execution results. The sampled programs are reranked by combining the verification score with the LLM generation probability, and marginalizing over programs with the same execution results. On four datasets across the domains of table QA, math QA and basic Python programming, LEVER consistently improves over the base code LLMs(4.6% to 10.9% with code-davinci-002) and achieves new state-of-the-art results on all of them.
2023.09.05.15.08.04;05.09.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.00087;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00087.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Omiye_J/0/1/0/all/0/1"">Jesutofunmi A. Omiye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gui_H/0/1/0/all/0/1"">Haiwen Gui</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1"">Shawheen J. Rezaei</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1"">James Zou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Daneshjou_R/0/1/0/all/0/1"">Roxana Daneshjou</a>";Jesutofunmi A. Omiye,Haiwen Gui,Shawheen J. Rezaei,James Zou,Roxana Daneshjou;Large language models in medicine: the potentials and pitfalls.;Large language models (LLMs) have been applied to tasks in healthcare, ranging from medical exam questions to responding to patient questions. With increasing institutional partnerships between companies producing LLMs and healthcare systems, real world clinical application is coming closer to reality. As these models gain traction, it is essential for healthcare practitioners to understand what LLMs are, their development, their current and potential applications, and the associated pitfalls when utilized in medicine. This review and accompanying tutorial aim to give an overview of these topics to aid healthcare practitioners in understanding the rapidly changing landscape of LLMs as applied to medicine.
2023.09.05.15.08.05;05.09.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.00155;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00155.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sladic_M/0/1/0/all/0/1"">Muris Sladi&#x107;</a>, <a href=""http://arxiv.org/find/cs/1/au:+Valeros_V/0/1/0/all/0/1"">Veronica Valeros</a>, <a href=""http://arxiv.org/find/cs/1/au:+Catania_C/0/1/0/all/0/1"">Carlos Catania</a>, <a href=""http://arxiv.org/find/cs/1/au:+Garcia_S/0/1/0/all/0/1"">Sebastian Garcia</a>";"Muris Sladi&#x107;,Veronica Valeros,Carlos Catania,Sebastian Garcia";LLM in the Shell: Generative Honeypots.;Honeypots are essential tools in cybersecurity. However, most of them (even the high-interaction ones) lack the required realism to engage and fool human attackers. This limitation makes them easily discernible, hindering their effectiveness. This work introduces a novel method to create dynamic and realistic software honeypots based on Large Language Models. Preliminary results indicate that LLMs can create credible and dynamic honeypots capable of addressing important limitations of previous honeypots, such as deterministic responses, lack of adaptability, etc. We evaluated the realism of each command by conducting an experiment with human attackers who needed to say if the answer from the honeypot was fake or not. Our proposed honeypot, called shelLM, reached an accuracy rate of 0.92.
2023.09.05.15.08.06;05.09.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.00208;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00208.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Sung_J/0/1/0/all/0/1"">Junwon Sung</a>, <a href=""http://arxiv.org/find/cs/1/au:+Heo_W/0/1/0/all/0/1"">Woojin Heo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Byun_Y/0/1/0/all/0/1"">Yunkyung Byun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1"">Youngsam Kim</a>";Junwon Sung,Woojin Heo,Yunkyung Byun,Youngsam Kim;Large Language Models for Semantic Monitoring of Corporate Disclosures: A Case Study on Korea's Top 50 KOSPI Companies.;In the rapidly advancing domain of artificial intelligence, state-of-the-art language models such as OpenAI's GPT-3.5-turbo and GPT-4 offer unprecedented opportunities for automating complex tasks. This research paper delves into the capabilities of these models for semantically analyzing corporate disclosures in the Korean context, specifically for timely disclosure. The study focuses on the top 50 publicly traded companies listed on the Korean KOSPI, based on market capitalization, and scrutinizes their monthly disclosure summaries over a period of 17 months. Each summary was assigned a sentiment rating on a scale ranging from 1(very negative) to 5(very positive). To gauge the effectiveness of the language models, their sentiment ratings were compared with those generated by human experts. Our findings reveal a notable performance disparity between GPT-3.5-turbo and GPT-4, with the latter demonstrating significant accuracy in human evaluation tests. The Spearman correlation coefficient was registered at 0.61, while the simple concordance rate was recorded at 0.82. This research contributes valuable insights into the evaluative characteristics of GPT models, thereby laying the groundwork for future innovations in the field of automated semantic monitoring.
2023.09.05.15.08.07;05.09.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2309.00237;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00237.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Kweon_S/0/1/0/all/0/1"">Sunjun Kweon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1"">Junu Kim</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1"">Jiyoun Kim</a>, <a href=""http://arxiv.org/find/cs/1/au:+Im_S/0/1/0/all/0/1"">Sujeong Im</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cho_E/0/1/0/all/0/1"">Eunbyeol Cho</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1"">Seongsu Bae</a>, <a href=""http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1"">Jungwoo Oh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1"">Gyubok Lee</a>, <a href=""http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1"">Jong Hak Moon</a>, <a href=""http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1"">Seng Chan You</a>, <a href=""http://arxiv.org/find/cs/1/au:+Baek_S/0/1/0/all/0/1"">Seungjin Baek</a>, <a href=""http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1"">Chang Hoon Han</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jung_Y/0/1/0/all/0/1"">Yoon Bin Jung</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jo_Y/0/1/0/all/0/1"">Yohan Jo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1"">Edward Choi</a>";Sunjun Kweon,Junu Kim,Jiyoun Kim,Sujeong Im,Eunbyeol Cho,Seongsu Bae,Jungwoo Oh,Gyubok Lee,Jong Hak Moon,Seng Chan You,Seungjin Baek,Chang Hoon Han,Yoon Bin Jung,Yohan Jo,Edward Choi;Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes.;The development of large language models tailored for handling patients' clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations. To address these challenges, we first create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature. We then use these synthetic notes to train our specialized clinical large language model, Asclepius. While Asclepius is trained on synthetic data, we assess its potential performance in real-world applications by evaluating it using real clinical notes. We benchmark Asclepius against several other large language models, including GPT-3.5-turbo and other open-source alternatives. To further validate our approach using synthetic notes, we also compare Asclepius with its variants trained on real clinical notes. Our findings convincingly demonstrate that synthetic clinical notes can serve as viable substitutes for real ones when constructing high-performing clinical language models. This conclusion is supported by detailed evaluations conducted by both GPT-4 and medical professionals. All resources including weights, codes, and data used in the development of Asclepius are made publicly accessible for future research.
2023.09.05.15.08.07;05.09.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;analyticsvidhya;;;https://www.analyticsvidhya.com/blog/2023/08/generative-ai-projects/;;;Top 8 Generative AI Projects;In a rapidly evolving technological panorama, the emergence of generative AI projects has redefined how we interact with, create, and experience content. These projects harness the power of artificial intelligence to replicate human creativity and productiveness, spanning from text chatbots to video generators. These generative AI projects stand as a testament to the ever-expanding competencies ...
2023.09.05.15.08.08;05.09.2023;09;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/the-research-agent-4ef8e6f1b741;;;The Research Agent: Addressing the Challenge of Answering Questions Based on a Large Text Corpus;I made an Autonomous AI Research Agent that can answer difficult questions with deep multi-hop reasoning capabilities
2023.09.05.15.08.08;05.09.2023;10;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2309.00136;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00136.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Asgarov_A/0/1/0/all/0/1"">Ali Asgarov</a>";Ali Asgarov;Predicting Financial Market Trends using Time Series Analysis and Natural Language Processing.;Forecasting financial market trends through time series analysis and natural language processing poses a complex and demanding undertaking, owing to the numerous variables that can influence stock prices. These variables encompass a spectrum of economic and political occurrences, as well as prevailing public attitudes. Recent research has indicated that the expression of public sentiments on social media platforms such as Twitter may have a noteworthy impact on the determination of stock prices. The objective of this study was to assess the viability of Twitter sentiments as a tool for predicting stock prices of major corporations such as Tesla, Apple. Our study has revealed a robust association between the emotions conveyed in tweets and fluctuations in stock prices. Our findings indicate that positivity, negativity, and subjectivity are the primary determinants of fluctuations in stock prices. The data was analyzed utilizing the Long-Short Term Memory neural network (LSTM) model, which is currently recognized as the leading methodology for predicting stock prices by incorporating Twitter sentiments and historical stock prices data. The models utilized in our study demonstrated a high degree of reliability and yielded precise outcomes for the designated corporations. In summary, this research emphasizes the significance of incorporating public opinions into the prediction of stock prices. The application of Time Series Analysis and Natural Language Processing methodologies can yield significant scientific findings regarding financial market patterns, thereby facilitating informed decision-making among investors. The results of our study indicate that the utilization of Twitter sentiments can serve as a potent instrument for forecasting stock prices, and ought to be factored in when formulating investment strategies.
2023.09.05.15.08.09;05.09.2023;11;07;Industry;I4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0254/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Intelligent Tapping Machine: Tap Geometry Inspection;Currently, the majority of industrial metal processing involves the use of taps for cutting. However, existing tap machines require relocation to specialized inspection stations and only assess the con-dition of the cutting edges for defects. They do not evaluate the quality of the cutting angles and the amount of removed material. Machine vision, a key component of smart manufacturing, is com-monly used for visual inspection. Taps are employed for processing various materials. Traditional tap replacement relies on the technician's accumulated empirical experience to determine the ser-vice life of the tap. Typically, inspecting tooth wear involves removing the tap and evaluating the degree of wear to determine if regrinding or replacement is necessary. Therefore, we propose the use of visual inspection of the tap's external features to determine whether replacement or regrinding is needed. We examined the bearing surface of the tap and utilized single images to identify the cutting angle, clearance angle, and cone angles. By inspecting the side of the tap, we calculated the wear of each cusp. We further investigated whether the cutting portion affected the length of the tool by measuring changes in tooth surface area and the amount of removed thread. This inspection process can facilitate the development of a tap life system, allowing for the estimation of the durability and wear of taps and nuts made of different materials. Statistical analysis can be employed to predict the lifespan of taps in production lines.
2023.09.05.15.08.10;05.09.2023;12;07;Industry;I4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0148/v1;;Preprints.org - The Multidisciplinary Preprint Platform;Iot Powered by Big Data: Architecture, Ecosystem, Applications;"To handle the huge amount of data generated by IoT devices, Big Data processing tools make it easier. This paper discusses the Big Data concept and its main V’s characteristics. It further describes IoT-enabling technologies; nominally cloud computing such as SaaS and PaaS. The centralization and infrastructure of Big Data systems, and how Cloud Computing gives a platform access to the data from anywhere. The paper explores IoT with big data architectural solutions for various use cases across the healthcare and transportation sectors."
2023.09.05.15.08.11;05.09.2023;13;07;Industry;I4.0, Production et al.;arxiv;2309.00460;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00460.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Flotzinger_J/0/1/0/all/0/1"">Johannes Flotzinger</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rosch_P/0/1/0/all/0/1"">Philipp J. R&#xf6;sch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Braml_T/0/1/0/all/0/1"">Thomas Braml</a>";Johannes Flotzinger,Philipp J. Rösch,Thomas Braml;dacl10k: Benchmark for Semantic Bridge Damage Segmentation.;"Reliably identifying reinforced concrete defects (RCDs)plays a crucial role in assessing the structural integrity, traffic safety, and long-term durability of concrete bridges, which represent the most common bridge type worldwide. Nevertheless, available datasets for the recognition of RCDs are small in terms of size and class variety, which questions their usability in real-world scenarios and their role as a benchmark. Our contribution to this problem is ""dacl10k"", an exceptionally diverse RCD dataset for multi-label semantic segmentation comprising 9,920 images deriving from real-world bridge inspections. dacl10k distinguishes 12 damage classes as well as 6 bridge components that play a key role in the building assessment and recommending actions, such as restoration works, traffic load limitations or bridge closures. In addition, we examine baseline models for dacl10k which are subsequently evaluated. The best model achieves a mean intersection-over-union of 0.42 on the test set. dacl10k, along with our baselines, will be openly accessible to researchers and practitioners, representing the currently biggest dataset regarding number of images and class diversity for semantic segmentation in the bridge inspection domain."
2023.09.05.15.08.01;05.09.2023;14;08;Supply Chain;Supply Chains, Transportation et al.;technologyreview;;;https://www.technologyreview.com/2023/08/29/1078245/unlocking-the-value-of-supply-chain-data-across-industries/;;;Unlocking the value of supply chain data across industries;The product shortages and supply-chain delays of the global covid-19 pandemic are still fresh memories. Consumers and industry are concerned that the next geopolitical climate event may have a similar impact. Against a backdrop of evolving regulations, these conditions mean manufacturers want to be prepared against short supplies, concerned customers, and weakened margins. For supply chain professionals, achieving a 'phygital' information flow—the blending of physical and digital data—is key to unlocking resilience and efficiency. As physical objects travel through supply chains, they generate a rich flow of data about the item and its journey—from its raw materials, its manufacturing conditions, even its expiration date—bringing new visibility and pinpointing bottlenecks.
2023.09.05.15.08.12;05.09.2023;15;09;Commerce;Commerce, Trading, Sales, Retail et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2307.05522&r=big;;Tom LiuStephen RobertsStefan Zohren;Deep Inception Networks: A General End-to-End Framework for Multi-asset Quantitative Strategies;We introduce Deep Inception Networks (DINs), a family of Deep Learning models that provide a general framework for end-to-end systematic trading strategies. DINs extract time series (TS) and cross sectional (CS) features directly from daily price returns. This removes the need for handcrafted features, and allows the model to learn from TS and CS information simultaneously. DINs benefit from a fully data-driven approach to feature extraction, whilst avoiding overfitting. Extending prior work on Deep Momentum Networks, DIN models directly output position sizes that optimise Sharpe ratio, but for the entire portfolio instead of individual assets. We propose a novel loss term to balance turnover regularisation against increased systemic risk from high correlation to the overall market. Using futures data, we show that DIN models outperform traditional TS and CS benchmarks, are robust to a range of transaction costs and perform consistently across random seeds. To balance the general nature of DIN models, we provide examples of how attention and Variable Selection Networks can aid the interpretability of investment decisions. These model-specific methods are particularly useful when the dimensionality of the input is high and variable importance fluctuates dynamically over time. Finally, we compare the performance of DIN models on other asset classes, and show how the space of potential features can be customised.
2023.09.05.15.08.13;05.09.2023;16;10;Operations;Infrastructure, Ecosystem et al.;arxiv;2309.00032;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00032.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1"">Yang Yue</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shyu_J/0/1/0/all/0/1"">Joseph Z. Shyu</a>";Yang Yue,Joseph Z. Shyu;Blockchain Based Open Network in Technology Intermediation.;Blockchain technology is developing using in reliable applications which can be designed to achieve decentralization and trustless. Based on the open network innovation theory, this paper proposes a technical intermediary management idea based on blockchain technology to improve the efficiency of technology intermediaries, providing accurate, reliable information and cutting cost for the market. This study demonstrates the advantage of blockchain to technology intermediaries. First, on a specific level, it can provide openness, transparency, decentralization and anonymity services. Second, the current industrial innovation elements are analyzed. blockchain improve the efficiency of technology intermediary, prevent risks and to make up for the shortcomings of traditional intermediaries. It has revolutionized the traditional technology intermediary. As this happens, it can revolutionize traditional technology intermediaries.
2023.09.05.15.08.02;05.09.2023;17;10;Operations;Infrastructure, Ecosystem et al.;towardsdatascience;;;https://towardsdatascience.com/how-i-leveraged-open-source-llms-to-achieve-massive-savings-on-a-large-compute-project-bd8bb3c7267;;;How I Leveraged Open Source LLMs to Achieve Massive Savings on a Large Compute Project;In the world of large language models (LLMs), the cost of computation can be a significant barrier, especially for extensive projects. I recently embarked on a project that required running 4,000,000 prompts with an average input length of 1000 tokens and an average output length of 200 tokens. That's nearly 5 billion tokens! The traditional approach of paying per token, as is common with models like GPT-3.5 and GPT-4, would have resulted in a hefty bill. However, I discovered that by leveraging open source LLMs, I could shift the pricing model to pay per hour of compute time, leading to substantial savings. This article will detail the approaches I took and compare and contrast each of them. Please note that while I share my experience with pricing, these are subject to change and may vary depending on your region and specific circumstances. The key takeaway here is the potential cost savings when leveraging open source LLMs and renting a GPU per hour, rather than the specific prices quoted.
2023.09.05.15.08.14;05.09.2023;18;12;Health;Medical, Health Care, Pharmacy et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202309.0189/v1;;Preprints.org - The Multidisciplinary Preprint Platform;A Topical Review on Enabling Technologies for Internet of Medical Things: Sensors, Devices, Platforms and Applications;The Internet of Things (IoT) is still a relatively new field of research, and its potential for use in the healthcare and medical sectors is enormous. In the last five years, IoT has been a go-to option for various applications such as using sensors for different features, machine-to-machine communication, etc., but precisely, in the medical sector, it is still lagging far behind compared to other sectors. Hence, this study emphasizes the IoT applications in medical fields, Medical IoT sensors and devices, IoT platforms for data visualization, and artificial intelligence in medical applica-tions. A systematic review considering PRISMA guidelines on research articles as well as the websites on IoMT sensors and devices have been carried out. A total of 986 articles after the year 2001 have been initially selected, and by applying the inclusion-exclusion criterion, a total of 597 articles have been identified. From these, 23 studies have been finally selected for this systematic review. This review analyzes different sensor monitoring circuits in detail, considering an Inten-sive Care Unit (ICU) scenario, device applications, and the data management system, including IoT platforms for the patients. Lastly, detailed discussion and challenges have been outlined, and possible prospects have been presented.
2023.09.05.15.08.15;05.09.2023;19;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2309.00064;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2309.00064.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Nasir_S/0/1/0/all/0/1"">Sidra Nasir</a>, <a href=""http://arxiv.org/find/cs/1/au:+Khan_R/0/1/0/all/0/1"">Rizwan Ahmed Khan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1"">Samita Bai</a>";Sidra Nasir,Rizwan Ahmed Khan,Samita Bai;Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond.;In the past decade, the deployment of deep learning (Artificial Intelligence (AI)) methods has become pervasive across a spectrum of real-world applications, often in safety-critical contexts. This comprehensive research article rigorously investigates the ethical dimensions intricately linked to the rapid evolution of AI technologies, with a particular focus on the healthcare domain. Delving deeply, it explores a multitude of facets including transparency, adept data management, human oversight, educational imperatives, and international collaboration within the realm of AI advancement. Central to this article is the proposition of a conscientious AI framework, meticulously crafted to accentuate values of transparency, equity, answerability, and a human-centric orientation. The second contribution of the article is the in-depth and thorough discussion of the limitations inherent to AI systems. It astutely identifies potential biases and the intricate challenges of navigating multifaceted contexts. Lastly, the article unequivocally accentuates the pressing need for globally standardized AI ethics principles and frameworks. Simultaneously, it aptly illustrates the adaptability of the ethical framework proposed herein, positioned skillfully to surmount emergent challenges.
2023.09.05.15.08.03;05.09.2023;20;12;Health;Medical, Health Care, Pharmacy et al.;research;;;https://blog.research.google/2023/08/multimodal-medical-ai.html;;;Multimodal medical AI;Medicine is an inherently multimodal discipline. When providing care, clinicians routinely interpret data from a wide range of modalities including medical images, clinical notes, lab tests, electronic health records, genomics, and more. Over the last decade or so, AI systems have achieved expert-level performance on specific tasks within specific modalities — some AI systems processing CT scans, while others analyzing high magnification pathology slides, and still others hunting for rare genetic variations. The inputs to these systems tend to be complex data such as images, and they typically provide structured outputs, whether in the form of discrete grades or dense image segmentation masks. In parallel, the capacities and capabilities of large language models (LLMs) have become so advanced that they have demonstrated comprehension and expertise in medical knowledge by both interpreting and responding in plain language. But how do we bring these capabilities together to build medical AI systems that can leverage information from all these sources
2023.09.02.13.14.01;02.09.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.16469;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.16469.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Phan_C/0/1/0/all/0/1"">Chau-Thang Phan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1"">Quoc-Nam Nguyen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1"">Kiet Van Nguyen</a>";Chau-Thang Phan,Quoc-Nam Nguyen,Kiet Van Nguyen;Link Prediction for Wikipedia Articles as a Natural Language Inference Task;"Link prediction task is vital to automatically understanding the structure of large knowledge bases. In this paper, we present our system to solve this task at the Data Science and Advanced Analytics 2023 Competition ""Efficient and Effective Link Prediction"" (DSAA-2023 Competition) with a corpus containing 948,233 training and 238,265 for public testing. This paper introduces an approach to link prediction in Wikipedia articles by formulating it as a natural language inference (NLI) task. Drawing inspiration from recent advancements in natural language processing and understanding, we cast link prediction as an NLI task, wherein the presence of a link between two articles is treated as a premise, and the task is to determine whether this premise holds based on the information presented in the articles. We implemented our system based on the Sentence Pair Classification for Link Prediction for the Wikipedia Articles task. Our system achieved 0.99996 Macro F1-score and 1.00000 Macro F1-score for the public and private test sets, respectively. Our team UIT-NLP ranked 3rd in performance on the private test set, equal to the scores of the first and second places. Our code is publicly for research purposes."
2023.09.02.13.14.02;02.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.16474;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.16474.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1"">Yongqiang Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Zhenyu Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1"">Feng Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1"">Xinhai Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1"">Donghong Liu</a>";Yongqiang Zhao,Zhenyu Li,Feng Zhang,Xinhai Xu,Donghong Liu;Enhancing Subtask Performance of Multi-modal Large Language Model;Multi-modal Large Language Model (MLLM) refers to a model expanded from a Large Language Model (LLM) that possesses the capability to handle and infer multi-modal data. Current MLLMs typically begin by using LLMs to decompose tasks into multiple subtasks, then employing individual pre-trained models to complete specific subtasks, and ultimately utilizing LLMs to integrate the results of each subtasks to obtain the results of the task. In real-world scenarios, when dealing with large projects, it is common practice to break down the project into smaller sub-projects, with different teams providing corresponding solutions or results. The project owner then decides which solution or result to use, ensuring the best possible outcome for each subtask and, consequently, for the entire project. Inspired by this, this study considers selecting multiple pre-trained models to complete the same subtask. By combining the results from multiple pre-trained models, the optimal subtask result is obtained, enhancing the performance of the MLLM. Specifically, this study first selects multiple pre-trained models focused on the same subtask based on distinct evaluation approaches, and then invokes these models in parallel to process input data and generate corresponding subtask results. Finally, the results from multiple pre-trained models for the same subtask are compared using the LLM, and the best result is chosen as the outcome for that subtask. Extensive experiments are conducted in this study using GPT-4 annotated datasets and human-annotated datasets. The results of various evaluation metrics adequately demonstrate the effectiveness of the proposed approach in this paper.
2023.09.02.13.14.03;02.09.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.16361;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.16361.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1"">Haochen Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1"">Yuyang Dong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1"">Chuan Xiao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Oyamada_M/0/1/0/all/0/1"">Masafumi Oyamada</a>";Haochen Zhang,Yuyang Dong,Chuan Xiao,Masafumi Oyamada;Large Language Models as Data Preprocessors;Large Language Models (LLMs), typified by OpenAI's GPT series and Meta's LLaMA variants, have marked a significant advancement in artificial intelligence. Trained on vast amounts of text data, LLMs are capable of understanding and generating human-like text across a diverse range of topics. This study expands on the applications of LLMs, exploring their potential in data preprocessing, a critical stage in data mining and analytics applications. We delve into the applicability of state-of-the-art LLMs such as GPT-3.5, GPT-4, and Vicuna-13B for error detection, data imputation, schema matching, and entity matching tasks. Alongside showcasing the inherent capabilities of LLMs, we highlight their limitations, particularly in terms of computational expense and inefficiency. We propose an LLM-based framework for data preprocessing, which integrates cutting-edge prompt engineering techniques, coupled with traditional methods like contextualization and feature selection, to improve the performance and efficiency of these models. The effectiveness of LLMs in data preprocessing is evaluated through an experimental study spanning 12 datasets. GPT-4 emerged as a standout, achieving 100\% accuracy or F1 score on 4 datasets, suggesting LLMs' immense potential in these tasks. Despite certain limitations, our study underscores the promise of LLMs in this domain and anticipates future developments to overcome current hurdles.
2023.09.02.13.14.04;02.09.2023;04;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2308.16599;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.16599.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wagner_F/0/1/0/all/0/1"">Felix Wagner</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nachtigall_F/0/1/0/all/0/1"">Florian Nachtigall</a>, <a href=""http://arxiv.org/find/cs/1/au:+Franken_L/0/1/0/all/0/1"">Lukas Franken</a>, <a href=""http://arxiv.org/find/cs/1/au:+Milojevic_Dupont_N/0/1/0/all/0/1"">Nikola Milojevic-Dupont</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pereira_R/0/1/0/all/0/1"">Rafael H.M. Pereira</a>, <a href=""http://arxiv.org/find/cs/1/au:+Koch_N/0/1/0/all/0/1"">Nicolas Koch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Runge_J/0/1/0/all/0/1"">Jakob Runge</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gonzalez_M/0/1/0/all/0/1"">Marta Gonzalez</a>, <a href=""http://arxiv.org/find/cs/1/au:+Creutzig_F/0/1/0/all/0/1"">Felix Creutzig</a>";Felix Wagner,Florian Nachtigall,Lukas Franken,Nikola Milojevic-Dupont,Rafael H.M. Pereira,Nicolas Koch,Jakob Runge,Marta Gonzalez,Felix Creutzig;A Causal Discovery Approach To Learn How Urban Form Shapes Sustainable Mobility Across Continents;Global sustainability requires low-carbon urban transport systems, shaped by adequate infrastructure, deployment of low-carbon transport modes and shifts in travel behavior. To adequately implement alterations in infrastructure, it's essential to grasp the location-specific cause-and-effect mechanisms that the constructed environment has on travel. Yet, current research falls short in representing causal relationships between the 6D urban form variables and travel, generalizing across different regions, and modeling urban form effects at high spatial resolution. Here, we address all three gaps by utilizing a causal discovery and an explainable machine learning framework to detect urban form effects on intra-city travel based on high-resolution mobility data of six cities across three continents. We show that both distance to city center, demographics and density indirectly affect other urban form features. By considering the causal relationships, we find that location-specific influences align across cities, yet vary in magnitude. In addition, the spread of the city and the coverage of jobs across the city are the strongest determinants of travel-related emissions, highlighting the benefits of compact development and associated benefits. Differences in urban form effects across the cities call for a more holistic definition of 6D measures. Our work is a starting point for location-specific analysis of urban form effects on mobility behavior using causal discovery approaches, which is highly relevant for city planners and municipalities across continents.
2023.09.02.13.14.05;02.09.2023;05;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2308.16538;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.16538.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Maple_C/0/1/0/all/0/1"">Carsten Maple</a>, <a href=""http://arxiv.org/find/cs/1/au:+Szpruch_L/0/1/0/all/0/1"">Lukasz Szpruch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Epiphaniou_G/0/1/0/all/0/1"">Gregory Epiphaniou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Staykova_K/0/1/0/all/0/1"">Kalina Staykova</a>, <a href=""http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1"">Simran Singh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Penwarden_W/0/1/0/all/0/1"">William Penwarden</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1"">Yisi Wen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"">Zijian Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hariharan_J/0/1/0/all/0/1"">Jagdish Hariharan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Avramovic_P/0/1/0/all/0/1"">Pavle Avramovic</a>";Carsten Maple,Lukasz Szpruch,Gregory Epiphaniou,Kalina Staykova,Simran Singh,William Penwarden,Yisi Wen,Zijian Wang,Jagdish Hariharan,Pavle Avramovic;The AI Revolution: Opportunities and Challenges for the Finance Sector;This report examines Artificial Intelligence (AI) in the financial sector, outlining its potential to revolutionise the industry and identify its challenges. It underscores the criticality of a well-rounded understanding of AI, its capabilities, and its implications to effectively leverage its potential while mitigating associated risks. The potential of AI potential extends from augmenting existing operations to paving the way for novel applications in the finance sector. The application of AI in the financial sector is transforming the industry. Its use spans areas from customer service enhancements, fraud detection, and risk management to credit assessments and high-frequency trading. However, along with these benefits, AI also presents several challenges. These include issues related to transparency, interpretability, fairness, accountability, and trustworthiness. The use of AI in the financial sector further raises critical questions about data privacy and security. A further issue identified in this report is the systemic risk that AI can introduce to the financial sector. Being prone to errors, AI can exacerbate existing systemic risks, potentially leading to financial crises. Regulation is crucial to harnessing the benefits of AI while mitigating its potential risks. Despite the global recognition of this need, there remains a lack of clear guidelines or legislation for AI use in finance. This report discusses key principles that could guide the formation of effective AI regulation in the financial sector, including the need for a risk-based approach, the inclusion of ethical considerations, and the importance of maintaining a balance between innovation and consumer protection. The report provides recommendations for academia, the finance industry, and regulators.
2023.09.02.13.14.06;02.09.2023;06;07;Industry;I4.0, Production et al.;arxiv;2308.13570;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.13570.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"">Dianhui Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Felicetti_M/0/1/0/all/0/1"">Matthew J. Felicetti</a>";Dianhui Wang,Matthew J. Felicetti;Stochastic Configuration Machines for Industrial Artificial Intelligence;Real-time predictive modelling with desired accuracy is highly expected in industrial artificial intelligence (IAI), where neural networks play a key role. Neural networks in IAI require powerful, high-performance computing devices to operate a large number of floating point data. Based on stochastic configuration networks (SCNs), this paper proposes a new randomized learner model, termed stochastic configuration machines (SCMs), to stress effective modelling and data size saving that are useful and valuable for industrial applications. Compared to SCNs and random vector functional-link (RVFL) nets with binarized implementation, the model storage of SCMs can be significantly compressed while retaining favourable prediction performance. Besides the architecture of the SCM learner model and its learning algorithm, as an important part of this contribution, we also provide a theoretical basis on the learning capacity of SCMs by analysing the model's complexity. Experimental studies are carried out over some benchmark datasets and three industrial applications. The results demonstrate that SCM has great potential for dealing with industrial data analytics.
2023.09.02.13.14.07;02.09.2023;07;07;Industry;I4.0, Production et al.;arxiv;2308.16259;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.16259.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1"">Hongshuo Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Magar_R/0/1/0/all/0/1"">Rishikesh Magar</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1"">Changwen Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1"">Amir Bariti Farimani</a>";Hongshuo Huang,Rishikesh Magar,Changwen Xu,Amir Bariti Farimani;Materials Informatics Transformer: A Language Model for Interpretable Materials Properties Prediction;Recently, the remarkable capabilities of large language models (LLMs) have been illustrated across a variety of research domains such as natural language processing, computer vision, and molecular modeling. We extend this paradigm by utilizing LLMs for material property prediction by introducing our model Materials Informatics Transformer (MatInFormer). Specifically, we introduce a novel approach that involves learning the grammar of crystallography through the tokenization of pertinent space group information. We further illustrate the adaptability of MatInFormer by incorporating task-specific data pertaining to Metal-Organic Frameworks (MOFs). Through attention visualization, we uncover the key features that the model prioritizes during property prediction. The effectiveness of our proposed model is empirically validated across 14 distinct datasets, hereby underscoring its potential for high throughput screening through accurate material property prediction.
2023.09.02.13.14.08;02.09.2023;08;08;Supply Chain;Supply Chains, Transportation et al.;arxiv;2104.14818;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2104.14818.pdf;" <a href=""http://arxiv.org/find/math/1/au:+Blaettchen_P/0/1/0/all/0/1"">Philippe Blaettchen</a>, <a href=""http://arxiv.org/find/math/1/au:+Calmon_A/0/1/0/all/0/1"">Andre P. Calmon</a>, <a href=""http://arxiv.org/find/math/1/au:+Hall_G/0/1/0/all/0/1"">Georgina Hall</a>";Philippe Blaettchen,Andre P. Calmon,Georgina Hall;Traceability Technology Adoption in Supply Chain Networks;Modern traceability technologies promise to improve supply chain management by simplifying recalls, increasing visibility, or verifying sustainable supplier practices. Initiatives leading the implementation of traceability technologies must choose the least-costly set of firms - or seed set - to target for early adoption. Choosing this seed set is challenging because firms are part of supply chains interlinked in complex networks, yielding an inherent supply chain effect: benefits obtained from traceability are conditional on technology adoption by a subset of firms in a product's supply chain. We prove that the problem of selecting the least-costly seed set in a supply chain network is hard to solve and even approximate within a polylogarithmic factor. Nevertheless, we provide a novel linear programming-based algorithm to identify the least-costly seed set. The algorithm is fixed-parameter tractable in the supply chain network's treewidth, which we show to be low in real-world supply chain networks. The algorithm also enables us to derive easily-computable bounds on the cost of selecting an optimal seed set. Finally, we leverage our algorithms to conduct large-scale numerical experiments that provide insights into how the supply chain network structure influences diffusion. These insights can help managers optimize their technology diffusion strategy.
2023.09.02.13.14.09;02.09.2023;09;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2305.19979;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.19979.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Gema_A/0/1/0/all/0/1"">Aryo Pradipta Gema</a>, <a href=""http://arxiv.org/find/cs/1/au:+Grabarczyk_D/0/1/0/all/0/1"">Dominik Grabarczyk</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wulf_W/0/1/0/all/0/1"">Wolf De Wulf</a>, <a href=""http://arxiv.org/find/cs/1/au:+Borole_P/0/1/0/all/0/1"">Piyush Borole</a>, <a href=""http://arxiv.org/find/cs/1/au:+Alfaro_J/0/1/0/all/0/1"">Javier Antonio Alfaro</a>, <a href=""http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1"">Pasquale Minervini</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vergari_A/0/1/0/all/0/1"">Antonio Vergari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rajan_A/0/1/0/all/0/1"">Ajitha Rajan</a>";Aryo Pradipta Gema,Dominik Grabarczyk,Wolf De Wulf,Piyush Borole,Javier Antonio Alfaro,Pasquale Minervini,Antonio Vergari,Ajitha Rajan;Knowledge Graph Embeddings in the Biomedical Domain: Are They Useful? A Look at Link Prediction, Rule Learning, and Downstream Polypharmacy Tasks;Knowledge graphs are powerful tools for representing and organising complex biomedical data. Several knowledge graph embedding algorithms have been proposed to learn from and complete knowledge graphs. However, a recent study demonstrates the limited efficacy of these embedding algorithms when applied to biomedical knowledge graphs, raising the question of whether knowledge graph embeddings have limitations in biomedical settings. This study aims to apply state-of-the-art knowledge graph embedding models in the context of a recent biomedical knowledge graph, BioKG, and evaluate their performance and potential downstream uses. We achieve a three-fold improvement in terms of performance based on the HITS@10 score over previous work on the same biomedical knowledge graph. Additionally, we provide interpretable predictions through a rule-based method. We demonstrate that knowledge graph embedding models are applicable in practice by evaluating the best-performing model on four tasks that represent real-life polypharmacy situations. Results suggest that knowledge learnt from large biomedical knowledge graphs can be transferred to such downstream use cases. Our code is available at https://github.com/aryopg/biokge.
2023.09.02.13.14.10;02.09.2023;10;12;Health;Medical, Health Care, Pharmacy et al.;arxiv;2308.16631;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.16631.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wac_M/0/1/0/all/0/1"">Marceli Wac</a>, <a href=""http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1"">Raul Santos-Rodriguez</a>, <a href=""http://arxiv.org/find/cs/1/au:+McWilliams_C/0/1/0/all/0/1"">Chris McWilliams</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bourdeaux_C/0/1/0/all/0/1"">Christopher Bourdeaux</a>";Marceli Wac,Raul Santos-Rodriguez,Chris McWilliams,Christopher Bourdeaux;Strategies for engaging clinical participants in the co-design of software for healthcare domains;Co-design is an effective method for designing software, but implementing it within the clinical setting comes with a set of unique challenges. This makes recruitment and engagement of participants difficult, which has been demonstrated in our study. Our work focused on designing and evaluating a data annotation tool, however, different types of interventions had to be carried out due to poor engagement with the study. We evaluated the effectiveness and feasibility of each of these strategies, their applicability to different stages of co-design research and discussed the barriers to participation present among participants from a clinical background.
2023.09.02.13.14.11;02.09.2023;11;99;Other;Others;acm;;http://cacm.acm.org/browse-by-subject/artificial-intelligence.rss;http://cacm.acm.org/careers/275972-scientific-discovery-in-the-age-of-artificial-intelligence;Communications of the ACM: Artificial Intelligence;Communications of the ACM: Artificial Intelligence;Scientific Discovery In the Age of Artificial Intelligence;Artificial intelligence is being increasingly integrated into scientific discovery to augment and accelerate research, helping scientists to generate hypotheses, design experiments, collect and interpret large datasets, and gain insights that might not have been possible using traditional scientific methods alone.
2023.09.01.17.34.01;01.09.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.16060;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.16060.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Staniek_M/0/1/0/all/0/1"">Michael Staniek</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schumann_R/0/1/0/all/0/1"">Raphael Schumann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zufle_M/0/1/0/all/0/1"">Maike Z&#xfc;fle</a>, <a href=""http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1"">Stefan Riezler</a>";Michael Staniek,Raphael Schumann,Maike Züfle,Stefan Riezler;Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap;We present Text-to-OverpassQL, a task designed to facilitate a natural language interface for querying geodata from OpenStreetMap (OSM). The Overpass Query Language (OverpassQL) allows users to formulate complex database queries and is widely adopted in the OSM ecosystem. Generating Overpass queries from natural language input serves multiple use-cases. It enables novice users to utilize OverpassQL without prior knowledge, assists experienced users with crafting advanced queries, and enables tool-augmented large language models to access information stored in the OSM database. In order to assess the performance of current sequence generation models on this task, we propose OverpassNL, a dataset of 8,352 queries with corresponding natural language inputs. We further introduce task specific evaluation metrics and ground the evaluation of the Text-to-OverpassQL task by executing the queries against the OSM database. We establish strong baselines by finetuning sequence-to-sequence models and adapting large language models with in-context examples. The detailed evaluation reveals strengths and weaknesses of the considered learning strategies, laying the foundations for further research into the Text-to-OverpassQL task.
2023.09.01.17.34.02;01.09.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.15645;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15645.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Okuda_K/0/1/0/all/0/1"">Katsumi Okuda</a>, <a href=""http://arxiv.org/find/cs/1/au:+Amarasinghe_S/0/1/0/all/0/1"">Saman Amarasinghe</a>";Katsumi Okuda,Saman Amarasinghe;AskIt: Unified Programming Interface for Programming with Large Language Models;In the evolving landscape of software development, Large Language Models (LLMs) exhibit a unique phenomenon known as emergent abilities, demonstrating adeptness across numerous tasks, from text summarization to code generation. While these abilities open up novel avenues in software design and crafting, their incorporation presents substantial challenges. Developers grapple with decisions surrounding the direct embedding of LLMs within applications versus employing them for code generation. Moreover, effective prompt design becomes a critical concern, given the necessity of data extraction from natural language outputs. To address these intricacies, this paper introduces AskIt, a domain-specific language (DSL) specifically designed for LLMs. AskIt simplifies LLM integration, offering type-guided output control, template-based function definitions, and a unified interface that diminishes the distinction between LLM-based code generation and application integration. Furthermore, through Programming by Example (PBE), AskIt harnesses the power of few-shot learning at the programming language level. Our evaluations underscore AskIt's potency. Across 50 tasks, AskIt generated concise prompts for the given tasks, achieving a 16.14% reduction in prompt length relative to benchmarks. Additionally, by enabling the transition from direct LLM application usage to function generation, AskIt achieved significant speedups, as observed in our GSM8K benchmark experiments. Through these advancements, AskIt streamlines the integration of LLMs in software development, offering a more efficient, versatile approach for leveraging emergent abilities. The implementations of AskIt in TypeScript and Python are available at https://github.com/katsumiok/ts-askit and https://github.com/katsumiok/pyaskit, respectively.
2023.09.01.17.34.03;01.09.2023;03;02;Energy;Electricity, Smart Grid et al.;arxiv;2308.16105;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.16105.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1"">Siavash Hosseini</a>, <a href=""http://arxiv.org/find/cs/1/au:+Akilan_T/0/1/0/all/0/1"">Thangarajah Akilan</a>";Siavash Hosseini,Thangarajah Akilan;Advanced Deep Regression Models for Forecasting Time Series Oil Production;Global oil demand is rapidly increasing and is expected to reach 106.3 million barrels per day by 2040. Thus, it is vital for hydrocarbon extraction industries to forecast their production to optimize their operations and avoid losses. Big companies have realized that exploiting the power of deep learning (DL) and the massive amount of data from various oil wells for this purpose can save a lot of operational costs and reduce unwanted environmental impacts. In this direction, researchers have proposed models using conventional machine learning (ML) techniques for oil production forecasting. However, these techniques are inappropriate for this problem as they can not capture historical patterns found in time series data, resulting in inaccurate predictions. This research aims to overcome these issues by developing advanced data-driven regression models using sequential convolutions and long short-term memory (LSTM) units. Exhaustive analyses are conducted to select the optimal sequence length, model hyperparameters, and cross-well dataset formation to build highly generalized robust models. A comprehensive experimental study on Volve oilfield data validates the proposed models. It reveals that the LSTM-based sequence learning model can predict oil production better than the 1-D convolutional neural network (CNN) with mean absolute error (MAE) and R2 score of 111.16 and 0.98, respectively. It is also found that the LSTM-based model performs better than all the existing state-of-the-art solutions and achieves a 37% improvement compared to a standard linear regression, which is considered the baseline model in this work.
2023.09.01.17.34.04;01.09.2023;04;02;Energy;Electricity, Smart Grid et al.;arxiv;2308.15806;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15806.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Mejia_Ruiz_G/0/1/0/all/0/1"">Gabriel E. Mejia-Ruiz</a>, <a href=""http://arxiv.org/find/eess/1/au:+Batmani_Y/0/1/0/all/0/1"">Yazdan Batmani</a>, <a href=""http://arxiv.org/find/eess/1/au:+Lakshminarayana_S/0/1/0/all/0/1"">Subhash Lakshminarayana</a>, <a href=""http://arxiv.org/find/eess/1/au:+Ahmed_S/0/1/0/all/0/1"">Shehab Ahmed</a>, <a href=""http://arxiv.org/find/eess/1/au:+Konstantinou_C/0/1/0/all/0/1"">Charalambos Konstantinou</a>";Gabriel E. Mejia-Ruiz,Yazdan Batmani,Subhash Lakshminarayana,Shehab Ahmed,Charalambos Konstantinou;Communication Reduction for Power Systems: An Observer-Based Event-Triggered Approach;The management of distributed and heterogeneous modern power networks necessitates the deployment of communication links, often characterized by limited bandwidth. This paper presents an event detection mechanism that significantly reduces the volume of data transmission to perform necessary control actions, using a scalable scheme that enhances the stability and reliability of power grids. The approach relies on implementing a linear quadratic regulator and the execution of a pair of Luenberger observers. The linear quadratic regulator minimizes the amount of energy required to achieve the control actions. Meanwhile, the Luenberger observers estimate the unmeasured states from the sensed states, providing the necessary information to trigger the event detection mechanism. The effectiveness of the method is tested via time-domain simulations on the IEEE 13-node test feeder interfaced with inverter-based distributed generation systems and the proposed observed-based event-triggered controller. The results demonstrate that the presented control scheme guarantees the bounding of the system states to a pre-specified limit while reducing the number of data packet transmissions by 39.8%.
2023.09.01.17.34.05;01.09.2023;05;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2308.15992;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15992.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1"">Bingqiao Luo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1"">Zhen Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1"">Qian Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ke_A/0/1/0/all/0/1"">Anli Ke</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1"">Shengliang Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1"">Bingsheng He</a>";Bingqiao Luo,Zhen Zhang,Qian Wang,Anli Ke,Shengliang Lu,Bingsheng He;AI-powered Fraud Detection in Decentralized Finance: A Project Life Cycle Perspective;In recent years, blockchain technology has introduced decentralized finance (DeFi) as an alternative to traditional financial systems. DeFi aims to create a transparent and efficient financial ecosystem using smart contracts and emerging decentralized applications. However, the growing popularity of DeFi has made it a target for fraudulent activities, resulting in losses of billions of dollars due to various types of frauds. To address these issues, researchers have explored the potential of artificial intelligence (AI) approaches to detect such fraudulent activities. Yet, there is a lack of a systematic survey to organize and summarize those existing works and to identify the future research opportunities. In this survey, we provide a systematic taxonomy of various frauds in the DeFi ecosystem, categorized by the different stages of a DeFi project's life cycle: project development, introduction, growth, maturity, and decline. This taxonomy is based on our finding: many frauds have strong correlations in the stage of the DeFi project. According to the taxonomy, we review existing AI-powered detection methods, including statistical modeling, natural language processing and other machine learning techniques, etc. We find that fraud detection in different stages employs distinct types of methods and observe the commendable performance of tree-based and graph-related models in tackling fraud detection tasks. By analyzing the challenges and trends, we present the findings to provide proactive suggestion and guide future research in DeFi fraud detection. We believe that this survey is able to support researchers, practitioners, and regulators in establishing a secure and trustworthy DeFi ecosystem.
2023.09.01.17.34.06;01.09.2023;06;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2308.15813;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15813.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Colas_A/0/1/0/all/0/1"">Anthony Colas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Araki_J/0/1/0/all/0/1"">Jun Araki</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1"">Zhengyu Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1"">Bingqing Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1"">Zhe Feng</a>";Anthony Colas,Jun Araki,Zhengyu Zhou,Bingqing Wang,Zhe Feng;Knowledge-grounded Natural Language Recommendation Explanation;Explanations accompanied by a recommendation can assist users in understanding the decision made by recommendation systems, which in turn increases a user's confidence and trust in the system. Recently, research has focused on generating natural language explanations in a human-readable format. Thus far, the proposed approaches leverage item reviews written by users, which are often subjective, sparse in language, and unable to account for new items that have not been purchased or reviewed before. Instead, we aim to generate fact-grounded recommendation explanations that are objectively described with item features while implicitly considering a user's preferences, based on the user's purchase history. To achieve this, we propose a knowledge graph (KG) approach to natural language explainable recommendation. Our approach draws on user-item features through a novel collaborative filtering-based KG representation to produce fact-grounded, personalized explanations, while jointly learning user-item representations for recommendation scoring. Experimental results show that our approach consistently outperforms previous state-of-the-art models on natural language explainable recommendation.
2023.09.01.17.34.07;01.09.2023;07;16;Human Resource;Human Resource et al.;repec;;http://nep.repec.org/rss/nep-gth.rss.xml;http://d.repec.org/n?u=RePEc:ukc:ukcedp:2302&r=gth;Nizar AllouchLuis A.GuardiolaA. Meca;Nizar AllouchLuis A.GuardiolaA. Meca;Measuring productivity in networks: A game-theoretic approach;Measuring individual productivity (or equivalently distributing the overall productivity) in a network structure of workers displaying peer effects has been a subject of ongoing interest in many areas ranging from academia to industry. In this paper, we propose a novel approach based on cooperative game theory that takes into account the peer effects of worker productivity represented by a complete bipartite network of in- teractions. More specifically, we construct a series of cooperative games where the characteristic function of each coalition of workers is equal to the sum of each worker intrinsic productivity as well as the productivity of other workers within a distance discounted by an attenuation factor. We show that these (truncated) games are balanced and converge to a balanced game when the distance of influence grows large. We then provide an explicit formula for the Shapley value and propose an alternative coalitionally stable distribution of productivity which is computationally much more tractable than the Shapley value. Lastly, we characterize this alternative distribution based on three sensible properties of a logistic network. This analysis enhances our understanding of game-theoretic analysis within logistics networks, offering valuable insights into the peer effects’ impact when assessing the overall productivity and its distribution among workers.
2023.09.01.17.34.08;01.09.2023;08;16;Human Resource;Human Resource et al.;arxiv;2303.06701;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2303.06701.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Boerma_J/0/1/0/all/0/1"">Job Boerma</a>, <a href=""http://arxiv.org/find/econ/1/au:+Tsyvinski_A/0/1/0/all/0/1"">Aleh Tsyvinski</a>, <a href=""http://arxiv.org/find/econ/1/au:+Wang_R/0/1/0/all/0/1"">Ruodu Wang</a>, <a href=""http://arxiv.org/find/econ/1/au:+Zhang_Z/0/1/0/all/0/1"">Zhenyuan Zhang</a>";Job Boerma,Aleh Tsyvinski,Ruodu Wang,Zhenyuan Zhang;Composite Sorting;We propose a new sorting framework: composite sorting. Composite sorting comprises of (1) distinct worker types assigned to the same occupation, and (2) a given worker type simultaneously being part of both positive and negative sorting. Composite sorting arises when fixed investments mitigate variable costs of mismatch. We completely characterize optimal sorting and additionally show it is more positive when mismatch costs are less concave. We then characterize equilibrium wages. Wages have a regional hierarchical structure - relative wages depend solely on sorting within skill groups. Quantitatively, composite sorting can generate a sizable portion of within-occupations wage dispersion in the US.
2023.09.01.17.34.09;01.09.2023;09;99;Other;Others;arxiv;2308.15517;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15517.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Kastanas_S/0/1/0/all/0/1"">Sotirios Kastanas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1"">Shaomu Tan</a>, <a href=""http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1"">Yi He</a>";Sotirios Kastanas,Shaomu Tan,Yi He;Document AI: A Comparative Study of Transformer-Based, Graph-Based Models, and Convolutional Neural Networks For Document Layout Analysis;Document AI aims to automatically analyze documents by leveraging natural language processing and computer vision techniques. One of the major tasks of Document AI is document layout analysis, which structures document pages by interpreting the content and spatial relationships of layout, image, and text. This task can be image-centric, wherein the aim is to identify and label various regions such as authors and paragraphs, or text-centric, where the focus is on classifying individual words in a document. Although there are increasingly sophisticated methods for improving layout analysis, doubts remain about the extent to which their findings can be generalized to a broader context. Specifically, prior work developed systems based on very different architectures, such as transformer-based, graph-based, and CNNs. However, no work has mentioned the effectiveness of these models in a comparative analysis. Moreover, while language-independent Document AI models capable of knowledge transfer have been developed, it remains to be investigated to what degree they can effectively transfer knowledge. In this study, we aim to fill these gaps by conducting a comparative evaluation of state-of-the-art models in document layout analysis and investigating the potential of cross-lingual layout analysis by utilizing machine translation techniques.
2023.08.31.13.07.01;31.08.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:ces:ceswps:_10529&r=cmp;Christian FiebergLars HornufDavid J. Streich;Christian FiebergLars HornufDavid J. Streich;Using GPT-4 for Financial Advice;We show that the recently released text-based artificial intelligence tool GPT-4 can provide suitable financial advice. The tool suggests specific investment portfolios that reflect an investor’s individual circumstances such as risk tolerance, risk capacity, and sustainability preference. Notably, while the suggested portfolios display home bias and are rather insensitive to the investment horizon, historical risk-adjusted performance is on par with a professionally managed benchmark portfolio. Given the current inability of GPT-4 to provide full-service financial advice, it may be used by financial advisors as a back-office tool for portfolio recommendation.
2023.08.31.13.07.02;31.08.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:zbw:rpaebs:62023&r=cmp;Hacker, Bernd;Hacker, Bernd;Will ChatGPT revolutionize accounting? The benefits of Artificial Intelligence (AI) in accounting;It's an experiment! This paper explores how ChatGPT can be used in accounting and reporting to automate routine tasks, increase efficiency, and better understand financial data. The creation of the paper itself was done with the help of ChatGPT, i.e., significant parts of this text were created by the AI and then edited and completed by the author in terms of content and language. On the one hand, this is intended to show the potential of the application in practice and to make it clear that dealing with the tools of AI will be indispensable in the future, but on the other hand, the risks and concerns are also addressed.
2023.08.31.13.07.03;31.08.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.14120;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.14120.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Arasteh_S/0/1/0/all/0/1"">Soroosh Tayebi Arasteh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1"">Tianyu Han</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lotfinia_M/0/1/0/all/0/1"">Mahshad Lotfinia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kuhl_C/0/1/0/all/0/1"">Christiane Kuhl</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kather_J/0/1/0/all/0/1"">Jakob Nikolas Kather</a>, <a href=""http://arxiv.org/find/cs/1/au:+Truhn_D/0/1/0/all/0/1"">Daniel Truhn</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nebelung_S/0/1/0/all/0/1"">Sven Nebelung</a>";Soroosh Tayebi Arasteh,Tianyu Han,Mahshad Lotfinia,Christiane Kuhl,Jakob Nikolas Kather,Daniel Truhn,Sven Nebelung;Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies;A knowledge gap persists between Machine Learning (ML) developers (e.g., data scientists) and practitioners (e.g., clinicians), hampering the full utilization of ML for clinical data analysis. We investigated the potential of the chatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this gap and perform ML analyses efficiently. Real-world clinical datasets and study details from large trials across various medical specialties were presented to chatGPT ADA without specific guidance. ChatGPT ADA autonomously developed state-of-the-art ML models based on the original study's training data to predict clinical outcomes such as cancer development, cancer progression, disease complications, or biomarkers such as pathogenic gene sequences. Strikingly, these ML models matched or outperformed their published counterparts. We conclude that chatGPT ADA offers a promising avenue to democratize ML in medicine, making advanced analytics accessible to non-ML experts and promoting broader applications in medical research and practice.
2023.08.31.13.07.04;31.08.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.14641;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.14641.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lechner_F/0/1/0/all/0/1"">Fabian Lechner</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lahnala_A/0/1/0/all/0/1"">Allison Lahnala</a>, <a href=""http://arxiv.org/find/cs/1/au:+Welch_C/0/1/0/all/0/1"">Charles Welch</a>, <a href=""http://arxiv.org/find/cs/1/au:+Flek_L/0/1/0/all/0/1"">Lucie Flek</a>";Fabian Lechner,Allison Lahnala,Charles Welch,Lucie Flek;Challenges of GPT-3-based Conversational Agents for Healthcare;The potential to provide patients with faster information access while allowing medical specialists to concentrate on critical tasks makes medical domain dialog agents appealing. However, the integration of large-language models (LLMs) into these agents presents certain limitations that may result in serious consequences. This paper investigates the challenges and risks of using GPT-3-based models for medical question-answering (MedQA). We perform several evaluations contextualized in terms of standard medical principles. We provide a procedure for manually designing patient queries to stress-test high-risk limitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail to respond adequately to these queries, generating erroneous medical information, unsafe recommendations, and content that may be considered offensive.
2023.08.31.13.07.05;31.08.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.15231;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15231.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Addlesee_A/0/1/0/all/0/1"">Angus Addlesee</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sieinska_W/0/1/0/all/0/1"">Weronika Siei&#x144;ska</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gunson_N/0/1/0/all/0/1"">Nancie Gunson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Garcia_D/0/1/0/all/0/1"">Daniel Hern&#xe1;ndez Garcia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dondrup_C/0/1/0/all/0/1"">Christian Dondrup</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lemon_O/0/1/0/all/0/1"">Oliver Lemon</a>";"Angus Addlesee,Weronika Siei&#x144;ska,Nancie Gunson,Daniel Hernández Garcia,Christian Dondrup,Oliver Lemon";Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering;This paper evaluates the extent to which current Large Language Models (LLMs) can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The `reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annotated 62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition MPCs. A `story' style prompt increased model hallucination, which could be detrimental if deployed in safety-critical settings. We conclude that multi-party conversations still challenge state-of-the-art LLMs.
2023.08.31.13.07.06;31.08.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.15272;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15272.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1"">Hao Wen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"">Yuanchun Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1"">Guohong Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1"">Shanhui Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1"">Tao Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1"">Toby Jia-Jun Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1"">Shiqi Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Yunhao Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yaqin Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Yunxin Liu</a>";Hao Wen,Yuanchun Li,Guohong Liu,Shanhui Zhao,Tao Yu,Toby Jia-Jun Li,Shiqi Jiang,Yunhao Liu,Yaqin Zhang,Yunxin Liu;Empowering LLM to use Smartphone for Intelligent Task Automation;Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or end-users. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system that can handle arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection techniques that augment the app-specific domain knowledge of LLM, and a multi-granularity query optimization module that reduces the cost of model inference. We integrate AutoDroid with off-the-shelf LLMs including online GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a new benchmark for memory-augmented Android task automation with 158 common tasks. The results demonstrated that AutoDroid is able to precisely generate actions with an accuracy of 90.9%, and complete tasks with a success rate of 71.3%, outperforming the GPT-4-powered baselines by 36.4% and 39.7%. The demo, benchmark suites, and source code of AutoDroid will be released at https://autodroid-sys.github.io/.
2023.08.31.13.07.07;31.08.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.15276;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15276.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1"">Yonghao Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Zheng Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"">Jie M. Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Papadakis_M/0/1/0/all/0/1"">Mike Papadakis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Harman_M/0/1/0/all/0/1"">Mark Harman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1"">Yong Liu</a>";Yonghao Wu,Zheng Li,Jie M. Zhang,Mike Papadakis,Mark Harman,Yong Liu;Large Language Models in Fault Localisation;Large Language Models (LLMs) have shown promise in multiple software engineering tasks including code generation, code summarisation, test generation and code repair. Fault localisation is essential for facilitating automatic program debugging and repair, and is demonstrated as a highlight at ChatGPT-4's launch event. Nevertheless, there has been little work understanding LLMs' capabilities for fault localisation in large-scale open-source programs. To fill this gap, this paper presents an in-depth investigation into the capability of ChatGPT-3.5 and ChatGPT-4, the two state-of-the-art LLMs, on fault localisation. Using the widely-adopted Defects4J dataset, we compare the two LLMs with the existing fault localisation techniques. We also investigate the stability and explanation of LLMs in fault localisation, as well as how prompt engineering and the length of code context affect the fault localisation effectiveness. Our findings demonstrate that within a limited code context, ChatGPT-4 outperforms all the existing fault localisation methods. Additional error logs can further improve ChatGPT models' localisation accuracy and stability, with an average 46.9% higher accuracy over the state-of-the-art baseline SmartFL in terms of TOP-1 metric. However, performance declines dramatically when the code context expands to the class-level, with ChatGPT models' effectiveness becoming inferior to the existing methods overall. Additionally, we observe that ChatGPT's explainability is unsatisfactory, with an accuracy rate of only approximately 30%. These observations demonstrate that while ChatGPT can achieve effective fault localisation performance under certain conditions, evident limitations exist. Further research is imperative to fully harness the potential of LLMs like ChatGPT for practical fault localisation applications.
2023.08.31.13.07.08;31.08.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.15022;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15022.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1"">Qingyue Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1"">Liang Ding</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"">Yanan Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1"">Zhiliang Tian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Shi Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1"">Dacheng Tao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1"">Li Guo</a>";Qingyue Wang,Liang Ding,Yanan Cao,Zhiliang Tian,Shi Wang,Dacheng Tao,Li Guo;Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models;Most open-domain dialogue systems suffer from forgetting important information, especially in a long-term conversation. Existing works usually train the specific retriever or summarizer to obtain key information from the past, which is time-consuming and highly depends on the quality of labeled data. To alleviate this problem, we propose to recursively generate summaries/ memory using large language models (LLMs) to enhance long-term memory ability. Specifically, our method first stimulates LLMs to memorize small dialogue contexts and then recursively produce new memory using previous memory and following contexts. Finally, the LLM can easily generate a highly consistent response with the help of the latest memory. We evaluate our method using ChatGPT and text-davinci-003, and the experiments on the widely-used public dataset show that our method can generate more consistent responses in a long-context conversation. Notably, our method is a potential solution to enable the LLM to model the extremely long context. Code and scripts will be released later.
2023.08.31.13.07.09;31.08.2023;09;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.2016/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Anomaly Detection in Power System State Estimation: Review and New Directions;Foundational and state-of-the-art anomaly detection methods through power system state estimation are reviewed. The traditional components for bad data detection such as chi-square testing, residual-based methods, and hypothesis testing are discussed to explain the motivations for recent anomaly detection methods given the increasing complexity of power grids, energy management systems, and cyber-threats. In particular, state estimation anomaly detection based on data-driven quickest change detection and artificial intelligence are discussed and directions for research are suggested with particular emphasis on considerations of the future smart grid.
2023.08.31.13.07.10;31.08.2023;10;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.2060/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Efficient Demand Side Management Using a Novel Decentralized Building Automation Algorithm;Τhe building automation control is a crucial factor for improving buildings energy efficiency and management, as well as improving the electricity grid's reliability indices. This paper presents the methodology, describes the necessary technology requirements and presents the decentralized building automation novel algorithm for Efficient demand side management in a building. All these are applied in an experimental university microgrid and the results are presented in terms of energy saving in kWh, money in € and working hours.
2023.08.31.13.07.11;31.08.2023;11;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.2119/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Renewable Energy Integration for Power Outage Mitigation: A Data-Driven Approach in Advancing Grid Resilience Strategies;This article presents a comprehensive study on enhancing grid resilience through advanced forecasting and optimization techniques in the context of power outages. Power outages pose significant challenges to modern societies, affecting various sectors such as industries, households, and critical infrastructures. The research combines statistical analysis, machine learning algorithms, and optimization methods to address this issue to develop a holistic approach for predicting and mitigating power outage events. The proposed methodology involves the use of Monte Carlo simulations in MATLAB for future outage prediction, Long Short-Term Memory (LSTM) networks for forecasting solar irradiance and load profiles, and a hybrid LSTM-Particle Swarm Optimization (PSO) model to improve accuracy. Furthermore, the role of Battery State of Charge (SoC) in enhancing system resilience is explored. The study also assesses the techno-economic advantages of a grid-tied microgrid integrated with solar panels and batteries over conventional grid systems. The results highlight the potential of the proposed approach in strengthening grid resilience, reducing downtime, and fostering sustainable energy utilization.
2023.08.31.13.07.12;31.08.2023;12;04;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:nbr:nberwo:31502&r=cmp;Bryan T. KellyDacheng Xiu;Bryan T. KellyDacheng Xiu;Financial Machine Learning;We survey the nascent literature on machine learning in the study of financial markets. We highlight the best examples of what this line of research has to offer and recommend promising directions for future research. This survey is designed for both financial economists interested in grasping machine learning tools, as well as for statisticians and machine learners seeking interesting financial contexts where advanced methods may be deployed.
2023.08.31.13.07.13;31.08.2023;13;04;Finance;Finance, DeFi, Insurance, Banking et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2306.16422&r=big;Ariel NeufeldJulian Sester;Ariel NeufeldJulian Sester;Neural networks can detect model-free static arbitrage strategies;In this paper we demonstrate both theoretically as well as numerically that neural networks can detect model-free static arbitrage opportunities whenever the market admits some. Due to the use of neural networks, our method can be applied to financial markets with a high number of traded securities and ensures almost immediate execution of the corresponding trading strategies. To demonstrate its tractability, effectiveness, and robustness we provide examples using real financial data. From a technical point of view, we prove that a single neural network can approximately solve a class of convex semi-infinite programs, which is the key result in order to derive our theoretical results that neural networks can detect model-free static arbitrage strategies whenever the financial market admits such opportunities.
2023.08.31.13.07.14;31.08.2023;14;07;Industry;I4.0, Production et al.;arxiv;2308.15366;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.15366.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1"">Zhaopeng Gu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1"">Bingke Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1"">Guibo Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1"">Yingying Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1"">Ming Tang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Jinqiao Wang</a>";Zhaopeng Gu,Bingke Zhu,Guibo Zhu,Yingying Chen,Ming Tang,Jinqiao Wang;AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language Models;Large Vision-Language Models (LVLMs) such as MiniGPT-4 and LLaVA have demonstrated the capability of understanding images and achieved remarkable performance in various visual tasks. Despite their strong abilities in recognizing common objects due to extensive training datasets, they lack specific domain knowledge and have a weaker understanding of localized details within objects, which hinders their effectiveness in the Industrial Anomaly Detection (IAD) task. On the other hand, most existing IAD methods only provide anomaly scores and necessitate the manual setting of thresholds to distinguish between normal and abnormal samples, which restricts their practical implementation. In this paper, we explore the utilization of LVLM to address the IAD problem and propose AnomalyGPT, a novel IAD approach based on LVLM. We generate training data by simulating anomalous images and producing corresponding textual descriptions for each image. We also employ an image decoder to provide fine-grained semantic and design a prompt learner to fine-tune the LVLM using prompt embeddings. Our AnomalyGPT eliminates the need for manual threshold adjustments, thus directly assesses the presence and locations of anomalies. Additionally, AnomalyGPT supports multi-turn dialogues and exhibits impressive few-shot in-context learning capabilities. With only one normal shot, AnomalyGPT achieves the state-of-the-art performance with an accuracy of 86.1%, an image-level AUC of 94.1%, and a pixel-level AUC of 95.3% on the MVTec-AD dataset. Code is available at https://github.com/CASIA-IVA-Lab/AnomalyGPT.
2023.08.31.13.07.15;31.08.2023;15;07;Industry;I4.0, Production et al.;arxiv;2206.07785;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2206.07785.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1"">Shashi Raj Pandey</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pinson_P/0/1/0/all/0/1"">Pierre Pinson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Popovski_P/0/1/0/all/0/1"">Petar Popovski</a>";Shashi Raj Pandey,Pierre Pinson,Petar Popovski;Strategic Coalition for Data Pricing in IoT Data Markets;"This paper considers a market for trading Internet of Things (IoT) data that is used to train machine learning models. The data, either raw or processed, is supplied to the market platform through a network and the price of such data is controlled based on the value it brings to the machine learning model. We explore the correlation property of data in a game-theoretical setting to eventually derive a simplified distributed solution for a data trading mechanism that emphasizes the mutual benefit of devices and the market. The key proposal is an efficient algorithm for markets that jointly addresses the challenges of availability and heterogeneity in participation, as well as the transfer of trust and the economic value of data exchange in IoT networks. The proposed approach establishes the data market by reinforcing collaboration opportunities between device with correlated data to avoid information leakage. Therein, we develop a network-wide optimization problem that maximizes the social value of coalition among the IoT devices of similar data types; at the same time, it minimizes the cost due to network externalities, i.e., the impact of information leakage due to data correlation, as well as the opportunity costs. Finally, we reveal the structure of the formulated problem as a distributed coalition game and solve it following the simplified split-and-merge algorithm. Simulation results show the efficacy of our proposed mechanism design toward a trusted IoT data market, with up to 32.72% gain in the average payoff for each seller."
2023.08.31.13.07.16;31.08.2023;16;09;Commerce;Commerce, Trading, Sales, Retail et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Smart_Contracts_as_a_tool_for_small_and_midsized_companies/24005568;TechRxiv RSS Feed;TechRxiv RSS Feed;Smart Contracts as a tool for small and midsized companies;Smart Contracts are a technology that leverages blockchain to automate and secure transactions. They are commonly used to manage transaction fees and mining rewards within blockchain networks, and can be programmed to execute automated transactions based on predetermined conditions. The use of smart contracts offers numerous benefits for small and medium-sized enterprises, including reduced transaction costs, improved transparency and accountability, and enhanced security and efficiency. The deployment of smart contracts in a company can also lead to increased automation of transactions, further streamlining processes and reducing the potential for human error.
2023.08.31.13.07.17;31.08.2023;17;09;Commerce;Commerce, Trading, Sales, Retail et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Sales_Forecasting_Based_on_Ensemble_Learning/24049452;TechRxiv RSS Feed;TechRxiv RSS Feed;Sales Forecasting Based on Ensemble Learning;Sales forecasting is the process of estimating future sales revenue for a given time period. It is an essential business function that helps organizations make informed decisions about future investments, production planning, and resource allocation. Sales forecasting is a vital process for businesses that want to plan, budget, invest, evaluate performance, and gain a competitive advantage It's important to note that some degree of uncertainty is always present and no algorithm can work perfectly for sales forecasting. However, by using a combination of methods and regularly reviewing and adjusting forecasts, organizations can make more accurate sales predictions and make better-informed business decisions. Our goal through this project is to compare performance of various models for sales forecasting and also try out an ensemble approach as well to see if the efficiency and accuracy of the model can be get better as compared to the singular models. For a dataset of the size of the Walmart data set, it is very important to choose the best algorithm which not only shows accuracy but efficiency as well. There are various machine learning models that can be used for sales prediction, including linear regression, decision trees, random forests, gradient boosting, neural networks, and support vector machines. We need to consider the strengths and weaknesses of each model and select the one that best fits the characteristics of the data and the problem we want to solve. The models that will be implementing for this study are XGBoost, LGBM and Catboost. These are gradient boosting models and extremely suitable for large datasets with regression which use regression techniques. Catboost uses symmetric trees while XGBoost and LGBM use asymmetric trees where XGBoost grows level wise and LGBM grows leaf wise. All three models have their own advantages which we need to utilize and see how much better the accuracy can be made. Among the three XGBoost has the advantage of flexibility and scalability, and can also be customized to fit the best hyper parameters. LGBM is the best when it comes to memory efficiency as well as the overall efficiency of the model. However we expect CatBoost which is a special version of GBDT to have the overall best accuracy. The performance of a machine learning model must be evaluated using appropriate metrics such as mean absolute error, mean squared error, root mean squared error, R-squared, and others. To utilize all the models and to try to reach the full potential of each model we will also implement a hybrid ensemble model in the form of a voting regressor. This helps remove any biases that the individual models may have and to enhance the overall performance of the model. For the voting regressor we will be using MAE values of each model to assign scores.
2023.08.29.16.06.01;29.08.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.14634;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2308.14634.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Loukas_L/0/1/0/all/0/1"">Lefteris Loukas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Stogiannidis_I/0/1/0/all/0/1"">Ilias Stogiannidis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Malakasiotis_P/0/1/0/all/0/1"">Prodromos Malakasiotis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vassos_S/0/1/0/all/0/1"">Stavros Vassos</a>";Lefteris Loukas,Ilias Stogiannidis,Prodromos Malakasiotis,Stavros Vassos;Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance;We propose the use of conversational GPT models for easy and quick few-shot text classification in the financial domain using the Banking77 dataset. Our approach involves in-context learning with GPT-3.5 and GPT-4, which minimizes the technical expertise required and eliminates the need for expensive GPU computing while yielding quick and accurate results. Additionally, we fine-tune other pre-trained, masked language models with SetFit, a recent contrastive learning technique, to achieve state-of-the-art results both in full-data and few-shot settings. Our findings show that querying GPT-3.5 and GPT-4 can outperform fine-tuned, non-generative models even with fewer examples. However, subscription fees associated with these solutions may be considered costly for small organizations. Lastly, we find that generative models perform better on the given task when shown representative samples selected by a human expert rather than when shown random ones. We conclude that a) our proposed methods offer a practical solution for few-shot tasks in datasets with limited label availability, and b) our state-of-the-art results can inspire future work in the area.
2023.08.29.16.06.02;29.08.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2304.09179;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2304.09179.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1"">Dhruvesh Patel</a>, <a href=""http://arxiv.org/find/cs/1/au:+Eghbalzadeh_H/0/1/0/all/0/1"">Hamid Eghbalzadeh</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kamra_N/0/1/0/all/0/1"">Nitin Kamra</a>, <a href=""http://arxiv.org/find/cs/1/au:+Iuzzolino_M/0/1/0/all/0/1"">Michael Louis Iuzzolino</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jain_U/0/1/0/all/0/1"">Unnat Jain</a>, <a href=""http://arxiv.org/find/cs/1/au:+Desai_R/0/1/0/all/0/1"">Ruta Desai</a>";Dhruvesh Patel,Hamid Eghbalzadeh,Nitin Kamra,Michael Louis Iuzzolino,Unnat Jain,Ruta Desai;Pretrained Language Models as Visual Planners for Human Assistance;"In our pursuit of advancing multi-modal AI assistants capable of guiding users to achieve complex multi-step goals, we propose the task of ""Visual Planning for Assistance (VPA)"". Given a succinct natural language goal, e.g., ""make a shelf"", and a video of the user's progress so far, the aim of VPA is to devise a plan, i.e., a sequence of actions such as ""sand shelf"", ""paint shelf"", etc. to realize the specified goal. This requires assessing the user's progress from the (untrimmed) video, and relating it to the requirements of natural language goal, i.e., which actions to select and in what order? Consequently, this requires handling long video history and arbitrarily complex action dependencies. To address these challenges, we decompose VPA into video action segmentation and forecasting. Importantly, we experiment by formulating the forecasting step as a multi-modal sequence modeling problem, allowing us to leverage the strength of pre-trained LMs (as the sequence model). This novel approach, which we call Visual Language Model based Planner (VLaMP), outperforms baselines across a suite of metrics that gauge the quality of the generated plans. Furthermore, through comprehensive ablations, we also isolate the value of each component--language pre-training, visual observations, and goal information. We have open-sourced all the data, model checkpoints, and training code."
2023.08.29.16.06.03;29.08.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2306.06624;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.06624.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1"">Yifan Song</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1"">Weimin Xiong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1"">Dawei Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1"">Wenhao Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1"">Han Qian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1"">Mingbo Song</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1"">Hailiang Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"">Cheng Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1"">Ke Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yao_R/0/1/0/all/0/1"">Rong Yao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1"">Ye Tian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1"">Sujian Li</a>";Yifan Song,Weimin Xiong,Dawei Zhu,Wenhao Wu,Han Qian,Mingbo Song,Hailiang Huang,Cheng Li,Ke Wang,Rong Yao,Ye Tian,Sujian Li;RestGPT: Connecting Large Language Models with Real-World RESTful APIs;Tool-augmented large language models (LLMs) have achieved remarkable progress in tackling a broad range of tasks. However, existing methods are mainly restricted to specifically designed tools and fail to fulfill complex instructions, having great limitations when confronted with real-world scenarios. In this paper, we explore a more realistic scenario by connecting LLMs with RESTful APIs, which adhere to the widely adopted REST software architectural style for web service development. To address the practical challenges of tackling complex instructions, we propose RestGPT, which exploits the power of LLMs and conducts a coarse-to-fine online planning mechanism to enhance the abilities of task decomposition and API selection. RestGPT also contains an API executor tailored for calling RESTful APIs, which can meticulously formulate parameters and parse API responses. To fully evaluate the performance of RestGPT, we propose RestBench, a high-quality benchmark which consists of two real-world scenarios and human-annotated instructions with gold solution paths. Experiments show that RestGPT is able to achieve impressive results in complex tasks and has strong robustness, which paves a new way towards AGI. RestGPT and RestBench is publicly available at https://restgpt.github.io/.
2023.08.29.16.06.04;29.08.2023;04;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2308.14215;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2308.14215.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ghimire_S/0/1/0/all/0/1"">Sushrut Ghimire</a>";Sushrut Ghimire;TimeTrail: Unveiling Financial Fraud Patterns through Temporal Correlation Analysis;"In the field of financial fraud detection, understanding the underlying patterns and dynamics is important to ensure effective and reliable systems. This research introduces a new technique, ""TimeTrail,"" which employs advanced temporal correlation analysis to explain complex financial fraud patterns. The technique leverages time-related insights to provide transparent and interpretable explanations for fraud detection decisions, enhancing accountability and trust. The ""TimeTrail"" methodology consists of three key phases: temporal data enrichment, dynamic correlation analysis, and interpretable pattern visualization. Initially, raw financial transaction data is enriched with temporal attributes. Dynamic correlations between these attributes are then quantified using innovative statistical measures. Finally, a unified visualization framework presents these correlations in an interpretable manner. To validate the effectiveness of ""TimeTrail,"" a study is conducted on a diverse financial dataset, surrounding various fraud scenarios. Results demonstrate the technique's capability to uncover hidden temporal correlations and patterns, performing better than conventional methods in both accuracy and interpretability. Moreover, a case study showcasing the application of ""TimeTrail"" in real-world scenarios highlights its utility for fraud detection."
2023.08.29.16.06.05;29.08.2023;05;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2308.06966;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06966.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1"">Yangning Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1"">Shirong Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1"">Xiaobin Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1"">Shen Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1"">Chengyue Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1"">Hai-Tao Zheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1"">Pengjun Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1"">Fei Huang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1"">Yong Jiang</a>";Yangning Li,Shirong Ma,Xiaobin Wang,Shen Huang,Chengyue Jiang,Hai-Tao Zheng,Pengjun Xie,Fei Huang,Yong Jiang;EcomGPT: Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce;Recently, instruction-following Large Language Models (LLMs) , represented by ChatGPT, have exhibited exceptional performance in general Natural Language Processing (NLP) tasks. However, the unique characteristics of E-commerce data pose significant challenges to general LLMs. An LLM tailored specifically for E-commerce scenarios, possessing robust cross-dataset/task generalization capabilities, is a pressing necessity. To solve this issue, in this work, we proposed the first e-commerce instruction dataset EcomInstruct, with a total of 2.5 million instruction data. EcomInstruct scales up the data size and task diversity by constructing atomic tasks with E-commerce basic data types, such as product information, user reviews. Atomic tasks are defined as intermediate tasks implicitly involved in solving a final task, which we also call Chain-of-Task tasks. We developed EcomGPT with different parameter scales by training the backbone model BLOOMZ with the EcomInstruct. Benefiting from the fundamental semantic understanding capabilities acquired from the Chain-of-Task tasks, EcomGPT exhibits excellent zero-shot generalization capabilities. Extensive experiments and human evaluations demonstrate that EcomGPT outperforms ChatGPT in term of cross-dataset/task generalization on E-commerce tasks.
2023.08.29.16.06.06;29.08.2023;06;12;Health;Medical, Health Care et al.;blog;;http://blog.google/technology/ai/rss/;https://blog.google/technology/health/cloud-next-generative-ai-health/;AI;AI;How 3 healthcare organizations are using generative AI;Medical themed graphic <https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Google_Health_Illo1_2096x1182.max-600x600.format-webp.webp> We’re introducing Google Cloud healthcare customers using Med-PaLM 2 and other generative AI solutions.
2023.08.29.16.06.07;29.08.2023;07;12;Health;Medical, Health Care et al.;arxiv;2308.12890;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12890.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1"">David Oniani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hilsman_J/0/1/0/all/0/1"">Jordan Hilsman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1"">Hang Dong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1"">Fengyi Gao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1"">Shiven Verma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yanshan Wang</a>";David Oniani,Jordan Hilsman,Hang Dong,Fengyi Gao,Shiven Verma,Yanshan Wang;Large Language Models Vote: Prompting for Rare Disease Identification;The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases affect a small fraction of the population. Rare disease identification from clinical notes inherently requires FSL techniques due to limited data availability. Manual data collection and annotation is both expensive and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FSL, available to those who signed the MIMIC-IV Data Use Agreement (DUA). Furthermore, in using MVP, each model is prompted multiple times, substantially increasing the time needed for manual annotation, and to address this, we assess the feasibility of using JSON for automating generative LLM evaluation.
2023.08.29.16.06.08;29.08.2023;08;12;Health;Medical, Health Care et al.;arxiv;2306.04802;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.04802.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1"">Hejie Cui</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1"">Jiaying Lu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Shiyu Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1"">Ran Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1"">Wenjing Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1"">Shaojun Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1"">Yue Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kan_X/0/1/0/all/0/1"">Xuan Kan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1"">Chen Ling</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1"">Liang Zhao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1"">Joyce Ho</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1"">Fei Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1"">Carl Yang</a>";Hejie Cui,Jiaying Lu,Shiyu Wang,Ran Xu,Wenjing Ma,Shaojun Yu,Yue Yu,Xuan Kan,Chen Ling,Liang Zhao,Joyce Ho,Fei Wang,Carl Yang;A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises;Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs (The resource is available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various healthcare domains, spanning from fine-grained basic science research to high-level clinical decision support. Lastly, we shed light on the opportunities for creating comprehensive and accurate HKGs in the era of large language models, presenting the potential to revolutionize healthcare delivery and enhance the interpretability and reliability of clinical prediction.
2023.08.29.16.06.09;29.08.2023;09;15;Control;Control, Planning, Processes et al.;arxiv;2308.13724;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.13724.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1"">Zhehua Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1"">Jiayang Song</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yao_K/0/1/0/all/0/1"">Kunpeng Yao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shu_Z/0/1/0/all/0/1"">Zhan Shu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1"">Lei Ma</a>";Zhehua Zhou,Jiayang Song,Kunpeng Yao,Zhan Shu,Lei Ma;ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning;Motivated by the substantial achievements observed in Large Language Models (LLMs) in the field of natural language processing, recent research has commenced investigations into the application of LLMs for complex, long-horizon sequential task planning challenges in robotics. LLMs are advantageous in offering the potential to enhance the generalizability as task-agnostic planners and facilitate flexible interaction between human instructors and planning systems. However, task plans generated by LLMs often lack feasibility and correctness. To address this challenge, we introduce ISR-LLM, a novel framework that improves LLM-based planning through an iterative self-refinement process. The framework operates through three sequential steps: preprocessing, planning, and iterative self-refinement. During preprocessing, an LLM translator is employed to convert natural language input into a Planning Domain Definition Language (PDDL) formulation. In the planning phase, an LLM planner formulates an initial plan, which is then assessed and refined in the iterative self-refinement step by using a validator. We examine the performance of ISR-LLM across three distinct planning domains. The results show that ISR-LLM is able to achieve markedly higher success rates in task accomplishments compared to state-of-the-art LLM-based planners. Moreover, it also preserves the broad applicability and generalizability of working with natural language instructions.
2023.08.29.11.41.01;29.08.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:bge:wpaper:1394&r=cmp;Gaël Le MensBalász KovácsMichael T. HannanGuillem Pros;Gaël Le MensBalász KovácsMichael T. HannanGuillem Pros;Uncovering the Semantics of Concepts Using GPT-4 and Other Recent Large Language Models;Recently, the world’s attention has been captivated by Large Language Models (LLMs) thanks to OpenAI’s Chat-GPT, which rapidly proliferated as an app powered by GPT-3 and now its successor, GPT-4. If these LLMs produce human-like text, the semantic spaces they construct likely align with those used by humans for interpreting and generating language. This suggests that social scientists could use these LLMs to construct measures of semantic similarity that match human judgment. In this article, we provide an empirical test of this intuition. We use GPT-4 to construct a new measure of typicality– the similarity of a text document to a concept or category. We evaluate its performance against other model-based typicality measures in terms of their correspondence with human typicality ratings. We conduct this comparative analysis in two domains: the typicality of books in literary genres (using an existing dataset of book descriptions) and the typicality of tweets authored by US Congress members in the Democratic and Republican parties (using a novel dataset). The GPT-4 Typicality measure not only meets or exceeds the current state-of-the-art but accomplishes this without any model training. This is a breakthrough because the previous state-of-the-art measure required fine-tuning a model (a BERT text classifier) on hundreds of thousands of text documents to achieve its performance. Our comparative analysis emphasizes the need for systematic empirical validation of measures based on LLMs: several measures based on other recent LLMs achieve at best a moderate correspondence with human judgments.
2023.08.29.11.41.02;29.08.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2306.12659&r=cmp;Boyu ZhangHongyang YangXiao-Yang Liu;Boyu ZhangHongyang YangXiao-Yang Liu;Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models;Sentiment analysis is a vital tool for uncovering insights from financial articles, news, and social media, shaping our understanding of market movements. Despite the impressive capabilities of large language models (LLMs) in financial natural language processing (NLP), they still struggle with accurately interpreting numerical values and grasping financial context, limiting their effectiveness in predicting financial sentiment. In this paper, we introduce a simple yet effective instruction tuning approach to address these issues. By transforming a small portion of supervised financial sentiment analysis data into instruction data and fine-tuning a general-purpose LLM with this method, we achieve remarkable advancements in financial sentiment analysis. In the experiment, our approach outperforms state-of-the-art supervised sentiment analysis models, as well as widely used LLMs like ChatGPT and LLaMAs, particularly in scenarios where numerical understanding and contextual comprehension are vital.
2023.08.29.11.41.03;29.08.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.13317;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.13317.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ioste_A/0/1/0/all/0/1"">Aline Ioste</a>";Aline Ioste;Transforming the Output of Generative Pre-trained Transformer: The Influence of the PGI Framework on Attention Dynamics;This paper presents a novel approach named Persona-Grouping-Intelligence (PGI), which has been crafted to tackle the challenges posed by GPT models when applied to real-world business issues. PGI leverages the inherent capabilities of the GPT model to comprehend intricate language structures and generate responses that are contextually relevant. The experiment occurred in a business scenario where human intelligence was being underutilized due to less optimized business processes. The primary objective of this approach is to leverage GPT models to reduce the workload on humans in tasks that are extensive, monotonous, and repetitive. Instead, the focus is redirected toward decision-making activities. Remarkably, the experiment yielded an accuracy rate of 93.81% in validating 4,000 responses generated by the model, underscoring the effectiveness of the PGI strategies. Effectively addressing the issue of underutilized human intelligence, this paradigm shift aligns business environments with dynamic machine intelligence, enabling them to navigate the intricacies of real-world challenges. This approach facilitates the practical utilization of these models to tackle actual problems. The methodology offers an opportunity to reshape the fundamental structure of business processes by seamlessly integrating human decision-making with adaptable machine intelligence. Consequently, this optimization enhances operational efficiency and elevates strategic decision-making across diverse business contexts.
2023.08.29.11.41.04;29.08.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.13032;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.13032.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Pavlyshenko_B/0/1/0/all/0/1"">Bohdan M. Pavlyshenko</a>";Bohdan M. Pavlyshenko;Financial News Analytics Using Fine-Tuned Llama 2 GPT Model;The paper considers the possibility to fine-tune Llama 2 Large Language Model (LLM) for the multitask analysis of financial news. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text from financial market perspectives, highlighting main points of a text, summarizing a text and extracting named entities with appropriate sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a multitask financial news analysis with a specified structure of response, part of response can be a structured text and another part of data can have JSON format for further processing. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models with quantitative target variables.
2023.08.29.11.41.05;29.08.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;medium;;;https://medium.com/@peter.lawrence_47665/knowledge-graphs-large-language-models-the-ability-for-users-to-ask-their-own-questions-e4afc348fa72;;;Enabling Users to ask Questions About a Process Plant - KG + LLM;In this article, we show how a knowledge graph can prompt or fine-tune an LLM enabling users to ask their questions. To illustrate this, we use an RDF knowledge graph of a process plant, the core of a Digital-Twin, to prompt or fine-tune OpenAI’s GPT LLM.
2023.08.29.11.41.06;29.08.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsai;;;https://pub.towardsai.net/bank-complaints-fictional-data-b885cc907b7d;;;(Generate) Bank Complaints Fictional Data;Fictional data is an important resource for training, testing, demonstration, and educational purposes.
2023.08.29.11.41.07;29.08.2023;07;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;googleblog;;;https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html;;;Visual Information Seeking in LLMs;There has been great progress towards adapting large language models (LLMs) to accommodate multimodal inputs for tasks including image captioning, visual question answering (VQA), and open vocabulary recognition. Despite such achievements, current state-of-the-art visual language models (VLMs) perform inadequately on visual information seeking datasets, such as Infoseek and OK-VQA, where external knowledge is required to answer the questions. In “AVIS: Autonomous Visual Information Seeking with Large Language Models” (https://arxiv.org/abs//2306.08129), Google Research introduces a novel method that achieves state-of-the-art results on visual information seeking tasks. Their method integrates LLMs with three types of tools:<BR/>1) computer vision tools for extracting visual information from images,<BR/>2) a web search tool for retrieving open world knowledge and facts, and <BR/>3) an image search tool to glean relevant information from metadata associated with visually similar images.<BR/>AVIS employs an LLM-powered planner to choose tools and queries at each step. It also uses an LLM-powered reasoner to analyze tool outputs and extract key information. A working memory component retains information throughout the process.
2023.08.29.11.41.08;29.08.2023;08;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;defog;;;https://defog.ai/blog/open-sourcing-sqlcoder/;;;Open-sourcing SQLCoder: a state-of-the-art LLM for SQL generation;SQLCoder - a state-of-the-art LLM for converting natural language questions to SQL queries. SQLCoder is a 15B parameter LLM, and a fine-tuned implementation of StarCoder. SQLCoder has been fine-tuned on hand-crafted SQL queries in increasing orders of difficulty. When fine-tuned on an individual database schema, it matches or outperforms GPT-4 performance.
2023.08.29.11.41.09;29.08.2023;09;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;towardsdatascience;;;https://towardsdatascience.com/how-to-use-chat-gpt-and-python-to-build-a-knowledge-graph-in-neo4j-based-on-your-own-articles-c622bc4e2eaa;;;How to Use Chat-GPT and Python to Build a Knowledge Graph in Neo4j Based on Your Own Articles;The way we will work with the technology in this article is through the programming language Python using OpenAI’s developer API. We will work on data from Medium (meta huh?) and build a knowledge graph. That may sound like a mouthful, but it is actually surprisingly easy to get started with.<BR/>The plan of attack is the following.<BR/>• Get the API to work and access it through Python.<BR/>• Use a sample text to do prompt engineering ensuring that the GPT-4 model understands what you want from it.<BR/>• Download your articles from Medium (you can of course use other pieces of text if you want) and pre-process the data.<BR/>• Extract and collect output from Chat-GPT.<BR/>• Post-process the output from Chat-GPT<BR/>• Write code to structure the data further into a graph using the Cypher query language.<BR/>• Play around with your new best friend and explore your articles.
2023.08.29.11.41.10;29.08.2023;10;02;Energy;Electricity, Smart Grid et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Development_of_Business_Models_based_on_Blockchain_in_energy_sector/24006381;TechRxiv RSS Feed;TechRxiv RSS Feed;Development of Business Models based on Blockchain in energy sector;This research examines the potential application of blockchain technology in the energy sector. It evaluates the current state of the energy industry and explores three potential future scenarios to illustrate the potential impact of blockchain. The study also highlights the shift towards the decentralization of energy production, as private households become ”prosumers” that both produce and consume energy. The research underscores the importance of companies in the energy sector to re-evaluate their enterprise management strategies to effectively incorporate blockchain technology and remain competitive in a rapidly changing landscape.
2023.08.29.11.41.11;29.08.2023;11;02;Energy;Electricity, Smart Grid et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Virtual_Power-Based_Technique_for_Enhancing_the_Large_Voltage_Disturbance_Stability_of_HV_Grid-Forming_Converters/24026460;TechRxiv RSS Feed;TechRxiv RSS Feed;Virtual Power-Based Technique for Enhancing the Large Voltage Disturbance Stability of HV Grid-Forming Converters;Grid-forming control plays an essential role in the modernization of HV electrical transmission grids, particularly in mitigating challenges imposed by large voltage disturbances. In this context, the concept of virtual power has gained prominence as a potential approach that improves stability following such disturbances. This paper illustrates the use of virtual power method in enhancing the large disturbance stability given by the grid-forming control. An adaptive virtual impedance is also proposed to further improve system dynamics. The methods are evaluated through large disturbance stability analysis and time-domain simulations.
2023.08.29.11.41.12;29.08.2023;12;02;Energy;Electricity, Smart Grid et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Automotive_Charger_Grid-Forming_Control_Opportunities_for_G2V_and_V2X_Applications/24033303;TechRxiv RSS Feed;TechRxiv RSS Feed;Automotive Charger Grid-Forming Control Opportunities for G2V and V2X Applications;Given the widespread use of electric vehicles, they can be used in their idle state to provide services when connected to the grid or supply power in islanded operation using the bidirectional charger. Today, when connected to the grid, reversible chargers employ grid-following control, and when operating in islanded conditions, they use constant voltage constant frequency control. However, limitations exist for both control strategies. In this context, grid forming control can be used to operate in all cases. This paper showcases the potential of grid-forming control when applied to a reversible charger for different operation modes of electric vehicles.
2023.08.29.11.41.13;29.08.2023;13;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1901/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;A Survey on Energy Storage in Electric Power Systems & Its Applications in MV/LV Networks;The surging electricity demand driven by a growing global population, coupled with the increasing electrification of industries, transportation, and power-intensive appliances, poses a substantial challenge to electricity systems worldwide. This challenge is further compounded by the pressing issue of climate change. To address climate change and mitigate the environmental consequences of fossil fuel use, renewable energy sources are expected to play a pivotal role. However, certain renewable sources, such as wind and solar, exhibit stochastic behavior, resulting in unpredictable power output and significant fluctuations. This intermittency presents a challenge in maintaining a stable and reliable power supply. To overcome this challenge and ensure a balanced electricity grid, the strategic deployment of energy storage devices throughout the power system becomes critically important. Energy storage technologies play a vital role in mitigating the mismatch between renewable power generation and consumption. Additionally, they enable the storage of surplus energy generated from renewable sources during periods of high production for later use during periods of low or no generation. Each technology possesses unique characteristics and applications, providing flexibility and diversity in energy storage solutions. This work provides an overview of different energy storage technologies and explores their role in establishing a sustainable power system.
2023.08.29.11.41.14;29.08.2023;14;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1971/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Enhancing Energy Efficiency in Connected Vehicles for Traffic Flow Optimization;The predominance of traffic lights in urban settings often induces fluctuations in traffic patterns and energy utilization among vehicles. To counteract the adverse effects of traffic lights on the energy efficiency of electric vehicles (EVs), a Multi-Intersections-Based Eco-Approach and Departure strategy (M-EAD) is proposed. This strategy aims to enhance vehicle energy efficiency, traffic flow, and battery longevity, all while upholding satisfactory driving comfort. The M-EAD strategy unfolds in two distinct stages: the optimization of an eco-friendly green signal window and the refinement of speed trajectories. The initial stage tackles the optimization of traffic light green signal windows, underpinned by the minimization of travel delays via solving the shortest path problem. In the subsequent stage, a receding horizon framework takes center stage, leveraging an iterative dynamic programming algorithm to tackle the speed optimization challenge. The objective here is to curtail energy consumption and reduce battery wear by finding an optimal speed trajectory. Furthermore, the real-world efficacy of this approach is substantiated through on-road vehicle tests, attesting to its viability in actual road scenarios.
2023.08.29.11.41.15;29.08.2023;15;04;Finance;Finance, DeFi, Insurance, Banking et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Use_of_AI_in_construction_financing_for_private_customers/21120136;TechRxiv RSS Feed;TechRxiv RSS Feed;Use of AI in construction financing for private customers;The use of AI has already penetrated some areas of life. By shaping machine learning, it can also be used in the area of construction financing. This includes the factors of advice, the potential of land and building, as well as financial security for lending. Trends in IT are primarily AI and its sub-areas of machine learning and dynamic automation. This paper presents a scenario of how AI can transform and automate the field of construction financing. Corresponding recommendations for action a
2023.08.29.11.41.16;29.08.2023;16;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2106.15221;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2106.15221.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1"">Linyi Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ng_T/0/1/0/all/0/1"">Tin Lok James Ng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Smyth_B/0/1/0/all/0/1"">Barry Smyth</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1"">Ruihai Dong</a>";Linyi Yang,Tin Lok James Ng,Barry Smyth,Ruihai Dong;Fact Check: Analyzing Financial Events from Multilingual News Sources;The explosion in the sheer magnitude and complexity of financial news data in recent years makes it increasingly challenging for investment analysts to extract valuable insights and perform analysis. We propose FactCheck in finance, a web-based news aggregator with deep learning models, to provide analysts with a holistic view of important financial events from multilingual news sources and extract events using an unsupervised clustering method. A web interface is provided to examine the credibility of news articles using a transformer-based fact-checker. The performance of the fact checker is evaluated using a dataset related to merger and acquisition (M\&A) events and is shown to outperform several strong baselines.
2023.08.29.11.41.17;29.08.2023;17;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2308.13289;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.13289.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Frey_S/0/1/0/all/0/1"">Sascha Frey</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Li_K/0/1/0/all/0/1"">Kang Li</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Nagy_P/0/1/0/all/0/1"">Peer Nagy</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Sapora_S/0/1/0/all/0/1"">Silvia Sapora</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Lu_C/0/1/0/all/0/1"">Chris Lu</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Zohren_S/0/1/0/all/0/1"">Stefan Zohren</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Foerster_J/0/1/0/all/0/1"">Jakob Foerster</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Calinescu_A/0/1/0/all/0/1"">Anisoara Calinescu</a>";Sascha Frey,Kang Li,Peer Nagy,Silvia Sapora,Chris Lu,Stefan Zohren,Jakob Foerster,Anisoara Calinescu;JAX-LOB: A GPU-Accelerated limit order book simulator to unlock large scale reinforcement learning for trading;Financial exchanges across the world use limit order books (LOBs) to process orders and match trades. For research purposes it is important to have large scale efficient simulators of LOB dynamics. LOB simulators have previously been implemented in the context of agent-based models (ABMs), reinforcement learning (RL) environments, and generative models, processing order flows from historical data sets and hand-crafted agents alike. For many applications, there is a requirement for processing multiple books, either for the calibration of ABMs or for the training of RL agents. We showcase the first GPU-enabled LOB simulator designed to process thousands of books in parallel, with a notably reduced per-message processing time. The implementation of our simulator - JAX-LOB - is based on design choices that aim to best exploit the powers of JAX without compromising on the realism of LOB-related mechanisms. We integrate JAX-LOB with other JAX packages, to provide an example of how one may address an optimal execution problem with reinforcement learning, and to share some preliminary results from end-to-end RL training on GPUs.
2023.08.29.11.41.18;29.08.2023;18;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2308.13032;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.13032.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Pavlyshenko_B/0/1/0/all/0/1"">Bohdan M. Pavlyshenko</a>";Bohdan M. Pavlyshenko;Financial News Analytics Using Fine-Tuned Llama 2 GPT Model;The paper considers the possibility to fine-tune Llama 2 Large Language Model (LLM) for the multitask analysis of financial news. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text from financial market perspectives, highlighting main points of a text, summarizing a text and extracting named entities with appropriate sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a multitask financial news analysis with a specified structure of response, part of response can be a structured text and another part of data can have JSON format for further processing. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models with quantitative target variables.
2023.08.29.11.41.19;29.08.2023;19;07;Industry;I4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1909/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Validating the Use of Mixed Reality in Industrial Quality Control: A Case Study;Quality control is a critical component in industrial manufacturing, directly influencing efficiency, product reliability, and ultimately, customer satisfaction. In the dynamic environment of industrial manufacturing, traditional methods of inspection may not adequately meet the evolving complexity, necessitating innovative approaches to bolster precision and productivity. In this study, we explore the application of mixed reality (MR) technology for real-time quality control in the assembly process. Our methodology involved the integration of smart glasses with a server-based image recognition system, designed to conduct real-time component analysis. The innovative aspect of our study lies in the harmonization of MR and computer vision algorithms, providing immediate visual feedback to inspectors and thereby improving the speed and accuracy of defect detection. YOLOv8 have been adopted in this study for detection object model. The project implementation occurred in a controlled environment to enable a comprehensive evaluation of the system functionality, the identification of possible problems and improvements in the system performance. The results indicated the viability of mixed reality as a powerful tool for enhancing traditional inspection processes. The fusion of MR and computer vision offers possibilities for future advancements in industrial quality control, paving the way for more efficient and reliable manufacturing ecosystems.
2023.08.29.11.41.20;29.08.2023;20;08;Supply Chain;Supply Chains, Transportation et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1894/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Sustainable Post-COVID-19 Global Supply Chain Methods: Conceptual Framework;There are two goals for this article. The first step is to perform a study of previous research on global supply chain method (GSCM) principles that can adapt and survive adversity, such as a pandemic. The second is to put forth a conceptual framework for the GSCM that would aid in the fight for a stronger GSCM in the event of future turbulence similar to that experienced during the COVID-19 pandemic. Is there, perhaps, a viable GSCM after COVID-19? Can the COVID-19 pandemic-related international logistics system (GSC) turbulences be predicted with certainty using these GSCM concepts? Regarding the raised issues, the paper concluded that, although arguable, sustainable GSCM is feasible and can be accomplished utilizing JIT, supply chain mitigation, and supply chain visibility, as demonstrated by the manufacturing firms referenced in the article.
2023.08.29.11.41.21;29.08.2023;21;09;Commerce;Commerce, Trading, Sales, Retail et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2306.17178&r=cmp;Cong ZhengJiafa HeCan Yang;Cong ZhengJiafa HeCan Yang;Optimal Execution Using Reinforcement Learning;This work is about optimal order execution, where a large order is split into several small orders to maximize the implementation shortfall. Based on the diversity of cryptocurrency exchanges, we attempt to extract cross-exchange signals by aligning data from multiple exchanges for the first time. Unlike most previous studies that focused on using single-exchange information, we discuss the impact of cross-exchange signals on the agent's decision-making in the optimal execution problem. Experimental results show that cross-exchange signals can provide additional information for the optimal execution of cryptocurrency to facilitate the optimal execution process.
2023.08.29.11.41.22;29.08.2023;22;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2308.13118;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.13118.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1"">Helen Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1"">Sercan O. Arik</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Jingtao Wang</a>";Helen Zhou,Sercan O. Arik,Jingtao Wang;Business Metric-Aware Forecasting for Inventory Management;Time-series forecasts play a critical role in business planning. However, forecasters typically optimize objectives that are agnostic to downstream business goals and thus can produce forecasts misaligned with business preferences. In this work, we demonstrate that optimization of conventional forecasting metrics can often lead to sub-optimal downstream business performance. Focusing on the inventory management setting, we derive an efficient procedure for computing and optimizing proxies of common downstream business metrics in an end-to-end differentiable manner. We explore a wide range of plausible cost trade-off scenarios, and empirically demonstrate that end-to-end optimization often outperforms optimization of standard business-agnostic forecasting metrics (by up to 45.7% for a simple scaling model, and up to 54.0% for an LSTM encoder-decoder model). Finally, we discuss how our findings could benefit other business contexts.
2023.08.29.11.41.23;29.08.2023;23;09;Commerce;Commerce, Trading, Sales, Retail et al.;towardsdatascience;;;https://towardsdatascience.com/mastering-the-art-of-pricing-optimization-a-data-science-solution-eb8befb79425;;;Mastering the Art of Pricing Optimization - Unlocking Secrets of Real-World Data Science Solutions for Pricing Optimization in Retail;Pricing plays a very crucial role in the world of business. Making a balance between sales and margins is very important for the success of any business. How can we do it in the data science way? In this section, we will build the intuition of an effective data science solution for pricing optimization and then we will go into the details and code of each component. Note - There are different types of pricing strategies but in this article, we will focus on building the pricing strategy for conventional businesses/established brands with enough data on price change history.
2023.08.29.11.41.24;29.08.2023;24;12;Health;Medical, Health Care et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:dar:wpaper:138523&r=cmp;Pumplun, LuisaPeters, FelixGawlitza, JoshuaBuxmann, Peter;Pumplun, LuisaPeters, FelixGawlitza, JoshuaBuxmann, Peter;Bringing Machine Learning Systems into Clinical Practice: A Design Science Approach to Explainable Machine Learning-Based Clinical Decision Support Systems;
2023.08.29.11.41.25;29.08.2023;25;12;Health;Medical, Health Care et al.;arxiv;2304.14454;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2304.14454.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1"">Chaoyi Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1"">Weixiong Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"">Xiaoman Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Ya Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yanfeng Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1"">Weidi Xie</a>";Chaoyi Wu,Weixiong Lin,Xiaoman Zhang,Ya Zhang,Yanfeng Wang,Weidi Xie;PMC-LLaMA: Towards Building Open-source Language Models for Medicine;"Recently, Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding. While demonstrating proficiency in everyday conversations and question-answering situations, these models frequently struggle in domains that require precision, such as medical applications, due to their lack of domain-specific knowledge. In this paper, we describe the procedure for building a powerful, open-source language model specifically designed for medicine applications, termed as PMC-LLaMA. Our contributions are threefold: (i) we systematically investigate the process of adapting a general-purpose foundation language model towards medical domain, this involves data-centric knowledge injection through the integration of 4.8M biomedical academic papers and 30K medical textbooks, as well as comprehensive fine-tuning for alignment with domain-specific instructions; (ii) we contribute a large-scale, comprehensive dataset for instruction tuning. This dataset encompasses medical question-answering (QA), rationale for reasoning, and conversational dialogues, comprising a total of 202M tokens; (iii) we conduct thorough ablation studies to demonstrate the effectiveness of each proposed component. While evaluating on various public medical question-answering benchmarks, our lightweight PMCLLaMA, which consists of only 13 billion parameters, exhibits superior performance, even surpassing ChatGPT. All models, codes, datasets can be found in https://github.com/chaoyi-wu/PMC-LLaMA."
2023.08.29.11.41.26;29.08.2023;26;99;Other;Others;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Empowering_Athletes_with_AI_and_Blockchain_A_New_Era_of_Personalized_Training_Secure_Data_Management_and_User_Engagement/24006396;TechRxiv RSS Feed;TechRxiv RSS Feed;Empowering Athletes with AI and Blockchain: A New Era of Personalized Training, Secure Data Management, and User Engagement;The convergence of blockchain technology and artificial intelligence (AI) in sports applications presents a revolutionary approach to enhancing sports experiences, optimizing performance, and personalizing user interactions. This article offers an in-depth review of the applications, algorithms, challenges, and future directions of blockchain and AI in sports applications. We delve into the use of AI algorithms and blockchain technology in sports apps to create secure, transparent platforms for transactions, analyze performance data, provide personalized insights, and foster fan engagement. The article scrutinizes the scientific underpinnings of blockchain and AI-enhanced sports apps, discussing the personalization of user experiences, performance analysis using AI and blockchain-powered tools, fan engagement strategies, ethical implications and data privacy, case studies and empirical evidence, challenges, and recommendations for further research. We underscore the potential of blockchain and AI in revolutionizing sports apps, offering tailored experiences, and optimizing user engagement. The article concludes by pinpointing areas for future research, including advanced data analytics, explainable AI models, ethical considerations, collaboration, longitudinal studies, optimization of user experiences, human-AI interaction, and generalization to diverse populations. By exploring these research avenues, the field of blockchain and AI-enhanced sports applications can continue to evolve, supporting fans, athletes, and coaches in achieving their goals and unlocking new dimensions of sports experiences.
2023.08.26.17.52.01;26.08.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;kdnuggets;;;https://www.kdnuggets.com/2023/08/7-projects-built-generative-ai.html;;;7 Projects Built with Generative AI;"With the advent of generative AI tools, like ChatGPT, a collection of standard projects, like object detection and recommendation systems, are not enough anymore to capture the attention of the company. In the last months, companies are opening positions for people able to build Generative AI solutions. For these reasons, we are going to explore 7 project ideas that use Large Language Models for solving the task:
• Create a Portfolio Website 
• Personalized Voice Assistant 
• Build your own AI translator
• Analyze research papers
• Creating Code documentation
• Automate Powerpoint presentations
• Sentiment Analysis of Reviews"
2023.08.26.17.52.02;26.08.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.12923;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12923.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1"">Hao Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Constante_Flores_G/0/1/0/all/0/1"">Gonzalo E. Constante-Flores</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1"">Can Li</a>";Hao Chen,Gonzalo E. Constante-Flores,Can Li;Diagnosing Infeasible Optimization Problems Using Large Language Models;Decision-making problems can be represented as mathematical optimization models, finding wide applications in fields such as economics, engineering and manufacturing, transportation, and health care. Optimization models are mathematical abstractions of the problem of making the best decision while satisfying a set of requirements or constraints. One of the primary barriers to deploying these models in practice is the challenge of helping practitioners understand and interpret such models, particularly when they are infeasible, meaning no decision satisfies all the constraints. Existing methods for diagnosing infeasible optimization models often rely on expert systems, necessitating significant background knowledge in optimization. In this paper, we introduce OptiChat, a first-of-its-kind natural language-based system equipped with a chatbot GUI for engaging in interactive conversations about infeasible optimization models. OptiChat can provide natural language descriptions of the optimization model itself, identify potential sources of infeasibility, and offer suggestions to make the model feasible. The implementation of OptiChat is built on GPT-4, which interfaces with an optimization solver to identify the minimal subset of constraints that render the entire optimization problem infeasible, also known as the Irreducible Infeasible Subset (IIS). We utilize few-shot learning, expert chain-of-thought, key-retrieve, and sentiment prompts to enhance OptiChat's reliability. Our experiments demonstrate that OptiChat assists both expert and non-expert users in improving their understanding of the optimization models, enabling them to quickly identify the sources of infeasibility.
2023.08.26.17.52.03;26.08.2023;03;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2307.00329;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.00329.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1"">Yanjiang Guo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yen-Jen Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zha_L/0/1/0/all/0/1"">Lihan Zha</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1"">Zheyuan Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1"">Jianyu Chen</a>";Yanjiang Guo,Yen-Jen Wang,Lihan Zha,Zheyuan Jiang,Jianyu Chen;DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment;Large language models encode a vast amount of semantic knowledge and possess remarkable understanding and reasoning capabilities. Previous research has explored how to ground language models in robotic tasks to ensure that the sequences generated by the language model are both logically correct and practically executable. However, low-level execution may deviate from the high-level plan due to environmental perturbations or imperfect controller design. In this paper, we propose DoReMi, a novel language model grounding framework that enables immediate Detection and Recovery from Misalignments between plan and execution. Specifically, LLMs are leveraged for both planning and generating constraints for planned steps. These constraints can indicate plan-execution misalignments and we use a vision question answering (VQA) model to check constraints during low-level skill execution. If certain misalignment occurs, our method will call the language model to re-plan in order to recover from misalignments. Experiments on various complex tasks including robot arms and humanoid robots demonstrate that our method can lead to higher task success rates and shorter task completion times. Videos of DoReMi are available at https://sites.google.com/view/doremi-paper.
2023.08.26.17.52.04;26.08.2023;04;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.12562;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12562.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1"">Kwan Ho Ryan Chan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chattopadhyay_A/0/1/0/all/0/1"">Aditya Chattopadhyay</a>, <a href=""http://arxiv.org/find/cs/1/au:+Haeffele_B/0/1/0/all/0/1"">Benjamin David Haeffele</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1"">Rene Vidal</a>";Kwan Ho Ryan Chan,Aditya Chattopadhyay,Benjamin David Haeffele,Rene Vidal;Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions;Variational Information Pursuit (V-IP) is a framework for making interpretable predictions by design by sequentially selecting a short chain of task-relevant, user-defined and interpretable queries about the data that are most informative for the task. While this allows for built-in interpretability in predictive models, applying V-IP to any task requires data samples with dense concept-labeling by domain experts, limiting the application of V-IP to small-scale tasks where manual data annotation is feasible. In this work, we extend the V-IP framework with Foundational Models (FMs) to address this limitation. More specifically, we use a two-step process, by first leveraging Large Language Models (LLMs) to generate a sufficiently large candidate set of task-relevant interpretable concepts, then using Large Multimodal Models to annotate each data sample by semantic similarity with each concept in the generated concept set. While other interpretable-by-design frameworks such as Concept Bottleneck Models (CBMs) require an additional step of removing repetitive and non-discriminative concepts to have good interpretability and test performance, we mathematically and empirically justify that, with a sufficiently informative and task-relevant query (concept) set, the proposed FM+V-IP method does not require any type of concept filtering. In addition, we show that FM+V-IP with LLM generated concepts can achieve better test performance than V-IP with human annotated concepts, demonstrating the effectiveness of LLMs at generating efficient query sets. Finally, when compared to other interpretable-by-design frameworks such as CBMs, FM+V-IP can achieve competitive test performance using fewer number of concepts/queries in both cases with filtered or unfiltered concept sets.
2023.08.26.17.52.05;26.08.2023;05;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.12682;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12682.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hazra_R/0/1/0/all/0/1"">Rishi Hazra</a>, <a href=""http://arxiv.org/find/cs/1/au:+Martires_P/0/1/0/all/0/1"">Pedro Zuidberg Dos Martires</a>, <a href=""http://arxiv.org/find/cs/1/au:+Raedt_L/0/1/0/all/0/1"">Luc De Raedt</a>";Rishi Hazra,Pedro Zuidberg Dos Martires,Luc De Raedt;SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge;"Large Language Models (LLMs) have demonstrated impressive planning abilities due to their vast ""world knowledge"". Yet, obtaining plans that are both feasible (grounded in affordances) and cost-effective (in plan length), remains a challenge, despite recent progress. This contrasts with heuristic planning methods that employ domain knowledge (formalized in action models such as PDDL) and heuristic search to generate feasible, optimal plans. Inspired by this, we propose to combine the power of LLMs and heuristic planning by leveraging the world knowledge of LLMs and the principles of heuristic search. Our approach, SayCanPay, employs LLMs to generate actions (Say) guided by learnable domain knowledge, that evaluates actions' feasibility (Can) and long-term reward/payoff (Pay), and heuristic search to select the best sequence of actions. Our contributions are (1) a novel framing of the LLM planning problem in the context of heuristic planning, (2) integrating grounding and cost-effective elements into the generated plans, and (3) using heuristic search over actions. Our extensive evaluations show that our model surpasses other LLM planning approaches."
2023.08.26.17.52.06;26.08.2023;06;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.12519;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12519.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1"">Yining Ye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1"">Xin Cong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1"">Yujia Qin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1"">Yankai Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1"">Zhiyuan Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1"">Maosong Sun</a>";Yining Ye,Xin Cong,Yujia Qin,Yankai Lin,Zhiyuan Liu,Maosong Sun;Large Language Model as Autonomous Decision Maker;While large language models (LLMs) exhibit impressive language understanding and in-context learning abilities, their decision-making ability still heavily relies on the guidance of task-specific expert knowledge when solving real-world tasks. To unleash the potential of LLMs as autonomous decision makers, this paper presents an approach JuDec to endow LLMs with the self-judgment ability, enabling LLMs to achieve autonomous judgment and exploration for decision making. Specifically, in JuDec, Elo-based Self-Judgment Mechanism is designed to assign Elo scores to decision steps to judge their values and utilities via pairwise comparisons between two solutions and then guide the decision-searching process toward the optimal solution accordingly. Experimental results on the ToolBench dataset demonstrate JuDec's superiority over baselines, achieving over 10% improvement in Pass Rate on diverse tasks. It offers higher-quality solutions and reduces costs (ChatGPT API calls), highlighting its effectiveness and efficiency.
2023.08.26.17.52.07;26.08.2023;07;02;Energy;Electricity, Smart Grid et al.;arxiv;2308.12921;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12921.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shojaeighadikolaei_A/0/1/0/all/0/1"">Amin Shojaeighadikolaei</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1"">Morteza Hashemi</a>";Amin Shojaeighadikolaei,Morteza Hashemi;An Efficient Distributed Multi-Agent Reinforcement Learning for EV Charging Network Control;The increasing trend in adopting electric vehicles (EVs) will significantly impact the residential electricity demand, which results in an increased risk of transformer overload in the distribution grid. To mitigate such risks, there are urgent needs to develop effective EV charging controllers. Currently, the majority of the EV charge controllers are based on a centralized approach for managing individual EVs or a group of EVs. In this paper, we introduce a decentralized Multi-agent Reinforcement Learning (MARL) charging framework that prioritizes the preservation of privacy for EV owners. We employ the Centralized Training Decentralized Execution-Deep Deterministic Policy Gradient (CTDE-DDPG) scheme, which provides valuable information to users during training while maintaining privacy during execution. Our results demonstrate that the CTDE framework improves the performance of the charging network by reducing the network costs. Moreover, we show that the Peak-to-Average Ratio (PAR) of the total demand is reduced, which, in turn, reduces the risk of transformer overload during the peak hours.
2023.08.26.17.52.08;26.08.2023;08;07;Industry;I4.0, Production et al.;arxiv;2308.12834;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12834.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1"">Wenlue Song</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1"">Hanyuan Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1"">Hongwei Meng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bian_E/0/1/0/all/0/1"">Evan Bian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1"">Cong Tang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xi_J/0/1/0/all/0/1"">Jiaqi Xi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1"">Haogang Zhu</a>";Wenlue Song,Hanyuan Wu,Hongwei Meng,Evan Bian,Cong Tang,Jiaqi Xi,Haogang Zhu;A Blockchain based Fund Management System for Construction Projects -- A Comprehensive Case Study in Xiong'an New Area China;As large scale construction projects become increasingly complex, the use and integration of advanced technologies are being emphasized more and more. However, the construction industry often lags behind most industries in the application of digital technologies. In recent years, a decentralized, peer-topeer blockchain technology has attracted widespread attention from academia and industry. This paper provides a solution that combines blockchain technology with construction project fund management. The system involves participants such as the owner's unit, construction companies, government departments, banks, etc., adopting the technical architecture of the Xiong'an Blockchain Underlying System. The core business and key logic processing are all implemented through smart contracts, ensuring the transparency and traceability of the fund payment process. The goal of ensuring investment quality, standardizing investment behavior, and strengthening cost control is achieved through blockchain technology. The application of this system in the management of Xiong'an construction projects has verified that blockchain technology plays a significant positive role in strengthening fund management, enhancing fund supervision, and ensuring fund safety in the construction process of engineering projects. It helps to eliminate the common problems of multi-party trust and transparent supervision in the industry and can further improve the investment benefits of government investment projects and improve the management system and operation mechanism of investment projects.
2023.08.26.17.52.09;26.08.2023;09;12;Health;Medical, Health Care et al.;arxiv;2306.06494;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.06494.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1"">Li Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1"">Bo Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1"">Ameer Hamza Khan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1"">Lu Fan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1"">Xiao-Ming Wu</a>";Li Xu,Bo Liu,Ameer Hamza Khan,Lu Fan,Xiao-Ming Wu;Multi-modal Pre-training for Medical Vision-language Understanding and Generation: An Empirical Study with A New Benchmark;With the availability of large-scale, comprehensive, and general-purpose vision-language (VL) datasets such as MSCOCO, vision-language pre-training (VLP) has become an active area of research and proven to be effective for various VL tasks such as visual-question answering. However, studies on VLP in the medical domain have so far been scanty. To provide a comprehensive perspective on VLP for medical VL tasks, we conduct a thorough experimental analysis to study key factors that may affect the performance of VLP with a unified vision-language Transformer. To allow making sound and quick pre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality, multi-modality radiographic dataset containing 18,434 image-caption pairs collected from an open-access online database MedPix. RGC can be used as a pre-training dataset or a new benchmark for medical report generation and medical image-text retrieval. By utilizing RGC and other available datasets for pre-training, we develop several key insights that can guide future medical VLP research and new strong baselines for various medical VL tasks.
2023.08.26.17.52.10;26.08.2023;10;12;Health;Medical, Health Care et al.;arxiv;2308.12890;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12890.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1"">David Oniani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hilsman_J/0/1/0/all/0/1"">Jordan Hilsman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1"">Hang Dong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1"">Fengyi Gao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1"">Shiven Verma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yanshan Wang</a>";David Oniani,Jordan Hilsman,Hang Dong,Fengyi Gao,Shiven Verma,Yanshan Wang;Large Language Models Vote: Prompting for Rare Disease Identification;The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases, affecting a small fraction of the population, inherently require FSL techniques due to limited data availability, though manual data collection and annotation is costly and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FSL, available to those who agreed to the MIMIC-IV Data Use Agreement (DUA). Furthermore, in using MVP, each model is prompted multiple times, substantially increasing the time needed for manual annotation, and to address this, we assess the feasibility of using JSON for automating generative LLM evaluation.
2023.08.25.11.46.01;25.08.2023;01;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.12241;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12241.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"">Junling Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1"">Chao Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1"">Peilin Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1"">Qichen Ye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chong_D/0/1/0/all/0/1"">Dading Chong</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1"">Kang Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1"">Yueqi Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1"">Yuwei Cao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1"">Shoujin Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1"">Chenyu You</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1"">Philip S.Yu</a>";Junling Liu,Chao Liu,Peilin Zhou,Qichen Ye,Dading Chong,Kang Zhou,Yueqi Xie,Yuwei Cao,Shoujin Wang,Chenyu You,Philip S.Yu;LLMRec: Benchmarking Large Language Models on Recommendation Task;Recently, the fast development of Large Language Models (LLMs) such as ChatGPT has significantly advanced NLP tasks by enhancing the capabilities of conversational models. However, the application of LLMs in the recommendation domain has not been thoroughly investigated. To bridge this gap, we propose LLMRec, a LLM-based recommender system designed for benchmarking LLMs on various recommendation tasks. Specifically, we benchmark several popular off-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendation tasks, including rating prediction, sequential recommendation, direct recommendation, explanation generation, and review summarization. Furthermore, we investigate the effectiveness of supervised finetuning to improve LLMs' instruction compliance ability. The benchmark results indicate that LLMs displayed only moderate proficiency in accuracy-based tasks such as sequential and direct recommendation. However, they demonstrated comparable performance to state-of-the-art methods in explainability-based tasks. We also conduct qualitative evaluations to further evaluate the quality of contents generated by different models, and the results show that LLMs can truly understand the provided information and generate clearer and more reasonable results. We aspire that this benchmark will serve as an inspiration for researchers to delve deeper into the potential of LLMs in enhancing recommendation performance. Our codes, processed data and benchmark results are available at https://github.com/williamliujl/LLMRec.
2023.08.25.11.46.02;25.08.2023;02;03;Transportation;Transport Equipment, Automotive, Self Driving et al.;arxiv;2308.12021;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12021.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1"">Tong Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1"">Lu Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1"">Sikang Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1"">Shaojie Shen</a>";Tong Li,Lu Zhang,Sikang Liu,Shaojie Shen;MARC: Multipolicy and Risk-aware Contingency Planning for Autonomous Driving;Generating safe and non-conservative behaviors in dense, dynamic environments remains challenging for automated vehicles due to the stochastic nature of traffic participants' behaviors and their implicit interaction with the ego vehicle. This paper presents a novel planning framework, Multipolicy And Risk-aware Contingency planning (MARC), that systematically addresses these challenges by enhancing the multipolicy-based pipelines from both behavior and motion planning aspects. Specifically, MARC realizes a critical scenario set that reflects multiple possible futures conditioned on each semantic-level ego policy. Then, the generated policy-conditioned scenarios are further formulated into a tree-structured representation with a dynamic branchpoint based on the scene-level divergence. Moreover, to generate diverse driving maneuvers, we introduce risk-aware contingency planning, a bi-level optimization algorithm that simultaneously considers multiple future scenarios and user-defined risk tolerance levels. Owing to the more unified combination of behavior and motion planning layers, our framework achieves efficient decision-making and human-like driving maneuvers. Comprehensive experimental results demonstrate superior performance to other strong baselines in various environments.
2023.08.25.11.46.03;25.08.2023;03;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2308.12212;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12212.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Xingyue/0/1/0/all/0/1"">Xingyue</a> (Stacy)Pu, <a href=""http://arxiv.org/find/q-fin/1/au:+Zohren_S/0/1/0/all/0/1"">Stefan Zohren</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Roberts_S/0/1/0/all/0/1"">Stephen Roberts</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Dong_X/0/1/0/all/0/1"">Xiaowen Dong</a>";Xingyue,Stephen Roberts,Xiaowen Dong;Learning to Learn Financial Networks for Optimising Momentum Strategies;Network momentum provides a novel type of risk premium, which exploits the interconnections among assets in a financial network to predict future returns. However, the current process of constructing financial networks relies heavily on expensive databases and financial expertise, limiting accessibility for small-sized and academic institutions. Furthermore, the traditional approach treats network construction and portfolio optimisation as separate tasks, potentially hindering optimal portfolio performance. To address these challenges, we propose L2GMOM, an end-to-end machine learning framework that simultaneously learns financial networks and optimises trading signals for network momentum strategies. The model of L2GMOM is a neural network with a highly interpretable forward propagation architecture, which is derived from algorithm unrolling. The L2GMOM is flexible and can be trained with diverse loss functions for portfolio performance, e.g. the negative Sharpe ratio. Backtesting on 64 continuous future contracts demonstrates a significant improvement in portfolio profitability and risk control, with a Sharpe ratio of 1.74 across a 20-year period.
2023.08.25.11.46.04;25.08.2023;04;07;Industry;I4.0, Production et al.;arxiv;2308.12129;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.12129.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Ogundare_O/0/1/0/all/0/1"">Oluwatosin Ogundare</a>, <a href=""http://arxiv.org/find/cs/1/au:+Araya_G/0/1/0/all/0/1"">Gustavo Quiros Araya</a>, <a href=""http://arxiv.org/find/cs/1/au:+Akrotirianakis_I/0/1/0/all/0/1"">Ioannis Akrotirianakis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1"">Ankit Shukla</a>";Oluwatosin Ogundare,Gustavo Quiros Araya,Ioannis Akrotirianakis,Ankit Shukla;Resiliency Analysis of LLM generated models for Industrial Automation;This paper proposes a study of the resilience and efficiency of automatically generated industrial automation and control systems using Large Language Models (LLMs). The approach involves modeling the system using percolation theory to estimate its resilience and formulating the design problem as an optimization problem subject to constraints. Techniques from stochastic optimization and regret analysis are used to find a near-optimal solution with provable regret bounds. The study aims to provide insights into the effectiveness and reliability of automatically generated systems in industrial automation and control, and to identify potential areas for improvement in their design and implementation.
2023.08.25.11.46.05;25.08.2023;05;09;Commerce;Commerce, Trading, Sales, Retail et al.;arxiv;2308.11939;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.11939.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Haque_M/0/1/0/all/0/1"">Md Sabbirul Haque</a>, <a href=""http://arxiv.org/find/cs/1/au:+Amin_M/0/1/0/all/0/1"">Md Shahedul Amin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Miah_J/0/1/0/all/0/1"">Jonayet Miah</a>";Md Sabbirul Haque,Md Shahedul Amin,Jonayet Miah;Retail Demand Forecasting: A Comparative Study for Multivariate Time Series;Accurate demand forecasting in the retail industry is a critical determinant of financial performance and supply chain efficiency. As global markets become increasingly interconnected, businesses are turning towards advanced prediction models to gain a competitive edge. However, existing literature mostly focuses on historical sales data and ignores the vital influence of macroeconomic conditions on consumer spending behavior. In this study, we bridge this gap by enriching time series data of customer demand with macroeconomic variables, such as the Consumer Price Index (CPI), Index of Consumer Sentiment (ICS), and unemployment rates. Leveraging this comprehensive dataset, we develop and compare various regression and machine learning models to predict retail demand accurately.
2023.08.25.11.46.06;25.08.2023;06;99;Other;Others;analyticsvidhya;;http://www.analyticsvidhya.com/feed/;https://www.analyticsvidhya.com/blog/2023/08/fashion-forward-with-generative-ai/;Jeevinee Vb;Jeevinee Vb;Fashion Forward with Generative AI;Introduction Fashion Forward with Generative AI embarks on a journey of creative synergy. It is revealing a new era where technology and fashion converge. This blog reveals Generative AI’s dramatic impact on fashion, promoting limitless innovation, individualized experiences, and sustainable practices. The perspective broadens through bespoke designs and trend forecasting, changing the essence of fashion. […] The post Fashion Forward with Generative AI <https://www.analyticsvidhya.com/blog/2023/08/fashion-forward-with-generative-ai/> appeared first on Analytics Vidhya <https://www.analyticsvidhya.com> .
2023.08.24.13.12.01;24.08.2023;01;00;CrossTopic;Generic, Cross Topic, et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/AI_in_Industry_Real-World_Applications_and_Case_Studies/23993565;TechRxiv RSS Feed;TechRxiv RSS Feed;AI in Industry: Real-World Applications and Case Studies;Artificial intelligence (AI) has advanced rapidly and is becoming a cornerstone technology that drives innovation and efficiency in various industries. This paper examines the real-world application of AI in multiple sectors, including healthcare, finance, agriculture, retail, energy, and automotive. Several case studies are described to understand better the practical applications, results, and challenges of implementing AI. While many industries have reaped enormous benefits from AI, inherent challenges include data privacy, the potential for bias, and the continuing demand for skilled labor. This comprehensive review aims to provide AI application insights to professionals and researchers. Thus, as AI grows, there may be challenges and avenues for future research.
2023.08.24.13.12.02;24.08.2023;02;01;Generative;Large Language and Foundation Models, Multi Modal Models et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:upf:upfgen:1864&r=cmp;Gaël Le MensBalász KovácsMichael T. HannanGuillem Pros;Gaël Le MensBalász KovácsMichael T. HannanGuillem Pros;Uncovering the semantics of concepts using GPT-4 and Other recent large language models;Recently, the world's attention has been captivated by Large Language Models (LLMs) thanks to OpenAI's Chat-GPT, which rapidly proliferated as an app powered by GPT-3 and now its successor, GPT-4. If these LLMs produce human-like text, the semantic spaces they construct likely align with those used by humans for interpreting and generating language. This suggests that social scientists could use these LLMs to construct measures of semantic similarity that match human judgment. In this article, we provide an empirical test of this intuition. We use GPT-4 to construct a new measure of typicalityâ€“ the similarity of a text document to a concept or category. We evaluate its performance against other model-based typicality measures in terms of their correspondence with human typicality ratings. We conduct this comparative analysis in two domains: the typicality of books in literary genres (using an existing dataset of book descriptions) and the typicality of tweets authored by US Congress members in the Democratic and Republican parties (using a novel dataset). The GPT-4 Typicality measure not only meets or exceeds the current state-of-the-art but accomplishes this without any model training. This is a breakthrough because the previous state-of-the-art measure required fine-tuning a model (a BERT text classifier) on hundreds of thousands of text documents to achieve its performance. Our comparative analysis emphasizes the need for systematic empirical validation of measures based on LLMs: several measures based on other recent LLMs achieve at best a moderate correspondence with human judgments.
2023.08.24.13.12.03;24.08.2023;03;02;Energy;Electricity, Smart Grid et al.;arxiv;2308.11263;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.11263.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Doostmohammadian_M/0/1/0/all/0/1"">Mohammadreza Doostmohammadian</a>";Mohammadreza Doostmohammadian;Distributed Energy Resource Management: All-Time Resource-Demand Feasibility, Delay-Tolerance, Nonlinearity, and Beyond;In this work, we propose distributed and networked energy management scenarios to optimize the production and reservation of energy among a set of distributed energy nodes. In other words, the idea is to optimally allocate the generated and reserved powers based on nodes' local cost gradient information while meeting the demand energy. One main concern is the all-time (or anytime) resource-demand feasibility, implying that at all iterations of the scheduling algorithm, the balance between the produced power and demand plus reserved power must hold. The other concern is to design algorithms to tolerate communication time-delays and changes in the network. Further, one can incorporate possible model nonlinearity in the algorithm to address both inherent (e.g., saturation and quantization) and purposefully-added (e.g., signum-based) nonlinearities in the model. The proposed optimal allocation algorithm addresses all the above concerns, while it benefits from possible features of the distributed (or networked) solutions such as no-single-node-of-failure and distributed information processing. We show both the all-time feasibility of the proposed scheme and its convergence under certain bound on the step-rate using Lyapunov-type proofs.
2023.08.24.13.12.04;24.08.2023;04;02;Energy;Electricity, Smart Grid et al.;arxiv;2308.11420;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.11420.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+YuanzhangXiao/0/1/0/all/0/1"">YuanzhangXiao</a>, <a href=""http://arxiv.org/find/cs/1/au:+ChaithanyaBandi/0/1/0/all/0/1"">ChaithanyaBandi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wei_E/0/1/0/all/0/1"">Ermin Wei</a>";YuanzhangXiao,ChaithanyaBandi,Ermin Wei;Supply Function Equilibrium in Networked Electricity Markets;We study deregulated power markets with strategic power suppliers. In deregulated markets, each supplier submits its supply function (i.e., the amount of electricity it is willing to produce at various prices) to the independent system operator (ISO), who based on the submitted supply functions, dispatches the suppliers to clear the market with minimal total generation cost. If all suppliers reported their true marginal cost functions as supply functions, the market outcome would be efficient (i.e., the total generation cost is minimized). However, when suppliers are strategic and aim to maximize their own profits, the reported supply functions are not necessarily the true marginal cost functions, and the resulting market outcome may be inefficient. The efficiency loss depends crucially on the topology of the underlying transmission network. This paper provides an analytical upper bound of the efficiency loss due to strategic suppliers, and proves that the bound is tight under a large class of transmission networks (i.e., weakly cyclic networks). Our upper bound sheds light on how the efficiency loss depends on the transmission network topology (e.g., the degrees of nodes, the admittances and flow limits of transmission lines).
2023.08.24.13.12.05;24.08.2023;05;04;Finance;Finance, DeFi, Insurance, Banking et al.;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/Transforming_the_Insurance_Industry_with_Blockchain_and_Smart_Contracts_Enhancing_Efficiency_Transparency_and_Trust/24006237;TechRxiv RSS Feed;TechRxiv RSS Feed;Transforming the Insurance Industry with Blockchain and Smart Contracts: Enhancing Efficiency, Transparency, and Trust;This scientific overview explores the application of blockchain technology and smart contracts in the insurance industry. It discusses their impact on various aspects such as claims management, underwriting, policy management, fraud prevention, and emerging trends. The benefits of automation, transparency, and efficiency in claims management are highlighted, along with examples of successful implementation. The potential of blockchain in enhancing underwriting processes and risk assessment through access to trusted data is explained. The advantages of transparent and auditable policy records, policy issuance, and enforcement through smart contracts are discussed. The role of blockchain in combating insurance fraud and its potential to improve trust and transparency are examined. The challenges of scalability, regulation, interoperability, and privacy are addressed, along with strategies for successful adoption. Lastly, the emerging trends of tokenization, parametric insurance, and peer-to-peer insurance are explored, envisioning a transformed insurance landscape driven by blockchain and smart contracts.
2023.08.24.13.12.06;24.08.2023;06;04;Finance;Finance, DeFi, Insurance, Banking et al.;arxiv;2308.11202;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2308.11202.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Panda_K/0/1/0/all/0/1"">Kapil Panda</a>";Kapil Panda;Analysis of Optimal Portfolio Management Using Hierarchical Clustering;Portfolio optimization is a task that investors use to determine the best allocations for their investments, and fund managers implement computational models to help guide their decisions. While one of the most common portfolio optimization models in the industry is the Markowitz Model, practitioners recognize limitations in its framework that lead to suboptimal out-of-sample performance and unrealistic allocations. In this study, I refine the Markowitz Model by incorporating machine learning to improve portfolio performance. By using a hierarchical clustering-based approach, I am able to enhance portfolio performance on a risk-adjusted basis compared to the Markowitz Model, across various market factors.
2023.08.24.13.12.07;24.08.2023;07;05;Legal;Legal, Law et al.;arxiv;2308.11462;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.11462.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Guha_N/0/1/0/all/0/1"">Neel Guha</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nyarko_J/0/1/0/all/0/1"">Julian Nyarko</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ho_D/0/1/0/all/0/1"">Daniel E. Ho</a>, <a href=""http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1"">Christopher R&#xe9;</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chilton_A/0/1/0/all/0/1"">Adam Chilton</a>, <a href=""http://arxiv.org/find/cs/1/au:+Narayana_A/0/1/0/all/0/1"">Aditya Narayana</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chohlas_Wood_A/0/1/0/all/0/1"">Alex Chohlas-Wood</a>, <a href=""http://arxiv.org/find/cs/1/au:+Peters_A/0/1/0/all/0/1"">Austin Peters</a>, <a href=""http://arxiv.org/find/cs/1/au:+Waldon_B/0/1/0/all/0/1"">Brandon Waldon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rockmore_D/0/1/0/all/0/1"">Daniel N. Rockmore</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zambrano_D/0/1/0/all/0/1"">Diego Zambrano</a>, <a href=""http://arxiv.org/find/cs/1/au:+Talisman_D/0/1/0/all/0/1"">Dmitry Talisman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hoque_E/0/1/0/all/0/1"">Enam Hoque</a>, <a href=""http://arxiv.org/find/cs/1/au:+Surani_F/0/1/0/all/0/1"">Faiz Surani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fagan_F/0/1/0/all/0/1"">Frank Fagan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sarfaty_G/0/1/0/all/0/1"">Galit Sarfaty</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dickinson_G/0/1/0/all/0/1"">Gregory M. Dickinson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Porat_H/0/1/0/all/0/1"">Haggai Porat</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hegland_J/0/1/0/all/0/1"">Jason Hegland</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1"">Jessica Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nudell_J/0/1/0/all/0/1"">Joe Nudell</a>, <a href=""http://arxiv.org/find/cs/1/au:+Niklaus_J/0/1/0/all/0/1"">Joel Niklaus</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nay_J/0/1/0/all/0/1"">John Nay</a>, <a href=""http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1"">Jonathan H. Choi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tobia_K/0/1/0/all/0/1"">Kevin Tobia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hagan_M/0/1/0/all/0/1"">Margaret Hagan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1"">Megan Ma</a>, <a href=""http://arxiv.org/find/cs/1/au:+Livermore_M/0/1/0/all/0/1"">Michael Livermore</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rasumov_Rahe_N/0/1/0/all/0/1"">Nikon Rasumov-Rahe</a>, <a href=""http://arxiv.org/find/cs/1/au:+Holzenberger_N/0/1/0/all/0/1"">Nils Holzenberger</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kolt_N/0/1/0/all/0/1"">Noam Kolt</a>, <a href=""http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1"">Peter Henderson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rehaag_S/0/1/0/all/0/1"">Sean Rehaag</a>, <a href=""http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1"">Sharad Goel</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1"">Shang Gao</a>, <a href=""http://arxiv.org/find/cs/1/au:+Williams_S/0/1/0/all/0/1"">Spencer Williams</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gandhi_S/0/1/0/all/0/1"">Sunny Gandhi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zur_T/0/1/0/all/0/1"">Tom Zur</a>, <a href=""http://arxiv.org/find/cs/1/au:+Iyer_V/0/1/0/all/0/1"">Varun Iyer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Zehua Li</a>";Neel Guha,Julian Nyarko,Daniel E. Ho,Christopher Ré,Adam Chilton,Aditya Narayana,Alex Chohlas-Wood,Austin Peters,Brandon Waldon,Daniel N. Rockmore,Diego Zambrano,Dmitry Talisman,Enam Hoque,Faiz Surani,Frank Fagan,Galit Sarfaty,Gregory M. Dickinson,Haggai Porat,Jason Hegland,Jessica Wu,Joe Nudell,Joel Niklaus,John Nay,Jonathan H. Choi,Kevin Tobia,Margaret Hagan,Megan Ma,Michael Livermore,Nikon Rasumov-Rahe,Nils Holzenberger,Noam Kolt,Peter Henderson,Sean Rehaag,Sharad Goel,Shang Gao,Spencer Williams,Sunny Gandhi,Tom Zur,Varun Iyer,Zehua Li;LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models;The advent of large language models (LLMs) and their adoption by the legal community has given rise to the question: what types of legal reasoning can LLMs perform? To enable greater study of this question, we present LegalBench: a collaboratively constructed legal reasoning benchmark consisting of 162 tasks covering six different types of legal reasoning. LegalBench was built through an interdisciplinary process, in which we collected tasks designed and hand-crafted by legal professionals. Because these subject matter experts took a leading role in construction, tasks either measure legal reasoning capabilities that are practically useful, or measure reasoning skills that lawyers find interesting. To enable cross-disciplinary conversations about LLMs in the law, we additionally show how popular legal frameworks for describing legal reasoning -- which distinguish between its many forms -- correspond to LegalBench tasks, thus giving lawyers and LLM developers a common vocabulary. This paper describes LegalBench, presents an empirical evaluation of 20 open-source and commercial LLMs, and illustrates the types of research explorations LegalBench enables.
2023.08.24.13.12.08;24.08.2023;08;05;Legal;Legal, Law et al.;arxiv;2308.11531;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.11531.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Barale_C/0/1/0/all/0/1"">Claire Barale</a>";Claire Barale;Empowering Refugee Claimants and their Lawyers: Using Machine Learning to Examine Decision-Making in Refugee Law;Our project aims at helping and supporting stakeholders in refugee status adjudications, such as lawyers, judges, governing bodies, and claimants, in order to make better decisions through data-driven intelligence and increase the understanding and transparency of the refugee application process for all involved parties. This PhD project has two primary objectives: (1) to retrieve past cases, and (2) to analyze legal decision-making processes on a dataset of Canadian cases. In this paper, we present the current state of our work, which includes a completed experiment on part (1) and ongoing efforts related to part (2). We believe that NLP-based solutions are well-suited to address these challenges, and we investigate the feasibility of automating all steps involved. In addition, we introduce a novel benchmark for future NLP research in refugee law. Our methodology aims to be inclusive to all end-users and stakeholders, with expected benefits including reduced time-to-decision, fairer and more transparent outcomes, and improved decision quality.
2023.08.24.13.12.09;24.08.2023;09;06;Public Services;Public Services;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1636/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Uncovering Top-Tier Machine Learning Classifier for Drinking Water Quality Detection;Water quality assessments are crucial for human health and environmental safeguards. The utilization of a subset of artificial intelligence such as Machine Learning (ML) presents significant impacts to enhance the prediction and classification of water quality. In this research, a set of diverse ML algorithms was evaluated to handle a comprehensive dataset of water quality measurements over an extended period. The aim was to develop a robust approach for accurately forecasting water quality. This approach employed machine learning classifiers such as Logistic Regression (LR), Support Vector Machine (SVM), Stochastic Gradient Descent (SGD), K-Nearest Neighbors (KNN), Gaussian Process Classification (GPC), Gaussian Naive Bayes (GNB), Random Forest (RF), Decision Tree (DT), XGBoost, and Multilayer Perceptron (MLP). The water quality parameters assessed for pH, hardness, solids, chloramines, sulfate, conductivity, organic carbon, trihalomethanes and turbidity. The XGBoost model exhibited the highest accuracy of 89.47% among the classifiers and Stacked Ensemble Classifiers (SEC) improved the prediction further to 92.98%. The findings suggest that XGBoost and the SEC hold promise as reliable approaches for water quality assessments in contrast of artificial intelligence.
2023.08.24.13.12.10;24.08.2023;10;08;Supply Chain;Supply Chains, Transportation et al.;repec;;http://nep.repec.org/rss/nep-pay.rss.xml;http://d.repec.org/n?u=RePEc:dar:wpaper:138753&r=pay;Lehner, Roland;Lehner, Roland;Cross-Supply Chain Collaboration Platform for Pallet Management;"Standardized pallets are an important factor in today's logistics sector to enable efficient processes in transport, storage and handling. By using an open exchange pool for pallets, additional opportunities arise for horizontal and vertical collaboration of various actors from different supply chains. The dissertation ""Cross-Supply Chain Collaboration Platform for Pallet Management"" investigates the potential of a digital platform for such cross-actor collaboration in pallet management. The designed platform has special mechanisms for balancing pallet debts that arise in the network and for joint planning of empty pallet flows. Therefore, the impact of the designed platforms on logistic processes, especially transports, is explored using simulation modeling. Furthermore, blockchain technology is investigated, which could be used for the implementation of the platform concept and could generate trust in a network of unknown actors. In this context, an empirical online-experiment is used to analyze in a differentiated way which specific features of the blockchain technology generate trust in technology and how these features interact with each other."
2023.08.24.13.12.11;24.08.2023;11;09;Commerce;Commerce, Trading, Sales, Recommendation et al.;arxiv;2308.11520;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.11520.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1"">Anusuya Krishnan</a>";Anusuya Krishnan;Exploring the Power of Topic Modeling Techniques in Analyzing Customer Reviews: A Comparative Analysis;The exponential growth of online social network platforms and applications has led to a staggering volume of user-generated textual content, including comments and reviews. Consequently, users often face difficulties in extracting valuable insights or relevant information from such content. To address this challenge, machine learning and natural language processing algorithms have been deployed to analyze the vast amount of textual data available online. In recent years, topic modeling techniques have gained significant popularity in this domain. In this study, we comprehensively examine and compare five frequently used topic modeling methods specifically applied to customer reviews. The methods under investigation are latent semantic analysis (LSA), latent Dirichlet allocation (LDA), non-negative matrix factorization (NMF), pachinko allocation model (PAM), Top2Vec, and BERTopic. By practically demonstrating their benefits in detecting important topics, we aim to highlight their efficacy in real-world scenarios. To evaluate the performance of these topic modeling methods, we carefully select two textual datasets. The evaluation is based on standard statistical evaluation metrics such as topic coherence score. Our findings reveal that BERTopic consistently yield more meaningful extracted topics and achieve favorable results.
2023.08.24.13.12.12;24.08.2023;12;09;Commerce;Commerce, Trading, Sales, Recommendation et al.;arxiv;2308.11137;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.11137.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1"">Hojoon Lee</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hwang_D/0/1/0/all/0/1"">Dongyoon Hwang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Min_K/0/1/0/all/0/1"">Kyushik Min</a>, <a href=""http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1"">Jaegul Choo</a>";Hojoon Lee,Dongyoon Hwang,Kyushik Min,Jaegul Choo;Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems;Interactive Recommender Systems (IRSs) have attracted a lot of attention, due to their ability to model interactive processes between users and recommender systems. Numerous approaches have adopted Reinforcement Learning (RL) algorithms, as these can directly maximize users' cumulative rewards. In IRS, researchers commonly utilize publicly available review datasets to compare and evaluate algorithms. However, user feedback provided in public datasets merely includes instant responses (e.g., a rating), with no inclusion of delayed responses (e.g., the dwell time and the lifetime value). Thus, the question remains whether these review datasets are an appropriate choice to evaluate the long-term effects of the IRS. In this work, we revisited experiments on IRS with review datasets and compared RL-based models with a simple reward model that greedily recommends the item with the highest one-step reward. Following extensive analysis, we can reveal three main findings: First, a simple greedy reward model consistently outperforms RL-based models in maximizing cumulative rewards. Second, applying higher weighting to long-term rewards leads to a degradation of recommendation performance. Third, user feedbacks have mere long-term effects on the benchmark datasets. Based on our findings, we conclude that a dataset has to be carefully verified and that a simple greedy baseline should be included for a proper evaluation of RL-based IRS approaches.
2023.08.24.13.12.13;24.08.2023;13;99;Other;Others;arxiv;2308.11478;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.11478.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Terenzi_L/0/1/0/all/0/1"">Lorenzo Terenzi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1"">Marco Hutter</a>";Lorenzo Terenzi,Marco Hutter;Towards Autonomous Excavation Planning;Excavation plans are crucial in construction projects, dictating the dirt disposal strategy and excavation sequence based on the final geometry and machinery available. While most construction processes rely heavily on coarse sequence planning and local execution planning driven by human expertise and intuition, fully automated planning tools are notably absent from the industry. This paper introduces a fully autonomous excavation planning system. Initially, the site is mapped, followed by user selection of the desired excavation geometry. The system then invokes a global planner to determine the sequence of poses for the excavator, ensuring complete site coverage. For each pose, a local excavation planner decides how to move the soil around the machine, and a digging planner subsequently dictates the sequence of digging trajectories to complete a patch. We showcased our system by autonomously excavating the largest pit documented so far, achieving an average digging cycle time of roughly 30 seconds, comparable to the one of a human operator.
2023.08.23.08.49.01;23.08.2023;01;02;Energy;Electricity, Smart Grid et al.;arxiv;2304.11963;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2304.11963.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1"">Zhuoxuan Li</a>, <a href=""http://arxiv.org/find/eess/1/au:+Chu_Z/0/1/0/all/0/1"">Zhongda Chu</a>, <a href=""http://arxiv.org/find/eess/1/au:+Teng_F/0/1/0/all/0/1"">Fei Teng</a>";Zhuoxuan Li,Zhongda Chu,Fei Teng;Optimal Design of Neural Network Structure for Power System Frequency Security Constraints;Recently, frequency security is challenged by high uncertainty and low inertia in power system with high penetration of Renewable Energy Sources (RES). In the context of Unit Commitment (UC) problems, frequency security constraints represented by neural networks have been developed and embedded into the optimization problem to represent complicated frequency dynamics. However, there are two major disadvantages related to this technique: the risk of overconfident prediction and poor computational efficiency. To handle these disadvantages, novel methodologies are proposed to optimally design the neural network structure, including the use of asymmetric loss function during the training stage and scientifically selecting neural network size and topology. The effectiveness of the proposed methodologies are validated by case study which reveals the improvement of conservativeness and mitigation of computation performance issues.
2023.08.23.08.49.02;23.08.2023;02;02;Energy;Electricity, Smart Grid et al.;arxiv;2308.09886;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.09886.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Abusafia_A/0/1/0/all/0/1"">Amani Abusafia</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lakhdari_A/0/1/0/all/0/1"">Abdallah Lakhdari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bouguettaya_A/0/1/0/all/0/1"">Athman Bouguettaya</a>";Amani Abusafia,Abdallah Lakhdari,Athman Bouguettaya;Flow-Based Energy Services Composition;We propose a novel spatio-temporal service composition framework for crowdsourcing multiple IoT energy services to cater to multiple energy requests. We define a new energy service model to leverage the wearable-based energy and wireless power transfer technologies. We reformulate the problem of spatio-temporal service composition to provision multiple energy requests as a matching problem. We leverage the fragmented nature of energy to offer partial services to maximize the utilization of energy services. We propose EnergyFlowComp, a modified Maximum Flow matching algorithm that efficiently provisions IoT energy services to accommodate multiple energy requests. Moreover, we propose PartialFlowComp, an extension of the EnergyFlowComp approach that considers the partial-temporal overlap between services and requests in provisioning. We conduct an extensive set of experiments to assess the effectiveness and efficiency of the proposed framework.
2023.08.23.08.49.03;23.08.2023;03;02;Energy;Electricity, Smart Grid et al.;arxiv;2110.07000;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2110.07000.pdf;" <a href=""http://arxiv.org/find/math/1/au:+Lan_L/0/1/0/all/0/1"">Leon Lan</a>, <a href=""http://arxiv.org/find/math/1/au:+Zocca_A/0/1/0/all/0/1"">Alessandro Zocca</a>";Leon Lan,Alessandro Zocca;Mixed-integer linear programming approaches for tree partitioning of power networks;In transmission networks, power flows and network topology are deeply intertwined due to power flow physics. Recent literature shows that a specific more hierarchical network structure can effectively inhibit the propagation of line failures across the entire system. In particular, a novel approach named tree partitioning has been proposed, which seeks to bolster the robustness of power networks through strategic alterations in network topology, accomplished via targeted line switching actions. Several tree partitioning problem formulations have been proposed by considering different objectives, among which power flow disruption and network congestion. Furthermore, various heuristic methods based on a two-stage and recursive approach have been proposed. The present work provides a general framework for tree partitioning problems based on mixed-integer linear programming (MILP). In particular, we present a novel MILP formulation to optimally solve tree partitioning problems and also propose a two-stage heuristic based on MILP. We perform extensive numerical experiments to solve two tree partitioning problem variants, demonstrating the excellent performance of our solution methods. Lastly, through exhaustive cascading failure simulations, we compare the effectiveness of various tree partitioning strategies and show that, on average, they can achieve a substantial reduction in lost load compared to the original topologies.
2023.08.23.08.49.04;23.08.2023;04;02;Energy;Electricity, Smart Grid et al.;arxiv;2308.02921;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.02921.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Lara_J/0/1/0/all/0/1"">Jose Daniel Lara</a>, <a href=""http://arxiv.org/find/eess/1/au:+Henriquez_Auba_R/0/1/0/all/0/1"">Rodrigo Henriquez-Auba</a>, <a href=""http://arxiv.org/find/eess/1/au:+Bossart_M/0/1/0/all/0/1"">Matthew Bossart</a>, <a href=""http://arxiv.org/find/eess/1/au:+Callaway_D/0/1/0/all/0/1"">Duncan S. Callaway</a>, <a href=""http://arxiv.org/find/eess/1/au:+Barrows_C/0/1/0/all/0/1"">Clayton Barrows</a>";Jose Daniel Lara,Rodrigo Henriquez-Auba,Matthew Bossart,Duncan S. Callaway,Clayton Barrows;PowerSimulationsDynamics.jl -- An Open Source Modeling Package for Modern Power Systems with Inverter-Based Resources;The inclusion of inverter-based resources from renewable energy creates new challenges for the stability and transient behavior of power systems which are best understood by studying their dynamic responses through simulation. In this paper, we develop an open source simulation toolbox, PowerSimulationDynamics.jl, to study the dynamic response of a balanced system with high penetration of inverter-based resources. PowerSimulationDynamics.jl is implemented in the Julia language and features a rich library of synchronous generator components and inverter models. In addition, it allows the study of both quasi-static phasors that employ an admittance matrix representation for the network and electromagnetic dq models that use a dynamic representation of the network. Case studies and validation exercises show that PowerSimulationDynamics.jl results closely match Quasi-Static Phasor (QSP) tools like Siemens PSSe, ANDES, and wave-form Electro-magnetic Transient (EMT) simulations like PSCAD
2023.08.23.08.49.05;23.08.2023;05;07;Industry;I4.0, Production et al.;arxiv;2306.03691;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.03691.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1"">Gang Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1"">Tianyu Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xue_C/0/1/0/all/0/1"">Chuanyu Xue</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Jiachen Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Nixon_M/0/1/0/all/0/1"">Mark Nixon</a>, <a href=""http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1"">Song Han</a>";Gang Wang,Tianyu Zhang,Chuanyu Xue,Jiachen Wang,Mark Nixon,Song Han;Time-Sensitive Networking (TSN) for Industrial Automation: A Survey;With the introduction of Cyber-Physical Systems (CPS) and Internet of Things (IoT) into industrial applications, industrial automation is undergoing tremendous change, especially with regard to improving efficiency and reducing the cost of products. Industrial automation applications are often required to transmit time- and safety-critical data to monitor and control industrial processes, especially for critical control systems. There are a number of solutions to meet these requirements (e.g., priority-based real-time schedules and closed-loop feedback control systems). However, due to their different processing capabilities (e.g., in the end devices and network switches), different vendors may come out with distinct solutions, and this makes the large-scale integration of devices from different vendors difficult or impossible. IEEE 802.1 Time-Sensitive Networking (TSN) is a standardization group formed to enhance and optimize the IEEE 802.1 network standards, especially for Ethernet-based networks. These solutions can be evolved and adapted into a cross-industry scenario, such as a large-scale distributed industrial plant, which requires multiple industrial entities working collaboratively. This paper provides a comprehensive review on the current advances in TSN standards for industrial automation. We present the state-of-the-art IEEE TSN standards and discuss the opportunities and challenges when integrating each protocol into the industry domains. Finally, we discuss some promising research about applying the TSN technology to industrial automation applications.
2023.08.23.08.49.06;23.08.2023;06;12;Health;Health Care et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1454/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Applications of ChatGPT/GPT4 in Biological Studies, Medical and Dental Care;Chat generative pre-trained transformer (ChatGPT) is a developed language model and a subgroup of artificial intelligence (AI) which has demonstrated noticeable innovation in interactions between computer models and human studies. The release of ChatGPT in November 2022 attracted over 100 million users in a short time. It has unlimited applications in different fields of studies such as technology and science. ChatGPT utilizes deep learning and internet text to produce responses that resemble human language, although their accuracy is not always guaranteed. ChatGPT and GPT-4 can make a huge revolution in biology, medical, dental research, and health care. However, it's important to acknowledge the limitations of ChatGPT such as limitation in accessing the latest data. ChatGPT has generated both excitement and concern regarding its potential misuse. Its utilization in scientific publications has sparked debates and prompted the development of policies to govern the use of it. Although ChatGPT has certain limitations, it could impact on many different fields of study. There are challenges associated with using ChatGPT in the field of laboratory medicine and biology, particularly in the interpretation of test results. In this article, we review some of the applications of ChatGPT and GPT-4 in biology, dental and medical studies, and concerns about ChatGPT. Despite ChatGPT's conversational abilities are impressive, there are important considerations regarding its use in different fields of research and academic public.
2023.08.23.08.49.07;23.08.2023;07;12;Health;Health Care et al.;arxiv;2308.09731;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.09731.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Nazary_F/0/1/0/all/0/1"">Fatemeh Nazary</a>, <a href=""http://arxiv.org/find/cs/1/au:+Deldjoo_Y/0/1/0/all/0/1"">Yashar Deldjoo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1"">Tommaso Di Noia</a>";Fatemeh Nazary,Yashar Deldjoo,Tommaso Di Noia;ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based Healthcare Decision Support using ChatGPT;This study presents an innovative approach to the application of large language models (LLMs) in clinical decision-making, focusing on OpenAI's ChatGPT. Our approach introduces the use of contextual prompts-strategically designed to include task description, feature description, and crucially, integration of domain knowledge-for high-quality binary classification tasks even in data-scarce scenarios. The novelty of our work lies in the utilization of domain knowledge, obtained from high-performing interpretable ML models, and its seamless incorporation into prompt design. By viewing these ML models as medical experts, we extract key insights on feature importance to aid in decision-making processes. This interplay of domain knowledge and AI holds significant promise in creating a more insightful diagnostic tool. Additionally, our research explores the dynamics of zero-shot and few-shot prompt learning based on LLMs. By comparing the performance of OpenAI's ChatGPT with traditional supervised ML models in different data conditions, we aim to provide insights into the effectiveness of prompt engineering strategies under varied data availability. In essence, this paper bridges the gap between AI and healthcare, proposing a novel methodology for LLMs application in clinical decision support systems. It highlights the transformative potential of effective prompt design, domain knowledge integration, and flexible learning approaches in enhancing automated decision-making.
2023.08.23.08.49.08;23.08.2023;08;12;Health;Health Care et al.;arxiv;2301.00280;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2301.00280.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zomorodi_M/0/1/0/all/0/1"">Mariam Zomorodi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ghodsollahee_I/0/1/0/all/0/1"">Ismail Ghodsollahee</a>, <a href=""http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1"">Jennifer H. Martin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Talley_N/0/1/0/all/0/1"">Nicholas J. Talley</a>, <a href=""http://arxiv.org/find/cs/1/au:+Salari_V/0/1/0/all/0/1"">Vahid Salari</a>, <a href=""http://arxiv.org/find/cs/1/au:+Plawiak_P/0/1/0/all/0/1"">Pawel Plawiak</a>, <a href=""http://arxiv.org/find/cs/1/au:+Rahimi_K/0/1/0/all/0/1"">Kazem Rahimi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Acharya_U/0/1/0/all/0/1"">U. Rajendra Acharya</a>";Mariam Zomorodi,Ismail Ghodsollahee,Jennifer H. Martin,Nicholas J. Talley,Vahid Salari,Pawel Plawiak,Kazem Rahimi,U. Rajendra Acharya;RECOMED: A Comprehensive Pharmaceutical Recommendation System;A comprehensive pharmaceutical recommendation system was designed based on the patients and drugs features extracted from Drugs.com and Druglib.com. First, data from these databases were combined, and a dataset of patients and drug information was built. Secondly, the patients and drugs were clustered, and then the recommendation was performed using different ratings provided by patients, and importantly by the knowledge obtained from patients and drug specifications, and considering drug interactions. To the best of our knowledge, we are the first group to consider patients conditions and history in the proposed approach for selecting a specific medicine appropriate for that particular user. Our approach applies artificial intelligence (AI) models for the implementation. Sentiment analysis using natural language processing approaches is employed in pre-processing along with neural network-based methods and recommender system algorithms for modeling the system. In our work, patients conditions and drugs features are used for making two models based on matrix factorization. Then we used drug interaction to filter drugs with severe or mild interactions with other drugs. We developed a deep learning model for recommending drugs by using data from 2304 patients as a training set, and then we used data from 660 patients as our validation set. After that, we used knowledge from critical information about drugs and combined the outcome of the model into a knowledge-based system with the rules obtained from constraints on taking medicine.
2023.08.23.08.49.09;23.08.2023;09;16;Human Resource;Human Resource et al.;acm;;http://cacm.acm.org/browse-by-subject/artificial-intelligence.rss;http://cacm.acm.org/careers/275620-projects-will-explore-ai-augmented-management-and-productivity;Communications of the ACM: Artificial Intelligence;Communications of the ACM: Artificial Intelligence;Projects Will Explore AI-Augmented Management and Productivity;MIT's Stephen A. Schwarzman College of Computing has awarded seed grants to seven projects <https://computing.mit.edu/artificial-intelligence-for-augmentation-and-productivity-seed-grants/> that are exploring how artificial intelligence and human-computer interaction can be leveraged to enhance modern work spaces.
2023.08.23.08.49.10;23.08.2023;10;16;Human Resource;Human Resource et al.;arxiv;2303.10130;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2303.10130.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Eloundou_T/0/1/0/all/0/1"">Tyna Eloundou</a>, <a href=""http://arxiv.org/find/econ/1/au:+Manning_S/0/1/0/all/0/1"">Sam Manning</a>, <a href=""http://arxiv.org/find/econ/1/au:+Mishkin_P/0/1/0/all/0/1"">Pamela Mishkin</a>, <a href=""http://arxiv.org/find/econ/1/au:+Rock_D/0/1/0/all/0/1"">Daniel Rock</a>";Tyna Eloundou,Sam Manning,Pamela Mishkin,Daniel Rock;GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models;We investigate the potential implications of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.
2023.08.23.08.49.11;23.08.2023;11;17;AgriCulture;Agriculture et al.;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:ags:aaea22:335782&r=cmp;Badruddoza, SyedFuad, SyedAmin, Modhurima D.;Badruddoza, SyedFuad, SyedAmin, Modhurima D.;Comparative Effectiveness of Machine Learning Methods for Causal Inference in Agricultural Economics;
2023.08.23.08.49.12;23.08.2023;12;99;Other;Others;acm;;http://cacm.acm.org/browse-by-subject/artificial-intelligence.rss;http://cacm.acm.org/news/275606-google-tests-ai-assistant-that-offers-life-advice;Communications of the ACM: Artificial Intelligence;Communications of the ACM: Artificial Intelligence;Google Tests AI Assistant That Offers Life Advice;Google is testing generative artificial intelligence technology programmed to serve as a life coach.
2023.08.21.16.58.01;21.08.2023;01;01;GenAI;Large Language and Foundation Models, Multi Modal Models et al.;arxiv;2308.03333;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.03333.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1"">Bin Yin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1"">Junjie Xie</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1"">Yu Qin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1"">Zixiang Ding</a>, <a href=""http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1"">Zhichao Feng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1"">Xiang Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1"">Wei Lin</a>";Bin Yin,Junjie Xie,Yu Qin,Zixiang Ding,Zhichao Feng,Xiang Li,Wei Lin;Heterogeneous Knowledge Fusion: A Novel Approach for Personalized Recommendation via LLM;The analysis and mining of user heterogeneous behavior are of paramount importance in recommendation systems. However, the conventional approach of incorporating various types of heterogeneous behavior into recommendation models leads to feature sparsity and knowledge fragmentation issues. To address this challenge, we propose a novel approach for personalized recommendation via Large Language Model (LLM), by extracting and fusing heterogeneous knowledge from user heterogeneous behavior information. In addition, by combining heterogeneous knowledge and recommendation tasks, instruction tuning is performed on LLM for personalized recommendations. The experimental results demonstrate that our method can effectively integrate user heterogeneous behavior and significantly improve recommendation performance.
2023.08.21.16.58.02;21.08.2023;02;02;Energy;Electricity, Smart Grid et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2306.14186&r=big;Raffaele Sgarlato;Raffaele Sgarlato;Statistical electricity price forecasting: A structural approach;"The availability of historical data related to electricity day-ahead prices and to the underlying price formation process is limited. In addition, the electricity market in Europe is facing a rapid transformation, which limits the representativeness of older observations for predictive purposes. On the other hand, machine learning methods that gained traction also in the domain of electricity price forecasting typically require large amounts of data. This study analyses the effectiveness of encoding well-established domain knowledge to mitigate the need for large training datasets. The domain knowledge is incorporated by imposing a structure on the price forecasting problem; the resulting accuracy gains are quantified in an experiment. Compared to an ""unstructured"" purely statistical model, it is shown that introducing intermediate quantity forecasts of load, renewable infeed, and cross-border exchange, paired with the estimation of supply curves, can result in a NRMSE reduction by 0.1 during daytime hours. The statistically most significant improvements are achieved in the first day of the forecasting horizon when a purely statistical model is combined with structured models. Finally, results are evaluated and interpreted with regard to the dynamic market conditions observed in Europe during the experiment period (from the 1st October 2022 to the 30th April 2023), highlighting the adaptive nature of models that are trained on shorter timescales."
2023.08.21.16.58.03;21.08.2023;03;02;Energy;Electricity, Smart Grid et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1371/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Using Deep Neural Network methods for forecasting energy productivity based on comparison of simulation and DNN results for central Poland - Swietokrzyskie Voivodeship;Forecasting electricity demand is of utmost importance for ensuring the stability of the entire energy sector. However, predicting the future electricity demand and its value poses a formidable challenge due to the intricate nature of the processes influenced by renewable energy sources. Within this piece, we have meticulously explored the efficacy of fundamental deep-learning models designed for electricity forecasting. Among the deep learning models, we have innovatively crafted recursive neural networks (RNNs) predominantly based on LSTM and combined architectures. The data-set employed was procured from a SolarEdge designer. The data-set encompasses daily records spanning the past year, encompassing an exhaustive collection of parameters extracted from solar farm (based on location in Central Europe (Poland Swietokrzyskie Voivodeship)). The experimental findings unequivocally demonstrated the exceptional superiority of the LSTM models over other counterparts concerning forecasting accuracy. Consequently, we compared multilayer DNN architectures with results provided by the simulator.
2023.08.21.16.58.04;21.08.2023;04;02;Energy;Electricity, Smart Grid et al.;arxiv;2306.03859;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.03859.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Jongh_S/0/1/0/all/0/1"">Steven de Jongh</a>, <a href=""http://arxiv.org/find/eess/1/au:+Mueller_F/0/1/0/all/0/1"">Felicitas Mueller</a>, <a href=""http://arxiv.org/find/eess/1/au:+Canizares_C/0/1/0/all/0/1"">Claudio Ca&#xf1;izares</a>, <a href=""http://arxiv.org/find/eess/1/au:+Leibfried_T/0/1/0/all/0/1"">Thomas Leibfried</a>, <a href=""http://arxiv.org/find/eess/1/au:+Bhattacharya_K/0/1/0/all/0/1"">Kankar Bhattacharya</a>";Steven de Jongh,Felicitas Mueller,Claudio Cañizares,Thomas Leibfried,Kankar Bhattacharya;Parameter Estimation in Electrical Distribution Systems with limited Measurements using Regression Methods;This paper presents novel methods for parameter identification in electrical grids with small numbers of spatially distributed measuring devices, which is an issue for distribution system operators managing aged and not properly mapped underground Low Voltage (LV) grids, especially in Germany. For this purpose, the total impedance of individual branches of the overall system is estimated by measuring currents and voltages at a subset of all system nodes over time. It is shown that, under common assumptions for electrical distsribution systems, an estimate of the total impedance can be made using readily computable proxies. Different regression methods are then used and compared to estimate the total impedance of the respective branches, with varying weights of the input data. The results on realistic LV feeders with different branch lengths and number of unmeasured segments are discussed and multiple influencing factors are investigated through simulations. It is shown that estimates of the total impedances can be obtained with acceptable quality under realistic assumptions.
2023.08.21.16.58.05;21.08.2023;05;02;Energy;Electricity, Smart Grid et al.;arxiv;2108.04667;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2108.04667.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1"">Zhen Wang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Xi_K/0/1/0/all/0/1"">Kaihua Xi</a>, <a href=""http://arxiv.org/find/eess/1/au:+Cheng_A/0/1/0/all/0/1"">Aijie Cheng</a>, <a href=""http://arxiv.org/find/eess/1/au:+Lin_H/0/1/0/all/0/1"">Hai Xiang Lin</a>, <a href=""http://arxiv.org/find/eess/1/au:+Ran_A/0/1/0/all/0/1"">Andr&#xe9; C. M. Ran</a>, <a href=""http://arxiv.org/find/eess/1/au:+Schuppen_J/0/1/0/all/0/1"">Jan H. van Schuppen</a>, <a href=""http://arxiv.org/find/eess/1/au:+Zhang_C/0/1/0/all/0/1"">Chenghui Zhang</a>";Zhen Wang,Kaihua Xi,Aijie Cheng,Hai Xiang Lin,André C. M. Ran,Jan H. van Schuppen,Chenghui Zhang;Synchronization of Power Systems under Stochastic Disturbances;The synchronization of power generators is an important condition for the proper functioning of a power system, in which the fluctuations in frequency and the phase angle differences between the generators are sufficiently small when subjected to stochastic disturbances. Serious fluctuations can prompt desynchronization, which may lead to widespread power outages. Here, we model the stochastic disturbance by a Brownian motion process in the linearized system of the non-linear power systems and characterize the fluctuations by the variances of the frequency and the phase angle differences in the invariant probability distribution. We propose a method to calculate the variances of the frequency and the phase angle differences. For the system with uniform disturbance-damping ratio, we derive explicit formulas for the variance matrices of the frequency and the phase angle differences. It is shown that the fluctuation of the frequency at a node depends on the disturbance-damping ratio and the inertia at this node only, and the fluctuations of the phase angle differences in the lines are independent of the inertia. In particular, the synchronization stability is related to the cycle space of the network. We reveal the influences of constructing new lines and increasing capacities of lines on the fluctuations in the phase angle differences in the existing lines. The results are illustrated for the transmission system of Shandong Province of China. For the system with non-uniform disturbance-damping ratio, we further obtain bounds of the variance matrices.
2023.08.21.16.58.06;21.08.2023;06;02;Energy;Electricity, Smart Grid et al.;arxiv;2308.08611;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.08611.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wahid_A/0/1/0/all/0/1"">A. Wahid</a>, <a href=""http://arxiv.org/find/cs/1/au:+faiud_I/0/1/0/all/0/1"">I faiud</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mason_K/0/1/0/all/0/1"">K. Mason</a>";A. Wahid,I faiud,K. Mason;Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach;This article investigates the use of Deep Q-Networks (DQNs) to optimize decision-making for photovoltaic (PV) systems installations in the agriculture sector. The study develops a DQN framework to assist agricultural investors in making informed decisions considering factors such as installation budget, government incentives, energy requirements, system cost, and long-term benefits. By implementing a reward mechanism, the DQN learns to make data-driven decisions on PV integration. The analysis provides a comprehensive understanding of how DQNs can support investors in making decisions about PV installations in agriculture. This research has significant implications for promoting sustainable and efficient farming practices while also paving the way for future advancements in this field. By leveraging DQNs, agricultural investors can make optimized decisions that improve energy efficiency, reduce environmental impact, and enhance profitability. This study contributes to the advancement of PV integration in agriculture and encourages further innovation in this promising area.
2023.08.21.16.58.07;21.08.2023;07;04;Finance;Finance, DeFi et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2306.12659&r=big;Boyu ZhangHongyang YangXiao-Yang Liu;Boyu ZhangHongyang YangXiao-Yang Liu;Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models;Sentiment analysis is a vital tool for uncovering insights from financial articles, news, and social media, shaping our understanding of market movements. Despite the impressive capabilities of large language models (LLMs) in financial natural language processing (NLP), they still struggle with accurately interpreting numerical values and grasping financial context, limiting their effectiveness in predicting financial sentiment. In this paper, we introduce a simple yet effective instruction tuning approach to address these issues. By transforming a small portion of supervised financial sentiment analysis data into instruction data and fine-tuning a general-purpose LLM with this method, we achieve remarkable advancements in financial sentiment analysis. In the experiment, our approach outperforms state-of-the-art supervised sentiment analysis models, as well as widely used LLMs like ChatGPT and LLaMAs, particularly in scenarios where numerical understanding and contextual comprehension are vital.
2023.08.21.16.58.08;21.08.2023;08;04;Finance;Finance, DeFi et al.;arxiv;2308.08683;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2308.08683.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Li_H/0/1/0/all/0/1"">Haochen Li</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Polukarova_M/0/1/0/all/0/1"">Maria Polukarova</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Ventre_C/0/1/0/all/0/1"">Carmine Ventre</a>";Haochen Li,Maria Polukarova,Carmine Ventre;Detecting Financial Market Manipulation with Statistical Physics Tools;We take inspiration from statistical physics to develop a novel conceptual framework for the analysis of financial markets. We model the order book dynamics as a motion of particles and define the momentum measure of the system as a way to summarise and assess the state of the market. Our approach proves useful in capturing salient financial market phenomena: in particular, it helps detect the market manipulation activities called spoofing and layering. We apply our method to identify pathological order book behaviours during the flash crash of the LUNA cryptocurrency, uncovering widespread instances of spoofing and layering in the market. Furthermore, we establish that our technique outperforms the conventional Z-score-based anomaly detection method in identifying market manipulations across both LUNA and Bitcoin cryptocurrency markets.
2023.08.21.16.58.09;21.08.2023;09;07;Industry;I4.0, Production et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1398/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Optimizing Manufacturing Cycles for Advantage Production: Application in Shipyards Traditional industry;This article explores the important role of traditional shipyards in the global maritime industry, covering aspects of construction, repair, and maintenance. With the advent of faster manufacturing techniques, traditional shipyards face important challenges such as planning errors, coordination problems, delivery delays, and underutilization of technology, which results in high costs, reduced productivity, and prolonged projects. The application of Manufacturing Cycle Efficiency (MCE) emerged as an important solution to significantly increase production efficiency. MCE empowers shipyards to deal effectively with waste, bottlenecks, and disruptions, thereby increasing performance, competitiveness, and profitability. Using a comprehensive approach that uses both qualitative and quantitative methods, including field surveys, and in-depth interviews in the traditional shipyards industry, this research identifies Non-Value-Added (NVA) processes, conducts process mapping, and calculates MCE. The findings reported in this article underscore the significant wastage in the production process, indicating an urgent need for improvement, given the current average MCE value of 67.08%, indicating considerable room for improvement. This article provides innovative perspectives on optimizing the traditional shipyards industry through production cycle efficiencies while offering actionable recommendations. Key focus areas include integrating management systems, adopting advanced technologies, and implementing sustainable strategies to improve MCE, especially by reducing non-value-added time wastage, such as inspection and storage. By implementing strategies that optimize production, minimize waste, and overcome the challenges of global competition, this research contributes to improving MCE. In conclusion, this study is an invaluable guide for industry stakeholders, enabling them to enhance their competitiveness and adapt effectively to a dynamic business environment.
2023.08.21.16.58.10;21.08.2023;10;09;Commerce;Commerce, Trading, Sales, Recommendation et al.;arxiv;2308.08799;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.08799.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Jing_J/0/1/0/all/0/1"">Jiazheng Jing</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1"">Yinan Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1"">Xin Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1"">Zhiqi Shen</a>";Jiazheng Jing,Yinan Zhang,Xin Zhou,Zhiqi Shen;Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation;Recommender systems have been gaining increasing research attention over the years. Most existing recommendation methods focus on capturing users' personalized preferences through historical user-item interactions, which may potentially violate user privacy. Additionally, these approaches often overlook the significance of the temporal fluctuation in item popularity that can sway users' decision-making. To bridge this gap, we propose Popularity-Aware Recommender (PARE), which makes non-personalized recommendations by predicting the items that will attain the highest popularity. PARE consists of four modules, each focusing on a different aspect: popularity history, temporal impact, periodic impact, and side information. Finally, an attention layer is leveraged to fuse the outputs of four modules. To our knowledge, this is the first work to explicitly model item popularity in recommendation systems. Extensive experiments show that PARE performs on par or even better than sophisticated state-of-the-art recommendation methods. Since PARE prioritizes item popularity over personalized user preferences, it can enhance existing recommendation methods as a complementary component. Our experiments demonstrate that integrating PARE with existing recommendation methods significantly surpasses the performance of standalone models, highlighting PARE's potential as a complement to existing recommendation methods. Furthermore, the simplicity of PARE makes it immensely practical for industrial applications and a valuable baseline for future research.
2023.08.21.16.58.11;21.08.2023;11;09;Commerce;Commerce, Trading, Sales, Recommendation et al.;arxiv;2308.08821;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.08821.pdf;" <a href=""http://arxiv.org/find/quant-ph/1/au:+Cao_X/0/1/0/all/0/1"">Xiao-Yu Cao</a>, <a href=""http://arxiv.org/find/quant-ph/1/au:+Li_B/0/1/0/all/0/1"">Bing-Hong Li</a>, <a href=""http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1"">Yang Wang</a>, <a href=""http://arxiv.org/find/quant-ph/1/au:+Fu_Y/0/1/0/all/0/1"">Yao Fu</a>, <a href=""http://arxiv.org/find/quant-ph/1/au:+Yin_H/0/1/0/all/0/1"">Hua-Lei Yin</a>, <a href=""http://arxiv.org/find/quant-ph/1/au:+Chen_Z/0/1/0/all/0/1"">Zeng-Bing Chen</a>";Xiao-Yu Cao,Bing-Hong Li,Yang Wang,Yao Fu,Hua-Lei Yin,Zeng-Bing Chen;Experimental quantum e-commerce;E-commerce, a type of trading that occurs at a high frequency on the Internet, requires guaranteeing the integrity, authentication and non-repudiation of messages through long distance. As current e-commerce schemes are vulnerable to computational attacks, quantum cryptography, ensuring information-theoretic security against adversary's repudiation and forgery, provides a solution to this problem. However, quantum solutions generally have much lower performance compared to classical ones. Besides, when considering imperfect devices, the performance of quantum schemes exhibits a significant decline. Here, for the first time, we demonstrate the whole e-commerce process of involving the signing of a contract and payment among three parties by proposing a quantum e-commerce scheme, which shows resistance of attacks from imperfect devices. Results show that with a maximum attenuation of 25 dB among participants, our scheme can achieve a signature rate of 0.82 times per second for an agreement size of approximately 0.428 megabit. This proposed scheme presents a promising solution for providing information-theoretic security for e-commerce.
2023.08.21.16.58.12;21.08.2023;12;12;Health;Health Care et al.;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:dar:wpaper:138523&r=big;Pumplun, LuisaPeters, FelixGawlitza, JoshuaBuxmann, Peter;Pumplun, LuisaPeters, FelixGawlitza, JoshuaBuxmann, Peter;Bringing Machine Learning Systems into Clinical Practice: A Design Science Approach to Explainable Machine Learning-Based Clinical Decision Support Systems;
2023.08.21.16.58.13;21.08.2023;13;12;Health;Health Care et al.;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1356/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Mapping a Model for Collaboration of Health Care Facilities, Diagnostic Laboratories, and Research Institutions: Management of Drug Resistant Tuberculosis in Rural Eastern Cape;Infectious illnesses have always posed a threat to human health, with tuberculosis being a major concern. The use of various medications and antibiotics in the fight against such TB has led to the emergence of drug-resistant tuberculosis, which has become increasingly difficult to manage. While there have been a few studies and proposed conceptual models on how to manage and prevent various drug-resistant TB mutations and lineages, a model aimed at limiting and con-trolling such mutations in rural areas burdened with tuberculosis is lacking. This study seeks to map a model that is to be used to bridge the gap by facilitating the exchange of knowledge among healthcare professionals in healthcare facilities, diagnostic laboratories, and research institutes, particularly for underprivileged communities in the Eastern Cape. The model will also serve as a guide to monitor and evaluate epidemiological TB management plans.
2023.08.21.16.58.14;21.08.2023;14;12;Health;Health Care et al.;arxiv;2111.04456;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2111.04456.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Okolo_C/0/1/0/all/0/1"">Chinasa T. Okolo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Amador_M/0/1/0/all/0/1"">Michelle Gonz&#xe1;lez Amador</a>";Chinasa T. Okolo,Michelle González Amador;ACIPS: A Framework for Evaluating Patient Perception in the Introduction of AI-Enabled Healthcare;In healthcare, the role of AI is continually evolving and understanding the challenges its introduction poses on relationships between healthcare providers and patients will require a regulatory and behavioural approach that can provide a guiding base for all users involved. In this paper, we present ACIPS (Acceptability, Comfortability, Informed Consent, Privacy, and Security), a framework for evaluating patient response to the introduction of AI-enabled digital technologies in healthcare settings. We justify the need for ACIPS with a general introduction of the challenges with and perceived relevance of AI in human-welfare centered fields, with an emphasis on the provision of healthcare. The framework is composed of five principles that measure the perceptions of acceptability, comfortability, informed consent, privacy, and security patients hold when learning how AI is used in their healthcare. We propose that the tenets composing this framework can be translated into guidelines outlining the proper use of AI in healthcare while broadening the limited understanding of this topic.
2023.08.21.16.58.15;21.08.2023;15;12;Health;Health Care et al.;arxiv;2211.07643;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2211.07643.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hennebelle_A/0/1/0/all/0/1"">Alain Hennebelle</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ismail_L/0/1/0/all/0/1"">Leila Ismail</a>, <a href=""http://arxiv.org/find/cs/1/au:+Materwala_H/0/1/0/all/0/1"">Huned Materwala</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kaabi_J/0/1/0/all/0/1"">Juma Al Kaabi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ranjan_P/0/1/0/all/0/1"">Priya Ranjan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Janardhanan_R/0/1/0/all/0/1"">Rajiv Janardhanan</a>";Alain Hennebelle,Leila Ismail,Huned Materwala,Juma Al Kaabi,Priya Ranjan,Rajiv Janardhanan;Secure and Privacy-Preserving Automated Machine Learning Operations into End-to-End Integrated IoT-Edge-Artificial Intelligence-Blockchain Monitoring System for Diabetes Mellitus Prediction;Diabetes Mellitus, one of the leading causes of death worldwide, has no cure to date and can lead to severe health complications, such as retinopathy, limb amputation, cardiovascular diseases, and neuronal disease, if left untreated. Consequently, it becomes crucial to take precautionary measures to avoid/predict the occurrence of diabetes. Machine learning approaches have been proposed and evaluated in the literature for diabetes prediction. This paper proposes an IoT-edge-Artificial Intelligence (AI)-blockchain system for diabetes prediction based on risk factors. The proposed system is underpinned by the blockchain to obtain a cohesive view of the risk factors data from patients across different hospitals and to ensure security and privacy of the user's data. Furthermore, we provide a comparative analysis of different medical sensors, devices, and methods to measure and collect the risk factors values in the system. Numerical experiments and comparative analysis were carried out between our proposed system, using the most accurate random forest (RF) model, and the two most used state-of-the-art machine learning approaches, Logistic Regression (LR) and Support Vector Machine (SVM), using three real-life diabetes datasets. The results show that the proposed system using RF predicts diabetes with 4.57% more accuracy on average compared to LR and SVM, with 2.87 times more execution time. Data balancing without feature selection does not show significant improvement. The performance is improved by 1.14% and 0.02% after feature selection for PIMA Indian and Sylhet datasets respectively, while it reduces by 0.89% for MIMIC III.
2023.08.21.16.58.16;21.08.2023;16;12;Health;Health Care et al.;arxiv;2308.08556;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.08556.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Luz_S/0/1/0/all/0/1"">Saturnino Luz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Masoodian_M/0/1/0/all/0/1"">Masood Masoodian</a>";Saturnino Luz,Masood Masoodian;Causally Linking Health Application Data and Personal Information Management Tools;The proliferation of consumer health devices such as smart watches, sleep monitors, smart scales, etc, in many countries, has not only led to growing interest in health monitoring, but also to the development of a countless number of ``smart'' applications to support the exploration of such data by members of the general public, sometimes with integration into professional health services. While a variety of health data streams has been made available by such devices to users, these streams are often presented as separate time-series visualizations, in which the potential relationships between health variables are not explicitly made visible. Furthermore, despite the fact that other aspects of life, such as work and social connectivity, have become increasingly digitised, health and well-being applications make little use of the potentially useful contextual information provided by widely used personal information management tools, such as shared calendar and email systems. This paper presents a framework for the integration of these diverse data sources, analytic and visualization tools, with inference methods and graphical user interfaces to help users by highlighting causal connections among such time-series.
2023.08.21.16.58.17;21.08.2023;17;13;Customer Relation;Management, Service et al.;schweitzer-online;;;https://www.schweitzer-online.de/ebook/Sheth/Artificial-Intelligence-Customer-Service/9783031338984/A67732128/;;;Artificial Intelligence in Customer Service;This edited volume elucidates how artificial intelligence (AI) can enable customer service to achieve higher customer engagement, superior user experiences, and increased well-being among customers and employees. As customer expectations dictate 24/7 availability from service departments and market pressures call for lower costs with higher efficiency, businesses have accepted that AI is vital in maintaining customer satisfaction. Yet, firms face tough challenges in choosing the right tool, optimizing integration, and striking the appropriate balance between AI systems and human efforts. In this context, chapters in this book capture the latest advancements in AI-enabled customer service through real-world examples. This volume offers a global perspective on this contemporary issue, covering topics such as the use of AI in enhancing customer well-being, data and technology integration, and customer engagement.
2023.08.21.16.58.18;21.08.2023;18;15;Control;Control, Planning, Collaboration et al.;arxiv;2308.08792;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.08792.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Qian_J/0/1/0/all/0/1"">Junkai Qian</a>, <a href=""http://arxiv.org/find/eess/1/au:+Jiang_Y/0/1/0/all/0/1"">Yuning Jiang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1"">Xin Liu</a>, <a href=""http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1"">Qing Wang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1"">Ting Wang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1"">Yuanming Shi</a>, <a href=""http://arxiv.org/find/eess/1/au:+Chen_W/0/1/0/all/0/1"">Wei Chen</a>";Junkai Qian,Yuning Jiang,Xin Liu,Qing Wang,Ting Wang,Yuanming Shi,Wei Chen;Federated Reinforcement Learning for Electric Vehicles Charging Control on Distribution Networks;With the growing popularity of electric vehicles (EVs), maintaining power grid stability has become a significant challenge. To address this issue, EV charging control strategies have been developed to manage the switch between vehicle-to-grid (V2G) and grid-to-vehicle (G2V) modes for EVs. In this context, multi-agent deep reinforcement learning (MADRL) has proven its effectiveness in EV charging control. However, existing MADRL-based approaches fail to consider the natural power flow of EV charging/discharging in the distribution network and ignore driver privacy. To deal with these problems, this paper proposes a novel approach that combines multi-EV charging/discharging with a radial distribution network (RDN) operating under optimal power flow (OPF) to distribute power flow in real time. A mathematical model is developed to describe the RDN load. The EV charging control problem is formulated as a Markov Decision Process (MDP) to find an optimal charging control strategy that balances V2G profits, RDN load, and driver anxiety. To effectively learn the optimal EV charging control strategy, a federated deep reinforcement learning algorithm named FedSAC is further proposed. Comprehensive simulation results demonstrate the effectiveness and superiority of our proposed algorithm in terms of the diversity of the charging control strategy, the power fluctuations on RDN, the convergence efficiency, and the generalization ability.
2023.08.21.16.58.19;21.08.2023;19;16;Human Resource;Human Resource et al.;arxiv;2308.08582;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.08582.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Maghsoudi_M/0/1/0/all/0/1"">Mehrdad Maghsoudi</a>";Mehrdad Maghsoudi;Uncovering the Skillsets Required in Computer Science Jobs Using Social Network Analysis;The rapid growth of technology and computer science, which has led to a surge in demand for skilled professionals in this field. The skill set required for computer science jobs has evolved rapidly, creating challenges for those already in the workforce who need to adapt their skills quickly to meet industry demands. To stay ahead of the curve, it is essential to understand the hottest skills needed in the field. The article introduces a new method for analyzing job advertisements using social network analysis to identify the most critical skills required by employers in the market. In this research, to form the communication network of skills, first 5763 skills were collected from the LinkedIn social network, then the relationship between skills was collected and searched in 7777 computer science job advertisements, and finally, the balanced communication network of skills was formed. The study analyzes the formed communication network of skills in the computer science job market and identifies four distinct communities of skills: Generalists, Infrastructure and Security, Software Development, and Embedded Systems. The findings reveal that employers value both hard and soft skills, such as programming languages and teamwork. Communication skills were found to be the most important skill in the labor market. Additionally, certain skills were highlighted based on their centrality indices, including communication, English, SQL, Git, and business skills, among others. The study provides valuable insights into the current state of the computer science job market and can help guide individuals and organizations in making informed decisions about skills acquisition and hiring practices.
2023.08.21.16.58.20;21.08.2023;20;16;Human Resource;Human Resource et al.;arxiv;2308.08776;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.08776.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Chen_Q/0/1/0/all/0/1"">Qin Chen</a>, <a href=""http://arxiv.org/find/econ/1/au:+Ge_J/0/1/0/all/0/1"">Jinfeng Ge</a>, <a href=""http://arxiv.org/find/econ/1/au:+Xie_H/0/1/0/all/0/1"">Huaqing Xie</a>, <a href=""http://arxiv.org/find/econ/1/au:+Xu_X/0/1/0/all/0/1"">Xingcheng Xu</a>, <a href=""http://arxiv.org/find/econ/1/au:+Yang_Y/0/1/0/all/0/1"">Yanqing Yang</a>";Qin Chen,Jinfeng Ge,Huaqing Xie,Xingcheng Xu,Yanqing Yang;Large Language Models at Work in China's Labor Market;This paper explores the potential impacts of large language models (LLMs) on the Chinese labor market. We analyze occupational exposure to LLM capabilities by incorporating human expertise and LLM classifications, following Eloundou et al. (2023)'s methodology. We then aggregate occupation exposure to the industry level to obtain industry exposure scores. The results indicate a positive correlation between occupation exposure and wage levels/experience premiums, suggesting higher-paying and experience-intensive jobs may face greater displacement risks from LLM-powered software. The industry exposure scores align with expert assessments and economic intuitions. We also develop an economic growth model incorporating industry exposure to quantify the productivity-employment trade-off from AI adoption. Overall, this study provides an analytical basis for understanding the labor market impacts of increasingly capable AI systems in China. Key innovations include the occupation-level exposure analysis, industry aggregation approach, and economic modeling incorporating AI adoption and labor market effects. The findings will inform policymakers and businesses on strategies for maximizing the benefits of AI while mitigating adverse disruption risks.
2023.08.19.16.21.01;19.08.2023;01;01;Foundation Models;Foundation Models;arxiv;2308.08031;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2308.08031.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Vamvourellis_D/0/1/0/all/0/1"">Dimitrios Vamvourellis</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Toth_M/0/1/0/all/0/1"">M&#xe1;t&#xe9; Toth</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Bhagat_S/0/1/0/all/0/1"">Snigdha Bhagat</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Desai_D/0/1/0/all/0/1"">Dhruv Desai</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Mehta_D/0/1/0/all/0/1"">Dhagash Mehta</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Pasquali_S/0/1/0/all/0/1"">Stefano Pasquali</a>";Dimitrios Vamvourellis,Máté Toth,Snigdha Bhagat,Dhruv Desai,Dhagash Mehta,Stefano Pasquali;Company Similarity using Large Language Models;Identifying companies with similar profiles is a core task in finance with a wide range of applications in portfolio construction, asset pricing and risk attribution. When a rigorous definition of similarity is lacking, financial analysts usually resort to 'traditional' industry classifications such as Global Industry Classification System (GICS) which assign a unique category to each company at different levels of granularity. Due to their discrete nature, though, GICS classifications do not allow for ranking companies in terms of similarity. In this paper, we explore the ability of pre-trained and finetuned large language models (LLMs) to learn company embeddings based on the business descriptions reported in SEC filings. We show that we can reproduce GICS classifications using the embeddings as features. We also benchmark these embeddings on various machine learning and financial metrics and conclude that the companies that are similar according to the embeddings are also similar in terms of financial performance metrics including return correlation.
2023.08.19.16.21.02;19.08.2023;02;01;Foundation Models;Foundation Models;arxiv;2308.08155;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.08155.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1"">Qingyun Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bansal_G/0/1/0/all/0/1"">Gagan Bansal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1"">Jieyu Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1"">Yiran Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1"">Shaokun Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_E/0/1/0/all/0/1"">Erkang Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1"">Beibin Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1"">Li Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1"">Xiaoyun Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1"">Chi Wang</a>";Qingyun Wu,Gagan Bansal,Jieyu Zhang,Yiran Wu,Shaokun Zhang,Erkang Zhu,Beibin Li,Li Jiang,Xiaoyun Zhang,Chi Wang;AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework;"This technical report presents AutoGen, a new framework that enables development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools. AutoGen's design offers multiple advantages: a) it gracefully navigates the strong but imperfect generation and reasoning abilities of these LLMs; b) it leverages human understanding and intelligence, while providing valuable automation through conversations between agents; c) it simplifies and unifies the implementation of complex LLM workflows as automated agent chats. We provide many diverse examples of how developers can easily use AutoGen to effectively solve tasks or build applications, ranging from coding, mathematics, operations research, entertainment, online decision-making, question answering, etc."
2023.08.19.16.21.03;19.08.2023;03;01;Foundation Models;Foundation Models;medium;;http://medium.com/feed/towards-artificial-intelligence;https://pub.towardsai.net/gorilla-enhancing-large-language-models-ability-to-use-api-calls-1975d223d7c3?source=rss----98111c9905da---4;Marcello Politi;Marcello Politi;Gorilla —  Enhancing Large Language Models’ Ability to Use API Calls;<https://pub.towardsai.net/gorilla-enhancing-large-language-models-ability-to-use-api-calls-1975d223d7c3?source=rss----98111c9905da---4> A Finetuned LLaMA-based Model to Improve LLMs’ API Call Accuracy and Adaptability Continue reading on Towards AI » <https://pub.towardsai.net/gorilla-enhancing-large-language-models-ability-to-use-api-calls-1975d223d7c3?source=rss----98111c9905da---4>
2023.08.19.16.21.04;19.08.2023;04;01;Foundation Models;Foundation Models;arxiv;2308.06502;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06502.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Platek_O/0/1/0/all/0/1"">Ond&#x159;ej Pl&#xe1;tek</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hudecek_V/0/1/0/all/0/1"">Vojt&#x11b;ch Hude&#x10d;ek</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schmidtova_P/0/1/0/all/0/1"">Patricia Schmidtov&#xe1;</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lango_M/0/1/0/all/0/1"">Mateusz Lango</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1"">Ond&#x159;ej Du&#x161;ek</a>";"Ondřej Plátek,Vojt&#x11b;ch Hude&#x10d;ek,Patricia Schmidtová,Mateusz Lango,Ond&#x159;ej Du&#x161;ek";Three Ways of Using Large Language Models to Evaluate Chat;This paper describes the systems submitted by team6 for ChatEval, the DSTC 11 Track 4 competition. We present three different approaches to predicting turn-level qualities of chatbot responses based on large language models (LLMs). We report improvement over the baseline using dynamic few-shot examples from a vector store for the prompts for ChatGPT. We also analyze the performance of the other two approaches and report needed improvements for future work. We developed the three systems over just two weeks, showing the potential of LLMs for this task. An ablation study conducted after the challenge deadline shows that the new Llama 2 models are closing the performance gap between ChatGPT and open-source LLMs. However, we find that the Llama 2 models do not benefit from few-shot examples in the same way as ChatGPT.
2023.08.19.16.21.05;19.08.2023;05;01;Foundation Models;Foundation Models;arxiv;2308.06111;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06111.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Hillebrand_L/0/1/0/all/0/1"">Lars Hillebrand</a>, <a href=""http://arxiv.org/find/cs/1/au:+Berger_A/0/1/0/all/0/1"">Armin Berger</a>, <a href=""http://arxiv.org/find/cs/1/au:+Deusser_T/0/1/0/all/0/1"">Tobias Deu&#xdf;er</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dilmaghani_T/0/1/0/all/0/1"">Tim Dilmaghani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Khaled_M/0/1/0/all/0/1"">Mohamed Khaled</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kliem_B/0/1/0/all/0/1"">Bernd Kliem</a>, <a href=""http://arxiv.org/find/cs/1/au:+Loitz_R/0/1/0/all/0/1"">R&#xfc;diger Loitz</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pielka_M/0/1/0/all/0/1"">Maren Pielka</a>, <a href=""http://arxiv.org/find/cs/1/au:+Leonhard_D/0/1/0/all/0/1"">David Leonhard</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bauckhage_C/0/1/0/all/0/1"">Christian Bauckhage</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sifa_R/0/1/0/all/0/1"">Rafet Sifa</a>";Lars Hillebrand,Armin Berger,Tobias Deußer,Tim Dilmaghani,Mohamed Khaled,Bernd Kliem,Rüdiger Loitz,Maren Pielka,David Leonhard,Christian Bauckhage,Rafet Sifa;Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models;Auditing financial documents is a very tedious and time-consuming process. As of today, it can already be simplified by employing AI-based solutions to recommend relevant text passages from a report for each legal requirement of rigorous accounting standards. However, these methods need to be fine-tuned regularly, and they require abundant annotated data, which is often lacking in industrial environments. Hence, we present ZeroShotALI, a novel recommender system that leverages a state-of-the-art large language model (LLM) in conjunction with a domain-specifically optimized transformer-based text-matching solution. We find that a two-step approach of first retrieving a number of best matching document sections per legal requirement with a custom BERT-based model and second filtering these selections using an LLM yields significant performance improvements over existing approaches.
2023.08.19.16.21.06;19.08.2023;06;01;Foundation Models;Foundation Models;arxiv;2308.06907;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2308.06907.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Arbel_Y/0/1/0/all/0/1"">Yonathan A. Arbel</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hoffman_D/0/1/0/all/0/1"">David Hoffman</a>";Yonathan A. Arbel,David Hoffman;Generative Interpretation;We introduce generative interpretation, a new approach to estimating contractual meaning using large language models. As AI triumphalism is the order of the day, we proceed by way of grounded case studies, each illustrating the capabilities of these novel tools in distinct ways. Taking well-known contracts opinions, and sourcing the actual agreements that they adjudicated, we show that AI models can help factfinders ascertain ordinary meaning in context, quantify ambiguity, and fill gaps in parties' agreements. We also illustrate how models can calculate the probative value of individual pieces of extrinsic evidence. After offering best practices for the use of these models given their limitations, we consider their implications for judicial practice and contract theory. Using LLMs permits courts to estimate what the parties intended cheaply and accurately, and as such generative interpretation unsettles the current interpretative stalemate. Their use responds to efficiency-minded textualists and justice-oriented contextualists, who argue about whether parties will prefer cost and certainty or accuracy and fairness. Parties--and courts--would prefer a middle path, in which adjudicators strive to predict what the contract really meant, admitting just enough context to approximate reality while avoiding unguided and biased assimilation of evidence. As generative interpretation offers this possibility, we argue it can become the new workhorse of contractual interpretation.
2023.08.19.16.21.07;19.08.2023;07;01;Foundation Models;Foundation Models;arxiv;2308.06507;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06507.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1"">Siheng Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1"">Cheng Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1"">Yichun Yin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1"">Xinyu Zhu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1"">Zesen Cheng</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1"">Lifeng Shang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1"">Xin Jiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1"">Qun Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"">Yujiu Yang</a>";Siheng Li,Cheng Yang,Yichun Yin,Xinyu Zhu,Zesen Cheng,Lifeng Shang,Xin Jiang,Qun Liu,Yujiu Yang;AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models;Information-seeking conversation, which aims to help users gather information through conversation, has achieved great progress in recent years. However, the research is still stymied by the scarcity of training data. To alleviate this problem, we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM). Specifically, we formulate the conversation generation problem as a language modeling task, then finetune an LLM with a few human conversations to capture the characteristics of the information-seeking process and use it for generating synthetic conversations with high quality. Experimental results on two frequently-used datasets verify that AutoConv has substantial improvements over strong baselines and alleviates the dependence on human annotation. In addition, we also provide several analysis studies to promote future research.
2023.08.19.16.21.08;19.08.2023;08;01;Foundation Models;Foundation Models;arxiv;2308.06610;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06610.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Robinson_A/0/1/0/all/0/1"">Ambrose Robinson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Thorne_W/0/1/0/all/0/1"">William Thorne</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1"">Ben P. Wu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Pandor_A/0/1/0/all/0/1"">Abdullah Pandor</a>, <a href=""http://arxiv.org/find/cs/1/au:+Essat_M/0/1/0/all/0/1"">Munira Essat</a>, <a href=""http://arxiv.org/find/cs/1/au:+Stevenson_M/0/1/0/all/0/1"">Mark Stevenson</a>, <a href=""http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1"">Xingyi Song</a>";Ambrose Robinson,William Thorne,Ben P. Wu,Abdullah Pandor,Munira Essat,Mark Stevenson,Xingyi Song;Bio-SIEVE: Exploring Instruction Tuning Large Language Models for Systematic Review Automation;Medical systematic reviews can be very costly and resource intensive. We explore how Large Language Models (LLMs) can support and be trained to perform literature screening when provided with a detailed set of selection criteria. Specifically, we instruction tune LLaMA and Guanaco models to perform abstract screening for medical systematic reviews. Our best model, Bio-SIEVE, outperforms both ChatGPT and trained traditional approaches, and generalises better across medical domains. However, there remains the challenge of adapting the model to safety-first scenarios. We also explore the impact of multi-task training with Bio-SIEVE-Multi, including tasks such as PICO extraction and exclusion reasoning, but find that it is unable to match single-task Bio-SIEVE's performance. We see Bio-SIEVE as an important step towards specialising LLMs for the biomedical systematic review process and explore its future developmental opportunities. We release our models, code and a list of DOIs to reconstruct our dataset for reproducibility.
2023.08.19.16.21.09;19.08.2023;09;01;Foundation Models;Foundation Models;arxiv;2308.06668;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06668.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1"">Jiajia Li</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1"">Mingle Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1"">Lirong Xiang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1"">Dong Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1"">Weichao Zhuang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1"">Xunyuan Yin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1"">Zhaojian Li</a>";Jiajia Li,Mingle Xu,Lirong Xiang,Dong Chen,Weichao Zhuang,Xunyuan Yin,Zhaojian Li;Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges;The past decade has witnessed the rapid development of ML and DL methodologies in agricultural systems, showcased by great successes in variety of agricultural applications. However, these conventional ML/DL models have certain limitations: They heavily rely on large, costly-to-acquire labeled datasets for training, require specialized expertise for development and maintenance, and are mostly tailored for specific tasks, thus lacking generalizability. Recently, foundation models have demonstrated remarkable successes in language and vision tasks across various domains. These models are trained on a vast amount of data from multiple domains and modalities. Once trained, they can accomplish versatile tasks with just minor fine-tuning and minimal task-specific labeled data. Despite their proven effectiveness and huge potential, there has been little exploration of applying FMs to agriculture fields. Therefore, this study aims to explore the potential of FMs in the field of smart agriculture. In particular, we present conceptual tools and technical background to facilitate the understanding of the problem space and uncover new research directions in this field. To this end, we first review recent FMs in the general computer science domain and categorize them into four categories: language FMs, vision FMs, multimodal FMs, and reinforcement learning FMs. Subsequently, we outline the process of developing agriculture FMs and discuss their potential applications in smart agriculture. We also discuss the unique challenges associated with developing AFMs, including model training, validation, and deployment. Through this study, we contribute to the advancement of AI in agriculture by introducing AFMs as a promising paradigm that can significantly mitigate the reliance on extensive labeled datasets and enhance the efficiency, effectiveness, and generalization of agricultural AI systems.
2023.08.19.16.21.10;19.08.2023;10;01;Foundation Models;Foundation Models;arxiv;2308.06272;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06272.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chamola_V/0/1/0/all/0/1"">Vinay Chamola</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bansal_G/0/1/0/all/0/1"">Gaurang Bansal</a>, <a href=""http://arxiv.org/find/cs/1/au:+Das_T/0/1/0/all/0/1"">Tridib Kumar Das</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hassija_V/0/1/0/all/0/1"">Vikas Hassija</a>, <a href=""http://arxiv.org/find/cs/1/au:+Reddy_N/0/1/0/all/0/1"">Naga Siva Sai Reddy</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1"">Jiacheng Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zeadally_S/0/1/0/all/0/1"">Sherali Zeadally</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hussain_A/0/1/0/all/0/1"">Amir Hussain</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1"">F. Richard Yu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1"">Mohsen Guizani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1"">Dusit Niyato</a>";Vinay Chamola,Gaurang Bansal,Tridib Kumar Das,Vikas Hassija,Naga Siva Sai Reddy,Jiacheng Wang,Sherali Zeadally,Amir Hussain,F. Richard Yu,Mohsen Guizani,Dusit Niyato;Beyond Reality: The Pivotal Role of Generative AI in the Metaverse;Imagine stepping into a virtual world that's as rich, dynamic, and interactive as our physical one. This is the promise of the Metaverse, and it's being brought to life by the transformative power of Generative Artificial Intelligence (AI). This paper offers a comprehensive exploration of how generative AI technologies are shaping the Metaverse, transforming it into a dynamic, immersive, and interactive virtual world. We delve into the applications of text generation models like ChatGPT and GPT-3, which are enhancing conversational interfaces with AI-generated characters. We explore the role of image generation models such as DALL-E and MidJourney in creating visually stunning and diverse content. We also examine the potential of 3D model generation technologies like Point-E and Lumirithmic in creating realistic virtual objects that enrich the Metaverse experience. But the journey doesn't stop there. We also address the challenges and ethical considerations of implementing these technologies in the Metaverse, offering insights into the balance between user control and AI automation. This paper is not just a study, but a guide to the future of the Metaverse, offering readers a roadmap to harnessing the power of generative AI in creating immersive virtual worlds.
2023.08.19.16.21.11;19.08.2023;11;01;Foundation Models;Foundation Models;arxiv;2308.06354;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06354.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Guevara_M/0/1/0/all/0/1"">Marco Guevara</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1"">Shan Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1"">Spencer Thomas</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chaunzwa_T/0/1/0/all/0/1"">Tafadzwa L. Chaunzwa</a>, <a href=""http://arxiv.org/find/cs/1/au:+Franco_I/0/1/0/all/0/1"">Idalid Franco</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kann_B/0/1/0/all/0/1"">Benjamin Kann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Moningi_S/0/1/0/all/0/1"">Shalini Moningi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1"">Jack Qian</a>, <a href=""http://arxiv.org/find/cs/1/au:+Goldstein_M/0/1/0/all/0/1"">Madeleine Goldstein</a>, <a href=""http://arxiv.org/find/cs/1/au:+Harper_S/0/1/0/all/0/1"">Susan Harper</a>, <a href=""http://arxiv.org/find/cs/1/au:+Aerts_H/0/1/0/all/0/1"">Hugo JWL Aerts</a>, <a href=""http://arxiv.org/find/cs/1/au:+Savova_G/0/1/0/all/0/1"">Guergana K. Savova</a>, <a href=""http://arxiv.org/find/cs/1/au:+Mak_R/0/1/0/all/0/1"">Raymond H. Mak</a>, <a href=""http://arxiv.org/find/cs/1/au:+Bitterman_D/0/1/0/all/0/1"">Danielle S. Bitterman</a>";Marco Guevara,Shan Chen,Spencer Thomas,Tafadzwa L. Chaunzwa,Idalid Franco,Benjamin Kann,Shalini Moningi,Jack Qian,Madeleine Goldstein,Susan Harper,Hugo JWL Aerts,Guergana K. Savova,Raymond H. Mak,Danielle S. Bitterman;Large Language Models to Identify Social Determinants of Health in Electronic Health Records;Social determinants of health (SDoH) have an important impact on patient outcomes but are incompletely collected from the electronic health records (EHR). This study researched the ability of large language models to extract SDoH from free text in EHRs, where they are most commonly documented, and explored the role of synthetic clinical text for improving the extraction of these scarcely documented, yet extremely valuable, clinical data. 800 patient notes were annotated for SDoH categories, and several transformer-based models were evaluated. The study also experimented with synthetic data generation and assessed for algorithmic bias. Our best-performing models were fine-tuned Flan-T5 XL (macro-F1 0.71) for any SDoH, and Flan-T5 XXL (macro-F1 0.70). The benefit of augmenting fine-tuning with synthetic data varied across model architecture and size, with smaller Flan-T5 models (base and large) showing the greatest improvements in performance (delta F1 +0.12 to +0.23). Model performance was similar on the in-hospital system dataset but worse on the MIMIC-III dataset. Our best-performing fine-tuned models outperformed zero- and few-shot performance of ChatGPT-family models for both tasks. These fine-tuned models were less likely than ChatGPT to change their prediction when race/ethnicity and gender descriptors were added to the text, suggesting less algorithmic bias (p<0.05). At the patient-level, our models identified 93.8% of patients with adverse SDoH, while ICD-10 codes captured 2.0%. Our method can effectively extracted SDoH information from clinic notes, performing better compare to GPT zero- and few-shot settings. These models could enhance real-world evidence on SDoH and aid in identifying patients needing social support.
2023.08.19.16.21.12;19.08.2023;12;01;Foundation Models;Foundation Models;arxiv;2308.06391;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.06391.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Dagan_G/0/1/0/all/0/1"">Gautier Dagan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Keller_F/0/1/0/all/0/1"">Frank Keller</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lascarides_A/0/1/0/all/0/1"">Alex Lascarides</a>";Gautier Dagan,Frank Keller,Alex Lascarides;Dynamic Planning with a LLM;While Large Language Models (LLMs) can solve many NLP tasks in zero-shot settings, applications involving embodied agents remain problematic. In particular, complex plans that require multi-step reasoning become difficult and too costly as the context window grows. Planning requires understanding the likely effects of one's actions and identifying whether the current environment satisfies the goal state. While symbolic planners find optimal solutions quickly, they require a complete and accurate representation of the planning problem, severely limiting their use in practical scenarios. In contrast, modern LLMs cope with noisy observations and high levels of uncertainty when reasoning about a task. Our work presents LLM Dynamic Planner (LLM-DP): a neuro-symbolic framework where an LLM works hand-in-hand with a traditional planner to solve an embodied task. Given action-descriptions, LLM-DP solves Alfworld faster and more efficiently than a naive LLM ReAct baseline.
2023.08.19.16.21.13;19.08.2023;13;01;Foundation Models;Foundation Models;arxiv;2308.04898;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.04898.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Singla_T/0/1/0/all/0/1"">Tanmay Singla</a>, <a href=""http://arxiv.org/find/cs/1/au:+Anandayuvaraj_D/0/1/0/all/0/1"">Dharun Anandayuvaraj</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kalu_K/0/1/0/all/0/1"">Kelechi G. Kalu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Schorlemmer_T/0/1/0/all/0/1"">Taylor R. Schorlemmer</a>, <a href=""http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1"">James C. Davis</a>";Tanmay Singla,Dharun Anandayuvaraj,Kelechi G. Kalu,Taylor R. Schorlemmer,James C. Davis;An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures;As we increasingly depend on software systems, the consequences of breaches in the software supply chain become more severe. High-profile cyber attacks like those on SolarWinds and ShadowHammer have resulted in significant financial and data losses, underlining the need for stronger cybersecurity. One way to prevent future breaches is by studying past failures. However, traditional methods of analyzing these failures require manually reading and summarizing reports about them. Automated support could reduce costs and allow analysis of more failures. Natural Language Processing (NLP) techniques such as Large Language Models (LLMs) could be leveraged to assist the analysis of failures. In this study, we assessed the ability of Large Language Models (LLMs) to analyze historical software supply chain breaches. We used LLMs to replicate the manual analysis of 69 software supply chain security failures performed by members of the Cloud Native Computing Foundation (CNCF). We developed prompts for LLMs to categorize these by four dimensions: type of compromise, intent, nature, and impact. GPT 3.5s categorizations had an average accuracy of 68% and Bard had an accuracy of 58% over these dimensions. We report that LLMs effectively characterize software supply chain failures when the source articles are detailed enough for consensus among manual analysts, but cannot yet replace human analysts. Future work can improve LLM performance in this context, and study a broader range of articles and failures.
2023.08.19.16.21.14;19.08.2023;14;01;Foundation Models;Foundation Models;arxiv;2308.04913;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.04913.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1"">Kaize Shi</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1"">Xueyao Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1"">Dingxian Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1"">Yinlin Fu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1"">Guandong Xu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1"">Qing Li</a>";Kaize Shi,Xueyao Sun,Dingxian Wang,Yinlin Fu,Guandong Xu,Qing Li;LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following;E-commerce authoring involves creating attractive, abundant, and targeted promotional content to drive product sales. The emergence of large language models (LLMs) introduces an innovative paradigm, offering a unified solution to address various authoring tasks within this scenario. However, mainstream LLMs trained on general corpora with common sense knowledge reveal limitations in fitting complex and personalized features unique to e-commerce products and customers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility, raising concerns about safeguarding voluminous customer privacy data during transmission. This paper proposes the LLaMA-E, the unified and customized instruction-following language models focusing on diverse e-commerce authoring tasks. Specifically, the domain experts create the seed instruction set from the tasks of ads generation, query-enhanced product title rewriting, product classification, purchase intent speculation, and general Q&A. These tasks enable the models to comprehensively understand precise e-commerce authoring knowledge by interleaving features covering typical service aspects of customers, sellers, and platforms. The GPT-3.5 is introduced as a teacher model, which expands the seed instructions to form a training set for the LLaMA-E models with various scales. The experimental results show that the proposed LLaMA-E models achieve state-of-the-art results in quantitative and qualitative evaluations, also exhibiting the advantage in zero-shot scenes. To the best of our knowledge, this study is the first to serve the LLMs to specific e-commerce authoring scenarios.
2023.08.19.16.21.15;19.08.2023;15;02;Energy;Energy;schweitzer-online;;;https://www.schweitzer-online.de/buch/Sun/Blockchain-Artificial-Intelligence-Technologies-for-Smart-Energy-Systems/9780367771270/A67702393/;;;Blockchain and Artificial Intelligence Technologies for Smart Energy Systems;
2023.08.19.16.21.16;19.08.2023;16;02;Energy;Energy;idw-online;;;https://idw-online.de/de/news819048;;;Ausbau der Stromnetze: Fraunhofer IEE modelliert Anforderungen für Verteilnetzbetreiber in der Planungsregion Ost;
2023.08.19.16.21.17;19.08.2023;17;02;Energy;Energy;arxiv;2305.05338;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2305.05338.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Liu_M/0/1/0/all/0/1"">Mengxiang Liu</a>, <a href=""http://arxiv.org/find/eess/1/au:+Teng_F/0/1/0/all/0/1"">Fei Teng</a>, <a href=""http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1"">Zhenyong Zhang</a>, <a href=""http://arxiv.org/find/eess/1/au:+Ge_P/0/1/0/all/0/1"">Pudong Ge</a>, <a href=""http://arxiv.org/find/eess/1/au:+Deng_R/0/1/0/all/0/1"">Ruilong Deng</a>, <a href=""http://arxiv.org/find/eess/1/au:+Sun_M/0/1/0/all/0/1"">Mingyang Sun</a>, <a href=""http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1"">Jiming Chen</a>";Mengxiang Liu,Fei Teng,Zhenyong Zhang,Pudong Ge,Ruilong Deng,Mingyang Sun,Jiming Chen;Enhancing Cyber-Resiliency of DER-based SmartGrid: A Survey;The rapid development of information and communications technology has enabled the use of digital-controlled and software-driven distributed energy resources (DERs) to improve the flexibility and efficiency of power supply, and support grid operations. However, this evolution also exposes geographically-dispersed DERs to cyber threats, including hardware and software vulnerabilities, communication issues, and personnel errors, etc. Therefore, enhancing the cyber-resiliency of DER-based smart grid - the ability to survive successful cyber intrusions - is becoming increasingly vital and has garnered significant attention from both industry and academia. In this survey, we aim to provide a systematical and comprehensive review regarding the cyber-resiliency enhancement (CRE) of DER-based smart grid. Firstly, an integrated threat modeling method is tailored for the hierarchical DER-based smart grid with special emphasis on vulnerability identification and impact analysis. Then, the defense-in-depth strategies encompassing prevention, detection, mitigation, and recovery are comprehensively surveyed, systematically classified, and rigorously compared. A CRE framework is subsequently proposed to incorporate the five key resiliency enablers. Finally, challenges and future directions are discussed in details. The overall aim of this survey is to demonstrate the development trend of CRE methods and motivate further efforts to improve the cyber-resiliency of DER-based smart grid.
2023.08.19.16.21.18;19.08.2023;18;02;Energy;Energy;arxiv;2308.05042;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.05042.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Grebel_H/0/1/0/all/0/1"">H. Grebel</a>";H. Grebel;An Electrical Grid with Discrete Energy Levels;Minimizing both power fluctuations and energy waste in an electrical grid is a central challenge to energy policy. Any discrepancy between power production and loads may lead to inefficiencies and instability in the system. While sensors and predictive models, which are based on historical data, have been implemented to make the grid more responsive to instabilities, they have difficulty addressing fluctuations in real time. Here we explore a model of an electrical grid which delivers discrete energy to the nodes and is supported by short-term energy storage units (STESU). The model is analyzed within the framework of randomly perturbed Markovian chain. We show that under reasonable assumptions the averaged energy in the grid maintains stability under randomly fluctuating energy conditions.
2023.08.19.16.21.19;19.08.2023;19;02;Energy;Energy;arxiv;2212.06984;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2212.06984.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Zhao_D/0/1/0/all/0/1"">Dongwei Zhao</a>, <a href=""http://arxiv.org/find/eess/1/au:+Coyle_S/0/1/0/all/0/1"">Sarah Coyle</a>, <a href=""http://arxiv.org/find/eess/1/au:+Sakti_A/0/1/0/all/0/1"">Apurba Sakti</a>, <a href=""http://arxiv.org/find/eess/1/au:+Botterud_A/0/1/0/all/0/1"">Audun Botterud</a>";Dongwei Zhao,Sarah Coyle,Apurba Sakti,Audun Botterud;Market Mechanisms for Low-Carbon Electricity Investments: A Game-Theoretical Analysis;Electricity markets are transforming from the dominance of conventional energy resources (CERs), e.g., fossil fuels, to low-carbon energy resources (LERs), e.g., renewables and energy storage. This work examines market mechanisms to incentivize LER investments, while ensuring adequate market revenues for investors, guiding investors' strategic investments towards social optimum, and protecting consumers from scarcity prices. To reduce the impact of excessive scarcity prices, we present a new market mechanism, which consists of a Penalty payment for lost load, a supply Incentive, and an energy price Uplift (PIU). We establish a game-theoretical framework to analyze market equilibrium. We prove that one Nash equilibrium under the penalty payment and supply incentive can reach the social optimum given quadratic supply costs of CERs. Although the price uplift can ensure adequate revenues, the resulting system cost deviates from the social optimum while the gap decreases as more CERs retire. Furthermore, under the traditional marginal-cost pricing (MCP) mechanism, investors may withhold investments to cause scarcity prices, but such behavior is absent under the PIU mechanism. Simulation results show that the PIU mechanism can reduce consumers' costs by over 30% compared with the MCP mechanism by reducing excessive revenues of low-cost CERs from scarcity prices.
2023.08.19.16.21.20;19.08.2023;20;02;Energy;Energy;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.0605/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Optimized Power Management Approach for Photovoltaic Systems with Hybrid Battery-Supercapacitor Storage;The paper addresses the ongoing and continuous interest in photovoltaic energy systems (PESs). In this context, the study focuses on an isolated photovoltaic system with hybrid bat-tery-supercapacitor storage (HBSS). The integration of supercapacitors (SCs) in this system is of particular importance because of their high specific power density. In photovoltaic (PV) systems, multi-storage systems use two or more energy storage technologies to enhance system perfor-mance and flexibility. When batteries and supercapacitors are combined in a PV system, their benefits are maximized and offer a more reliable, efficient, and cost-effective energy storage op-tion. In addition, effective multi-storage power management in a PV system needs a solid grasp of the energy storage technologies, load power demand profiles, and the whole system architecture. In this work, battery-supercapacitor storage system (HBSS) is established by combining batteries and supercapacitors. The primary objective is to devise a novel management algorithm that ef-fectively controls the different power sources. The algorithm's purpose is to regulate the charge and discharge cycles of the HBSS, ensuring that the state of charge (SOC) of both batteries and supercapacitors remains within the desired range. The proposed management algorithm is de-signed to be simple, efficient, and light on computational resources. It efficiently handles the energy flow within the HBSS, optimizing the usage of both batteries and supercapacitors based on real-time conditions and energy demands. By maintaining the SOC of these energy storage components within the specified limits, the proposed method ensures their longevity and max-imizes their performance. Simulation results obtained from applying the management strategy are found to be satisfactory. These results show that the proposed algorithm maintains the SOC of batteries and supercapacitors within the desired range, leading to improved energy management and enhanced system efficiency.
2023.08.19.16.21.21;19.08.2023;21;02;Energy;Energy;techrxiv;;http://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/New_Electricity_Distribution_Paradigm_in_Distribution_Systems_for_DC_Devices_Integration/23816640;TechRxiv RSS Feed;TechRxiv RSS Feed;New Electricity Distribution Paradigm in Distribution Systems for DC Devices Integration;A new electricity distribution scheme in distribution systems is proposed in this paper. The AC and DC power sources are controlled to inject AC and DC simultaneously into distribution lines. LC filters are designed in a new way to extract AC and DC from their superposition in the distribution line current for the AC and DC devices, respectively. Therefore, the DC power sources, e.g., solar panels, can directly inject DC without the DC/AC conversions. Moreover, the AC and DC loads can be supplied directly with AC and DC, respectively, without the AC/DC or DC/AC conversions. The equipment cost and the power loss associated with these conversions are thus reduced. Simulation results show that the proposed scheme can regulate the AC and DC load voltage and drive the renewable energy resources-powered DC voltage sources to follow their maximum power point tracking profiles.
2023.08.19.16.21.22;19.08.2023;22;02;Energy;Energy;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202307.1533/v2;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Advancing the Sustainability of Risk Assessments within the Renewable Energy Sector- Review of Published Risk Assessments;Abstract: The epistemology of the traditional risk assessment examined has a taxonomy based upon deterministic, behaviouristic and compatibilist methodologies which are likely driven by neo-liberal market related requirements for bigger, faster cheaper wind-turbines. Analysis of available risk assessments suggested that there is no conscious effort to deceive the reader although the intended audience is unclear. The language, and scoring mechanisms utilized indicates the presence of conformity bias, confirmation bias, and numerical inconsistency leading to data ossification. By reverse engineering risk assessment content, Pragmatic and Social Psychological aspects can be investigated, and the adequacy of the document can be evaluated using evidence-based models.
2023.08.19.16.21.23;19.08.2023;23;02;Energy;Energy;arxiv;2308.01882;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.01882.pdf;" <a href=""http://arxiv.org/find/math/1/au:+Miehling_S/0/1/0/all/0/1"">Sebastian Miehling</a>, <a href=""http://arxiv.org/find/math/1/au:+Hanel_A/0/1/0/all/0/1"">Andreas Hanel</a>, <a href=""http://arxiv.org/find/math/1/au:+Lambert_J/0/1/0/all/0/1"">Jerry Lambert</a>, <a href=""http://arxiv.org/find/math/1/au:+Fendt_S/0/1/0/all/0/1"">Sebastian Fendt</a>, <a href=""http://arxiv.org/find/math/1/au:+Spliethoff_H/0/1/0/all/0/1"">Hartmut Spliethoff</a>";Sebastian Miehling,Andreas Hanel,Jerry Lambert,Sebastian Fendt,Hartmut Spliethoff;Energy System Optimisation using (Mixed Integer) Linear Programming;Although energy system optimisation based on linear optimisation is often used for influential energy outlooks and studies for political decision-makers, the underlying background still needs to be described in the scientific literature in a concise and general form. This study presents the main equations and advanced ideas and explains further possibilities mixed integer linear programming offers in energy system optimisation. Furthermore, the equations are shown using an example system to present a more practical point of view. Therefore, this study is aimed at researchers trying to understand the background of studies using energy system optimisation and researchers building their implementation into a new framework. This study describes how to build a standard model, how to implement advanced equations using linear programming, and how to implement advanced equations using mixed integer linear programming, as well as shows a small exemplary system. - Presentation of the OpTUMus energy system optimisation framework - Set of equations for a fully functional energy system model - Example of a simple energy system model
2023.08.19.16.21.24;19.08.2023;24;02;Energy;Energy;arxiv;2307.16149;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.16149.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1"">Xun Yuan</a>, <a href=""http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1"">Yang Yang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Alromih_A/0/1/0/all/0/1"">Arwa Alromih</a>, <a href=""http://arxiv.org/find/cs/1/au:+Gope_P/0/1/0/all/0/1"">Prosanta Gope</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sikdar_B/0/1/0/all/0/1"">Biplab Sikdar</a>";Xun Yuan,Yang Yang,Arwa Alromih,Prosanta Gope,Biplab Sikdar;An Effective LSTM-DDPM Scheme for Energy Theft Detection and Forecasting in Smart Grid;Energy theft detection (ETD) and energy consumption forecasting (ECF) are two interconnected challenges in smart grid systems. Addressing these issues collectively is crucial for ensuring system security. This paper addresses the interconnected challenges of ETD and ECF in smart grid systems. The proposed solution combines long short-term memory (LSTM) and a denoising diffusion probabilistic model (DDPM) to generate input reconstruction and forecasting. By leveraging the reconstruction and forecasting errors, the system identifies instances of energy theft, with the methods based on reconstruction error and forecasting error complementing each other in detecting different types of attacks. Through extensive experiments on real-world and synthetic datasets, the proposed scheme outperforms baseline methods in ETD and ECF problems. The ensemble method significantly enhances ETD performance, accurately detecting energy theft attacks that baseline methods fail to detect. The research offers a comprehensive and effective solution for addressing ETD and ECF challenges, demonstrating promising results and improved security in smart grid systems.
2023.08.19.16.21.25;19.08.2023;25;02;Energy;Energy;arxiv;2301.08360;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2301.08360.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Wang_Y/0/1/0/all/0/1"">Yuanrong Wang</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Swaminathan_V/0/1/0/all/0/1"">Vignesh Raja Swaminathan</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Granger_N/0/1/0/all/0/1"">Nikita P. Granger</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Perez_C/0/1/0/all/0/1"">Carlos Ros Perez</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Michler_C/0/1/0/all/0/1"">Christian Michler</a>";Yuanrong Wang,Vignesh Raja Swaminathan,Nikita P. Granger,Carlos Ros Perez,Christian Michler;Domain-adapted Learning and Imitation: DRL for Power Arbitrage;In this paper, we discuss the Dutch power market, which is comprised of a day-ahead market and an intraday balancing market that operates like an auction. Due to fluctuations in power supply and demand, there is often an imbalance that leads to different prices in the two markets, providing an opportunity for arbitrage. To address this issue, we restructure the problem and propose a collaborative dual-agent reinforcement learning approach for this bi-level simulation and optimization of European power arbitrage trading. We also introduce two new implementations designed to incorporate domain-specific knowledge by imitating the trading behaviours of power traders. By utilizing reward engineering to imitate domain expertise, we are able to reform the reward system for the RL agent, which improves convergence during training and enhances overall performance. Additionally, the tranching of orders increases bidding success rates and significantly boosts profit and loss (P&L). Our study demonstrates that by leveraging domain expertise in a general learning problem, the performance can be improved substantially, and the final integrated approach leads to a three-fold improvement in cumulative P&L compared to the original agent. Furthermore, our methodology outperforms the highest benchmark policy by around 50% while maintaining efficient computational performance.
2023.08.19.16.21.26;19.08.2023;26;02;Energy;Energy;arxiv;2307.14304;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.14304.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Hou_S/0/1/0/all/0/1"">Shengren Hou</a>, <a href=""http://arxiv.org/find/eess/1/au:+Duque_E/0/1/0/all/0/1"">Edgar Mauricio Salazar Duque</a>, <a href=""http://arxiv.org/find/eess/1/au:+Palensky_P/0/1/0/all/0/1"">Peter Palensky</a>, <a href=""http://arxiv.org/find/eess/1/au:+Vergara_P/0/1/0/all/0/1"">Pedro P. Vergara</a>";Shengren Hou,Edgar Mauricio Salazar Duque,Peter Palensky,Pedro P. Vergara;A Constraint Enforcement Deep Reinforcement Learning Framework for Optimal Energy Storage Systems Dispatch;The optimal dispatch of energy storage systems (ESSs) presents formidable challenges due to the uncertainty introduced by fluctuations in dynamic prices, demand consumption, and renewable-based energy generation. By exploiting the generalization capabilities of deep neural networks (DNNs), deep reinforcement learning (DRL) algorithms can learn good-quality control models that adaptively respond to distribution networks' stochastic nature. However, current DRL algorithms lack the capabilities to enforce operational constraints strictly, often even providing unfeasible control actions. To address this issue, we propose a DRL framework that effectively handles continuous action spaces while strictly enforcing the environments and action space operational constraints during online operation. Firstly, the proposed framework trains an action-value function modeled using DNNs. Subsequently, this action-value function is formulated as a mixed-integer programming (MIP) formulation enabling the consideration of the environment's operational constraints. Comprehensive numerical simulations show the superior performance of the proposed MIP-DRL framework, effectively enforcing all constraints while delivering high-quality dispatch decisions when compared with state-of-the-art DRL algorithms and the optimal solution obtained with a perfect forecast of the stochastic variables.
2023.08.19.16.21.27;19.08.2023;27;02;Energy;Energy;arxiv;2307.09922;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.09922.pdf;" <a href=""http://arxiv.org/find/math/1/au:+Taylor_J/0/1/0/all/0/1"">Josh A. Taylor</a>";Josh A. Taylor;Information Structures in AC/DC Grids;The converters in an AC/DC grid form actuated boundaries between the AC and DC subgrids. We show how in both simple linear and balanced dq-frame models, the states on either side of these boundaries are coupled only by control inputs. This topological property imparts all AC/DC grids with poset-causal information structures. A practical benefit is that certain decentralized control problems that are hard in general are tractable for poset-causal systems. We also show that special cases like multi-terminal DC grids can have coordinated and leader-follower information structures.
2023.08.19.16.21.28;19.08.2023;28;02;Energy;Energy;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202307.1243/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;An Integrated Testbed for Power System Cyber-Physical Operations Training;The increased adoption of information and communication technology for smart grid applications will require innovative cyber-physical system (CPS) testbeds to support research and education in the field. The groundbreaking CPS testbeds with realistic and scalable platforms have progressively gained interest in recent years, with electric power flowing in the physical layer and information flowing in the network layer. However, CPSs are critical infrastructures and not designed for testing or direct training, as any misbehaving in an actual system operation could cause a catastrophic impact on its operation. Based on that, it is not easy to efficiently train professionals in CPSs. Aiming to support the advancement and encourage the training of industry professionals, this paper proposes and develops a complete testbed with commercial tools. The testbed can reliably replicate the performance of smart grid systems and the main potential cyber threats that electric grids may face. The complex interdependencies between the cyber and physical domains are discussed in detail, and different case scenarios are presented, providing insightful guidelines for key features and design decisions for future smart grid testbeds.
2023.08.19.16.21.29;19.08.2023;29;02;Energy;Energy;arxiv;2307.07191;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.07191.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"">Zhixian Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1"">Qingsong Wen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1"">Chaoli Zhang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1"">Liang Sun</a>, <a href=""http://arxiv.org/find/cs/1/au:+Krannichfeldt_L/0/1/0/all/0/1"">Leandro Von Krannichfeldt</a>, <a href=""http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1"">Yi Wang</a>";Zhixian Wang,Qingsong Wen,Chaoli Zhang,Liang Sun,Leandro Von Krannichfeldt,Yi Wang;Benchmarks and Custom Package for Electrical Load Forecasting;Load forecasting is of great significance in the power industry as it can provide a reference for subsequent tasks such as power grid dispatch, thus bringing huge economic benefits. However, there are many differences between load forecasting and traditional time series forecasting. On the one hand, load forecasting aims to minimize the cost of subsequent tasks such as power grid dispatch, rather than simply pursuing prediction accuracy. On the other hand, the load is largely influenced by many external factors, such as temperature or calendar variables. In addition, the scale of predictions (such as building-level loads and aggregated-level loads) can also significantly impact the predicted results. In this paper, we provide a comprehensive load forecasting archive, which includes load domain-specific feature engineering to help forecasting models better model load data. In addition, different from the traditional loss function which only aims for accuracy, we also provide a method to customize the loss function based on the forecasting error, integrating it into our forecasting framework. Based on this, we conducted extensive experiments on load data at different levels, providing a reference for researchers to compare different load forecasting models.
2023.08.19.16.21.30;19.08.2023;30;02;Energy;Energy;arxiv;2307.06861;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.06861.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Othman_A/0/1/0/all/0/1"">Abdullah Othman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kaddoum_G/0/1/0/all/0/1"">Georges Kaddoum</a>, <a href=""http://arxiv.org/find/cs/1/au:+Evangelista_J/0/1/0/all/0/1"">Joao V. C. Evangelista</a>, <a href=""http://arxiv.org/find/cs/1/au:+Au_M/0/1/0/all/0/1"">Minh Au</a>, <a href=""http://arxiv.org/find/cs/1/au:+Agba_B/0/1/0/all/0/1"">Basile L. Agba</a>";Abdullah Othman,Georges Kaddoum,Joao V. C. Evangelista,Minh Au,Basile L. Agba;Digital Twinning in Smart Grid Networks: Interplay, Resource Allocation and Use Cases;Motivated by climate change, increasing industrialization and energy reliability concerns, the smart grid is set to revolutionize traditional power systems. Moreover, the exponential annual rise in number of grid-connected users and emerging key players e.g. electric vehicles strain the limited radio resources, which stresses the need for novel and scalable resource management techniques. Digital twin is a cutting-edge virtualization technology that has shown great potential by offering solutions for inherent bottlenecks in traditional wireless networks. In this article, we set the stage for various roles digital twinning can fulfill by optimizing congested radio resources in a proactive and resilient smart grid. Digital twins can help smart grid networks through real-time monitoring, advanced precise modeling and efficient radio resource allocation for normal operations and service restoration following unexpected events. However, reliable real-time communications, intricate abstraction abilities, interoperability with other smart grid technologies, robust computing capabilities and resilient security schemes are some open challenges for future work on digital twins.
2023.08.19.16.21.31;19.08.2023;31;02;Energy;Energy;repec;;http://nep.repec.org/rss/nep-for.rss.xml;http://d.repec.org/n?u=RePEc:hhs:nhhfms:2023_011&r=for;Andersson, JonasSheybanivaziri, Samaneh;Andersson, JonasSheybanivaziri, Samaneh;Probabilistic forecasting of electricity prices using an augmented LMARX-model;In this paper, we study the performance of prediction intervals in situations applicable to electricity markets. In order to do so we first introduce an extension of the logistic mixture autoregressive with exogenous variables (LMARX) model, see (Wong, Li, 2001), where we allow for multiplicative seasonality and lagged mixture probabilities. The reason for using this model is the prevalence of spikes in electricity prices. This feature creates a quickly varying, and sometimes bimodal, forecast distribution. The model is fitted to the price data from the electricity market forecasting competition GEFCom2014. Additionally, we compare the outcomes of our presumably more accurate representation of reality, the LMARX model, with other widely utilized approaches that have been employed in the literature.
2023.08.19.16.21.32;19.08.2023;32;02;Energy;Energy;arxiv;2307.03040;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2307.03040.pdf;" <a href=""http://arxiv.org/find/math/1/au:+Engelmann_A/0/1/0/all/0/1"">Alexander Engelmann</a>, <a href=""http://arxiv.org/find/math/1/au:+Kaupmann_M/0/1/0/all/0/1"">Michael Kaupmann</a>, <a href=""http://arxiv.org/find/math/1/au:+Faulwasser_T/0/1/0/all/0/1"">Timm Faulwasser</a>";Alexander Engelmann,Michael Kaupmann,Timm Faulwasser;Distributed Interior Point Methods for Optimization in Energy Networks;This note discusses an essentially decentralized interior point method, which is well suited for optimization problems arising in energy networks. Advantages of the proposed method are guaranteed and fast local convergence also for problems with non-convex constraints. Moreover, our method exhibits a small communication footprint and it achieves a comparably high solution accuracy with a limited number of iterations, whereby the local subproblems are of low computational complexity. We illustrate the performance of the proposed method on a problem from energy systems, i.e., we consider an optimal power flow problem with 708 buses.
2023.08.19.16.21.33;19.08.2023;33;02;Energy;Energy;arxiv;2306.17186;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.17186.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zekiye_A/0/1/0/all/0/1"">Abdulrezzak Zekiye</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ozkasap_O/0/1/0/all/0/1"">&#xd6;znur &#xd6;zkasap</a>";Abdulrezzak Zekiye,Öznur Özkasap;Blockchain-based Federated Learning for Decentralized Energy Management Systems;The Internet of Energy (IoE) is a distributed paradigm that leverages smart networks and distributed system technologies to enable decentralized energy systems. In contrast to the traditional centralized energy systems, distributed Energy Internet systems comprise multiple components and communication requirements that demand innovative technologies for decentralization, reliability, efficiency, and security. Recent advances in blockchain architectures, smart contracts, and distributed federated learning technologies have opened up new opportunities for realizing decentralized Energy Internet services. In this paper, we present a comprehensive analysis and classification of state-of-the-art solutions that employ blockchain, smart contracts, and federated learning for the IoE domains. Specifically, we identify four representative system models and discuss their key aspects. These models demonstrate the diverse ways in which blockchain, smart contracts, and federated learning can be integrated to support the main domains of IoE, namely distributed energy trading and sharing, smart microgrid energy networks, and electric and connected vehicle management. Furthermore, we provide a detailed comparison of the different levels of decentralization, the advantages of federated learning, and the benefits of using blockchain for the IoE systems. Additionally, we identify open issues and areas for future research for integrating federated learning and blockchain in the Internet of Energy domains.
2023.08.19.16.21.34;19.08.2023;34;02;Energy;Energy;techrxiv;;https://www.techrxiv.org/rss/portal/techrxiv;https://www.techrxiv.org/articles/preprint/A_Lightweight_Privacy-Preserving_Electricity_Theft_Detection_Scheme_in_Smart_Grid/23577003;TechRxiv RSS Feed;TechRxiv RSS Feed;A Lightweight Privacy-Preserving Electricity Theft Detection Scheme in Smart Grid;The detection of electricity theft, which focuses on privacy protection and system security, has been extensively researched in the smart grid. However, existing solutions have not taken into account the enormous communication overhead that will be incurred in practical environments due to the large scale of the smart grid and the vast number of smart meters. Furthermore, there has been a lack of further research on the detection models and periods. Therefore, we propose a lightweight privacy-preserving electricity theft detection scheme. Specifically, we introduce differential privacy in the inner product encryption process of electricity data and neural network weights under the vector type, providing strict privacy protection without affecting data utility. Secondly, a combination detection model that extracts local and global features of electricity data is proposed. Furthermore, we explore the impact of detection periods on six different datasets. The experimental results based on real electricity consumption data demonstrate that our scheme has lower communication overhead and higher accuracy.
2023.08.19.16.21.35;19.08.2023;35;02;Energy;Energy;arxiv;2306.15499;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.15499.pdf;" <a href=""http://arxiv.org/find/math/1/au:+Ramin_D/0/1/0/all/0/1"">Danial Ramin</a>, <a href=""http://arxiv.org/find/math/1/au:+Spinelli_S/0/1/0/all/0/1"">Stefano Spinelli</a>, <a href=""http://arxiv.org/find/math/1/au:+Brusaferri_A/0/1/0/all/0/1"">Alessandro Brusaferri</a>";Danial Ramin,Stefano Spinelli,Alessandro Brusaferri;Demand-side management via optimal production scheduling in power-intensive industries: The case of metal casting process;The increasing challenges to the grid stability posed by the penetration of renewable energy resources urge a more active role for demand response programs as viable alternatives to a further expansion of peak power generators. This work presents a methodology to exploit the demand flexibility of energy-intensive industries under Demand-Side Management programs in the energy and reserve markets. To this end, we propose a novel scheduling model for a multi-stage multi-line process, which incorporates both the critical manufacturing constraints and the technical requirements imposed by the market. Using mixed integer programming approach, two optimization problems are formulated to sequentially minimize the cost in a day-ahead energy market and maximize the reserve provision when participating in the ancillary market. The effectiveness of day-ahead scheduling model has been verified for the case of a real metal casting plant in the Nordic market, where a significant reduction of energy cost is obtained. Furthermore, the reserve provision is shown to be a potential tool for capitalizing on the reserve market as a secondary revenue stream.
2023.08.19.16.21.36;19.08.2023;36;02;Energy;Energy;arxiv;2306.15072;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.15072.pdf;" <a href=""http://arxiv.org/find/eess/1/au:+Sahu_A/0/1/0/all/0/1"">Abhijeet Sahu</a>, <a href=""http://arxiv.org/find/eess/1/au:+Wlazlo_P/0/1/0/all/0/1"">Patrick Wlazlo</a>, <a href=""http://arxiv.org/find/eess/1/au:+Gaudet_N/0/1/0/all/0/1"">Nastassja Gaudet</a>, <a href=""http://arxiv.org/find/eess/1/au:+Goulart_A/0/1/0/all/0/1"">Ana Goulart</a>, <a href=""http://arxiv.org/find/eess/1/au:+Rogers_E/0/1/0/all/0/1"">Edmond Rogers</a>, <a href=""http://arxiv.org/find/eess/1/au:+Davis_K/0/1/0/all/0/1"">Katherine Davis</a>";Abhijeet Sahu,Patrick Wlazlo,Nastassja Gaudet,Ana Goulart,Edmond Rogers,Katherine Davis;A Firewall Optimization for Threat-Resilient Micro-Segmentation in Power System Networks;Electric power delivery relies on a communications backbone that must be secure. SCADA systems are essential to critical grid functions and include industrial control systems (ICS) protocols such as the Distributed Network Protocol-3 (DNP3). These protocols are vulnerable to cyber threats that power systems, as cyber-physical critical infrastructure, must be protected against. For this reason, the NERC Critical Infrastructure Protection standard CIP-005-5 specifies that an electronic system perimeter is needed, accomplished with firewalls. This paper presents how these electronic system perimeters can be optimally found and generated using a proposed meta-heuristic approach for optimal security zone formation for large-scale power systems. Then, to implement the optimal firewall rules in a large scale power system model, this work presents a prototype software tool that takes the optimization results and auto-configures the firewall nodes for different utilities in a cyber-physical testbed. Using this tool, firewall policies are configured for all the utilities and their substations within a synthetic 2000-bus model, assuming two different network topologies. Results generate the optimal electronic security perimeters to protect a power system's data flows and compare the number of firewalls, monetary cost, and risk alerts from path analysis.
2023.08.19.16.21.37;19.08.2023;37;02;Energy;Energy;arxiv;2306.14186;http://export.arxiv.org/rss/stat;http://arxiv.org/pdf/2306.14186.pdf;" <a href=""http://arxiv.org/find/stat/1/au:+Sgarlato_R/0/1/0/all/0/1"">Raffaele Sgarlato</a>";Raffaele Sgarlato;Statistical electricity price forecasting: A structural approach;"The availability of historical data related to electricity day-ahead prices and to the underlying price formation process is limited. In addition, the electricity market in Europe is facing a rapid transformation, which limits the representativeness of older observations for predictive purposes. On the other hand, machine learning methods that gained traction also in the domain of electricity price forecasting typically require large amounts of data. This study analyses the effectiveness of encoding well-established domain knowledge to mitigate the need for large training datasets. The domain knowledge is incorporated by imposing a structure on the price forecasting problem; the resulting accuracy gains are quantified in an experiment. Compared to an ""unstructured"" purely statistical model, it is shown that introducing intermediate quantity forecasts of load, renewable infeed, and cross-border exchange, paired with the estimation of supply curves, can result in a NRMSE reduction by 0.1 during daytime hours. The statistically most significant improvements are achieved in the first day of the forecasting horizon when a purely statistical model is combined with structured models. Finally, results are evaluated and interpreted with regard to the dynamic market conditions observed in Europe during the experiment period (from the 1st October 2022 to the 30th April 2023), highlighting the adaptive nature of models that are trained on shorter timescales."
2023.08.19.16.21.38;19.08.2023;38;02;Energy;Energy;arxiv;2306.13397;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2306.13397.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Huo_L/0/1/0/all/0/1"">Long Huo</a>, <a href=""http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1"">Xin Chen</a>";Long Huo,Xin Chen;Higher-order Motif-based Time Series Classification for Forced Oscillation Source Location in Power Grids;Time series motifs are used for discovering higher-order structures of time series data. Based on time series motifs, the motif embedding correlation field (MECF) is proposed to characterize higher-order temporal structures of dynamical system time series. A MECF-based unsupervised learning approach is applied in locating the source of the forced oscillation (FO), a periodic disturbance that detrimentally impacts power grids. Locating the FO source is imperative for system stability. Compared with the Fourier analysis, the MECF-based unsupervised learning is applicable under various FO situations, including the single FO, FO with resonance, and multiple sources FOs. The MECF-based unsupervised learning is a data-driven approach without any prior knowledge requirement of system models or typologies. Tests on the UK high-voltage transmission grid illustrate the effectiveness of MECF-based unsupervised learning. In addition, the impacts of coupling strength and measurement noise on locating the FO source by the MECF-based unsupervised learning are investigated.
2023.08.19.16.21.39;19.08.2023;39;02;Energy;Energy;repec;;http://nep.repec.org/rss/nep-ind.rss.xml;http://d.repec.org/n?u=RePEc:ris:albaec:2023_007&r=ind;Brown, David P.Eckert, AndrewSilveira, Douglas;Brown, David P.Eckert, AndrewSilveira, Douglas;Screening for Collusion in Wholesale Electricity Markets: A Review of the Literature;Wholesale electricity markets have several features that increase the likelihood of collusion, including frequent interaction, multimarket contact, and a high degree of information transparency. As a result, screening techniques for detecting collusive agreements are desired. In this paper, we survey the existing literature on collusive screens and collusion in electricity markets. We discuss key features of non-competitive behaviour to be reflected in screens and suggest directions for improved screening in this industry. In particular, there is considerable potential to include machine learning and data mining techniques in screens in the electricity sector due to recent improvements in these methods.
2023.08.19.16.21.40;19.08.2023;40;02;Energy;Energy;repec;;http://nep.repec.org/rss/nep-cmp.rss.xml;http://d.repec.org/n?u=RePEc:osf:osfxxx:ye254&r=cmp;Alfarisi, Omar;Alfarisi, Omar;Artificial Energy General Intelligence AEGI;Artificial Energy General Intelligence (AEGI) is a natural progression of Artificial General Intelligence (AGI) that caters to the energy industry. It is crucial to optimize the entire value chain involved in generating, transporting, and storing energy for the betterment of humanity, the environment, industry, and the scientific community. Most research efforts focus on a specific area of the value chain, leading to a disconnect between multiple disciplines and hindering effective problem-solving. AEGI proposes integrating the learning from each discipline in the energy sector to create an optimal solution that simultaneously addresses multiple objectives. This integration is more complex than solving each discipline's challenges separately, but achieving a sustainable and efficient energy system is necessary.
2023.08.19.16.21.41;19.08.2023;41;02;Energy;Energy;repec;;http://nep.repec.org/rss/nep-big.rss.xml;http://d.repec.org/n?u=RePEc:syd:wpaper:2023-03&r=big;Sinan DengJohn InekweVladimir SmirnovAndrew WaitChao Wang;Sinan DengJohn InekweVladimir SmirnovAndrew WaitChao Wang;Machine Learning and Deep Learning Forecasts of Electricity Imbalance Prices;In this paper, we propose a seasonal attention mechanism, the effectiveness of which is evaluated via the Bidirectional Long Short-Term Memory (BiLSTM) model. We compare its performance with alternative deep learning and machine learning models in forecasting the balancing settlement prices in the electricity market of Great Britain. Critically, the Seasonal Attention-Based BiLSTM framework provides a superior forecast of extreme prices with an out-of-sample gain in the predictability of 25-37% compared with models in the literature. Our forecasting techniques could aid both market participants, to better manage their risk and assign their assets, and policy makers, to operate the system at lower cost.
2023.08.19.16.21.42;19.08.2023;42;02;Energy;Energy;repec;;http://nep.repec.org/rss/nep-for.rss.xml;http://d.repec.org/n?u=RePEc:arx:papers:2305.16255&r=for;Paul GhelasiFlorian Ziel;Paul GhelasiFlorian Ziel;Hierarchical forecasting for aggregated curves with an application to day-ahead electricity price auctions;Aggregated curves are common structures in economics and finance, and the most prominent examples are supply and demand curves. In this study, we exploit the fact that all aggregated curves have an intrinsic hierarchical structure, and thus hierarchical reconciliation methods can be used to improve the forecast accuracy. We provide an in-depth theory on how aggregated curves can be constructed or deconstructed, and conclude that these methods are equivalent under weak assumptions. We consider multiple reconciliation methods for aggregated curves, including previously established bottom-up, top-down, and linear optimal reconciliation approaches. We also present a new benchmark reconciliation method called 'aggregated-down' with similar complexity to bottom-up and top-down approaches, but it tends to provide better accuracy in this setup. We conducted an empirical forecasting study on the German day-ahead power auction market by predicting the demand and supply curves, where their equilibrium determines the electricity price for the next day. Our results demonstrate that hierarchical reconciliation methods can be used to improve the forecasting accuracy of aggregated curves.
2023.08.19.16.21.43;19.08.2023;43;02;Energy;Energy;repec;;http://nep.repec.org/rss/nep-cta.rss.xml;http://d.repec.org/n?u=RePEc:diw:diwwpp:dp2035&r=cta;Karsten NeuhoffFernanda BallesterosMats KrögerJörn C. Richstein;Karsten NeuhoffFernanda BallesterosMats KrögerJörn C. Richstein;Contracting Matters: Hedging Producers and Consumers with a Renewable Energy Pool;Renewable energy installations are rapidly gaining market share due to falling technology costs and supportive policies. Meanwhile, the energy price crisis resulting from the Russian-Ukrainian war has shifted the energy policy debate toward the question of how consumers can benefit more from the low and stable generation costs of renewable electricity. Here we suggest a Renewable Pool (“RE-Pool”) under which the government passes the conditions of Contracts-for-Difference on to consumers who thereby benefit from reliably low-cost electricity supply. We assess the effect on financing costs, scale, and system friendliness of wind investments, as well risk hedging for consumers’ volume risks and hedging incentives.
2023.08.19.16.21.44;19.08.2023;44;02;Energy;Energy;repec;;http://nep.repec.org/rss/nep-tre.rss.xml;http://d.repec.org/n?u=RePEc:zbw:qmsrps:202210&r=tre;Dokka, TrivikramBruno, JorgeSenGupta, SonaliAnwar, Sakib;Dokka, TrivikramBruno, JorgeSenGupta, SonaliAnwar, Sakib;Pricing and Electric Vehicle Charging Equilibria;We study equilibria in an Electric Vehicle (EV) charging game, a cost minimization game inherent to decentralized charging control strategy for EV power demand management. In our model, each user optimizes its total cost which is sum of direct power cost and the indirect dissatisfaction cost. We show that, taking player specific price independent dissatisfaction cost into account, contrary to popular belief, herding only happens at lower EV uptake. Moreover, this is true for both linear and logistic dissatisfaction functions. We study the question of existence of price profiles to induce a desired equilibrium. We define two types of equilibria, distributed and non-distributed equilibria, and show that under logistic dissatisfaction, only non-distributed equilibria are possible by feasibly setting prices. In linear case, both type of equilibria are possible but price discrimination is necessary to induce distributed equilibria. Finally, we show that in the case of symmetric EV users, mediation cannot improve upon Nash equilibria.
2023.08.19.16.21.45;19.08.2023;45;03;Transportation;Transportation;arxiv;2308.07457;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.07457.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wilbur_M/0/1/0/all/0/1"">Michael Wilbur</a>, <a href=""http://arxiv.org/find/cs/1/au:+Sivagnanam_A/0/1/0/all/0/1"">Amutheezan Sivagnanam</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ayman_A/0/1/0/all/0/1"">Afiya Ayman</a>, <a href=""http://arxiv.org/find/cs/1/au:+Samaranayeke_S/0/1/0/all/0/1"">Samitha Samaranayeke</a>, <a href=""http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1"">Abhishek Dubey</a>, <a href=""http://arxiv.org/find/cs/1/au:+Laszka_A/0/1/0/all/0/1"">Aron Laszka</a>";Michael Wilbur,Amutheezan Sivagnanam,Afiya Ayman,Samitha Samaranayeke,Abhishek Dubey,Aron Laszka;Artificial Intelligence for Smart Transportation;There are more than 7,000 public transit agencies in the U.S. (and many more private agencies), and together, they are responsible for serving 60 billion passenger miles each year. A well-functioning transit system fosters the growth and expansion of businesses, distributes social and economic benefits, and links the capabilities of community members, thereby enhancing what they can accomplish as a society. Since affordable public transit services are the backbones of many communities, this work investigates ways in which Artificial Intelligence (AI) can improve efficiency and increase utilization from the perspective of transit agencies. This book chapter discusses the primary requirements, objectives, and challenges related to the design of AI-driven smart transportation systems. We focus on three major topics. First, we discuss data sources and data. Second, we provide an overview of how AI can aid decision-making with a focus on transportation. Lastly, we discuss computational problems in the transportation domain and AI approaches to these problems.
2023.08.19.16.21.46;19.08.2023;46;03;Transportation;Transportation;arxiv;2308.07426;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.07426.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1"">Zehui Wang</a>, <a href=""http://arxiv.org/find/cs/1/au:+Hopken_W/0/1/0/all/0/1"">Wolfram H&#xf6;pken</a>, <a href=""http://arxiv.org/find/cs/1/au:+Jannach_D/0/1/0/all/0/1"">Dietmar Jannach</a>";Zehui Wang,Wolfram Höpken,Dietmar Jannach;A Survey on Point-of-Interest Recommendations Leveraging Heterogeneous Data;Tourism is an important application domain for recommender systems. In this domain, recommender systems are for example tasked with providing personalized recommendations for transportation, accommodation, points-of-interest (POIs), or tourism services. Among these tasks, in particular the problem of recommending POIs that are of likely interest to individual tourists has gained growing attention in recent years. Providing POI recommendations to tourists \emph{during their trip} can however be especially challenging due to the variability of the users' context. With the rapid development of the Web and today's multitude of online services, vast amounts of data from various sources have become available, and these heterogeneous data sources represent a huge potential to better address the challenges of in-trip POI recommendation problems. In this work, we provide a comprehensive survey of published research on POI recommendation between 2017 and 2022 from the perspective of heterogeneous data sources. Specifically, we investigate which types of data are used in the literature and which technical approaches and evaluation methods are predominant. Among other aspects, we find that today's research works often focus on a narrow range of data sources, leaving great potential for future works that better utilize heterogeneous data sources and diverse data types for improved in-trip recommendations.
2023.08.19.16.21.47;19.08.2023;47;03;Transportation;Transportation;arxiv;2208.11061;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2208.11061.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1"">Bodong Zhou</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1"">Jiahui Liu</a>, <a href=""http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1"">Songyi Cui</a>, <a href=""http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1"">Yaping Zhao</a>";Bodong Zhou,Jiahui Liu,Songyi Cui,Yaping Zhao;Large-Scale Traffic Congestion Prediction based on Multimodal Fusion and Representation Mapping;With the progress of the urbanisation process, the urban transportation system is extremely critical to the development of cities and the quality of life of the citizens. Among them, it is one of the most important tasks to judge traffic congestion by analysing the congestion factors. Recently, various traditional and machine-learning-based models have been introduced for predicting traffic congestion. However, these models are either poorly aggregated for massive congestion factors or fail to make accurate predictions for every precise location in large-scale space. To alleviate these problems, a novel end-to-end framework based on convolutional neural networks is proposed in this paper. With learning representations, the framework proposes a novel multimodal fusion module and a novel representation mapping module to achieve traffic congestion predictions on arbitrary query locations on a large-scale map, combined with various global reference information. The proposed framework achieves significant results and efficient inference on real-world large-scale datasets.
2023.08.19.16.21.48;19.08.2023;48;04;Finance;Finance;analyticsvidhya;;http://www.analyticsvidhya.com/feed/;https://www.analyticsvidhya.com/blog/2023/08/rbi-embraces-conversational-ai-and-offline-payments-using-upi/;K.sabreena;K.sabreena;RBI Embraces Conversational AI and Offline Payments Using UPI;Breaking new ground in digital payments, the Reserve Bank of India (RBI) has unveiled plans to introduce advanced Unified Payments Interface (UPI) features. RBI’s initiative to integrate conversational AI and offline payments aims at enhancing the accessibility, convenience, and inclusivity of digital transactions. Also Read: How India Is Using Cutting-Edge AI to Tackle Payment Frauds […] The post RBI Embraces Conversational AI and Offline Payments Using UPI <https://www.analyticsvidhya.com/blog/2023/08/rbi-embraces-conversational-ai-and-offline-payments-using-upi/> appeared first on Analytics Vidhya <https://www.analyticsvidhya.com> .
2023.08.19.16.21.49;19.08.2023;49;04;Finance;Finance;arxiv;2308.08031;http://export.arxiv.org/rss/q-fin;http://arxiv.org/pdf/2308.08031.pdf;" <a href=""http://arxiv.org/find/q-fin/1/au:+Vamvourellis_D/0/1/0/all/0/1"">Dimitrios Vamvourellis</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Toth_M/0/1/0/all/0/1"">M&#xe1;t&#xe9; Toth</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Bhagat_S/0/1/0/all/0/1"">Snigdha Bhagat</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Desai_D/0/1/0/all/0/1"">Dhruv Desai</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Mehta_D/0/1/0/all/0/1"">Dhagash Mehta</a>, <a href=""http://arxiv.org/find/q-fin/1/au:+Pasquali_S/0/1/0/all/0/1"">Stefano Pasquali</a>";Dimitrios Vamvourellis,Máté Toth,Snigdha Bhagat,Dhruv Desai,Dhagash Mehta,Stefano Pasquali;Company Similarity using Large Language Models;Identifying companies with similar profiles is a core task in finance with a wide range of applications in portfolio construction, asset pricing and risk attribution. When a rigorous definition of similarity is lacking, financial analysts usually resort to 'traditional' industry classifications such as Global Industry Classification System (GICS) which assign a unique category to each company at different levels of granularity. Due to their discrete nature, though, GICS classifications do not allow for ranking companies in terms of similarity. In this paper, we explore the ability of pre-trained and finetuned large language models (LLMs) to learn company embeddings based on the business descriptions reported in SEC filings. We show that we can reproduce GICS classifications using the embeddings as features. We also benchmark these embeddings on various machine learning and financial metrics and conclude that the companies that are similar according to the embeddings are also similar in terms of financial performance metrics including return correlation.
2023.08.19.16.21.50;19.08.2023;50;04;Finance;Finance;arxiv;2308.08362;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.08362.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Braine_L/0/1/0/all/0/1"">Lee Braine</a>, <a href=""http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1"">Shreepad Shukla</a>, <a href=""http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1"">Piyush Agrawal</a>";Lee Braine,Shreepad Shukla,Piyush Agrawal;Functional Consistency across Retail Central Bank Digital Currency and Commercial Bank Money;Central banks are actively exploring central bank digital currencies (CBDCs) by conducting research, proofs of concept and pilots. However, adoption of a retail CBDC can risk fragmenting both payments markets and retail deposits if the retail CBDC and commercial bank money do not have common operational characteristics. In this paper, we focus on a potential UK retail CBDC, the 'digital pound', and the Bank of England's 'platform model'. We first explore how the concept of functional consistency could mitigate the risk of fragmentation. We next identify the common operational characteristics that are required to achieve functional consistency across all forms of regulated retail digital money. We identify four design options based on the provision of these common operational characteristics by the central bank, payment interface providers (PIPs), technical service providers (TSPs) or a financial market infrastructure (FMI). We next identify architecturally-significant use cases and select key capabilities that support these use cases and the common operational characteristics. We evaluate the suitability of the design options to provide these key capabilities and draw insights. We conclude that no single design option could provide functional consistency across digital pounds and commercial bank money and, instead, a complete solution would need to combine the suitable design option(s) for each key capability and include common ecosystem services provided by an FMI and TSPs.
2023.08.19.16.21.51;19.08.2023;51;04;Finance;Finance;arxiv;2308.07522;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.07522.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_V/0/1/0/all/0/1"">Victor Zitian Chen</a>";Victor Zitian Chen;Finding Stakeholder-Material Information from 10-K Reports using Fine-Tuned BERT and LSTM Models;All public companies are required by federal securities law to disclose their business and financial activities in their annual 10-K reports. Each report typically spans hundreds of pages, making it difficult for human readers to identify and extract the material information efficiently. To solve the problem, I have fine-tuned BERT models and RNN models with LSTM layers to identify stakeholder-material information, defined as statements that carry information about a company's influence on its stakeholders, including customers, employees, investors, and the community and natural environment. The existing practice uses keyword search to identify such information, which is my baseline model. Using business expert-labeled training data of nearly 6,000 sentences from 62 10-K reports published in 2022, the best model has achieved an accuracy of 0.904 and an F1 score of 0.899 in test data, significantly above the baseline model's 0.781 and 0.749 respectively. Furthermore, the same work was replicated on more granular taxonomies, based on which four distinct groups of stakeholders (i.e., customers, investors, employees, and the community and natural environment) are tested separately. Similarly, fined-tuned BERT models outperformed LSTM and the baseline. The implications for industry application and ideas for future extensions are discussed.
2023.08.19.16.21.52;19.08.2023;52;04;Finance;Finance;arxiv;2308.07935;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.07935.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Fatouros_G/0/1/0/all/0/1"">Georgios Fatouros</a>, <a href=""http://arxiv.org/find/cs/1/au:+Soldatos_J/0/1/0/all/0/1"">John Soldatos</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kouroumali_K/0/1/0/all/0/1"">Kalliopi Kouroumali</a>, <a href=""http://arxiv.org/find/cs/1/au:+Makridis_G/0/1/0/all/0/1"">Georgios Makridis</a>, <a href=""http://arxiv.org/find/cs/1/au:+Kyriazis_D/0/1/0/all/0/1"">Dimosthenis Kyriazis</a>";Georgios Fatouros,John Soldatos,Kalliopi Kouroumali,Georgios Makridis,Dimosthenis Kyriazis;Transforming Sentiment Analysis in the Financial Domain with ChatGPT;Financial sentiment analysis plays a crucial role in decoding market trends and guiding strategic trading decisions. Despite the deployment of advanced deep learning techniques and language models to refine sentiment analysis in finance, this study breaks new ground by investigating the potential of large language models, particularly ChatGPT 3.5, in financial sentiment analysis, with a strong emphasis on the foreign exchange market (forex). Employing a zero-shot prompting approach, we examine multiple ChatGPT prompts on a meticulously curated dataset of forex-related news headlines, measuring performance using metrics such as precision, recall, f1-score, and Mean Absolute Error (MAE) of the sentiment class. Additionally, we probe the correlation between predicted sentiment and market returns as an additional evaluation approach. ChatGPT, compared to FinBERT, a well-established sentiment analysis model for financial texts, exhibited approximately 35\% enhanced performance in sentiment classification and a 36\% higher correlation with market returns. By underlining the significance of prompt engineering, particularly in zero-shot contexts, this study spotlights ChatGPT's potential to substantially boost sentiment analysis in financial applications. By sharing the utilized dataset, our intention is to stimulate further research and advancements in the field of financial services.
2023.08.19.16.21.53;19.08.2023;53;05;Legal;Legal;arxiv;2308.02032;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.02032.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Westermann_H/0/1/0/all/0/1"">Hannes Westermann</a>, <a href=""http://arxiv.org/find/cs/1/au:+Benyekhlef_K/0/1/0/all/0/1"">Karim Benyekhlef</a>";Hannes Westermann,Karim Benyekhlef;JusticeBot: A Methodology for Building Augmented Intelligence Tools for Laypeople to Increase Access to Justice;Laypeople (i.e. individuals without legal training) may often have trouble resolving their legal problems. In this work, we present the JusticeBot methodology. This methodology can be used to build legal decision support tools, that support laypeople in exploring their legal rights in certain situations, using a hybrid case-based and rule-based reasoning approach. The system ask the user questions regarding their situation and provides them with legal information, references to previous similar cases and possible next steps. This information could potentially help the user resolve their issue, e.g. by settling their case or enforcing their rights in court. We present the methodology for building such tools, which consists of discovering typically applied legal rules from legislation and case law, and encoding previous cases to support the user. We also present an interface to build tools using this methodology and a case study of the first deployed JusticeBot version, focused on landlord-tenant disputes, which has been used by thousands of individuals.
2023.08.19.16.21.54;19.08.2023;54;05;Legal;Legal;worldtimebuddy;;;https://www.worldtimebuddy.com/cest-to-cet-converter>;;;https://www.schweitzer-online.de/ebook/Anesa/Digital-REvolution-Legal-Discourse/9783111048789/A65681363/;Michael Laux Dipl.-Math. Dipl.-Ing. Enterprise Attention Management Methodology Exploration & Intelligence, Innovation, AI, Semantics, Causality, Algorithmic Analytics SAP SE, Dietmar-Hopp-Allee 16, 69190 Walldorf, Germany CET < / UTC+01:00 (CEST / UTC+02:00 - from Last Su.03 to Last Su.10) T +49.6227.7.64019 <tel:+49.6227.7.64019> | F +49.6227.78.36607 <tel:+49%206227%207836607> | M +49.160.360.3157 <tel:+49%20160%203603157> E Michael.Laux@sap.com <mailto:Michael.Laux@sap.com> | S LinkedIn <http://www.linkedin.com/in/michael-laux-analytixon> | W Analytixon <http://analytixon.com/> www.sap.com <http://www.sap.com/> This Email is completely written without usage of LLMs. Pflichtangaben/Mandatory Disclosure Statement: http://www.sap.com/impressum <http://www.sap.com/impressum?> Diese E-Mail kann Betriebs- oder Geschäftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtümlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfältigung oder Weitergabe der E-Mail ausdrücklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank. This e-mail may contain trade secrets or privileged, undisclosed, or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying, or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation Please consider the impact on the environment before printing this e-mail.
2023.08.19.16.21.55;19.08.2023;55;05;Legal;Legal;arxiv;2308.05502;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.05502.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Greco_C/0/1/0/all/0/1"">Candida M. Greco</a>, <a href=""http://arxiv.org/find/cs/1/au:+Tagarelli_A/0/1/0/all/0/1"">Andrea Tagarelli</a>";Candida M. Greco,Andrea Tagarelli;Bringing order into the realm of Transformer-based language models for artificial intelligence and law;Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the state-of-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitations and opportunities for further research development.
2023.08.19.16.21.56;19.08.2023;56;07;Industry;Industry;preprints;;http://www.preprints.org/rss;https://www.preprints.org/manuscript/202308.1287/v1;Preprints.org - The Multidisciplinary Preprint Platform;Preprints.org - The Multidisciplinary Preprint Platform;Applying Stochastic Models to Analyze Vibration Features of Roller Bearings;Machinery parts gradually wear out over time due to regular usage. To improve machinery health and prevent critical issues, a reliable prognosis framework can be implemented by monitoring the behaviour of machinery parts and issuing warnings before they reach a critical state. To achieve this, vibration data from roller bearings experiencing various fault conditions have been collected. Different techniques from the literature were combined to analyze the distinct configurations in the vibration data sets and identify the main defects in roller bearings. The significant features extracted from this analysis were then used to create optimized stochastic model equations, separately regressing inner and outer race fault features to healthy bearing features under random conditions. These models can help engineers design more dependable systems, optimize their performance, and minimize the risk of failures and downtime.
2023.08.19.16.21.57;19.08.2023;57;09;Trading;Trading;arxiv;2308.07830;http://export.arxiv.org/rss/econ;http://arxiv.org/pdf/2308.07830.pdf;" <a href=""http://arxiv.org/find/econ/1/au:+Colias_J/0/1/0/all/0/1"">John V. Colias</a> (1), <a href=""http://arxiv.org/find/econ/1/au:+Park_S/0/1/0/all/0/1"">Stella Park</a> (2), <a href=""http://arxiv.org/find/econ/1/au:+Horn_E/0/1/0/all/0/1"">Elizabeth Horn</a> (1) ((1) Decision Analyst, (2) AT&amp;T)";"<a href=""http://arxiv.org/find/econ/1/au:+Colias_J/0/1/0/all/0/1"">John V. Colias</a> (1), <a href=""http://arxiv.org/find/econ/1/au:+Park_S/0/1/0/all/0/1"">Stella Park</a> (2), <a href=""http://arxiv.org/find/econ/1/au:+Horn_E/0/1/0/all/0/1"">Elizabeth Horn</a> (1) ((1) Decision Analyst, (2) AT&amp;T)";Optimizing B2B Product Offers with Machine Learning, Mixed Logit, and Nonlinear Programming;"In B2B markets, value-based pricing and selling has become an important alternative to discounting. This study outlines a modeling method that uses customer data (product offers made to each current or potential customer, features, discounts, and customer purchase decisions) to estimate a mixed logit choice model. The model is estimated via hierarchical Bayes and machine learning, delivering customer-level parameter estimates. Customer-level estimates are input into a nonlinear programming next-offer maximization problem to select optimal features and discount level for customer segments, where segments are based on loyalty and discount elasticity. The mixed logit model is integrated with economic theory (the random utility model), and it predicts both customer perceived value for and response to alternative future sales offers. The methodology can be implemented to support value-based pricing and selling efforts. Contributions to the literature include: (a) the use of customer-level parameter estimates from a mixed logit model, delivered via a hierarchical Bayes estimation procedure, to support value-based pricing decisions; (b) validation that mixed logit customer-level modeling can deliver strong predictive accuracy, not as high as random forest but comparing favorably; and (c) a nonlinear programming problem that uses customer-level mixed logit estimates to select optimal features and discounts."
2023.08.19.16.21.58;19.08.2023;58;10;Operations;Operations;arxiv;2308.07505;http://export.arxiv.org/rss/cs;http://arxiv.org/pdf/2308.07505.pdf;" <a href=""http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1"">Le Chen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1"">Xianzhong Ding</a>, <a href=""http://arxiv.org/find/cs/1/au:+Emani_M/0/1/0/all/0/1"">Murali Emani</a>, <a href=""http://arxiv.org/find/cs/1/au:+Vanderbruggen_T/0/1/0/all/0/1"">Tristan Vanderbruggen</a>, <a href=""http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1"">Pei-hung Lin</a>, <a href=""http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1"">Chuanhua Liao</a>";Le Chen,Xianzhong Ding,Murali Emani,Tristan Vanderbruggen,Pei-hung Lin,Chuanhua Liao;Data Race Detection Using Large Language Models;Large language models (LLMs) are demonstrating significant promise as an alternate strategy to facilitate analyses and optimizations of high-performance computing programs, circumventing the need for resource-intensive manual tool creation. In this paper, we explore a novel LLM-based data race detection approach combining prompting engineering and fine-tuning techniques. We create a dedicated dataset named DRB-ML, which is derived from DataRaceBench, with fine-grain labels showing the presence of data race pairs and their associated variables, line numbers, and read/write information. DRB-ML is then used to evaluate representative LLMs and fine-tune open-source ones. Our experiment shows that LLMs can be a viable approach to data race detection. However, they still cannot compete with traditional data race detection tools when we need detailed information about variable pairs causing data races.
